{"title": "Cap\u00edtulo 33 Sets grandes de datos | Introducci\u00f3n a la ciencia de datos", "author": "Rafael A Irizarry", "url": null, "hostname": null, "description": "Este libro presenta conceptos y destrezas que les ayudar\u00e1n abordar los retos de situaciones actuales del an\u00e1lisis de datos. Cubre conceptos de probabilidad, inferencia estad\u00edstica, regresi\u00f3n lineal y machine learning. Adem\u00e1s, les permitir\u00e1 desarrollar destrezas como la programaci\u00f3n R, el wrangling de datos con dplyr, la visualizaci\u00f3n de datos con ggplot2, la organizaci\u00f3n de archivos con Shell de UNIX / Linux, el control de versiones con GitHub y la preparaci\u00f3n de documentos reproducibles con R markdown.", "sitename": null, "date": "2009-09-21", "id": null, "license": null, "body": null, "comments": "", "commentsbody": null, "raw_text": null, "text": "Cap\u00edtulo 33 Sets grandes de datos\nLos problemas de machine learning a menudo implican sets de datos que son tan o m\u00e1s grandes que el set de datos MNIST. Existe una variedad de t\u00e9cnicas computacionales y conceptos estad\u00edsticos que son \u00fatiles para an\u00e1lisis de grandes sets de datos. En este cap\u00edtulo, exploramos brevemente estas t\u00e9cnicas y conceptos al describir \u00e1lgebra matricial, reducci\u00f3n de dimensiones, regularizaci\u00f3n y factorizaci\u00f3n de matrices. Utilizamos sistemas de recomendaci\u00f3n relacionados con las clasificaciones de pel\u00edculas como un ejemplo motivador.\n33.1 \u00c1lgebra matricial\nEn machine learning, las situaciones en las que todos los predictores son num\u00e9ricos, o pueden representarse como n\u00fameros son comunes. El set de datos de d\u00edgitos es un ejemplo: cada p\u00edxel registra un n\u00famero entre 0 y 255. Carguemos los datos:\nEn estos casos, a menudo es conveniente guardar los predictores en una matriz y el resultado en un vector en lugar de utilizar un data frame. Pueden ver que los predictores se guardan en una matriz:\nEsta matriz representa 60,000 d\u00edgitos, as\u00ed que para los ejemplos en este cap\u00edtulo, usaremos un subconjunto m\u00e1s manejable. Tomaremos los primeros 1,000 predictores\nx y etiquetas\ny:\nLa raz\u00f3n principal para usar matrices es que ciertas operaciones matem\u00e1ticas necesarias para desarrollar c\u00f3digo eficiente se pueden realizar usando t\u00e9cnicas de una rama de las matem\u00e1ticas llamada \u00e1lgebra lineal. De hecho, \u00e1lgebra lineal y notaci\u00f3n matricial son elementos claves del lenguaje utilizado en trabajos acad\u00e9micos que describen t\u00e9cnicas de machine learning. No cubriremos \u00e1lgebra lineal en detalle aqu\u00ed, pero demostraremos c\u00f3mo usar matrices en R para que puedan aplicar las t\u00e9cnicas de \u00e1lgebra lineal ya implementadas en la base R u otros paquetes.\nPara motivar el uso de matrices, plantearemos cinco preguntas/desaf\u00edos:\n1. \u00bfAlgunos d\u00edgitos requieren m\u00e1s tinta que otros? Estudien la distribuci\u00f3n de la oscuridad total de p\u00edxeles y c\u00f3mo var\u00eda seg\u00fan los d\u00edgitos.\n2. \u00bfAlgunos p\u00edxeles no son informativos? Estudien la variaci\u00f3n de cada p\u00edxel y eliminen los predictores (columnas) asociados con los p\u00edxeles que no cambian mucho y, por lo tanto, no proveen mucha informaci\u00f3n para la clasificaci\u00f3n.\n3. \u00bfPodemos eliminar las manchas? Primero, observen la distribuci\u00f3n de todos los valores de p\u00edxeles. Usen esto para elegir un umbral para definir el espacio no escrito. Luego, cambien cualquier valor por debajo de ese umbral a 0.\n4. Binaricen los datos. Primero, observen la distribuci\u00f3n de todos los valores de p\u00edxeles. Usen esto para elegir un umbral para distinguir entre escritura y no escritura. Luego, conviertan todas las entradas en 1 o 0, respectivamente.\n5. Escalen cada uno de los predictores en cada entrada para tener el mismo promedio y desviaci\u00f3n est\u00e1ndar.\nPara completar esto, tendremos que realizar operaciones matem\u00e1ticas que involucran varias variables. El tidyverse no est\u00e1 desarrollado para realizar este tipo de operaciones matem\u00e1ticas. Para esta tarea, es conveniente usar matrices.\nAntes de hacer esto, presentaremos la notaci\u00f3n matricial y el c\u00f3digo R b\u00e1sico para definir y operar en matrices.\n33.1.1 Notaci\u00f3n\nEn \u00e1lgebra matricial, tenemos tres tipos principales de objetos: escalares, vectores y matrices. Un escalar es solo un n\u00famero, por ejemplo \\(a = 1\\). Para denotar escalares en notaci\u00f3n matricial, generalmente usamos una letra min\u00fascula no en negrilla.\nLos vectores son como los vectores num\u00e9ricos que definimos en R: incluyen varias entradas escalares. Por ejemplo, la columna que contiene el primer p\u00edxel:\ntiene 1,000 entradas. En \u00e1lgebra matricial, utilizamos la siguiente notaci\u00f3n para un vector que representa un atributo/predictor:\n\\[ \\begin{pmatrix} x_1\\\\\\ x_2\\\\\\ \\vdots\\\\\\ x_N \\end{pmatrix} \\]\nDel mismo modo, podemos usar la notaci\u00f3n matem\u00e1tica para representar diferentes atributos matem\u00e1ticamente agregando un \u00edndice:\n\\[ \\mathbf{X}_1 = \\begin{pmatrix} x_{1,1}\\\\ \\vdots\\\\ x_{N,1} \\end{pmatrix} \\mbox{ and } \\mathbf{X}_2 = \\begin{pmatrix} x_{1,2}\\\\ \\vdots\\\\ x_{N,2} \\end{pmatrix} \\]\nSi estamos escribiendo una columna, como \\(\\mathbf{X}_1\\), en una oraci\u00f3n, a menudo usamos la notaci\u00f3n: \\(\\mathbf{X}_1 = ( x_{1,1}, \\dots x_{N,1})^\\top\\) con \\(^\\top\\) la operaci\u00f3n de transposici\u00f3n que convierte las columnas en filas y las filas en columnas.\nUna matriz se puede definir como una serie de vectores del mismo tama\u00f1o unidos como columnas:\n[x_1 <- 1:5] [x_2 <- 6:10] [cbind(x_1, x_2)] [#> x_1 x_2] [#> [1,] 1 6] [#> [2,] 2 7] [#> [3,] 3 8] [#> [4,] 4 9] [#> [5,] 5 10]\nMatem\u00e1ticamente, los representamos con letras may\u00fasculas en negrilla:\n\\[ \\mathbf{X} = [ \\mathbf{X}_1 \\mathbf{X}_2 ] = \\begin{pmatrix} x_{1,1}&x_{1,2}\\\\ \\vdots\\\\ x_{N,1}&x_{N,2} \\end{pmatrix} \\]\nLa dimensi\u00f3n de una matriz a menudo es un atributo importante necesario para asegurar que se puedan realizar ciertas operaciones. La dimensi\u00f3n es un resumen de dos n\u00fameros definido como el n\u00famero de filas \\(\\times\\) el n\u00famero de columnas. En R, podemos extraer la dimensi\u00f3n de una matriz con la funci\u00f3n\ndim:\nLos vectores pueden considerarse \\(N\\times 1\\) matrices. Sin embargo, en R, un vector no tiene dimensiones:\nNo obstante, expl\u00edcitamente convertimos un vector en una matriz usando la funci\u00f3n\nas.matrix:\nPodemos usar esta notaci\u00f3n para denotar un n\u00famero arbitrario de predictores con la siguiente matriz \\(N\\times p\\), por ejemplo, con \\(p=784\\):\n\\[ \\mathbf{X} = \\begin{pmatrix} x_{1,1}&\\dots & x_{1,p} \\\\ x_{2,1}&\\dots & x_{2,p} \\\\ & \\vdots & \\\\ x_{N,1}&\\dots & x_{N,p} \\end{pmatrix} \\]\nAlmacenamos esta matriz en x:\nAhora aprenderemos varias operaciones \u00fatiles relacionadas con el \u00e1lgebra matricial. Utilizamos tres de las preguntas motivadoras mencionadas anteriormente.\n33.1.2 Convertir un vector en una matriz\nA menudo es \u00fatil convertir un vector en una matriz. Por ejemplo, debido a que las variables son p\u00edxeles en una cuadr\u00edcula, podemos convertir las filas de intensidades de p\u00edxeles en una matriz que representa esta cuadr\u00edcula.\nPodemos convertir un vector en una matriz con la funci\u00f3n\nmatrix y especificando el n\u00famero de filas y columnas que debe tener la matriz resultante. La matriz se llena por columna: la primera columna se llena primero, luego la segunda y as\u00ed sucesivamente. Este ejemplo ayuda a ilustrar:\n[my_vector <- 1:15] [mat <- matrix(my_vector, 5, 3)] [mat] [#> [,1] [,2] [,3]] [#> [1,] 1 6 11] [#> [2,] 2 7 12] [#> [3,] 3 8 13] [#> [4,] 4 9 14] [#> [5,] 5 10 15]\nPodemos llenar por fila usando el argumento\nbyrow. Entonces, por ejemplo, para transponer la matriz\nmat, podemos usar:\n[mat_t <- matrix(my_vector, 3, 5, byrow = TRUE)] [mat_t] [#> [,1] [,2] [,3] [,4] [,5]] [#> [1,] 1 2 3 4 5] [#> [2,] 6 7 8 9 10] [#> [3,] 11 12 13 14 15]\nCuando convertimos las columnas en filas, nos referimos a las operaciones como transponer la matriz. La funci\u00f3n\nt se puede usar para transponer directamente una matriz:\nAdvertencia: La funci\u00f3n\nmatrix recicla valores en el vector sin advertencia si el producto de las columnas y las filas no coincide con la longitud del vector:\n[matrix(my_vector, 4, 5)] [#> Warning in matrix(my_vector, 4, 5): la longitud de los datos [15] no es] [#> un subm\u00faltiplo o m\u00faltiplo del n\u00famero de filas [4] en la matriz] [#> [,1] [,2] [,3] [,4] [,5]] [#> [1,] 1 5 9 13 2] [#> [2,] 2 6 10 14 3] [#> [3,] 3 7 11 15 4] [#> [4,] 4 8 12 1 5]\nPara poner las intensidades de p\u00edxeles de nuestra, digamos, tercera entrada, que es 4 en la cuadr\u00edcula, podemos usar:\nPara confirmar que lo hemos hecho correctamente, podemos usar la funci\u00f3n\nimage, que muestra una imagen de su tercer argumento. La parte superior de este gr\u00e1fico es el p\u00edxel 1, que se muestra en la parte inferior para que la imagen se voltee. A continuaci\u00f3n incluimos el c\u00f3digo que muestra c\u00f3mo voltearlo:\n33.1.3 Res\u00famenes de filas y columnas\nPara la primera tarea, relacionada con la oscuridad total de p\u00edxeles, queremos sumar los valores de cada fila y luego visualizar c\u00f3mo estos valores var\u00edan por d\u00edgito.\nLa funci\u00f3n\nrowSums toma una matriz como entrada y calcula los valores deseados:\nTambi\u00e9n podemos calcular los promedios con\nrowMeans si queremos que los valores permanezcan entre 0 y 255:\nUna vez que tengamos esto, podemos generar un diagrama de caja:\n[tibble(labels = as.factor(y), row_averages = avg) |>] [qplot(labels, row_averages, data = _, geom = \"boxplot\")]\nDe este gr\u00e1fico vemos que, como era de esperar, los 1s usan menos tinta que los otros d\u00edgitos.\nPodemos calcular las sumas y los promedios de la columna usando la funci\u00f3n\ncolSums y\ncolMeans, respectivamente.\nEl paquete matrixStats agrega funciones que realizan operaciones en cada fila o columna de manera muy eficiente, incluyendo las funciones\nrowSds y\ncolSds.\n33.1.4\napply\nLas funciones que acabamos de describir est\u00e1n realizando una operaci\u00f3n similar a la que hacen\nsapply y la funci\u00f3n\nmap de purrr: aplicar la misma funci\u00f3n a una parte de su objeto. En este caso, la funci\u00f3n se aplica a cada fila o cada columna. La funci\u00f3n\napply les permite aplicar cualquier funci\u00f3n, no solo\nsum o\nmean, a una matriz. El primer argumento es la matriz, el segundo es la dimensi\u00f3n (1 para las filas y 2 para las columnas) y el tercero es la funci\u00f3n. As\u00ed, por ejemplo,\nrowMeans se puede escribir como:\nPero noten que al igual que con\nsapply y\nmap, podemos ejecutar cualquier funci\u00f3n. Entonces, si quisi\u00e9ramos la desviaci\u00f3n est\u00e1ndar para cada columna, podr\u00edamos escribir:\nLa desventaja de esta flexibilidad es que estas operaciones no son tan r\u00e1pidas como las funciones dedicadas, como\nrowMeans.\n33.1.5 Filtrar columnas basado en res\u00famenes\nAhora pasamos a la tarea 2: estudiar la variaci\u00f3n de cada p\u00edxel y eliminar las columnas asociadas con p\u00edxeles que no cambian mucho y, por lo tanto, no informan la clasificaci\u00f3n. Aunque es un enfoque simplista, cuantificaremos la variaci\u00f3n de cada p\u00edxel con su desviaci\u00f3n est\u00e1ndar en todas las entradas. Como cada columna representa un p\u00edxel, utilizamos la funci\u00f3n\ncolSds del paquete matrixStats:\nUn vistazo r\u00e1pido a la distribuci\u00f3n de estos valores muestra que algunos p\u00edxeles tienen una variabilidad muy baja de entrada a entrada:\nEsto tiene sentido ya que no escribimos en algunas partes del cuadro. Aqu\u00ed est\u00e1 la variaci\u00f3n graficada por ubicaci\u00f3n:\nVemos que hay poca variaci\u00f3n en las esquinas.\nPodr\u00edamos eliminar atributos que no tienen variaci\u00f3n ya que estos no nos ayuda a predecir. En la Secci\u00f3n\n[2.4.7](r-basics.html#matrices), describimos las operaciones utilizadas para extraer columnas:\ny para extraer filas:\nAdem\u00e1s, podemos usar \u00edndices l\u00f3gicos para determinar qu\u00e9 columnas o filas mantener. Entonces, si quisi\u00e9ramos eliminar predictores no informativos de nuestra matriz, podr\u00edamos escribir esta l\u00ednea de c\u00f3digo:\nSolo se mantienen las columnas para las que la desviaci\u00f3n est\u00e1ndar es superior a 60, lo que elimina m\u00e1s de la mitad de los predictores.\nAqu\u00ed agregamos una advertencia importante relacionada con el subconjunto de matrices: si seleccionan una columna o una fila, el resultado ya no es una matriz sino un vector.\nSin embargo, podemos preservar la clase de matriz usando el argumento\ndrop=FALSE:\n33.1.6 Indexaci\u00f3n con matrices\nPodemos hacer r\u00e1pidamente un histograma de todos los valores en nuestro set de datos. Vimos c\u00f3mo podemos convertir vectores en matrices. Tambi\u00e9n podemos deshacer esto y convertir matrices en vectores. La operaci\u00f3n se realiza por fila:\nPara ver un histograma de todos nuestros datos predictores, podemos usar:\nNotamos una clara dicotom\u00eda que se explica como partes de la imagen con tinta y partes sin ella. Si creemos que los valores menor que, digamos, 50 son manchas, podemos cambiarlos a cero usando:\nPara ver un ejemplo de c\u00f3mo esto ocurre, usamos una matriz m\u00e1s peque\u00f1a:\n[mat <- matrix(1:15, 5, 3)] [mat[mat < 3] <- 0] [mat] [#> [,1] [,2] [,3]] [#> [1,] 0 6 11] [#> [2,] 0 7 12] [#> [3,] 3 8 13] [#> [4,] 4 9 14] [#> [5,] 5 10 15]\nTambi\u00e9n podemos usar operadores l\u00f3gicas con una matriz de valores logicos:\n33.1.7 Binarizar los datos\nEl histograma anterior parece sugerir que estos datos son principalmente binarios. Un p\u00edxel tiene tinta o no. Usando lo que hemos aprendido, podemos binarizar los datos usando solo operaciones de matrices:\nTambi\u00e9n podemos convertir a una matriz de valores l\u00f3gicos y luego forzar una conversi\u00f3n a n\u00fameros como este:\n33.1.8 Vectorizaci\u00f3n para matrices\nEn R, si restamos un vector de una matriz, el primer elemento del vector se resta de la primera fila, el segundo elemento de la segunda fila, y as\u00ed sucesivamente. Usando notaci\u00f3n matem\u00e1tica, lo escribir\u00edamos de la siguiente manera:\n\\[ \\begin{pmatrix} X_{1,1}&\\dots & X_{1,p} \\\\ X_{2,1}&\\dots & X_{2,p} \\\\ & \\vdots & \\\\ X_{N,1}&\\dots & X_{N,p} \\end{pmatrix} - \\begin{pmatrix} a_1\\\\\\ a_2\\\\\\ \\vdots\\\\\\ a_N \\end{pmatrix} = \\begin{pmatrix} X_{1,1}-a_1&\\dots & X_{1,p} -a_1\\\\ X_{2,1}-a_2&\\dots & X_{2,p} -a_2\\\\ & \\vdots & \\\\ X_{N,1}-a_n&\\dots & X_{N,p} -a_n \\end{pmatrix} \\]\nLo mismo es v\u00e1lido para otras operaciones aritm\u00e9ticas. Esto implica que podemos escalar cada fila de una matriz as\u00ed:\nSi desean escalar cada columna, tengan cuidado ya que este enfoque no funciona para las columnas. Para realizar una operaci\u00f3n similar, convertimos las columnas en filas usando la transposici\u00f3n\nt, procedemos como se indica arriba y volvemos a transponer:\nTambi\u00e9n podemos usar la funci\u00f3n\nsweep que funciona de manera similar a\napply. Toma cada entrada de un vector y la resta de la fila o columna correspondiente.\nLa funci\u00f3n\nsweep tiene otro argumento que les permite definir la operaci\u00f3n aritm\u00e9tica. Entonces, para dividir por la desviaci\u00f3n est\u00e1ndar, hacemos lo siguiente:\n33.1.9 Operaciones de \u00e1lgebra matricial\nFinalmente, aunque no discutimos las operaciones de \u00e1lgebra matricial, como la multiplicaci\u00f3n de matrices, compartimos aqu\u00ed los comandos relevantes para aquellos que conocen las matem\u00e1ticas y quieren aprender el c\u00f3digo:\n1. La multiplicaci\u00f3n de matrices se realiza con\n%*%. Por ejemplo, el producto cruzado es:\n2. Podemos calcular el producto cruzado directamente con la funci\u00f3n:\n3. Para calcular el inverso de una funci\u00f3n, usamos\nsolve. Aqu\u00ed se aplica al producto cruzado:\n4. La descomposici\u00f3n QR est\u00e1 f\u00e1cilmente disponible mediante el uso de la funci\u00f3n\nqr:\n33.2 Ejercicios\n1. Cree una matriz de 100 por 10 de n\u00fameros normales generados aleatoriamente. Ponga el resultado en\nx.\n2. Aplique las tres funciones de R que le dan la dimensi\u00f3n de\nx, el n\u00famero de filas de\nx y el n\u00famero de columnas de\nx, respectivamente.\n3. Agregue el escalar 1 a la fila 1, el escalar 2 a la fila 2 y as\u00ed sucesivamente, a la matriz\nx.\n4. Agregue el escalar 1 a la columna 1, el escalar 2 a la columna 2 y as\u00ed sucesivamente, a la matriz\nx. Sugerencia: use\nsweep con\nFUN = \"+\".\n5. Calcule el promedio de cada fila de\nx.\n6. Calcule el promedio de cada columna de\nx.\n7. Para cada d\u00edgito en los datos de entrenamiento MNIST, calcule la proporci\u00f3n de p\u00edxeles que se encuentran en un \u00e1rea gris, definida como valores entre 50 y 205. Haga un diagrama de caja basado en clase de d\u00edgitos. Sugerencia: utilice operadores l\u00f3gicos y\nrowMeans.\n33.3 Distancia\nMuchos de los an\u00e1lisis que realizamos con datos de alta dimensi\u00f3n se relacionan directa o indirectamente con la distancia. La mayor\u00eda de las t\u00e9cnicas de agrupamiento y machine learning se basan en la capacidad de definir la distancia entre observaciones, utilizando atributos (features en ingl\u00e9s) o predictores.\n33.3.1 Distancia euclidiana\nComo repaso, definamos la distancia entre dos puntos, \\(A\\) y \\(B\\), en un plano cartesiano.\nLa distancia euclidiana entre \\(A\\) y \\(B\\) es simplemente:\n\\[ \\mbox{dist}(A,B) = \\sqrt{ (A_x-B_x)^2 + (A_y-B_y)^2} \\]\nEsta definici\u00f3n se aplica al caso de una dimensi\u00f3n, en la que la distancia entre dos n\u00fameros es el valor absoluto de su diferencia. Entonces, si nuestros dos n\u00fameros unidimensionales son \\(A\\) y \\(B\\), la distancia es:\n\\[ \\mbox{dist}(A,B) = \\sqrt{ (A - B)^2 } = | A - B | \\]\n33.3.2 Distancia en dimensiones superiores\nAnteriormente presentamos un set de datos de entrenamiento con matriz para 784 atributos. Con fines ilustrativos, veremos una muestra aleatoria de 2s y 7s.\n[library(tidyverse)] [library(dslabs)] [if(!exists(\"mnist\")) mnist <- read_mnist()] [set.seed(1995)] [ind <- which(mnist$train$labels %in% c(2,7)) |> sample(500)] [x <- mnist$train$images[ind,]] [y <- mnist$train$labels[ind]]\nLos predictores est\u00e1n en\nx y las etiquetas en\ny.\nPara el prop\u00f3sito de, por ejemplo, suavizamiento, estamos interesados en describir la distancia entre observaciones; en este caso, d\u00edgitos. M\u00e1s adelante, con el fin de seleccionar atributos, tambi\u00e9n podr\u00edamos estar interesados en encontrar p\u00edxeles que se comporten de manera similar en todas las muestras.\nPara definir la distancia, necesitamos saber qu\u00e9 son puntos, ya que la distancia matem\u00e1tica se calcula entre puntos. Con datos de alta dimensi\u00f3n, los puntos ya no est\u00e1n en el plano cartesiano. En cambio, los puntos est\u00e1n en dimensiones m\u00e1s altas. Ya no podemos visualizarlos y necesitamos pensar de manera abstracta. Por ejemplo, predictores \\(\\mathbf{X}_i\\) se definen como un punto en el espacio dimensional 784: \\(\\mathbf{X}_i = (x_{i,1},\\dots,x_{i,784})^\\top\\).\nUna vez que definamos los puntos de esta manera, la distancia euclidiana se define de manera muy similar a la de dos dimensiones. Por ejemplo, la distancia entre los predictores para dos observaciones, digamos observaciones \\(i=1\\) y \\(i=2\\), es:\n\\[ \\mbox{dist}(1,2) = \\sqrt{ \\sum_{j=1}^{784} (x_{1,j}-x_{2,j })^2 } \\]\nEste es solo un n\u00famero no negativo, tal como lo es para dos dimensiones.\n33.3.3 Ejemplo de distancia euclidiana\nLas etiquetas para las tres primeras observaciones son:\nLos vectores de predictores para cada una de estas observaciones son:\nEl primer y tercer n\u00famero son 7s y el segundo es un 2. Esperamos que las distancias entre el mismo n\u00famero:\nsean m\u00e1s peque\u00f1as que entre diferentes n\u00fameros:\nComo se esperaba, los 7s est\u00e1n m\u00e1s cerca uno del otro.\nUna forma m\u00e1s r\u00e1pida de calcular esto es usar \u00e1lgebra matricial:\n[sqrt(crossprod(x_1 - x_2))] [#> [,1]] [#> [1,] 3273] [sqrt(crossprod(x_1 - x_3))] [#> [,1]] [#> [1,] 2311] [sqrt(crossprod(x_2 - x_3))] [#> [,1]] [#> [1,] 2636]\nTambi\u00e9n podemos calcular todas las distancias a la vez de manera relativamente r\u00e1pida utilizando la funci\u00f3n\ndist, que calcula la distancia entre cada fila y produce un objeto de clase\ndist:\nHay varias funciones relacionadas con machine learning en R que toman objetos de clase\ndist como entrada. Para acceder a las entradas usando \u00edndices de fila y columna, necesitamos forzar\nd a ser una matriz. Podemos ver la distancia que calculamos arriba de esta manera:\nR\u00e1pidamente vemos una imagen de estas distancias usando este c\u00f3digo:\nSi ordenamos esta distancia por las etiquetas, podemos ver que, en general, los 2s est\u00e1n m\u00e1s cerca uno del otro y los 7s est\u00e1n m\u00e1s cerca el uno del otro:\nAlgo que notamos aqu\u00ed es que parece haber m\u00e1s uniformidad en la forma en que se dibujan los 7s, ya que parecen estar m\u00e1s cercas (m\u00e1s rojos) a otros 7s que los 2s a otros 2s.\n33.3.4 Espacio predictor\nEl espacio predictor (predictor space en ingl\u00e9s) es un concepto que a menudo se usa para describir algoritmos de machine learning. El t\u00e9rmino espacio se refiere a una definici\u00f3n matem\u00e1tica que no describimos en detalle aqu\u00ed. En cambio, ofrecemos una explicaci\u00f3n simplificada para ayudar a entender el t\u00e9rmino espacio predictor cuando se usa en el contexto de algoritmos de machine learning.\nEl espacio predictor puede considerarse como la colecci\u00f3n de todos los posibles vectores de predictores que deben considerarse para el reto en cuesti\u00f3n de machine learning. Cada miembro del espacio se conoce como un punto. Por ejemplo, en el set de datos 2 o 7, el espacio predictor consta de todos los pares \\((x_1, x_2)\\) tal que ambos \\(x_1\\) y \\(x_2\\) est\u00e1n dentro de 0 y 1. Este espacio en particular puede representarse gr\u00e1ficamente como un cuadrado. En el set de datos MNIST, el espacio predictor consta de todos los vectores de 784 dimensiones, con cada elemento vectorial un n\u00famero entero entre 0 y 256. Un elemento esencial de un espacio predictor es que necesitamos definir una funci\u00f3n que nos de la distancia entre dos puntos. En la mayor\u00eda de los casos, usamos la distancia euclidiana, pero hay otras posibilidades. Un caso particular en el que no podemos simplemente usar la distancia euclidiana es cuando tenemos predictores categ\u00f3ricos.\nDefinir un espacio predictor es \u00fatil en machine learning porque hacemos cosas como definir vecindarios de puntos, como lo requieren muchas t\u00e9cnicas de suavizaci\u00f3n. Por ejemplo, podemos definir un vecindario como todos los puntos que est\u00e1n dentro de 2 unidades de un centro predefinido. Si los puntos son bidimensionales y usamos la distancia euclidiana, este vecindario se representa gr\u00e1ficamente como un c\u00edrculo con radio 2. En tres dimensiones, el vecindario es una esfera. Pronto aprenderemos sobre algoritmos que dividen el espacio en regiones que no se superponen y luego hacen diferentes predicciones para cada regi\u00f3n utilizando los datos de la regi\u00f3n.\n33.3.5 Distancia entre predictores\nTambi\u00e9n podemos calcular distancias entre predictores. Si \\(N\\) es el n\u00famero de observaciones, la distancia entre dos predictores, digamos 1 y 2, es:\n\\[ \\mbox{dist}(1,2) = \\sqrt{ \\sum_{i=1}^{N} (x_{i,1}-x_{i,2})^2 } \\]\nPara calcular la distancia entre todos los pares de los 784 predictores, primero podemos transponer la matriz y luego usar\ndist:\n33.4 Ejercicios\n1. Cargue el siguiente set de datos:\nEste set de datos incluye una matriz\nx:\ncon la expresi\u00f3n g\u00e9nica medida en 500 genes para 189 muestras biol\u00f3gicas que representan siete tejidos diferentes. El tipo de tejido se almacena en\ny:\nCalcule la distancia entre cada observaci\u00f3n y almac\u00e9nela en un objeto\nd.\n2. Compare la distancia entre las dos primeras observaciones (ambos cerebelos), las observaciones 39 y 40 (ambos colones) y las observaciones 73 y 74 (ambos endometrios). Vea si las observaciones del mismo tipo de tejido est\u00e1n m\u00e1s cercanas entre s\u00ed.\n3. Vemos que, de hecho, las observaciones del mismo tipo de tejido est\u00e1n m\u00e1s cercanas entre s\u00ed en los seis ejemplos de tejido que acabamos de examinar. Haga un diagrama de todas las distancias usando la funci\u00f3n\nimage para ver si este patr\u00f3n es general. Sugerencia: primero convierta\nd en una matriz.\n33.5 Reducci\u00f3n de dimensiones\nUn reto t\u00edpico de machine learning incluir\u00e1 una gran cantidad de predictores, lo que hace que la visualizaci\u00f3n sea algo retante. Hemos mostrado m\u00e9todos para visualizar datos univariados y emparejados, pero los gr\u00e1ficos que revelan relaciones entre muchas variables son m\u00e1s complicados en dimensiones m\u00e1s altas. Por ejemplo, para comparar cada uno de las 784 atributos en nuestro ejemplo de predicci\u00f3n de d\u00edgitos, tendr\u00edamos que crear, por ejemplo, 306,936 diagramas de dispersi\u00f3n. La creaci\u00f3n de un \u00fanico diagrama de dispersi\u00f3n de los datos es imposible debido a la alta dimensionalidad.\nAqu\u00ed describimos t\u00e9cnicas eficaces y \u00fatiles para el an\u00e1lisis exploratorio de datos, entre otras cosas, generalmente conocidas como reducci\u00f3n de dimensiones. La idea general es reducir la dimensi\u00f3n del set de datos mientras se conservan caracter\u00edsticas importantes, como la distancia entre atributos u observaciones. Con menos dimensiones, la visualizaci\u00f3n es m\u00e1s factible. La t\u00e9cnica detr\u00e1s de todo, la descomposici\u00f3n de valores singulares, tambi\u00e9n es \u00fatil en otros contextos. El an\u00e1lisis de componentes principales (principal component analysis o PCA por sus siglas en ingl\u00e9s) es el enfoque que mostraremos. Antes de aplicar PCA a sets de datos de alta dimensi\u00f3n, motivaremos las ideas con un ejemplo sencillo.\n33.5.1 Preservando la distancia\nConsideremos un ejemplo con alturas de gemelos. Algunas parejas son adultas, otras son ni\u00f1os. Aqu\u00ed simulamos 100 puntos bidimensionales que representan el n\u00famero de desviaciones est\u00e1ndar que cada individuo tiene respecto a la altura media. Cada punto es un par de gemelos. Utilizamos la funci\u00f3n\nmvrnorm del paquete MASS para simular datos de distribuci\u00f3n normal de dos variables.\n[set.seed(1988)] [library(MASS)] [n <- 100] [Sigma <- matrix(c(9, 9 * 0.9, 9 * 0.92, 9 * 1), 2, 2)] [x <- rbind(mvrnorm(n/ 2, c(69, 69), Sigma),] [mvrnorm(n/ 2, c(55, 55), Sigma))]\nUn diagrama de dispersi\u00f3n revela que la correlaci\u00f3n es alta y que hay dos grupos de gemelos, los adultos (puntos superiores derechos) y los ni\u00f1os (puntos inferiores izquierdos):\nNuestros atributos son \\(N\\) puntos bidimensionales, las dos alturas y, con fines ilustrativos, finjiremos como si visualizar dos dimensiones es demasiado dif\u00edcil. Por lo tanto, queremos reducir las dimensiones de dos a una, pero todav\u00eda poder entender atributos importantes de los datos, por ejemplo, que las observaciones se agrupan en dos grupos: adultos y ni\u00f1os.\nConsideremos un desaf\u00edo espec\u00edfico: queremos un resumen unidimensional de nuestros predictores a partir del cual podamos aproximar la distancia entre dos observaciones. En el gr\u00e1fico anterior, mostramos la distancia entre la observaci\u00f3n 1 y 2 (azul) y la observaci\u00f3n 1 y 51 (rojo). Noten que la l\u00ednea azul es m\u00e1s corta, que implica que 1 y 2 est\u00e1n m\u00e1s cerca.\nPodemos calcular estas distancias usando\ndist:\nEsta distancia se basa en dos dimensiones y necesitamos una aproximaci\u00f3n de distancia basada en solo una.\nComencemos con un enfoque simplista de solo eliminar una de las dos dimensiones. Comparemos las distancias reales con la distancia calculada solo con la primera dimensi\u00f3n:\nAqu\u00ed est\u00e1n las distancias aproximadas versus las distancias originales:\nEl gr\u00e1fico se ve casi igual si usamos la segunda dimensi\u00f3n. Obtenemos una subestimaci\u00f3n general. Esto no sorprende porque estamos a\u00f1adiendo m\u00e1s cantidades positivas al c\u00e1lculo de la distancia a medida que aumentamos el n\u00famero de dimensiones. Si, en cambio, usamos un promedio, como este:\n\\[\\sqrt{ \\frac{1}{2} \\sum_{j=1}^2 (X_{1,j}-X_{2,j})^2 },\\]\nentonces la subestimaci\u00f3n desaparece. Dividimos la distancia por \\(\\sqrt{2}\\) para lograr la correcci\u00f3n.\nEsto funciona bastante bien y obtenemos una diferencia t\u00edpica de:\nAhora, \u00bfpodemos elegir un resumen unidimensional que haga que esta aproximaci\u00f3n sea a\u00fan mejor?\nSi consideramos el diagrama de dispersi\u00f3n anterior y visualizamos una l\u00ednea entre cualquier par de puntos, la longitud de esta l\u00ednea es la distancia entre los dos puntos. Estas l\u00edneas tienden a ir a lo largo de la direcci\u00f3n de la diagonal. Noten que si en su lugar graficamos la diferencia versus el promedio:\npodemos ver c\u00f3mo la distancia entre puntos se explica principalmente por la primera dimensi\u00f3n: el promedio.\nEsto significa que podemos ignorar la segunda dimensi\u00f3n y no perder demasiada informaci\u00f3n. Si la l\u00ednea es completamente plana, no perdemos ninguna informaci\u00f3n. Usando la primera dimensi\u00f3n de esta matriz transformada, obtenemos una aproximaci\u00f3n a\u00fan mejor:\ncon la diferencia t\u00edpica mejorada aproximadamente un 35%:\nM\u00e1s tarde, aprendemos que\nz[,1] es el primer componente principal de la matriz\nx.\n33.5.2 Transformaciones lineales (avanzado)\nTengan en cuenta que cada fila de \\(X\\) se transform\u00f3 usando una transformaci\u00f3n lineal. Para cualquier fila \\(i\\), la primera entrada fue:\n\\[Z_{i,1} = a_{1,1} X_{i,1} + a_{2,1} X_{i,2}\\]\ncon \\(a_{1,1} = 0.5\\) y \\(a_{2,1} = 0.5\\).\nLa segunda entrada tambi\u00e9n fue una transformaci\u00f3n lineal:\n\\[Z_{i,2} = a_{1,2} X_{i,1} + a_{2,2} X_{i,2}\\]\ncon \\(a_{1,2} = 1\\) y \\(a_{2,2} = -1\\).\nAdem\u00e1s, podemos usar la transformaci\u00f3n lineal para obtener \\(X\\) de \\(Z\\):\n\\[X_{i,1} = b_{1,1} Z_{i,1} + b_{2,1} Z_{i,2}\\]\ncon \\(b_{1,2} = 1\\) y \\(b_{2,1} = 0.5\\) y\n\\[X_{i,2} = b_{2,1} Z_{i,1} + b_{2,2} Z_{i,2}\\]\ncon \\(b_{2,1} = 1\\) y \\(a_{1,2} = -0.5\\).\nSi saben \u00e1lgebra lineal, pueden escribir la operaci\u00f3n que acabamos de realizar de esta manera:\n\\[ Z = X A \\mbox{ with } A = \\, \\begin{pmatrix} 1/2&1\\\\ 1/2&-1\\\\ \\end{pmatrix}. \\]\nY que podemos transformar de vuelta a \\(X\\) multiplicando por \\(A^{-1}\\) as\u00ed:\n\\[ X = Z A^{-1} \\mbox{ with } A^{-1} = \\, \\begin{pmatrix} 1&1\\\\ 1/2&-1/2\\\\ \\end{pmatrix}. \\]\nLa reducci\u00f3n de dimensiones frecuentemente se puede describir como la aplicaci\u00f3n de una transformaci\u00f3n \\(A\\) a una matriz \\(X\\) con muchas columnas que mueven la informaci\u00f3n contenida en \\(X\\) a las primeras columnas de \\(Z=AX\\), manteniendo solo estas pocas columnas informativas y reduciendo as\u00ed la dimensi\u00f3n de los vectores contenidos en las filas.\n33.5.3 Transformaciones ortogonales (avanzado)\nNoten que dividimos lo anterior por \\(\\sqrt{2}\\) para tomar en cuenta las diferencias en las dimensiones al comparar una distancia de 2 dimensiones con una distancia de 1 dimensi\u00f3n. De hecho, podemos garantizar que las escalas de distancia sigan siendo las mismas si volvemos a escalar las columnas de \\(A\\) para asegurar que la suma de cuadrados es 1:\n\\[a_{1,1}^2 + a_{2,1}^2 = 1\\mbox{ and } a_{1,2}^2 + a_{2,2}^2=1,\\]\ny que la correlaci\u00f3n de las columnas es 0:\n\\[ a_{1,1} a_{1,2} + a_{2,1} a_{2,2} = 0. \\]\nRecuerden que si las columnas est\u00e1n centradas para tener un promedio de 0, entonces la suma de los cuadrados es equivalente a la varianza o desviaci\u00f3n est\u00e1ndar al cuadrado.\nEn nuestro ejemplo, para lograr ortogonalidad, multiplicamos el primer set de coeficientes (primera columna de \\(A\\)) por \\(\\sqrt{2}\\) y el segundo por \\(1/\\sqrt{2}\\). Entonces obtenemos la misma distancia exacta cuando usamos ambas dimensiones:\nEsto nos da una transformaci\u00f3n que preserva la distancia entre dos puntos:\ny una aproximaci\u00f3n mejorada si usamos solo la primera dimensi\u00f3n:\nEn este caso, \\(Z\\) se llama una rotaci\u00f3n ortogonal de \\(X\\): conserva las distancias entre filas.\nTengan en cuenta que al usar la transformaci\u00f3n anterior, podemos resumir la distancia entre cualquier par de gemelos con una sola dimensi\u00f3n. Por ejemplo, una exploraci\u00f3n de datos unidimensionales de la primera dimensi\u00f3n de \\(Z\\) muestra claramente que hay dos grupos, adultos y ni\u00f1os:\nRedujimos exitosamente el n\u00famero de dimensiones de dos a uno con muy poca p\u00e9rdida de informaci\u00f3n.\nLa raz\u00f3n por la que pudimos hacer esto es porque las columnas de \\(X\\) estaban muy correlacionadas:\ny la transformaci\u00f3n produjo columnas no correlacionadas con informaci\u00f3n \u201cindependiente\u201d en cada columna:\nUna forma en que esta informaci\u00f3n puede ser \u00fatil en una aplicaci\u00f3n de machine learning es que podemos reducir la complejidad de un modelo utilizando solo \\(Z_1\\) en lugar de ambos \\(X_1\\) y \\(X_2\\).\nEs com\u00fan obtener datos con varios predictores altamente correlacionados. En estos casos, PCA, que describimos a continuaci\u00f3n, puede ser bastante \u00fatil para reducir la complejidad del modelo que se est\u00e1 ajustando.\n33.5.4 An\u00e1lisis de componentes principales\nEn el c\u00e1lculo anterior, la variabilidad total en nuestros datos puede definirse como la suma de la suma de los cuadrados de las columnas. Suponemos que las columnas est\u00e1n centradas, por lo que esta suma es equivalente a la suma de las varianzas de cada columna:\n\\[ v_1 + v_2, \\mbox{ with } v_1 = \\frac{1}{N}\\sum_{i=1}^N X_{i,1}^2 \\mbox{ and } v_2 = \\frac{1}{N}\\sum_{i=1}^N X_{i,2}^2 \\]\nPodemos calcular \\(v_1\\) y \\(v_2\\) al utilizar:\ny podemos mostrar matem\u00e1ticamente que si aplicamos una transformaci\u00f3n ortogonal como la anterior, la variaci\u00f3n total sigue siendo la misma:\nSin embargo, mientras que la variabilidad en las dos columnas de\nX es casi la misma, en la versi\u00f3n transformada \\(Z\\), el 99% de la variabilidad se incluye solo en la primera dimensi\u00f3n:\nEl primer componente principal (principal component o PC por sus siglas en ingl\u00e9s) de una matriz \\(X\\) es la transformaci\u00f3n ortogonal lineal de \\(X\\) que maximiza esta variabilidad. La funci\u00f3n\nprcomp provee esta informaci\u00f3n:\nTengan en cuenta que el primer PC es casi el mismo que ese proporcionado por el \\((X_1 + X_2)/ \\sqrt{2}\\) que utilizamos anteriormente (excepto quiz\u00e1s por un cambio de signo que es arbitrario).\nLa funci\u00f3n\nprcomp devuelve la rotaci\u00f3n necesaria para transformar \\(X\\) para que la variabilidad de las columnas disminuya de m\u00e1s variable a menos (se accede con\n$rotation) as\u00ed como la nueva matriz resultante (que se accede con\n$x). Por defecto,\nprcomp centra las columnas de \\(X\\) antes de calcular las matrices.\nEntonces, usando la multiplicaci\u00f3n de matrices que se muestra arriba, notamos que las dos siguientes operaciones dan el mismo resultado (demostrado por una diferencia entre elementos de pr\u00e1cticamente cero):\nLa rotaci\u00f3n es ortogonal, lo que significa que el inverso es su transposici\u00f3n. Entonces tambi\u00e9n tenemos que estos dos son id\u00e9nticos:\nPodemos visualizarlos para ver c\u00f3mo el primer componente resume los datos. En el gr\u00e1fico a continuaci\u00f3n, el rojo representa valores altos y el azul representa valores negativos. M\u00e1s adelante, en la Secci\u00f3n\n[33.11.1](sets-grandes-de-datos.html#factor-analysis), aprendemos por qu\u00e9 llamamos a estos pesos (weights en ingl\u00e9s) y patrones (patterns en ingl\u00e9s):\nResulta que podemos encontrar esta transformaci\u00f3n lineal no solo para dos dimensiones, sino tambi\u00e9n para matrices de cualquier dimensi\u00f3n \\(p\\).\nPara una matriz multidimensional \\(X\\) con \\(p\\) columnas, se puede encontrar una transformaci\u00f3n \\(Z\\) que conserva la distancia entre filas, pero con la varianza de las columnas en orden decreciente. La segunda columna es el segundo componente principal, la tercera columna es el tercer componente principal y as\u00ed sucesivamente. Como en nuestro ejemplo, si despu\u00e9s de un cierto n\u00famero de columnas, digamos \\(k\\), las variaciones de las columnas de \\(Z_j\\) con \\(j>k\\) son muy peque\u00f1as, significa que estas dimensiones tienen poco que contribuir a la distancia y podemos aproximar la distancia entre dos puntos con solo \\(k\\) dimensiones. Si \\(k\\) es mucho m\u00e1s peque\u00f1o que \\(p\\), entonces podemos lograr un resumen muy eficiente de nuestros datos.\n33.5.5 Ejemplo de lirios\nLos datos del lirio (iris en ingl\u00e9s) son un ejemplo ampliamente utilizado en los cursos de an\u00e1lisis de datos. Incluye cuatro medidas bot\u00e1nicas relacionadas con tres especies de flores:\nSi imprimen\niris$Species, ver\u00e1n que los datos est\u00e1n ordenados por especie.\nCalculemos la distancia entre cada observaci\u00f3n. Pueden ver claramente las tres especies con una especie muy diferente de las otras dos:\n[x <- iris[,1:4] |> as.matrix()] [d <- dist(x)] [image(as.matrix(d), col = rev(RColorBrewer::brewer.pal(9, \"RdBu\")))]\nNuestros predictores aqu\u00ed tienen cuatro dimensiones, pero tres est\u00e1n muy correlacionadas:\n[cor(x)] [#> Sepal.Length Sepal.Width Petal.Length Petal.Width] [#> Sepal.Length 1.000 -0.118 0.872 0.818] [#> Sepal.Width -0.118 1.000 -0.428 -0.366] [#> Petal.Length 0.872 -0.428 1.000 0.963] [#> Petal.Width 0.818 -0.366 0.963 1.000]\nSi aplicamos PCA, deber\u00edamos poder aproximar esta distancia con solo dos dimensiones, comprimiendo las dimensiones altamente correlacionadas. Utilizando la funci\u00f3n\nsummary, podemos ver la variabilidad explicada por cada PC:\n[pca <- prcomp(x)] [summary(pca)] [#> Importance of components:] [#> PC1 PC2 PC3 PC4] [#> Standard deviation 2.056 0.4926 0.2797 0.15439] [#> Proportion of Variance 0.925 0.0531 0.0171 0.00521] [#> Cumulative Proportion 0.925 0.9777 0.9948 1.00000]\nLas dos primeras dimensiones representan el 97% de la variabilidad. Por lo tanto, deber\u00edamos poder aproximar bien la distancia con dos dimensiones. Podemos visualizar los resultados de PCA:\nY ver que el primer patr\u00f3n es la longitud del s\u00e9palo, la longitud del p\u00e9talo y el ancho del p\u00e9talo (rojo) en una direcci\u00f3n y el ancho del s\u00e9palo (azul) en la otra. El segundo patr\u00f3n es la longitud del s\u00e9palo y el ancho del p\u00e9talo en una direcci\u00f3n (azul) y la longitud y el ancho del p\u00e9talo en la otra (rojo). Pueden ver de los pesos que la primera PC1 controla la mayor parte de la variabilidad y separa claramente el primer tercio de las muestras (setosa) de los dos tercios (versicolor y virginica). Si miran la segunda columna de los pesos, observar\u00e1n que separa un poco versicolor (rojo) de virginica (azul).\nPodemos ver esto mejor al graficar los dos primeros PCs con color representando especie:\n[data.frame(pca$x[,1:2], Species=iris$Species) |>] [ggplot(aes(PC1,PC2, fill = Species))+] [geom_point(cex=3, pch=21) +] [coord_fixed(ratio = 1)]\nVemos que las dos primeras dimensiones preservan la distancia:\nEste ejemplo es m\u00e1s realista que el primer ejemplo artificial que utilizamos, ya que mostramos c\u00f3mo podemos visualizar los datos usando dos dimensiones cuando los datos eran de cuatro dimensiones.\n33.5.6 Ejemplo de MNIST\nEl ejemplo de d\u00edgitos escritos tiene 784 atributos. \u00bfHay espacio para la reducci\u00f3n de datos? \u00bfPodemos crear algoritmos sencillos de machine learning con menos atributos?\nCarguemos los datos:\nDebido a que los p\u00edxeles son tan peque\u00f1os, esperamos que los p\u00edxeles cercanos entre s\u00ed en la cuadr\u00edcula est\u00e9n correlacionados, lo que significa que la reducci\u00f3n de dimensi\u00f3n deber\u00eda ser posible.\nProbemos PCA y exploremos la variaci\u00f3n de los PCs. Esto tomar\u00e1 unos segundos ya que es una matriz bastante grande.\nPodemos ver que los primeros PCs ya explican un gran porcentaje de la variabilidad:\n[summary(pca)$importance[,1:5]] [#> PC1 PC2 PC3 PC4 PC5] [#> Standard deviation 576.823 493.238 459.8993 429.8562 408.5668] [#> Proportion of Variance 0.097 0.071 0.0617 0.0539 0.0487] [#> Cumulative Proportion 0.097 0.168 0.2297 0.2836 0.3323]\nY con solo mirar las dos primeras PCs vemos informaci\u00f3n sobre la clase. Aqu\u00ed hay una muestra aleatoria de 2,000 d\u00edgitos:\n[data.frame(PC1 = pca$x[,1], PC2 = pca$x[,2],] [label=factor(mnist$train$label)) |>] [sample_n(2000) |>] [ggplot(aes(PC1, PC2, fill=label))+] [geom_point(cex=3, pch=21)]\nTambi\u00e9n podemos ver las combinaciones lineales en la cuadr\u00edcula para tener una idea de lo que se est\u00e1 ponderando:\nLos PCs de menor varianza parecen estar relacionadas a la variabilidad irrelevante en las esquinas:\nAhora apliquemos la transformaci\u00f3n que aprendimos con los datos de entrenamiento a los datos de evaluaci\u00f3n, reduzcamos la dimensi\u00f3n y ejecutemos\nknn3 en solo un peque\u00f1o n\u00famero de dimensiones.\nIntentamos 36 dimensiones ya que esto explica aproximadamente el 80% de los datos. Primero, ajuste el modelo:\n[library(caret)] [k <- 36] [x_train <- pca$x[,1:k]] [y <- factor(mnist$train$labels)] [fit <- knn3(x_train, y)]\nAhora, transformen el set de evaluaci\u00f3n:\nY estamos listos para predecir y evaluar los resultados:\n[y_hat <- predict(fit, x_test, type = \"class\")] [confusionMatrix(y_hat, factor(mnist$test$labels))$overall[\"Accuracy\"]] [#> Accuracy] [#> 0.975]\nCon solo 36 dimensiones, obtenemos una exactitud muy superior a 0.95.\n33.6 Ejercicios\n1. Queremos explorar los predictores\ntissue_gene_expression grafic\u00e1ndolos.\nProcuramos tener una idea de qu\u00e9 observaciones est\u00e1n cercas entre s\u00ed, pero como los predictores son de 500 dimensiones, es dif\u00edcil graficar. Grafique los dos primeros componentes principales con color representando el tipo de tejido.\n2. Los predictores de cada observaci\u00f3n se miden en el mismo dispositivo de medici\u00f3n (un microarreglo de expresi\u00f3n g\u00e9nica) despu\u00e9s de un procedimiento experimental. Se utiliza un dispositivo y procedimiento diferente para cada observaci\u00f3n. Esto puede introducir sesgos que afecten a todos los predictores de cada observaci\u00f3n de la misma manera. Para explorar el efecto de este posible sesgo, para cada observaci\u00f3n, calcule el promedio de todos los predictores y luego grafique esto contra el primer PC con el color que representa el tejido. Indique la correlaci\u00f3n.\n3. Vemos una asociaci\u00f3n con el primer PC y los promedios de observaci\u00f3n. Vuelva a hacer el PCA pero solo despu\u00e9s de quitar el centro.\n4. Para los primeros 10 PCs, haga un diagrama de caja que muestre los valores para cada tejido.\n5. Grafique el porcentaje de varianza explicado por el n\u00famero de PC. Sugerencia: use la funci\u00f3n\nsummary.\n33.7 Sistemas de recomendaci\u00f3n\nLos sistemas de recomendaci\u00f3n utilizan clasificaciones que los consumidores le han dado a art\u00edculos para hacer recomendaciones espec\u00edficas. Las compa\u00f1\u00edas que venden muchos productos a muchos clientes y permiten que estos clientes califiquen sus productos, como Amazon, pueden recopilar sets de datos masivos que se pueden utilizar para predecir qu\u00e9 calificaci\u00f3n le otorgar\u00e1 un usuario en particular a un art\u00edculo espec\u00edfico. Art\u00edculos para los cuales se predice una calificaci\u00f3n alta para un usuario particular, se recomiendan a ese usuario.\nNetflix utiliza un sistema de recomendaci\u00f3n para predecir cu\u00e1ntas estrellas le dar\u00e1 un usuario a una pel\u00edcula espec\u00edfica. Una estrella sugiere que no es una buena pel\u00edcula, mientras que cinco estrellas sugieren que es una pel\u00edcula excelente. Aqu\u00ed, ofrecemos los conceptos b\u00e1sicos de c\u00f3mo se hacen estas recomendaciones, motivados por algunos de los enfoques adoptados por los ganadores del Netflix challenge.\nEn octubre de 2006, Netflix le dio un reto a la comunidad de ciencia de datos: mejoren nuestro algoritmo de recomendaci\u00f3n por un 10% y ganen un mill\u00f3n de d\u00f3lares. En septiembre de 2009, los ganadores se anunciaron\n[120](#fn120). Pueden leer un buen resumen de c\u00f3mo se cre\u00f3 el algoritmo ganador aqu\u00ed: [http://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/](http://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/)\ny una explicaci\u00f3n m\u00e1s detallada aqu\u00ed:\n[http://www.netflixprize.com/assets/GrandPrize2009_BPC_BellKor.pdf](http://www.netflixprize.com/assets/GrandPrize2009_BPC_BellKor.pdf). Ahora le mostraremos algunas de las estrategias de an\u00e1lisis de datos utilizadas por el equipo ganador.\n33.7.1 Datos de Movielens\nLos datos de Netflix no est\u00e1n disponibles p\u00fablicamente, pero el laboratorio de investigaci\u00f3n GroupLens\n[121](#fn121) gener\u00f3 su propia base de datos con m\u00e1s de 20 millones de calificaciones para m\u00e1s de 27,000 pel\u00edculas por m\u00e1s de 138,000 usuarios. Ponemos a disposici\u00f3n un peque\u00f1o subconjunto de estos datos a trav\u00e9s del paquete dslabs:\nPodemos ver que esta tabla est\u00e1 en formato tidy con miles de filas:\n[movielens |> as_tibble()] [#> # A tibble: 100,004 \u00d7 7] [#> movieId title year genres userId rating timestamp] [#> <int> <chr> <int> <fct> <int> <dbl> <int>] [#> 1 31 Dangerous Minds 1995 Drama 1 2.5 1.26e9] [#> 2 1029 Dumbo 1941 Anima\u2026 1 3 1.26e9] [#> 3 1061 Sleepers 1996 Thril\u2026 1 3 1.26e9] [#> 4 1129 Escape from New York 1981 Actio\u2026 1 2 1.26e9] [#> 5 1172 Cinema Paradiso (Nuovo c\u2026 1989 Drama 1 4 1.26e9] [#> # \u2026 with 99,999 more rows]\nCada fila representa una calificaci\u00f3n dada por un usuario a una pel\u00edcula.\nPodemos ver la cantidad de usuarios \u00fanicos que dan calificaciones y cu\u00e1ntas pel\u00edculas \u00fanicas fueron calificadas:\n[movielens |>] [summarize(n_users = n_distinct(userId),] [n_movies = n_distinct(movieId))] [#> n_users n_movies] [#> 1 671 9066]\nSi multiplicamos esos dos n\u00fameros, obtenemos un n\u00famero mayor de 5 millones. Sin embargo, nuestra tabla de datos tiene aproximadamente 100,000 filas. Esto implica que no todos los usuarios calificaron todas las pel\u00edculas. Por lo tanto, podemos pensar en estos datos como una matriz muy grande, con usuarios en las filas y pel\u00edculas en las columnas, con muchas celdas vac\u00edas. La funci\u00f3n\npivot_longer nos permite convertirla a este formato, pero si lo intentamos para toda la matriz, colgaremos a R. Mostremos la matriz para seis usuarios y cuatro pel\u00edculas.\n|userId||Pulp Fiction||Shawshank Redemption||Forrest Gump||Silence of the Lambs|\n|13||3.5||4.5||5.0||NA|\n|15||5.0||2.0||1.0||5.0|\n|16||NA||4.0||NA||NA|\n|17||5.0||5.0||2.5||4.5|\n|19||5.0||4.0||5.0||3.0|\n|20||0.5||4.5||2.0||0.5|\nPueden pensar en la tarea de un sistema de recomendaci\u00f3n como completar los\nNAs en la tabla de arriba. Para ver cu\u00e1n dispersa es la matriz, aqu\u00ed tenemos la matriz para una muestra aleatoria de 100 pel\u00edculas y 100 usuarios con amarillo indicando una combinaci\u00f3n de usuario/pel\u00edcula para la que tenemos una calificaci\u00f3n.\nEste reto de machine learning es m\u00e1s complicado de lo que hemos estudiado hasta ahora porque cada resultado \\(Y\\) tiene un set diferente de predictores. Para ver esto, tengan en cuenta que si estamos prediciendo la calificaci\u00f3n de la pel\u00edcula \\(i\\) por usuario \\(u\\), en principio, todas las otras clasificaciones relacionadas con la pel\u00edcula \\(i\\) y por el usuario \\(u\\) pueden usarse como predictores, pero diferentes usuarios califican diferentes pel\u00edculas y diferentes n\u00fameros de pel\u00edculas. Adem\u00e1s, podemos usar informaci\u00f3n de otras pel\u00edculas que hemos determinado que son parecidas a la pel\u00edcula \\(i\\) o de usuarios que se consideran similares al usuario \\(u\\). B\u00e1sicamente, toda la matriz se puede utilizar como predictores para cada celda.\nVeamos algunas de las propiedades generales de los datos para entender mejor los retos.\nLo primero que notamos es que algunas pel\u00edculas se eval\u00faan m\u00e1s que otras. A continuaci\u00f3n se muestra la distribuci\u00f3n. Esto no deber\u00eda sorprendernos dado que hay pel\u00edculas de gran \u00e9xito vistas por millones y pel\u00edculas art\u00edsticas e independientes vistas por pocos. Nuestra segunda observaci\u00f3n es que algunos usuarios son m\u00e1s activos que otros en la calificaci\u00f3n de pel\u00edculas:\n33.7.2 Sistemas de recomendaci\u00f3n como un desaf\u00edo de machine learning\nPara ver c\u00f3mo esto se puede considerar machine learning, noten que necesitamos construir un algoritmo con los datos que hemos recopilado que luego se aplicar\u00e1n fuera de nuestro control, a medida que los usuarios busquen recomendaciones de pel\u00edculas. As\u00ed que creamos un set de evaluaci\u00f3n para evaluar la exactitud de los modelos que implementamos.\n[library(caret)] [set.seed(755)] [test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.2,] [list = FALSE)] [train_set <- movielens[-test_index,]] [test_set <- movielens[test_index,]]\nPara asegurarnos de que no incluimos usuarios y pel\u00edculas en el set de evaluaci\u00f3n que no aparecen en el set de entrenamiento, eliminamos estas entradas usando la funci\u00f3n\nsemi_join:\n33.7.3 Funci\u00f3n de p\u00e9rdida\nEl Netflix challenge us\u00f3 la p\u00e9rdida de error t\u00edpica: decidieron un ganador basado en la desviaci\u00f3n cuadr\u00e1tica media (RMSE por sus siglas en ingl\u00e9s) en un set de evaluaci\u00f3n. Definimos \\(y_{u,i}\\) como la calificaci\u00f3n de la pel\u00edcula \\(i\\) por usuario \\(u\\) y denotamos nuestra predicci\u00f3n con \\(\\hat{y}_{u,i}\\). El RMSE se define entonces como:\n\\[ \\mbox{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{u,i}^{} \\left( \\hat{y}_{u,i} - y_{u,i} \\right)^2 } \\] con \\(N\\) siendo el n\u00famero de combinaciones de usuario/pel\u00edcula y la suma que ocurre en todas estas combinaciones.\nRecuerden que podemos interpretar el RMSE de manera similar a una desviaci\u00f3n est\u00e1ndar: es el error t\u00edpico que cometemos al predecir una calificaci\u00f3n de pel\u00edcula. Si este n\u00famero es mayor que 1, significa que nuestro error t\u00edpico es mayor que una estrella, lo cual no es bueno.\nEscribamos una funci\u00f3n que calcule el RMSE para vectores de clasificaciones y sus predictores correspondientes:\n33.7.4 Un primer modelo\nComencemos construyendo el sistema de recomendaci\u00f3n m\u00e1s sencillo posible: predecimos la misma calificaci\u00f3n para todas las pel\u00edculas, independientemente del usuario. \u00bfQu\u00e9 n\u00famero deber\u00eda ser esta predicci\u00f3n? Podemos usar un enfoque basado en modelos para responder a esto. Un modelo que supone la misma calificaci\u00f3n para todas las pel\u00edculas y usuarios con todas las diferencias explicadas por la variaci\u00f3n aleatoria se ver\u00eda as\u00ed:\n\\[ Y_{u,i} = \\mu + \\varepsilon_{u,i} \\]\ncon \\(\\varepsilon_{i,u}\\) errores independientes muestreados de la misma distribuci\u00f3n centrada en 0 y \\(\\mu\\) la calificaci\u00f3n \u201cverdadera\u201d para todas las pel\u00edculas. Sabemos que el estimador que minimiza el RMSE es el estimador de m\u00ednimos cuadrados de \\(\\mu\\) y, en este caso, es el promedio de todas las calificaciones:\nSi predecimos todas las calificaciones desconocidas con \\(\\hat{\\mu}\\), obtenemos el siguiente RMSE:\nTengan en cuenta que si usan cualquier otro n\u00famero, obtendr\u00e1m un RMSE m\u00e1s alto. Por ejemplo:\nAl observar la distribuci\u00f3n de calificaciones, podemos visualizar que esta es la desviaci\u00f3n est\u00e1ndar de esa distribuci\u00f3n. Obtenemos un RMSE de aproximadamente 1. Para ganar el gran premio de $1,000,000, un equipo participante tuvo que obtener un RMSE de aproximadamente 0.857. \u00a1Definitivamente podemos mejorar!\nA medida que avanzamos, compararemos diferentes enfoques. Comencemos creando una tabla de resultados con este enfoque simplista:\n33.7.5 Modelando los efectos de pel\u00edculas\nSabemos por experiencia que algunas pel\u00edculas generalmente tienen una calificaci\u00f3n m\u00e1s alta que otras. Esta intuici\u00f3n, que las diferentes pel\u00edculas se clasifican de manera diferente, la confirma los datos. Podemos expandir nuestro modelo anterior agregando el t\u00e9rmino \\(b_i\\) para representar la clasificaci\u00f3n promedio de la pel\u00edcula \\(i\\):\n\\[ Y_{u,i} = \\mu + b_i + \\varepsilon_{u,i} \\]\nLos libros de texto de estad\u00edsticas se refieren a \\(b\\)s como efectos. Sin embargo, en los art\u00edculos sobre el Netflix challenge, se refieren a ellos como \u201csesgo\u201d (o bias en ingl\u00e9s; por lo tanto, la notaci\u00f3n \\(b\\)).\nDe nuevo podemos usar m\u00ednimos cuadrados para estimar \\(b_i\\) de la siguiente manera:\nComo hay miles de \\(b_i\\), a medida que cada pel\u00edcula obtiene una, la funci\u00f3n\nlm() ser\u00e1 muy lenta aqu\u00ed. Por eso, no recomendamos ejecutar el c\u00f3digo anterior. Pero en esta situaci\u00f3n particular, sabemos que el estimador de los m\u00ednimos cuadrados \\(\\hat{b}_i\\) es solo el promedio de \\(Y_{u,i} - \\hat{\\mu}\\) para cada pel\u00edcula \\(i\\). Entonces podemos calcularlos de esta manera (dejaremos de usar la notaci\u00f3n\nhat en el c\u00f3digo para representar los estimadores en el futuro):\n[mu <- mean(train_set$rating)] [movie_avgs <- train_set |>] [group_by(movieId) |>] [summarize(b_i = mean(rating - mu))]\nPodemos ver que estos estimadores var\u00edan sustancialmente:\nRecuerden \\(\\hat{\\mu}=3.5\\), entonces una \\(b_i = 1.5\\) implica una calificaci\u00f3n perfecta de cinco estrellas.\nVeamos cu\u00e1nto mejora nuestra predicci\u00f3n cuando usamos \\(\\hat{y}_{u,i} = \\hat{\\mu} + \\hat{b}_i\\):\n[predicted_ratings <- mu + test_set |>] [left_join(movie_avgs, by='movieId') |>] [pull(b_i)] [RMSE(predicted_ratings, test_set$rating)] [#> [1] 0.989]\nYa observamos una mejora. \u00bfPero podemos mejorar m\u00e1s?\n33.7.6 Efectos de usuario\nCalculemos la calificaci\u00f3n promedio para el usuario \\(u\\) para aquellos que han calificado 100 o m\u00e1s pel\u00edculas:\n[train_set |>] [group_by(userId) |>] [filter(n()>=100) |>] [summarize(b_u = mean(rating)) |>] [ggplot(aes(b_u)) +] [geom_histogram(bins = 30, color = \"black\")]\nNoten que tambi\u00e9n existe una variabilidad sustancial entre los usuarios: algunos usuarios son muy exigentes y otros adoran cada pel\u00edcula. Esto implica que una mejora adicional de nuestro modelo puede ser:\n\\[ Y_{u,i} = \\mu + b_i + b_u + \\varepsilon_{u,i} \\]\nd\u00f3nde \\(b_u\\) es un efecto espec\u00edfico de cada usuario. Ahora, si un usuario exigente (\\(b_u\\) negativo) califica una pel\u00edcula excelente (\\(b_i\\) positiva), los efectos se contrarrestan y podemos predecir correctamente que este usuario le dio a esta gran pel\u00edcula un 3 en lugar de un 5.\nPara ajustar este modelo, podr\u00edamos nuevamente usar\nlm as\u00ed:\npero, por las razones descritas anteriormente, no lo haremos. En cambio, calcularemos una aproximaci\u00f3n calculando \\(\\hat{\\mu}\\) y \\(\\hat{b}_i\\) y estimando \\(\\hat{b}_u\\) como el promedio de \\(y_{u,i} - \\hat{\\mu} - \\hat{b}_i\\):\n[user_avgs <- train_set |>] [left_join(movie_avgs, by='movieId') |>] [group_by(userId) |>] [summarize(b_u = mean(rating - mu - b_i))]\nAhora podemos construir predictores y ver cu\u00e1nto mejora el RMSE:\n33.8 Ejercicios\n1. Cargue los datos\nmovielens.\nCalcule el n\u00famero de calificaciones para cada pel\u00edcula y luego comp\u00e1relo con el a\u00f1o en que sali\u00f3 la pel\u00edcula. Transforme los datos usando la ra\u00edz cuadrada en los recuentos.\n2. Vemos que, en promedio, las pel\u00edculas que salieron despu\u00e9s de 1993 obtienen m\u00e1s calificaciones. Tambi\u00e9n vemos que con las pel\u00edculas m\u00e1s nuevas, a partir de 1993, el n\u00famero de calificaciones disminuye con el a\u00f1o: entre m\u00e1s reciente sea una pel\u00edcula, menos tiempo han tenido los usuarios para calificarla.\nEntre las pel\u00edculas que salieron en 1993 o m\u00e1s tarde, \u00bfcu\u00e1les son las 25 pel\u00edculas con m\u00e1s calificaciones por a\u00f1o? Adem\u00e1s, indique la calificaci\u00f3n promedio.\n3. De la tabla construida en el ejemplo anterior, vemos que las pel\u00edculas mejor calificadas tienden a tener calificaciones superiores al promedio. Esto no es sorprendente: m\u00e1s personas ven pel\u00edculas populares. Para confirmar esto, estratifique las pel\u00edculas posteriores a 1993 por calificaciones por a\u00f1o y calcule sus calificaciones promedio. Haga un gr\u00e1fico de la calificaci\u00f3n promedio versus calificaciones por a\u00f1o y muestre un estimador de la tendencia.\n4. En el ejercicio anterior, vemos que entre m\u00e1s se califica una pel\u00edcula, mayor es la calificaci\u00f3n. Suponga que est\u00e1 haciendo un an\u00e1lisis predictivo en el que necesita completar las calificaciones faltantes con alg\u00fan valor. \u00bfCu\u00e1l de las siguientes estrategias usar\u00eda?\n- Completar los valores faltantes con la calificaci\u00f3n promedio de todas las pel\u00edculas.\n- Completar los valores faltantes con 0.\n- Completar el valor con un valor m\u00e1s bajo que el promedio ya que la falta de calificaci\u00f3n se asocia con calificaciones m\u00e1s bajas. Pruebe diferentes valores y eval\u00fae la predicci\u00f3n en un set de evaluaci\u00f3n.\n- Ninguna de las anteriores.\n5. El set de datos\nmovielens tambi\u00e9n incluye un sello de tiempo. Esta variable representa el tiempo y los datos en los que se le dio la calificaci\u00f3n. Las unidades son segundos desde el 1 de enero de 1970. Cree una nueva columna\ndate con la fecha. Sugerencia: use la funci\u00f3n\nas_datetime en el paquete lubridate.\n6. Calcule la calificaci\u00f3n promedio de cada semana y calcule este promedio para cada d\u00eda. Sugerencia: use la funci\u00f3n\nround_date antes de\ngroup_by.\n7. El gr\u00e1fico muestra alguna evidencia de un efecto temporero. Si definimos \\(d_{u,i}\\) como el d\u00eda que el usuario \\(u\\) hizo su calificaci\u00f3n de la pel\u00edcula \\(i\\), \u00bfcu\u00e1l de los siguientes modelos es el m\u00e1s apropiado?\n- \\(Y_{u,i} = \\mu + b_i + b_u + d_{u,i} + \\varepsilon_{u,i}\\).\n- \\(Y_{u,i} = \\mu + b_i + b_u + d_{u,i}\\beta + \\varepsilon_{u,i}\\).\n- \\(Y_{u,i} = \\mu + b_i + b_u + d_{u,i}\\beta_i + \\varepsilon_{u,i}\\).\n- \\(Y_{u,i} = \\mu + b_i + b_u + f(d_{u,i}) + \\varepsilon_{u,i}\\), con \\(f\\) una funci\u00f3n suave de \\(d_{u,i}\\).\n8. Los datos\nmovielens tambi\u00e9n tienen un columna\ngenres. Esta columna incluye todos los g\u00e9neros que aplican a la pel\u00edcula. Algunas pel\u00edculas pertenecen a varios g\u00e9neros. Defina una categor\u00eda como cualquier combinaci\u00f3n que aparezca en esta columna. Mantenga solo categor\u00edas con m\u00e1s de 1,000 calificaciones. Luego, calcule el promedio y error est\u00e1ndar para cada categor\u00eda. Grafique estos usando diagramas de barras de error.\n9. El gr\u00e1fico muestra evidencia convincente de un efecto de g\u00e9nero. Si definimos \\(g_{u,i}\\) como el g\u00e9nero para la calificaci\u00f3n del usuario \\(u\\) de la pel\u00edcula \\(i\\), \u00bfcu\u00e1l de los siguientes modelos es el m\u00e1s apropiado?\n- \\(Y_{u,i} = \\mu + b_i + b_u + d_{u,i} + \\varepsilon_{u,i}\\).\n- \\(Y_{u,i} = \\mu + b_i + b_u + d_{u,i}\\beta + \\varepsilon_{u,i}\\).\n- \\(Y_{u,i} = \\mu + b_i + b_u + \\sum_{k=1}^K x_{u,i} \\beta_k + \\varepsilon_{u,i}\\), con \\(x^k_{u,i} = 1\\) si \\(g_{u,i}\\) es genero \\(k\\).\n- \\(Y_{u,i} = \\mu + b_i + b_u + f(d_{u,i}) + \\varepsilon_{u,i}\\), con \\(f\\) una funci\u00f3n suave de \\(d_{u,i}\\).\n33.9 Regularizaci\u00f3n\n33.9.1 Motivaci\u00f3n\nA pesar de la gran variaci\u00f3n de pel\u00edcula a pel\u00edcula, nuestra mejora en RMSE fue solo como 5%. Exploremos d\u00f3nde cometimos errores en nuestro primer modelo, usando solo efectos de pel\u00edcula \\(b_i\\). Aqu\u00ed est\u00e1n los 10 errores m\u00e1s grandes:\n[test_set |>] [left_join(movie_avgs, by='movieId') |>] [mutate(residual = rating - (mu + b_i)) |>] [arrange(desc(abs(residual))) |>] [slice(1:10) |>] [pull(title)] [#> [1] \"Kingdom, The (Riget)\" \"Heaven Knows, Mr. Allison\"] [#> [3] \"American Pimp\" \"Chinatown\"] [#> [5] \"American Beauty\" \"Apocalypse Now\"] [#> [7] \"Taxi Driver\" \"Wallace & Gromit: A Close Shave\"] [#> [9] \"Down in the Delta\" \"Stalag 17\"]\nTodas estas parecen ser pel\u00edculas desconocidas. Para muchas de ellas, predecimos calificaciones altas. Echemos un vistazo a las 10 peores y 10 mejores pel\u00edculas basadas en \\(\\hat{b}_i\\). Primero, vamos a crear una base de datos que conecta\nmovieId al t\u00edtulo de la pel\u00edcula:\nAqu\u00ed est\u00e1n las 10 mejores pel\u00edculas seg\u00fan nuestro estimador:\n[movie_avgs |> left_join(movie_titles, by=\"movieId\") |>] [arrange(desc(b_i)) |>] [slice(1:10) |>] [pull(title)] [#> [1] \"When Night Is Falling\"] [#> [2] \"Lamerica\"] [#> [3] \"Mute Witness\"] [#> [4] \"Picture Bride (Bijo photo)\"] [#> [5] \"Red Firecracker, Green Firecracker (Pao Da Shuang Deng)\"] [#> [6] \"Paris, France\"] [#> [7] \"Faces\"] [#> [8] \"Maya Lin: A Strong Clear Vision\"] [#> [9] \"Heavy\"] [#> [10] \"Gate of Heavenly Peace, The\"]\nY aqu\u00ed est\u00e1n las 10 peores:\n[movie_avgs |> left_join(movie_titles, by=\"movieId\") |>] [arrange(b_i) |>] [slice(1:10) |>] [pull(title)] [#> [1] \"Children of the Corn IV: The Gathering\"] [#> [2] \"Barney's Great Adventure\"] [#> [3] \"Merry War, A\"] [#> [4] \"Whiteboyz\"] [#> [5] \"Catfish in Black Bean Sauce\"] [#> [6] \"Killer Shrews, The\"] [#> [7] \"Horrors of Spider Island (Ein Toter Hing im Netz)\"] [#> [8] \"Monkeybone\"] [#> [9] \"Arthur 2: On the Rocks\"] [#> [10] \"Red Heat\"]\nTodas parecen ser bastante desconocidas. Veamos con qu\u00e9 frecuencia se califican.\n[train_set |> count(movieId) |>] [left_join(movie_avgs, by=\"movieId\") |>] [left_join(movie_titles, by=\"movieId\") |>] [arrange(desc(b_i)) |>] [slice(1:10) |>] [pull(n)] [#> [1] 1 1 1 1 3 1 1 2 1 1] [train_set |> count(movieId) |>] [left_join(movie_avgs) |>] [left_join(movie_titles, by=\"movieId\") |>] [arrange(b_i) |>] [slice(1:10) |>] [pull(n)] [#> Joining, by = \"movieId\"] [#> [1] 1 1 1 1 1 1 1 1 1 1]\nLas supuestas pel\u00edculas \u201cmejores\u201d y \u201cpeores\u201d fueron calificadas por muy pocos usuarios, en la mayor\u00eda de los casos por solo 1. Estas pel\u00edculas son en su mayor\u00eda desconocidas. Esto se debe a que con solo unos pocos usuarios, tenemos m\u00e1s incertidumbre. Por lo tanto, mayores estimadores de \\(b_i\\), negativo o positivo, son m\u00e1s probables.\nEstos son estimadores ruidosos en los que no debemos confiar, especialmente cuando se trata de predicciones. Grandes errores pueden aumentar nuestro RMSE, por lo que preferimos ser conservadores cuando no estamos seguros.\nEn secciones anteriores, calculamos el error est\u00e1ndar y construimos intervalos de confianza para tomar en cuenta los diferentes niveles de incertidumbre. Sin embargo, al hacer predicciones, necesitamos un n\u00famero, una predicci\u00f3n, no un intervalo. Para esto, presentamos el concepto de regularizaci\u00f3n.\nLa regularizaci\u00f3n nos permite penalizar estimadores m\u00e1s grandes que se forman utilizando peque\u00f1os tama\u00f1os de muestra. Tienen puntos en com\u00fan con el enfoque bayesiano que redujo las predicciones descritas en la Secci\u00f3n\n[16.4](models.html#bayesian-statistics).\n33.9.2 M\u00ednimos cuadrados penalizados\nLa idea general detr\u00e1s de la regularizaci\u00f3n es restringir la variabilidad total de los tama\u00f1os del efecto. \u00bfPor qu\u00e9 esto ayuda? Consideren un caso en el que tenemos pel\u00edcula \\(i=1\\) con 100 clasificaciones de usuarios y 4 pel\u00edculas \\(i=2,3,4,5\\) con solo una calificaci\u00f3n de usuario. Tenemos la intenci\u00f3n de ajustar el modelo:\n\\[ Y_{u,i} = \\mu + b_i + \\varepsilon_{u,i} \\]\nSupongan que sabemos que la calificaci\u00f3n promedio es, digamos, \\(\\mu = 3\\). Si usamos m\u00ednimos cuadrados, el estimador para el primer efecto de pel\u00edcula \\(b_1\\) es el promedio de las 100 calificaciones de los usuarios, \\(1/100 \\sum_{i=1}^{100} (Y_{i,1} - \\mu)\\), que esperamos sea bastante preciso. Sin embargo, el estimador para las pel\u00edculas 2, 3, 4 y 5 ser\u00e1 simplemente la desviaci\u00f3n observada de la calificaci\u00f3n promedio \\(\\hat{b}_i = Y_{u,i} - \\hat{\\mu}\\). Pero esto es un estimador basado en un solo n\u00famero, por lo cual no ser\u00e1 preciso. Tengan en cuenta que estos estimadores hacen el error \\(Y_{u,i} - \\mu + \\hat{b}_i\\) igual a 0 para \\(i=2,3,4,5\\), pero este es un caso de sobreentrenamiento. De hecho, ignorando al \u00fanico usuario y adivinando que las pel\u00edculas 2, 3, 4 y 5 son solo pel\u00edculas promedio (\\(b_i = 0\\)) podr\u00eda ofrecer una mejor predicci\u00f3n. La idea general de la regresi\u00f3n penalizada es controlar la variabilidad total de los efectos de la pel\u00edcula: \\(\\sum_{i=1}^5 b_i^2\\). Espec\u00edficamente, en lugar de minimizar la ecuaci\u00f3n de m\u00ednimos cuadrados, minimizamos una ecuaci\u00f3n que a\u00f1ade una penalizaci\u00f3n:\n\\[\\sum_{u,i} \\left(y_{u,i} - \\mu - b_i\\right)^2 + \\lambda \\sum_{i} b_i^2\\]\nEl primer t\u00e9rmino es solo la suma de errores cuadrados y el segundo es una penalizaci\u00f3n que aumenta cuando muchos \\(b_i\\) son grandes. Usando c\u00e1lculo, podemos mostrar que los valores de \\(b_i\\) que minimizan esta ecuaci\u00f3n son:\n\\[ \\hat{b}_i(\\lambda) = \\frac{1}{\\lambda + n_i} \\sum_{u=1}^{n_i} \\left(Y_{u,i} - \\hat{\\mu}\\right) \\]\nd\u00f3nde \\(n_i\\) es la cantidad de clasificaciones hechas para la pel\u00edcula \\(i\\). Este enfoque tendr\u00e1 el efecto deseado: cuando nuestro tama\u00f1o de muestra \\(n_i\\) es muy grande, un caso que nos dar\u00e1 un estimador estable, entonces la penalizaci\u00f3n \\(\\lambda\\) es efectivamente ignorada ya que \\(n_i+\\lambda \\approx n_i\\). Sin embargo, cuando el \\(n_i\\) es peque\u00f1o, entonces el estimador \\(\\hat{b}_i(\\lambda)\\) se encoge hacia 0. Entre m\u00e1s grande \\(\\lambda\\), m\u00e1s nos encogemos.\nCalculemos estos estimadores regularizados de \\(b_i\\) utilizando \\(\\lambda=3\\). M\u00e1s adelante, veremos por qu\u00e9 elegimos 3.\n[lambda <- 3] [mu <- mean(train_set$rating)] [movie_reg_avgs <- train_set |>] [group_by(movieId) |>] [summarize(b_i = sum(rating - mu)/(n()+lambda), n_i = n())]\nPara ver c\u00f3mo se reducen los estimadores, hagamos un gr\u00e1fico de los estimadores regularizados versus los estimadores de m\u00ednimos cuadrados.\n[tibble(original = movie_avgs$b_i,] [regularlized = movie_reg_avgs$b_i,] [n = movie_reg_avgs$n_i) |>] [ggplot(aes(original, regularlized, size=sqrt(n))) +] [geom_point(shape=1, alpha=0.5)]\nAhora, echemos un vistazo a las 10 mejores pel\u00edculas seg\u00fan los estimadores penalizados \\(\\hat{b}_i(\\lambda)\\):\n[train_set |>] [count(movieId) |>] [left_join(movie_reg_avgs, by = \"movieId\") |>] [left_join(movie_titles, by = \"movieId\") |>] [arrange(desc(b_i)) |>] [slice(1:10) |>] [pull(title)] [#> [1] \"Paris Is Burning\" \"Shawshank Redemption, The\"] [#> [3] \"Godfather, The\" \"African Queen, The\"] [#> [5] \"Band of Brothers\" \"Paperman\"] [#> [7] \"On the Waterfront\" \"All About Eve\"] [#> [9] \"Usual Suspects, The\" \"Ikiru\"]\n\u00a1Esto tiene mucho m\u00e1s sentido! Estas pel\u00edculas son m\u00e1s populares y tienen m\u00e1s calificaciones. Aqu\u00ed est\u00e1n las 10 peores pel\u00edculas:\n[train_set |>] [count(movieId) |>] [left_join(movie_reg_avgs, by = \"movieId\") |>] [left_join(movie_titles, by=\"movieId\") |>] [arrange(b_i) |>] [select(title, b_i, n) |>] [slice(1:10) |>] [pull(title)] [#> [1] \"Battlefield Earth\"] [#> [2] \"Joe's Apartment\"] [#> [3] \"Super Mario Bros.\"] [#> [4] \"Speed 2: Cruise Control\"] [#> [5] \"Dungeons & Dragons\"] [#> [6] \"Batman & Robin\"] [#> [7] \"Police Academy 6: City Under Siege\"] [#> [8] \"Cats & Dogs\"] [#> [9] \"Disaster Movie\"] [#> [10] \"Mighty Morphin Power Rangers: The Movie\"]\n\u00bfMejoramos nuestros resultados?\n[predicted_ratings <- test_set |>] [left_join(movie_reg_avgs, by = \"movieId\") |>] [mutate(pred = mu + b_i) |>] [pull(pred)] [RMSE(predicted_ratings, test_set$rating)] [#> [1] 0.97]\n#> # A tibble: 4 \u00d7 2 #> method RMSE #> <chr> <dbl> #> 1 Just the average 1.05 #> 2 Movie Effect Model 0.989 #> 3 Movie + User Effects Model 0.905 #> 4 Regularized Movie Effect Model 0.970\nLos estimadores penalizados ofrecen una gran mejora sobre los estimadores de m\u00ednimos cuadrados.\n33.9.3 C\u00f3mo elegir los t\u00e9rminos de penalizaci\u00f3n\nNoten que \\(\\lambda\\) es un par\u00e1metro de ajuste. Podemos usar validaci\u00f3n cruzada para elegirlo.\n[lambdas <- seq(0, 10, 0.25)] [mu <- mean(train_set$rating)] [just_the_sum <- train_set |>] [group_by(movieId) |>] [summarize(s = sum(rating - mu), n_i = n())] [rmses <- sapply(lambdas, function(l){] [predicted_ratings <- test_set |>] [left_join(just_the_sum, by='movieId') |>] [mutate(b_i = s/(n_i+l)) |>] [mutate(pred = mu + b_i) |>] [pull(pred)] [return(RMSE(predicted_ratings, test_set$rating))] [})] [qplot(lambdas, rmses)] [lambdas[which.min(rmses)]] [#> [1] 3]\nSin embargo, si bien mostramos esto como una ilustraci\u00f3n, en la pr\u00e1ctica deber\u00edamos usar validaci\u00f3n cruzada completa solo en el set de entrenamiento, sin usar el set de evaluaci\u00f3n hasta la evaluaci\u00f3n final. El set de evaluaci\u00f3n nunca debe utilizarse para el ajustamiento.\nTambi\u00e9n podemos utilizar la regularizaci\u00f3n para estimar los efectos del usuario. Estamos minimizando:\n\\[ \\sum_{u,i} \\left(y_{u,i} - \\mu - b_i - b_u \\right)^2 + \\lambda \\left(\\sum_{i} b_i^2 + \\sum_{u} b_u^2\\right) \\]\nLos estimadores que minimizan esto se pueden encontrar de manera similar a lo que hicimos anteriormente. Aqu\u00ed usamos validaci\u00f3n cruzada para elegir un \\(\\lambda\\):\n[lambdas <- seq(0, 10, 0.25)] [rmses <- sapply(lambdas, function(l){] [mu <- mean(train_set$rating)] [b_i <- train_set |>] [group_by(movieId) |>] [summarize(b_i = sum(rating - mu)/(n()+l))] [b_u <- train_set |>] [left_join(b_i, by=\"movieId\") |>] [group_by(userId) |>] [summarize(b_u = sum(rating - b_i - mu)/(n()+l))] [predicted_ratings <-] [test_set |>] [left_join(b_i, by = \"movieId\") |>] [left_join(b_u, by = \"userId\") |>] [mutate(pred = mu + b_i + b_u) |>] [pull(pred)] [return(RMSE(predicted_ratings, test_set$rating))] [})] [qplot(lambdas, rmses)]\nPara el modelo completo, el \\(\\lambda\\) \u00f3ptimo es:\n|method||RMSE|\n|Just the average||1.053|\n|Movie Effect Model||0.989|\n|Movie + User Effects Model||0.905|\n|Regularized Movie Effect Model||0.970|\n|Regularized Movie + User Effect Model||0.881|\n33.10 Ejercicios\nUn experto en educaci\u00f3n aboga por escuelas m\u00e1s peque\u00f1as. El experto basa esta recomendaci\u00f3n en el hecho de que entre las mejores escuelas, muchas son escuelas peque\u00f1as. Simulemos un set de datos para 100 escuelas. Primero, simulemos el n\u00famero de estudiantes en cada escuela.\nAhora asignemos una calidad verdadera para cada escuela completamente independiente del tama\u00f1o. Este es el par\u00e1metro que queremos estimar.\n[mu <- round(80 + 2 * rt(1000, 5))] [range(mu)] [schools <- data.frame(id = paste(\"PS\",1:100),] [size = n,] [quality = mu,] [rank = rank(-mu))]\nPodemos ver que las 10 mejores escuelas son:\nAhora hagamos que los estudiantes en la escuela tomen un examen. Existe una variabilidad aleatoria en la toma de ex\u00e1menes, por lo que simularemos las puntuaciones de los ex\u00e1menes distribuidos normalmente con el promedio determinado por la calidad de la escuela y las desviaciones est\u00e1ndar de 30 puntos porcentuales:\n[scores <- sapply(1:nrow(schools), function(i){] [scores <- rnorm(schools$size[i], schools$quality[i], 30)] [scores] [})] [schools <- schools |> mutate(score = sapply(scores, mean))]\n1. \u00bfCu\u00e1les son las mejores escuelas seg\u00fan la puntuaci\u00f3n promedio? Muestre solo la identificaci\u00f3n, el tama\u00f1o y la puntuaci\u00f3n promedio.\n2. Compare el tama\u00f1o medio de la escuela con el tama\u00f1o medio de las 10 mejores escuelas seg\u00fan la puntuaci\u00f3n.\n3. Seg\u00fan esta prueba, parece que las escuelas peque\u00f1as son mejores que las grandes. Cinco de las 10 mejores escuelas tienen 100 estudiantes o menos. \u00bfPero c\u00f3mo puede ser \u00e9sto? Construimos la simulaci\u00f3n para que la calidad y el tama\u00f1o sean independientes. Repita el ejercicio para las peores 10 escuelas.\n4. \u00a1Lo mismo es cierto para las peores escuelas! Tambi\u00e9n son peque\u00f1as. Grafique la puntuaci\u00f3n promedio versus el tama\u00f1o de la escuela para ver qu\u00e9 est\u00e1 pasando. Destaque las 10 mejores escuelas seg\u00fan la calidad verdadera. Use la transformaci\u00f3n de escala logar\u00edtmica para el tama\u00f1o.\n5. Podemos ver que el error est\u00e1ndar de la puntuaci\u00f3n tiene una mayor variabilidad cuando la escuela es m\u00e1s peque\u00f1a. Esta es una realidad estad\u00edstica b\u00e1sica que aprendimos en las secciones de probabilidad e inferencia. De hecho, noten que 4 de las 10 mejores escuelas se encuentran en las 10 mejores escuelas seg\u00fan la puntuaci\u00f3n del examen.\nUsemos la regularizaci\u00f3n para elegir las mejores escuelas. Recuerde que la regularizaci\u00f3n encoge las desviaciones del promedio hacia 0. Entonces para aplicar la regularizaci\u00f3n aqu\u00ed, primero debemos definir el promedio general para todas las escuelas:\ny luego definir, para cada escuela, c\u00f3mo se desv\u00eda de ese promedio. Escriba un c\u00f3digo que calcule la puntuaci\u00f3n por encima del promedio de cada escuela pero dividi\u00e9ndolo por \\(n + \\lambda\\) en lugar de \\(n\\), con \\(n\\) el tama\u00f1o de la escuela y \\(\\lambda\\) un par\u00e1metro de regularizaci\u00f3n. Intente con \\(\\lambda = 3\\).\n6. Noten que esto mejora un poco las cosas. El n\u00famero de escuelas peque\u00f1as que no figuran entre las mejores ahora es 4. \u00bfExiste un \\(\\lambda\\) mejor? Encuentre el \\(\\lambda\\) que minimiza el RMSE = \\(1/100 \\sum_{i=1}^{100} (\\mbox{quality} - \\mbox{estimate})^2\\).\n7. Clasifique las escuelas seg\u00fan el promedio obtenido con los mejores \\(\\alpha\\). Tengan en cuenta que ninguna escuela peque\u00f1a se incluye incorrectamente.\n8. Un error com\u00fan al usar la regularizaci\u00f3n es reducir los valores hacia 0 que no est\u00e1n centrados alrededor de 0. Por ejemplo, si no restamos el promedio general antes de reducir, obtenemos un resultado muy similar. Confirme esto volviendo a ejecutar el c\u00f3digo del ejercicio 6, pero sin eliminar la media general.\n33.11 Factorizaci\u00f3n de matrices\nLa factorizaci\u00f3n de matrices es un concepto ampliamente utilizado en machine learning. Est\u00e1 muy relacionado con el an\u00e1lisis de factores, la descomposici\u00f3n de valores singulares (singular value decomposition o SVD por sus siglas en ingl\u00e9s) y el an\u00e1lisis de componentes principales (PCA). Aqu\u00ed describimos el concepto en el contexto de los sistemas de recomendaci\u00f3n de pel\u00edculas.\nHemos descrito c\u00f3mo el modelo:\n\\[ Y_{u,i} = \\mu + b_i + b_u + \\varepsilon_{u,i} \\]\nexplica las diferencias de pel\u00edcula a pel\u00edcula a trav\u00e9s de la \\(b_i\\) y las diferencias de usuario a usuario a trav\u00e9s de la \\(b_u\\). Pero este modelo omite una fuente importante de variaci\u00f3n relacionada con el hecho de que los grupos de pel\u00edculas tienen patrones de calificaci\u00f3n similares y los grupos de usuarios tambi\u00e9n tienen patrones de calificaci\u00f3n similares. Descubriremos estos patrones estudiando los residuos:\n\\[ r_{u,i} = y_{u,i} - \\hat{b}_i - \\hat{b}_u \\]\nPara ver esto, convertiremos los datos en una matriz para que cada usuario obtenga una fila, cada pel\u00edcula obtenga una columna y \\(y_{u,i}\\) sea la entrada en fila \\(u\\) y columna \\(i\\). Con fines ilustrativos, solo consideraremos un peque\u00f1o subconjunto de pel\u00edculas con muchas calificaciones y usuarios que han calificado muchas pel\u00edculas. Tambi\u00e9n inclu\u00edmos Scent of a Woman (\nmovieId == 3252) porque la usamos para un ejemplo espec\u00edfico:\n[train_small <- movielens |>] [group_by(movieId) |>] [filter(n() >= 50 | movieId == 3252) |> ungroup() |>] [group_by(userId) |>] [filter(n() >= 50) |> ungroup()] [y <- train_small |>] [select(userId, movieId, rating) |>] [pivot_wider(names_from = \"movieId\", values_from = \"rating\") |>] [as.matrix()]\nAgregamos nombres de fila y columna:\n[rownames(y)<- y[,1]] [y <- y[,-1]] [movie_titles <- movielens |>] [select(movieId, title) |>] [distinct()] [colnames(y) <- with(movie_titles, title[match(colnames(y), movieId)])]\ny los convertimos en residuos eliminando los efectos de columna y fila:\nSi el modelo anterior explica todas las se\u00f1ales, y los \\(\\varepsilon\\) son solo ruido, entonces los residuos para diferentes pel\u00edculas deben ser independientes entre s\u00ed. Pero no lo son. Aqu\u00ed hay unos ejemplos:\n[m_1 <- \"Godfather, The\"] [m_2 <- \"Godfather: Part II, The\"] [p1 <- qplot(y[ ,m_1], y[,m_2], xlab = m_1, ylab = m_2)] [m_1 <- \"Godfather, The\"] [m_3 <- \"Goodfellas\"] [p2 <- qplot(y[ ,m_1], y[,m_3], xlab = m_1, ylab = m_3)] [m_4 <- \"You've Got Mail\"] [m_5 <- \"Sleepless in Seattle\"] [p3 <- qplot(y[ ,m_4], y[,m_5], xlab = m_4, ylab = m_5)] [gridExtra::grid.arrange(p1, p2 ,p3, ncol = 3)]\nEstos gr\u00e1ficos muestran que a los usuarios que les gust\u00f3 The Godfather m\u00e1s de lo que el modelo espera de ellos, seg\u00fan la pel\u00edcula y los efectos del usuario, tambi\u00e9n les gust\u00f3 The Godfather II m\u00e1s de lo esperado. Se observa una relaci\u00f3n similar al comparar The Godfather y Goodfellas. Aunque no es tan fuerte, todav\u00eda hay correlaci\u00f3n. Tambi\u00e9n vemos correlaciones entre You\u2019ve Got Mail y Sleepless in Seattle.\nAl observar la correlaci\u00f3n entre pel\u00edculas, podemos ver un patr\u00f3n (cambiamos los nombres de las columnas para ahorrar espacio de impresi\u00f3n):\n[x <- y[, c(m_1, m_2, m_3, m_4, m_5)]] [short_names <- c(\"Godfather\", \"Godfather2\", \"Goodfellas\",] [\"You've Got\", \"Sleepless\")] [colnames(x) <- short_names] [cor(x, use=\"pairwise.complete\")] [#> Godfather Godfather2 Goodfellas You've Got Sleepless] [#> Godfather 1.000 0.829 0.444 -0.440 -0.378] [#> Godfather2 0.829 1.000 0.521 -0.331 -0.358] [#> Goodfellas 0.444 0.521 1.000 -0.481 -0.402] [#> You've Got -0.440 -0.331 -0.481 1.000 0.533] [#> Sleepless -0.378 -0.358 -0.402 0.533 1.000]\nParece que hay personas a las que les gustan las comedias rom\u00e1nticas m\u00e1s de lo esperado, mientras que hay otras personas a las que les gustan las pel\u00edculas de g\u00e1ngsters m\u00e1s de lo esperado.\nEstos resultados nos dicen que hay estructura en los datos. Pero, \u00bfc\u00f3mo podemos modelar esto?\n33.11.1 An\u00e1lisis de factores\nAqu\u00ed hay una ilustraci\u00f3n, usando una simulaci\u00f3n, de c\u00f3mo podemos usar un poco de estructura para predecir el \\(r_{u,i}\\). Supongan que nuestros residuos\nr se ven as\u00ed:\n[round(r, 1)] [#> Godfather Godfather2 Goodfellas You've Got Sleepless] [#> 1 2.0 2.3 2.2 -1.8 -1.9] [#> 2 2.0 1.7 2.0 -1.9 -1.7] [#> 3 1.9 2.4 2.1 -2.3 -2.0] [#> 4 -0.3 0.3 0.3 -0.4 -0.3] [#> 5 -0.3 -0.4 0.3 0.2 0.3] [#> 6 -0.1 0.1 0.2 -0.3 0.2] [#> 7 -0.1 0.0 -0.2 -0.2 0.3] [#> 8 0.2 0.2 0.1 0.0 0.4] [#> 9 -1.7 -2.1 -1.8 2.0 2.4] [#> 10 -2.3 -1.8 -1.7 1.8 1.7] [#> 11 -1.7 -2.0 -2.1 1.9 2.3] [#> 12 -1.8 -1.7 -2.1 2.3 2.0]\nParece que hay un patr\u00f3n aqu\u00ed. De hecho, podemos ver patrones de correlaci\u00f3n muy fuertes:\n[cor(r)] [#> Godfather Godfather2 Goodfellas You've Got Sleepless] [#> Godfather 1.000 0.980 0.978 -0.974 -0.966] [#> Godfather2 0.980 1.000 0.983 -0.987 -0.992] [#> Goodfellas 0.978 0.983 1.000 -0.986 -0.989] [#> You've Got -0.974 -0.987 -0.986 1.000 0.986] [#> Sleepless -0.966 -0.992 -0.989 0.986 1.000]\nPodemos crear vectores\nq y\np, que pueden explicar gran parte de la estructura que vemos. Los\nq se ver\u00edan as\u00ed:\ny reduce las pel\u00edculas a dos grupos: g\u00e1ngster (codificado con 1) y romance (codificado con -1). Tambi\u00e9n podemos reducir los usuarios a tres grupos:\nlos que les gustan las pel\u00edculas de g\u00e1ngsters y no les gustan las pel\u00edculas rom\u00e1nticas (codificadas como 2), los que les gustan las pel\u00edculas rom\u00e1nticas y no les gustan las pel\u00edculas de g\u00e1ngsters (codificadas como -2), y los que no les importa (codificadas como 0). El punto principal aqu\u00ed es que casi podemos reconstruir \\(r\\), que tiene 60 valores, con un par de vectores que totalizan 17 valores. Noten que\np y\nq son equivalentes a los patrones y pesos que describimos en la Secci\u00f3n\n[33.5.4](sets-grandes-de-datos.html#pca).\nSi \\(r\\) contiene los residuos para usuarios \\(u=1,\\dots,12\\) para peliculas \\(i=1,\\dots,5\\), podemos escribir la siguiente f\u00f3rmula matem\u00e1tica para nuestros residuos \\(r_{u,i}\\).\n\\[ r_{u,i} \\approx p_u q_i \\] Esto implica que podemos explicar m\u00e1s variabilidad modificando nuestro modelo anterior para recomendaciones de pel\u00edculas a:\n\\[ Y_{u,i} = \\mu + b_i + b_u + p_u q_i + \\varepsilon_{u,i} \\]\nSin embargo, motivamos la necesidad del t\u00e9rmino \\(p_u q_i\\) con una simulaci\u00f3n sencilla. La estructura que se encuentra en los datos suele ser m\u00e1s compleja. Por ejemplo, en esta primera simulaci\u00f3n supusimos que solo hab\u00eda un factor \\(p_u\\) que determinaba a cu\u00e1l de las dos pel\u00edculas de g\u00e9neros \\(u\\) pertenece. Pero la estructura en nuestros datos de pel\u00edculas parece ser mucho m\u00e1s complicada que las pel\u00edculas de g\u00e1ngsters versus las rom\u00e1nticas. Podemos tener muchos otros factores. Aqu\u00ed presentamos una simulaci\u00f3n un poco m\u00e1s compleja. Ahora agregamos una sexta pel\u00edcula.\n[round(r, 1)] [#> Godfather Godfather2 Goodfellas You've Got Sleepless Scent] [#> 1 0.5 0.6 1.6 -0.5 -0.5 -1.6] [#> 2 1.5 1.4 0.5 -1.5 -1.4 -0.4] [#> 3 1.5 1.6 0.5 -1.6 -1.5 -0.5] [#> 4 -0.1 0.1 0.1 -0.1 -0.1 0.1] [#> 5 -0.1 -0.1 0.1 0.0 0.1 -0.1] [#> 6 0.5 0.5 -0.4 -0.6 -0.5 0.5] [#> 7 0.5 0.5 -0.5 -0.6 -0.4 0.4] [#> 8 0.5 0.6 -0.5 -0.5 -0.4 0.4] [#> 9 -0.9 -1.0 -0.9 1.0 1.1 0.9] [#> 10 -1.6 -1.4 -0.4 1.5 1.4 0.5] [#> 11 -1.4 -1.5 -0.5 1.5 1.6 0.6] [#> 12 -1.4 -1.4 -0.5 1.6 1.5 0.6]\nAl explorar la estructura de correlaci\u00f3n de este nuevo set de datos:\n[colnames(r)[4:6] <- c(\"YGM\", \"SS\", \"SW\")] [cor(r)] [#> Godfather Godfather2 Goodfellas YGM SS SW] [#> Godfather 1.000 0.997 0.562 -0.997 -0.996 -0.571] [#> Godfather2 0.997 1.000 0.577 -0.998 -0.999 -0.583] [#> Goodfellas 0.562 0.577 1.000 -0.552 -0.583 -0.994] [#> YGM -0.997 -0.998 -0.552 1.000 0.998 0.558] [#> SS -0.996 -0.999 -0.583 0.998 1.000 0.588] [#> SW -0.571 -0.583 -0.994 0.558 0.588 1.000]\nnotamos que quiz\u00e1s necesitamos un segundo factor para tomar en cuenta el hecho de que a algunos usuarios les gusta Al Pacino, mientras que a otros no les gusta o no les importa. Observen que la estructura general de la correlaci\u00f3n obtenida de los datos simulados no est\u00e1 tan lejos de la correlaci\u00f3n real:\n[six_movies <- c(m_1, m_2, m_3, m_4, m_5, m_6)] [x <- y[, six_movies]] [colnames(x) <- colnames(r)] [cor(x, use=\"pairwise.complete\")] [#> Godfather Godfather2 Goodfellas YGM SS SW] [#> Godfather 1.0000 0.829 0.444 -0.440 -0.378 0.0589] [#> Godfather2 0.8285 1.000 0.521 -0.331 -0.358 0.1186] [#> Goodfellas 0.4441 0.521 1.000 -0.481 -0.402 -0.1230] [#> YGM -0.4397 -0.331 -0.481 1.000 0.533 -0.1699] [#> SS -0.3781 -0.358 -0.402 0.533 1.000 -0.1822] [#> SW 0.0589 0.119 -0.123 -0.170 -0.182 1.0000]\nPara explicar esta estructura m\u00e1s complicada, necesitamos dos factores. Por ejemplo, algo como lo siguiente:\n[t(q)] [#> Godfather Godfather2 Goodfellas You've Got Sleepless Scent] [#> [1,] 1 1 1 -1 -1 -1] [#> [2,] 1 1 -1 -1 -1 1]\ncon el primer factor (la primera fila) utilizado para codificar las pel\u00edculas de g\u00e1ngster versus las pel\u00edculas rom\u00e1nticas y un segundo factor (la segunda fila) para explicar los grupos de pel\u00edculas con Al Pacino versus los grupos sin Al Pacino. Tambi\u00e9n necesitaremos dos sets de coeficientes para explicar la variabilidad introducida por los tipos de grupos \\(3\\times 3\\):\n[t(p)] [#> 1 2 3 4 5 6 7 8 9 10 11 12] [#> [1,] 1.0 1.0 1.0 0 0 0.0 0.0 0.0 -1 -1.0 -1.0 -1.0] [#> [2,] -0.5 0.5 0.5 0 0 0.5 0.5 0.5 0 -0.5 -0.5 -0.5]\nEl modelo con dos factores tiene 36 par\u00e1metros que se pueden usar para explicar gran parte de la variabilidad en las 72 clasificaciones:\n\\[ Y_{u,i} = \\mu + b_i + b_u + p_{u,1} q_{1,i} + p_{u,2} q_{2,i} + \\varepsilon_{u,i} \\]\nTengan en cuenta que en una aplicaci\u00f3n de datos real, necesitamos ajustar este modelo a los datos. Para explicar la correlaci\u00f3n compleja que observamos en datos reales, generalmente permitimos que las entradas de \\(p\\) y \\(q\\) sean valores continuos, en lugar de discretos como las que usamos en la simulaci\u00f3n. Por ejemplo, en lugar de dividir las pel\u00edculas en g\u00e1ngster o romance, definimos un continuo. Adem\u00e1s, recuerden que este no es un modelo lineal y para ajustarlo necesitamos usar un algoritmo diferente a ese usado por\nlm para encontrar los par\u00e1metros que minimizan los m\u00ednimos cuadrados. Los algoritmos ganadores del Netflix challenge ajustaron un modelo similar al anterior y utilizaron la regularizaci\u00f3n para penalizar por grandes valores de \\(p\\) y \\(q\\), en lugar de usar m\u00ednimos cuadrados. Implementar este enfoque est\u00e1 m\u00e1s all\u00e1 del alcance de este libro.\n33.11.2 Conexi\u00f3n a SVD y PCA\nLa descomposici\u00f3n:\n\\[ r_{u,i} \\approx p_{u,1} q_{1,i} + p_{u,2} q_{2,i} \\]\nest\u00e1 muy relacionada a SVD y PCA. SVD y PCA son conceptos complicados, pero una forma de entenderlos es que SVD es un algoritmo que encuentra los vectores \\(p\\) y \\(q\\) que nos permiten reescribir la matriz \\(\\mbox{r}\\) con \\(m\\) filas y \\(n\\) columnas como:\n\\[ r_{u,i} = p_{u,1} q_{1,i} + p_{u,2} q_{2,i} + \\dots + p_{u,n} q_{n,i} \\]\ncon la variabilidad de cada t\u00e9rmino disminuyendo y con las \\(p\\)s no correlacionadas. El algoritmo tambi\u00e9n calcula esta variabilidad para que podamos saber cu\u00e1nta de la variabilidad total de las matrices se explica a medida que vayamos agregando nuevos t\u00e9rminos. Esto nos deja ver que, con solo unos pocos t\u00e9rminos, podemos explicar la mayor parte de la variabilidad.\nVeamos un ejemplo con los datos de la pel\u00edcula. Para calcular la descomposici\u00f3n, haremos que los residuos con NAs sean iguales a 0:\nLos vectores \\(q\\) se denominan componentes principales y se almacenan en esta matriz:\nMientras que la \\(p\\), o los efectos del usuario, est\u00e1n aqu\u00ed:\nPodemos ver la variabilidad de cada uno de los vectores:\nTambi\u00e9n notamos que los dos primeros componentes principales est\u00e1n relacionados a la estructura en las opiniones sobre pel\u00edculas:\nCon solo mirar los 10 primeros en cada direcci\u00f3n, vemos un patr\u00f3n significativo. El primer PC muestra la diferencia entre las pel\u00edculas aclamadas por la cr\u00edtica en un lado:\n#> [1] \"Pulp Fiction\" \"Seven (a.k.a. Se7en)\" #> [3] \"Fargo\" \"2001: A Space Odyssey\" #> [5] \"Silence of the Lambs, The\" \"Clockwork Orange, A\" #> [7] \"Taxi Driver\" \"Being John Malkovich\" #> [9] \"Royal Tenenbaums, The\" \"Shining, The\"\ny los \u00e9xitos de taquilla de Hollywood en otro:\n#> [1] \"Independence Day (a.k.a. ID4)\" \"Shrek\" #> [3] \"Spider-Man\" \"Titanic\" #> [5] \"Twister\" \"Armageddon\" #> [7] \"Harry Potter and the Sorcer...\" \"Forrest Gump\" #> [9] \"Lord of the Rings: The Retu...\" \"Enemy of the State\"\nMientras que el segundo PC parece ir de pel\u00edculas art\u00edsticas e independientes:\n#> [1] \"Shawshank Redemption, The\" \"Truman Show, The\" #> [3] \"Little Miss Sunshine\" \"Slumdog Millionaire\" #> [5] \"Amelie (Fabuleux destin d'A...\" \"Kill Bill: Vol. 1\" #> [7] \"American Beauty\" \"City of God (Cidade de Deus)\" #> [9] \"Mars Attacks!\" \"Beautiful Mind, A\"\nhacia favoritas de los nerds:\n#> [1] \"Lord of the Rings: The Two ...\" \"Lord of the Rings: The Fell...\" #> [3] \"Lord of the Rings: The Retu...\" \"Matrix, The\" #> [5] \"Star Wars: Episode IV - A N...\" \"Star Wars: Episode VI - Ret...\" #> [7] \"Star Wars: Episode V - The ...\" \"Spider-Man 2\" #> [9] \"Dark Knight, The\" \"Speed\"\nAjustar un modelo que incorpora estos estimadores es complicado. Para aquellos interesados en implementar un enfoque que incorpore estas ideas, recomendamos el paquete recommenderlab. Los detalles est\u00e1n m\u00e1s all\u00e1 del alcance de este libro.\n33.12 Ejercicios\nEn este set de ejercicios, trataremos un tema \u00fatil para comprender la factorizaci\u00f3n de matrices: la descomposici\u00f3n de valores singulares (singular value decomposition o SVD por sus siglas en ingl\u00e9s). SVD es un resultado matem\u00e1tico que se usa ampliamente en machine learning, tanto en la pr\u00e1ctica como para comprender las propiedades matem\u00e1ticas de algunos algoritmos. Este es un tema bastante avanzado y para completar este set de ejercicios tendr\u00e1n que estar familiarizados con conceptos de \u00e1lgebra lineal, como la multiplicaci\u00f3n de matrices, las matrices ortogonales y las matrices diagonales.\nEl SVD nos dice que podemos descomponer un \\(N\\times p\\) matriz \\(Y\\) con \\(p < N\\) como:\n\\[ Y = U D V^{\\top} \\]\ncon \\(U\\) y \\(V\\) ortogonal de dimensiones \\(N\\times p\\) y \\(p\\times p\\), respectivamente, y \\(D\\) un \\(p \\times p\\) matriz diagonal con los valores de la diagonal decreciendo:\n\\[d_{1,1} \\geq d_{2,2} \\geq \\dots d_{p,p}.\\]\nEn este ejercicio, veremos una de las formas en que esta descomposici\u00f3n puede ser \u00fatil. Para hacer esto, construiremos un set de datos que representa las calificaciones de 100 estudiantes en 24 materias diferentes. El promedio general se ha eliminado, por lo que estos datos representan el punto porcentual que cada estudiante recibi\u00f3 por encima o por debajo de la puntuaci\u00f3n promedio de la prueba. Entonces un 0 representa una calificaci\u00f3n promedio (C), un 25 es una calificaci\u00f3n alta (A +) y un -25 representa una calificaci\u00f3n baja (F). Puede simular los datos de esta manera:\n[set.seed(1987)] [n <- 100] [k <- 8] [Sigma <- 64 * matrix(c(1, .75, .5, .75, 1, .5, .5, .5, 1), 3, 3)] [m <- MASS::mvrnorm(n, rep(0, 3), Sigma)] [m <- m[order(rowMeans(m), decreasing = TRUE),]] [y <- m %x% matrix(rep(1, k), nrow = 1) +] [matrix(rnorm(matrix(n * k * 3)), n, k * 3)] [colnames(y) <- c(paste(rep(\"Math\",k), 1:k, sep=\"_\"),] [paste(rep(\"Science\",k), 1:k, sep=\"_\"),] [paste(rep(\"Arts\",k), 1:k, sep=\"_\"))]\nNuestro objetivo es describir el desempe\u00f1o de los estudiantes de la manera m\u00e1s sucinta posible. Por ejemplo, queremos saber si los resultados de estas pruebas son solo n\u00fameros independientes aleatorios. \u00bfTodos los estudiantes son igual de buenos? \u00bfSer bueno en un tema implica ser bueno en otro? \u00bfC\u00f3mo ayuda el SVD con todo esto? Iremos paso a paso para mostrar que con solo tres pares relativamente peque\u00f1os de vectores podemos explicar gran parte de la variabilidad en este \\(100 \\times 24\\) set de datos.\nPuede visualizar las 24 puntuaciones de las pruebas para los 100 estudiantes al graficar una imagen:\n[my_image <- function(x, zlim = range(x), ...){] [colors = rev(RColorBrewer::brewer.pal(9, \"RdBu\"))] [cols <- 1:ncol(x)] [rows <- 1:nrow(x)] [image(cols, rows, t(x[rev(rows),,drop=FALSE]), xaxt = \"n\", yaxt = \"n\",] [xlab=\"\", ylab=\"\", col = colors, zlim = zlim, ...)] [abline(h=rows + 0.5, v = cols + 0.5)] [axis(side = 1, cols, colnames(x), las = 2)] [}] [my_image(y)]\n1. \u00bfC\u00f3mo describir\u00eda los datos basados en esta figura?\n- Las puntuaciones de las pruebas son independientes entre s\u00ed.\n- Los estudiantes que eval\u00faan bien est\u00e1n en la parte superior de la imagen y parece que hay tres agrupaciones por materia.\n- Los estudiantes que son buenos en matem\u00e1ticas no son buenos en ciencias.\n- Los estudiantes que son buenos en matem\u00e1ticas no son buenos en humanidades.\n2. Puede examinar la correlaci\u00f3n entre las puntuaciones de la prueba directamente de esta manera:\n\u00bfCu\u00e1l de las siguientes opciones describe mejor lo que ve?\n- Las puntuaciones de las pruebas son independientes.\n- Las matem\u00e1ticas y las ciencias est\u00e1n altamente correlacionadas, pero las humanidades no.\n- Existe una alta correlaci\u00f3n entre las pruebas en la misma materia pero no hay correlaci\u00f3n entre las materias.\n- Hay una correlaci\u00f3n entre todas las pruebas, pero es mayor si las pruebas son de ciencias y matem\u00e1ticas e incluso mayor dentro de cada materia.\n3. Recuerde que la ortogonalidad significa que \\(U^{\\top}U\\) y \\(V^{\\top}V\\) son iguales a la matriz de identidad. Esto implica que tambi\u00e9n podemos reescribir la descomposici\u00f3n como:\n\\[ Y V = U D \\mbox{ or } U^{\\top}Y = D V^{\\top}\\]\nPodemos pensar en \\(YV\\) y \\(U^{\\top}V\\) como dos transformaciones de Y que preservan la variabilidad total de \\(Y\\) ya que \\(U\\) y \\(V\\) son ortogonales.\nUse la funci\u00f3n\nsvd para calcular el SVD de\ny. Esta funci\u00f3n devolver\u00e1 \\(U\\), \\(V\\) y las entradas diagonales de \\(D\\).\nPuede verificar que el SVD funciona al escribir:\nCalcule la suma de cuadrados de las columnas de \\(Y\\) y gu\u00e1rdelas en\nss_y. Luego calcule la suma de cuadrados de columnas del transformado \\(YV\\) y gu\u00e1rdelas en\nss_yv. Confirme que\nsum(ss_y) es igual a\nsum(ss_yv).\n4. Vemos que se conserva la suma total de cuadrados. Esto es porque \\(V\\) es ortogonal. Ahora para comenzar a entender c\u00f3mo \\(YV\\) es \u00fatil, grafique\nss_y contra el n\u00famero de columna y luego haga lo mismo para\nss_yv. \u00bfQu\u00e9 observa?\n5. Vemos que la variabilidad de las columnas de \\(YV\\) est\u00e1 disminuyendo. Adem\u00e1s, vemos que, en relaci\u00f3n con los tres primeros, la variabilidad de las columnas m\u00e1s all\u00e1 del tercero es casi 0. Ahora observe que no tuvimos que calcular\nss_yv porque ya tenemos la respuesta \u00bfC\u00f3mo? Recuerde que \\(YV = UD\\) y como \\(U\\) es ortogonal, sabemos que la suma de cuadrados de las columnas de \\(UD\\) son las entradas diagonales de \\(D\\) al cuadrado. Confirme esto graficando la ra\u00edz cuadrada de\nss_yv versus las entradas diagonales de \\(D\\).\n6. De lo anterior, sabemos que la suma de cuadrados de las columnas de \\(Y\\) (la suma total de cuadrados) se a\u00f1ade a la suma de\ns$d^2 y que la transformaci\u00f3n \\(YV\\) nos da columnas con sumas de cuadrados iguales a\ns$d^2. Ahora calcule qu\u00e9 porcentaje de la variabilidad total se explica solo por las tres primeras columnas de \\(YV\\).\n7. Vemos que casi el 99% de la variabilidad se explica por las primeras tres columnas de \\(YV = UD\\). Entonces esto implica que deber\u00edamos poder explicar gran parte de la variabilidad y estructura que encontramos al explorar los datos con unas pocas columnas. Antes de continuar, vamos a mostrar un truco computacional \u00fatil para evitar crear la matriz\ndiag(s$d). Para motivar esto, notamos que si escribimos \\(U\\) en sus columnas \\([U_1, U_2,\\dots, U_p]\\), entonces \\(UD\\) es igual a:\n\\[UD = [U_1 d_{1,1}, U_2 d_{2,2}, \\dots, U_p d_{p,p}]\\]\nUtilice la funci\u00f3n\nsweep para calcular \\(UD\\) sin construir\ndiag(s$d) y sin usar multiplicaci\u00f3n de matrices.\n8. Sabemos que \\(U_1 d_{1,1}\\), la primera columna de \\(UD\\), tiene la mayor variabilidad de todas las columnas de \\(UD\\). Anteriormente vimos una imagen de \\(Y\\):\nen la que podemos ver que la variabilidad de estudiante a estudiante es bastante grande y que parece que los estudiantes que son buenos en una materia son buenos en todas. Esto implica que el promedio (en todas las materias) de cada alumno debe explicar en gran medida la variabilidad. Calcule la puntuaci\u00f3n promedio de cada estudiante y graf\u00edquelo contra \\(U_1 d_{1,1}\\). Describa lo que encuentra.\n9. Notamos que los signos en SVD son arbitrarios porque:\n\\[ U D V^{\\top} = (-U) D (-V)^{\\top} \\]\nCon esto en mente, vemos que la primera columna de \\(UD\\) es casi id\u00e9ntica a la puntuaci\u00f3n promedio de cada estudiante, excepto por el signo.\nEsto implica que multiplicar \\(Y\\) por la primera columna de \\(V\\) debe realizar una operaci\u00f3n similar a tomar el promedio. Haga un gr\u00e1fico de imagen de \\(V\\) y describa la primera columna en relaci\u00f3n con las otras y c\u00f3mo se relaciona esto con tomar un promedio.\n10. Ya vimos que podemos reescribir \\(UD\\) como:\n\\[U_1 d_{1,1} + U_2 d_{2,2} + \\dots + U_p d_{p,p}\\]\ncon \\(U_j\\) la columna j de \\(U\\). Esto implica que podemos reescribir todo el SVD como:\n\\[Y = U_1 d_{1,1} V_1 ^{\\top} + U_2 d_{2,2} V_2 ^{\\top} + \\dots + U_p d_{p,p} V_p ^{\\top}\\]\ncon \\(V_j\\) la columna j de \\(V\\). Grafique \\(U_1\\), luego grafique \\(V_1^{\\top}\\) usando el mismo rango para los l\u00edmites del eje y, entonces haga una imagen de \\(U_1 d_{1,1} V_1 ^{\\top}\\) y comp\u00e1rela con la imagen de \\(Y\\). Sugerencia: use la funci\u00f3n\nmy_image definida anteriormente y el argumento\ndrop=FALSE para asegurar que los subconjuntos de matrices son matrices.\n11. Vemos que con solo un vector de longitud 100, un escalar y un vector de longitud 24, nos acercamos a reconstruir la matriz \\(100 \\times 24\\) original. Esta es nuestra primera factorizaci\u00f3n de matrices:\n\\[ Y \\approx d_{1,1} U_1 V_1^{\\top}\\]\nSabemos que explica\ns $d[1]^2/sum(s$ d^2) * 100 por ciento de la variabilidad total. Nuestra aproximaci\u00f3n solo explica la observaci\u00f3n de que los buenos estudiantes tienden a ser buenos en todas las materias. Pero otro aspecto de los datos originales que nuestra aproximaci\u00f3n no explica es la mayor similitud que observamos dentro de las materias. Podemos ver esto calculando la diferencia entre nuestra aproximaci\u00f3n y los datos originales y luego calculando las correlaciones. Pueden ver esto ejecutando este c\u00f3digo:\n[resid <- y - with(s,(u[,1, drop=FALSE]*d[1]) %*% t(v[,1, drop=FALSE]))] [my_image(cor(resid), zlim = c(-1,1))] [axis(side = 2, 1:ncol(y), rev(colnames(y)), las = 2)]\nAhora que hemos eliminado el efecto general del estudiante, el gr\u00e1fico de correlaci\u00f3n revela que todav\u00eda no hemos explicado la correlaci\u00f3n interna de la materia ni el hecho de que las puntuaciones en matem\u00e1ticas y ciencias son m\u00e1s parecidas entre s\u00ed que a las puntuaciones en las artes. As\u00ed que exploremos la segunda columna del SVD. Repita el ejercicio anterior pero para la segunda columna: grafique \\(U_2\\), entonces grafique \\(V_2^{\\top}\\) usando el mismo rango para los l\u00edmites del eje y, finalmente haga una imagen de \\(U_2 d_{2,2} V_2 ^{\\top}\\) y comp\u00e1rela con la imagen de\nresid.\n12. La segunda columna se relaciona claramente con la diferencia de habilidad del estudiante en matem\u00e1ticas/ciencias versus las artes. Podemos ver esto m\u00e1s claramente en el gr\u00e1fico de\ns$v[,2]. Sumar las matrices resultantes usando estas dos columnas ayudar\u00e1 con nuestra aproximaci\u00f3n:\n\\[ Y \\approx d_{1,1} U_1 V_1^{\\top} + d_{2,2} U_2 V_2^{\\top} \\]\nSabemos que explicar\u00e1:\nporcentaje de la variabilidad total. Podemos calcular nuevos residuos as\u00ed:\n[resid <- y - with(s,sweep(u[,1:2], 2, d[1:2], FUN=\"*\") %*% t(v[,1:2]))] [my_image(cor(resid), zlim = c(-1,1))] [axis(side = 2, 1:ncol(y), rev(colnames(y)), las = 2)]\ny ver que la estructura que queda es impulsada por las diferencias entre matem\u00e1ticas y ciencias. Confirme esto graficando \\(U_3\\), luego grafique \\(V_3^{\\top}\\) usando el mismo rango para los l\u00edmites del eje y, luego haga una imagen de \\(U_3 d_{3,3} V_3 ^{\\top}\\) y comp\u00e1rela con la imagen de\nresid.\n13. La tercera columna se relaciona claramente con la diferencia de habilidad del estudiante en matem\u00e1ticas y ciencias. Podemos ver esto m\u00e1s claramente en el gr\u00e1fico de\ns$v[,3]. Agregar la matriz que obtenemos con estas dos columnas ayudar\u00e1 con nuestra aproximaci\u00f3n:\n\\[ Y \\approx d_{1,1} U_1 V_1^{\\top} + d_{2,2} U_2 V_2^{\\top} + d_{3,3} U_3 V_3^{\\top}\\]\nSabemos que explicar\u00e1:\nporcentaje de la variabilidad total. Podemos calcular nuevos residuos como este:\n[resid <- y - with(s,sweep(u[,1:3], 2, d[1:3], FUN=\"*\") %*% t(v[,1:3]))] [my_image(cor(resid), zlim = c(-1,1))] [axis(side = 2, 1:ncol(y), rev(colnames(y)), las = 2)]\nYa no vemos estructura en los residuos: parecen ser independientes entre s\u00ed. Esto implica que podemos describir los datos con el siguiente modelo:\n\\[ Y = d_{1,1} U_1 V_1^{\\top} + d_{2,2} U_2 V_2^{\\top} + d_{3,3} U_3 V_3^{\\top} + \\varepsilon\\]\ncon \\(\\varepsilon\\) una matriz de errores independientes id\u00e9nticamente distribuidos. Este modelo es \u00fatil porque resumimos \\(100 \\times 24\\) observaciones con \\(3 \\times (100+24+1) = 375\\) n\u00fameros. Adem\u00e1s, los tres componentes del modelo tienen interpretaciones \u00fatiles: 1) la capacidad general de un estudiante, 2) la diferencia en la habilidad entre las matem\u00e1ticas/ciencias y las artes, y 3) las diferencias restantes entre las tres materias. Los tama\u00f1os \\(d_{1,1}, d_{2,2}\\) y \\(d_{3,3}\\) nos dicen la variabilidad explicada por cada componente. Finalmente, tengan en cuenta que los componentes \\(d_{j,j} U_j V_j^{\\top}\\) son equivalentes al componente principal j.\nTermine el ejercicio graficando una imagen de \\(Y\\), una imagen de \\(d_{1,1} U_1 V_1^{\\top} + d_{2,2} U_2 V_2^{\\top} + d_{3,3} U_3 V_3^{\\top}\\) y una imagen de los residuos, todos con el mismo\nzlim.\n14. Avanzado: El set de datos\nmovielens incluido en el paquete dslabs es un peque\u00f1o subconjunto de un set de datos m\u00e1s grande con millones de clasificaciones. Puede encontrar el set de datos m\u00e1s reciente aqu\u00ed:\n[https://grouplens.org/datasets/movielens/20m/](https://grouplens.org/datasets/movielens/20m/). Cree su propio sistema de recomendaciones utilizando todas las herramientas que le hemos mostrado.", "language": null, "image": null, "pagetype": "book", "links": ["./", "index.html", "agradecimientos.html", "introducci\u00f3n.html", "introducci\u00f3n.html#los-casos-de-estudio", "introducci\u00f3n.html#qui\u00e9n-encontrar\u00e1-\u00fatil-este-libro", "introducci\u00f3n.html#que-cubre-este-libro", "introducci\u00f3n.html#qu\u00e9-no-cubre-este-libro", "getting-started.html", "getting-started.html#por-qu\u00e9-r", "getting-started.html#la-consola-r", "getting-started.html#scripts", "getting-started.html#rstudio", "getting-started.html#paneles", "getting-started.html#atajos-de-teclado", "getting-started.html#c\u00f3mo-ejecutar-comandos-mientras-editan-scripts", "getting-started.html#c\u00f3mo-cambiar-las-opciones-globales", "getting-started.html#instalaci\u00f3n-de-paquetes-de-r", "r-basics.html", "r-basics.html#caso-de-estudio-los-asesinatos-con-armas-en-ee.-uu.", "r-basics.html#lo-b\u00e1sico", "r-basics.html#objetos", "r-basics.html#el-espacio-de-trabajo", "r-basics.html#funciones", "r-basics.html#otros-objetos-predefinidos", "r-basics.html#nombres-de-variables", "r-basics.html#c\u00f3mo-guardar-su-espacio-de-trabajo", "r-basics.html#scripts-motivantes", "r-basics.html#c\u00f3mo-comentar-su-c\u00f3digo", "r-basics.html#ejercicios", "r-basics.html#tipos-de-datos", "r-basics.html#data-frames", "r-basics.html#c\u00f3mo-examinar-un-objeto", "r-basics.html#el-operador-de-acceso", "r-basics.html#vectores-num\u00e9ricos-de-caracteres-y-l\u00f3gicos", "r-basics.html#factors", "r-basics.html#listas", "r-basics.html#matrices", "r-basics.html#ejercicios-1", "r-basics.html#vectors", "r-basics.html#c\u00f3mo-crear-vectores", "r-basics.html#nombres", "r-basics.html#secuencias", "r-basics.html#c\u00f3mo-crear-un-subconjunto", "r-basics.html#la-conversi\u00f3n-forzada", "r-basics.html#not-available-na", "r-basics.html#ejercicios-2", "r-basics.html#sorting", "r-basics.html#sort", "r-basics.html#order", "r-basics.html#max-y-which.max", "r-basics.html#rank", "r-basics.html#cuidado-con-el-reciclaje", "r-basics.html#ejercicios-3", "r-basics.html#aritm\u00e9tica-de-vectores", "r-basics.html#rescaling-un-vector", "r-basics.html#dos-vectores", "r-basics.html#ejercicios-4", "r-basics.html#indexaci\u00f3n", "r-basics.html#c\u00f3mo-crear-subconjuntos-con-l\u00f3gicos", "r-basics.html#operadores-l\u00f3gicos", "r-basics.html#which", "r-basics.html#match", "r-basics.html#in", "r-basics.html#ejercicios-5", "r-basics.html#gr\u00e1ficos-b\u00e1sicos", "r-basics.html#plot", "r-basics.html#hist", "r-basics.html#boxplot", "r-basics.html#image", "r-basics.html#ejercicios-6", "conceptos-b\u00e1sicos-de-programaci\u00f3n.html", "conceptos-b\u00e1sicos-de-programaci\u00f3n.html#conditionals", "conceptos-b\u00e1sicos-de-programaci\u00f3n.html#c\u00f3mo-definir-funciones", "conceptos-b\u00e1sicos-de-programaci\u00f3n.html#namespaces", "conceptos-b\u00e1sicos-de-programaci\u00f3n.html#bucles-for", "conceptos-b\u00e1sicos-de-programaci\u00f3n.html#vectorization", "conceptos-b\u00e1sicos-de-programaci\u00f3n.html#ejercicios-7", "tidyverse.html", "tidyverse.html#tidy-data", "tidyverse.html#ejercicios-8", "tidyverse.html#c\u00f3mo-manipular-los-data-frames", "tidyverse.html#c\u00f3mo-a\u00f1adir-una-columna-con-mutate", "tidyverse.html#c\u00f3mo-crear-subconjuntos-con-filter", "tidyverse.html#c\u00f3mo-seleccionar-columnas-con-select", "tidyverse.html#ejercicios-9", "tidyverse.html#el-pipe-o", "tidyverse.html#ejercicios-10", "tidyverse.html#c\u00f3mo-resumir-datos", "tidyverse.html#summarize", "tidyverse.html#res\u00famenes-m\u00faltiples", "tidyverse.html#group-by", "tidyverse.html#pull", "tidyverse.html#c\u00f3mo-ordenar-los-data-frames", "tidyverse.html#c\u00f3mo-ordenar-anidadamente", "tidyverse.html#los-primeros-n", "tidyverse.html#ejercicios-11", "tidyverse.html#tibbles", "tidyverse.html#los-tibbles-se-ven-mejor", "tidyverse.html#los-subconjuntos-de-tibbles-son-tibbles", "tidyverse.html#los-tibbles-pueden-tener-entradas-complejas", "tidyverse.html#los-tibbles-se-pueden-agrupar", "tidyverse.html#c\u00f3mo-crear-un-tibble-usando-tibble-en-lugar-de-data.frame", "tidyverse.html#el-marcador-de-posici\u00f3n", "tidyverse.html#el-paquete-purrr", "tidyverse.html#los-condicionales-de-tidyverse", "tidyverse.html#case_when", "tidyverse.html#between", "tidyverse.html#ejercicios-12", "importing-data.html", "importing-data.html#las-rutas-y-el-directorio-de-trabajo", "importing-data.html#el-sistema-de-archivos", "importing-data.html#las-rutas-relativas-y-completas", "importing-data.html#el-directorio-de-trabajo", "importing-data.html#c\u00f3mo-generar-los-nombres-de-ruta", "importing-data.html#c\u00f3mo-copiar-los-archivos-usando-rutas", "importing-data.html#los-paquetes-readr-y-readxl", "importing-data.html#readr", "importing-data.html#readxl", "importing-data.html#ejercicios-13", "importing-data.html#c\u00f3mo-descargar-archivos", "importing-data.html#las-funciones-de-importaci\u00f3n-de-base-r", "importing-data.html#scan", "importing-data.html#archivos-de-texto-versus-archivos-binarios", "importing-data.html#unicode-versus-ascii", "importing-data.html#c\u00f3mo-organizar-datos-con-hojas-de-c\u00e1lculo", "importing-data.html#ejercicios-14", "introducci\u00f3n-a-la-visualizaci\u00f3n-de-datos.html", "ggplot2.html", "ggplot2.html#los-componentes-de-un-gr\u00e1fico", "ggplot2.html#objetos-ggplot", "ggplot2.html#geometr\u00edas", "ggplot2.html#mapeos-est\u00e9ticos", "ggplot2.html#capas", "ggplot2.html#c\u00f3mo-probar-varios-argumentos", "ggplot2.html#mapeos-est\u00e9ticos-globales-versus-locales", "ggplot2.html#escalas", "ggplot2.html#etiquetas-y-t\u00edtulos", "ggplot2.html#categor\u00edas-como-colores", "ggplot2.html#anotaci\u00f3n-formas-y-ajustes", "ggplot2.html#add-on-packages", "ggplot2.html#c\u00f3mo-combinarlo-todo", "ggplot2.html#qplot", "ggplot2.html#cuadr\u00edculas-de-gr\u00e1ficos", "ggplot2.html#ejercicios-15", "distributions.html", "distributions.html#tipos-de-variables", "distributions.html#estudio-de-caso-describiendo-alturas-de-estudiantes", "distributions.html#la-funci\u00f3n-de-distribuci\u00f3n", "distributions.html#cdf-intro", "distributions.html#histogramas", "distributions.html#densidad-suave", "distributions.html#c\u00f3mo-interpretar-el-eje-y", "distributions.html#densidades-permiten-estratificaci\u00f3n", "distributions.html#ejercicios-16", "distributions.html#normal-distribution", "distributions.html#unidades-est\u00e1ndar", "distributions.html#gr\u00e1ficos-q-q", "distributions.html#percentiles", "distributions.html#diagramas-de-caja", "distributions.html#stratification", "distributions.html#student-height-cont", "distributions.html#ejercicios-17", "distributions.html#other-geometries", "distributions.html#diagramas-de-barras", "distributions.html#histogramas-1", "distributions.html#gr\u00e1ficos-de-densidad", "distributions.html#diagramas-de-caja-1", "distributions.html#gr\u00e1ficos-q-q-1", "distributions.html#im\u00e1genes", "distributions.html#gr\u00e1ficos-r\u00e1pidos", "distributions.html#ejercicios-18", "gapminder.html", "gapminder.html#estudio-de-caso-nuevas-ideas-sobre-la-pobreza", "gapminder.html#la-prueba-de-hans-rosling", "gapminder.html#diagramas-de-dispersi\u00f3n", "gapminder.html#separar-en-facetas", "gapminder.html#facet_wrap", "gapminder.html#escalas-fijas-para-mejores-comparaciones", "gapminder.html#gr\u00e1ficos-de-series-de-tiempo", "gapminder.html#etiquetas-en-lugar-de-leyendas", "gapminder.html#transformaciones-de-datos", "gapminder.html#transformaci\u00f3n-logar\u00edtmica", "gapminder.html#qu\u00e9-base", "gapminder.html#transformar-los-valores-o-la-escala", "gapminder.html#c\u00f3mo-visualizar-distribuciones-multimodales", "gapminder.html#c\u00f3mo-comparar-m\u00faltiples-distribuciones-con-diagramas-de-caja-y-gr\u00e1ficos-ridge", "gapminder.html#diagramas-de-caja-2", "gapminder.html#gr\u00e1ficos-ridge", "gapminder.html#ejemplo-distribuciones-de-ingresos-de-1970-versus-2010", "gapminder.html#c\u00f3mo-obtener-acceso-a-variables-calculadas", "gapminder.html#densidades-ponderadas", "gapminder.html#la-falacia-ecol\u00f3gica-y-la-importancia-de-mostrar-los-datos", "gapminder.html#logit", "gapminder.html#mostrar-los-datos", "principios-de-visualizaci\u00f3n-de-datos.html", "principios-de-visualizaci\u00f3n-de-datos.html#c\u00f3mo-codificar-datos-utilizando-se\u00f1ales-visuales", "principios-de-visualizaci\u00f3n-de-datos.html#cu\u00e1ndo-incluir-0", "principios-de-visualizaci\u00f3n-de-datos.html#no-distorsionar-cantidades", "principios-de-visualizaci\u00f3n-de-datos.html#ordenar-categor\u00edas-por-un-valor-significativo", "principios-de-visualizaci\u00f3n-de-datos.html#mostrar-los-datos-1", "principios-de-visualizaci\u00f3n-de-datos.html#c\u00f3mo-facilitar-comparaciones", "principios-de-visualizaci\u00f3n-de-datos.html#usen-ejes-comunes", "principios-de-visualizaci\u00f3n-de-datos.html#alineen-gr\u00e1ficos-verticalmente-para-ver-cambios-horizontales-y-horizontalmente-para-ver-cambios-verticales", "principios-de-visualizaci\u00f3n-de-datos.html#consideren-transformaciones", "principios-de-visualizaci\u00f3n-de-datos.html#se\u00f1ales-visuales-comparadas-deben-estar-adyacentes", "principios-de-visualizaci\u00f3n-de-datos.html#usen-color", "principios-de-visualizaci\u00f3n-de-datos.html#consideren-los-dalt\u00f3nicos", "principios-de-visualizaci\u00f3n-de-datos.html#gr\u00e1ficos-para-dos-variables", "principios-de-visualizaci\u00f3n-de-datos.html#slope-charts", "principios-de-visualizaci\u00f3n-de-datos.html#gr\u00e1fico-bland-altman", "principios-de-visualizaci\u00f3n-de-datos.html#c\u00f3mo-codificar-una-tercera-variable", "principios-de-visualizaci\u00f3n-de-datos.html#eviten-los-gr\u00e1ficos-pseudo-tridimensionales", "principios-de-visualizaci\u00f3n-de-datos.html#eviten-demasiados-d\u00edgitos-significativos", "principios-de-visualizaci\u00f3n-de-datos.html#consideren-a-su-audiencia", "principios-de-visualizaci\u00f3n-de-datos.html#ejercicios-19", "principios-de-visualizaci\u00f3n-de-datos.html#vaccines", "principios-de-visualizaci\u00f3n-de-datos.html#ejercicios-20", "robust-summaries.html", "robust-summaries.html#valores-at\u00edpicos", "robust-summaries.html#mediana", "robust-summaries.html#el-rango-intercuartil-iqr", "robust-summaries.html#la-definici\u00f3n-de-tukey-de-un-valor-at\u00edpico", "robust-summaries.html#desviaci\u00f3n-absoluta-mediana", "robust-summaries.html#ejercicios-21", "robust-summaries.html#estudio-de-caso-alturas-autoreportadas-de-estudiantes", "introducci\u00f3n-a-las-estad\u00edsticas-con-r.html", "probabilidad.html", "probabilidad.html#probabilidad-discreta", "probabilidad.html#frecuencia-relativa", "probabilidad.html#notaci\u00f3n", "probabilidad.html#distribuciones-de-probabilidad", "probabilidad.html#simulaciones-monte-carlo-para-datos-categ\u00f3ricos", "probabilidad.html#fijar-la-semilla-aleatoria", "probabilidad.html#con-y-sin-reemplazo", "probabilidad.html#independencia", "probabilidad.html#probabilidades-condicionales", "probabilidad.html#reglas-de-la-adici\u00f3n-y-de-la-multiplicaci\u00f3n", "probabilidad.html#regla-de-la-multiplicaci\u00f3n", "probabilidad.html#regla-de-la-multiplicaci\u00f3n-bajo-independencia", "probabilidad.html#regla-de-la-adici\u00f3n", "probabilidad.html#combinaciones-y-permutaciones", "probabilidad.html#ejemplo-monte-carlo", "probabilidad.html#ejemplos", "probabilidad.html#problema-monty-hall", "probabilidad.html#problema-de-cumplea\u00f1os", "probabilidad.html#infinito-en-la-pr\u00e1ctica", "probabilidad.html#ejercicios-22", "probabilidad.html#probabilidad-continua", "probabilidad.html#distribuciones-te\u00f3ricas-continuas", "probabilidad.html#distribuciones-te\u00f3ricas-como-aproximaciones", "probabilidad.html#la-densidad-de-probabilidad", "probabilidad.html#simulaciones-monte-carlo-para-variables-continuas", "probabilidad.html#distribuciones-continuas", "probabilidad.html#ejercicios-23", "variables-aleatorias.html", "variables-aleatorias.html#variables-aleatorias-1", "variables-aleatorias.html#modelos-de-muestreo", "variables-aleatorias.html#la-distribuci\u00f3n-de-probabilidad-de-una-variable-aleatoria", "variables-aleatorias.html#distribuciones-versus-distribuciones-de-probabilidad", "variables-aleatorias.html#notaci\u00f3n-para-variables-aleatorias", "variables-aleatorias.html#el-valor-esperado-y-el-error-est\u00e1ndar", "variables-aleatorias.html#poblaci\u00f3n-sd-versus-la-muestra-sd", "variables-aleatorias.html#teorema-del-l\u00edmite-central", "variables-aleatorias.html#cu\u00e1n-grande-es-grande-en-el-teorema-del-l\u00edmite-central", "variables-aleatorias.html#propiedades-estad\u00edsticas-de-promedios", "variables-aleatorias.html#ley-de-los-grandes-n\u00fameros", "variables-aleatorias.html#malinterpretando-la-ley-de-promedios", "variables-aleatorias.html#ejercicios-24", "variables-aleatorias.html#estudio-de-caso-the-big-short", "variables-aleatorias.html#tasas-de-inter\u00e9s-explicadas-con-modelo-de-oportunidad", "variables-aleatorias.html#the-big-short", "variables-aleatorias.html#ejercicios-25", "inference.html", "inference.html#encuestas", "inference.html#el-modelo-de-muestreo-para-encuestas", "inference.html#poblaciones-muestras-par\u00e1metros-y-estimadores", "inference.html#el-promedio-de-la-muestra", "inference.html#par\u00e1metros", "inference.html#encuesta-versus-pron\u00f3stico", "inference.html#propiedades-de-nuestro-estimador-valor-esperado-y-error-est\u00e1ndar", "inference.html#ejercicios-26", "inference.html#clt", "inference.html#una-simulaci\u00f3n-monte-carlo", "inference.html#la-diferencia", "inference.html#sesgo-por-qu\u00e9-no-realizar-una-encuesta-bien-grande", "inference.html#ejercicios-27", "inference.html#intervalos-de-confianza", "inference.html#una-simulaci\u00f3n-monte-carlo-1", "inference.html#el-idioma-correcto", "inference.html#ejercicios-28", "inference.html#poder", "inference.html#valores-p", "inference.html#association-tests", "inference.html#lady-tasting-tea", "inference.html#tablas-2x2", "inference.html#prueba-de-chi-cuadrado", "inference.html#odds-ratio", "inference.html#intervalos-de-confianza-para-el-riesgo-relativo", "inference.html#correcci\u00f3n-de-recuento-peque\u00f1o", "inference.html#muestras-grandes-valores-p-peque\u00f1os", "inference.html#ejercicios-29", "models.html", "models.html#agregadores-de-encuestas", "models.html#datos-de-encuesta", "models.html#sesgo-de-los-encuestadores", "models.html#data-driven-model", "models.html#ejercicios-30", "models.html#bayesian-statistics", "models.html#teorema-de-bayes", "models.html#simulaci\u00f3n-del-teorema-de-bayes", "models.html#bayes-en-la-pr\u00e1ctica", "models.html#modelos-jer\u00e1rquicos", "models.html#ejercicios-31", "models.html#election-forecasting", "models.html#bayesian-approach", "models.html#el-sesgo-general", "models.html#representaciones-matem\u00e1ticas-de-modelos", "models.html#prediciendo-el-colegio-electoral", "models.html#pron\u00f3sticos", "models.html#ejercicios-32", "models.html#t-dist", "regression.html", "regression.html#estudio-de-caso-la-altura-es-hereditaria", "regression.html#corr-coef", "regression.html#la-correlaci\u00f3n-de-muestra-es-una-variable-aleatoria", "regression.html#la-correlaci\u00f3n-no-siempre-es-un-resumen-\u00fatil", "regression.html#conditional-expectation", "regression.html#la-l\u00ednea-de-regresi\u00f3n", "regression.html#la-regresi\u00f3n-mejora-la-precisi\u00f3n", "regression.html#distribuci\u00f3n-normal-de-dos-variables-avanzada", "regression.html#varianza-explicada", "regression.html#advertencia-hay-dos-l\u00edneas-de-regresi\u00f3n", "regression.html#ejercicios-33", "linear-models.html", "linear-models.html#estudio-de-caso-moneyball", "linear-models.html#sabermetrics", "linear-models.html#conceptos-b\u00e1sicos-de-b\u00e9isbol", "linear-models.html#no-hay-premios-para-bb", "linear-models.html#base-por-bolas-o-bases-robadas", "linear-models.html#regresi\u00f3n-aplicada-a-las-estad\u00edsticas-de-b\u00e9isbol", "linear-models.html#confusi\u00f3n", "linear-models.html#c\u00f3mo-entender-la-confusi\u00f3n-a-trav\u00e9s-de-la-estratificaci\u00f3n", "linear-models.html#regresi\u00f3n-lineal-m\u00faltiple", "linear-models.html#lse", "linear-models.html#interpretando-modelos-lineales", "linear-models.html#estimadores-de-m\u00ednimos-cuadrados-lse", "linear-models.html#la-funci\u00f3n-lm", "linear-models.html#el-lse-consiste-de-variables-aleatorias", "linear-models.html#valores-pronosticados-son-variables-aleatorias", "linear-models.html#ejercicios-34", "linear-models.html#regresi\u00f3n-lineal-en-el-tidyverse", "linear-models.html#el-paquete-broom", "linear-models.html#ejercicios-35", "linear-models.html#estudio-de-caso-moneyball-continuaci\u00f3n", "linear-models.html#a\u00f1adiendo-informaci\u00f3n-sobre-salario-y-posici\u00f3n", "linear-models.html#escoger-nueve-jugadores", "linear-models.html#la-falacia-de-la-regresi\u00f3n", "linear-models.html#modelos-de-error-de-medici\u00f3n", "linear-models.html#ejercicios-36", "la-correlaci\u00f3n-no-implica-causalidad.html", "la-correlaci\u00f3n-no-implica-causalidad.html#correlaci\u00f3n-espuria", "la-correlaci\u00f3n-no-implica-causalidad.html#valores-at\u00edpicos-1", "la-correlaci\u00f3n-no-implica-causalidad.html#inversi\u00f3n-de-causa-y-efecto", "la-correlaci\u00f3n-no-implica-causalidad.html#factores-de-confusi\u00f3n", "la-correlaci\u00f3n-no-implica-causalidad.html#ejemplo-admisiones-a-la-universidad-de-california-berkeley", "la-correlaci\u00f3n-no-implica-causalidad.html#confusi\u00f3n-explicada-gr\u00e1ficamente", "la-correlaci\u00f3n-no-implica-causalidad.html#calcular-promedio-luego-de-estratificar", "la-correlaci\u00f3n-no-implica-causalidad.html#la-paradoja-de-simpson", "la-correlaci\u00f3n-no-implica-causalidad.html#ejercicios-37", "introducci\u00f3n-al-wrangling-de-datos.html", "c\u00f3mo-cambiar-el-formato-de-datos.html", "c\u00f3mo-cambiar-el-formato-de-datos.html#pivot_longer", "c\u00f3mo-cambiar-el-formato-de-datos.html#pivot_wider", "c\u00f3mo-cambiar-el-formato-de-datos.html#separate", "c\u00f3mo-cambiar-el-formato-de-datos.html#unite", "c\u00f3mo-cambiar-el-formato-de-datos.html#ejercicios-38", "unir-tablas.html", "unir-tablas.html#joins", "unir-tablas.html#left-join", "unir-tablas.html#right-join", "unir-tablas.html#inner-join", "unir-tablas.html#full-join", "unir-tablas.html#semi-join", "unir-tablas.html#anti-join", "unir-tablas.html#binding", "unir-tablas.html#pegando-columnas", "unir-tablas.html#pegando-filas", "unir-tablas.html#operadores-de-sets", "unir-tablas.html#intersecar", "unir-tablas.html#uni\u00f3n", "unir-tablas.html#setdiff", "unir-tablas.html#setequal", "unir-tablas.html#ejercicios-39", "extracci\u00f3n-de-la-web.html", "extracci\u00f3n-de-la-web.html#html", "extracci\u00f3n-de-la-web.html#el-paquete-rvest", "extracci\u00f3n-de-la-web.html#css-selectors", "extracci\u00f3n-de-la-web.html#json", "extracci\u00f3n-de-la-web.html#ejercicios-40", "procesamiento-de-cadenas.html", "procesamiento-de-cadenas.html#stringr", "procesamiento-de-cadenas.html#estudio-de-caso-1-datos-de-asesinatos-en-ee.-uu.", "procesamiento-de-cadenas.html#estudio-de-caso-2-alturas-autoreportadas", "procesamiento-de-cadenas.html#c\u00f3mo-escapar-al-definir-cadenas", "procesamiento-de-cadenas.html#expresiones-regulares", "procesamiento-de-cadenas.html#las-cadenas-son-expresiones-regulares", "procesamiento-de-cadenas.html#caracteres-especiales", "procesamiento-de-cadenas.html#clases-de-caracteres", "procesamiento-de-cadenas.html#anclas", "procesamiento-de-cadenas.html#cuantificadores", "procesamiento-de-cadenas.html#espacio-en-blanco-s", "procesamiento-de-cadenas.html#cuantificadores-1", "procesamiento-de-cadenas.html#todo-excepto", "procesamiento-de-cadenas.html#groups", "procesamiento-de-cadenas.html#buscar-y-reemplazar-con-expresiones-regulares", "procesamiento-de-cadenas.html#buscar-y-reemplazar-usando-grupos", "procesamiento-de-cadenas.html#probar-y-mejorar", "procesamiento-de-cadenas.html#podar", "procesamiento-de-cadenas.html#c\u00f3mo-cambiar-de-may\u00fasculas-o-min\u00fasculas", "procesamiento-de-cadenas.html#estudio-de-caso-2-alturas-autoreportadas-continuaci\u00f3n", "procesamiento-de-cadenas.html#la-funci\u00f3n-extract", "procesamiento-de-cadenas.html#juntando-todas-la-piezas", "procesamiento-de-cadenas.html#divisi\u00f3n-de-cadenas", "procesamiento-de-cadenas.html#estudio-de-caso-3-extracci\u00f3n-de-tablas-de-un-pdf", "procesamiento-de-cadenas.html#recode", "procesamiento-de-cadenas.html#ejercicios-41", "c\u00f3mo-leer-y-procesar-fechas-y-horas.html", "c\u00f3mo-leer-y-procesar-fechas-y-horas.html#datos-tipo-fecha", "c\u00f3mo-leer-y-procesar-fechas-y-horas.html#lubridate", "c\u00f3mo-leer-y-procesar-fechas-y-horas.html#ejercicios-42", "miner\u00eda-de-textos.html", "miner\u00eda-de-textos.html#estudio-de-caso-tuits-de-trump", "miner\u00eda-de-textos.html#texto-como-datos", "miner\u00eda-de-textos.html#an\u00e1lisis-de-sentimiento", "miner\u00eda-de-textos.html#ejercicios-43", "introducci\u00f3n-a-machine-learning.html", "introducci\u00f3n-a-machine-learning.html#notaci\u00f3n-1", "introducci\u00f3n-a-machine-learning.html#un-ejemplo", "introducci\u00f3n-a-machine-learning.html#ejercicios-44", "introducci\u00f3n-a-machine-learning.html#m\u00e9tricas-de-evaluaci\u00f3n", "introducci\u00f3n-a-machine-learning.html#training-test", "introducci\u00f3n-a-machine-learning.html#exactitud-general", "introducci\u00f3n-a-machine-learning.html#matriz-de-confusi\u00f3n", "introducci\u00f3n-a-machine-learning.html#sensibilidad-y-especificidad", "introducci\u00f3n-a-machine-learning.html#exactitud-equilibrada-y-medida-f_1", "introducci\u00f3n-a-machine-learning.html#la-prevalencia-importa-en-la-pr\u00e1ctica", "introducci\u00f3n-a-machine-learning.html#curvas-roc-y-precision-recall", "introducci\u00f3n-a-machine-learning.html#loss-function", "introducci\u00f3n-a-machine-learning.html#ejercicios-45", "introducci\u00f3n-a-machine-learning.html#probabilidades-y-expectativas-condicionales", "introducci\u00f3n-a-machine-learning.html#probabilidades-condicionales-1", "introducci\u00f3n-a-machine-learning.html#expectativas-condicionales", "introducci\u00f3n-a-machine-learning.html#la-expectativa-condicional-minimiza-la-funci\u00f3n-de-p\u00e9rdida-cuadr\u00e1tica", "introducci\u00f3n-a-machine-learning.html#ejercicios-46", "introducci\u00f3n-a-machine-learning.html#two-or-seven", "suavizaci\u00f3n.html", "suavizaci\u00f3n.html#suavizaci\u00f3n-de-compartimientos", "suavizaci\u00f3n.html#kernels", "suavizaci\u00f3n.html#regresi\u00f3n-ponderada-local-loess", "suavizaci\u00f3n.html#ajustando-con-par\u00e1bolas", "suavizaci\u00f3n.html#cuidado-con-los-par\u00e1metros-de-suavizaci\u00f3n-predeterminados", "suavizaci\u00f3n.html#smoothing-ml-connection", "suavizaci\u00f3n.html#ejercicios-47", "cross-validation.html", "cross-validation.html#knn-cv-intro", "cross-validation.html#sobreentrenamiento", "cross-validation.html#sobre-suavizaci\u00f3n", "cross-validation.html#escogiendo-la-k-en-knn", "cross-validation.html#descripci\u00f3n-matem\u00e1tica-de-validaci\u00f3n-cruzada", "cross-validation.html#validaci\u00f3n-cruzada-k-fold", "cross-validation.html#ejercicios-48", "cross-validation.html#bootstrap", "cross-validation.html#ejercicios-49", "caret.html", "caret.html#la-funci\u00f3n-train-de-caret", "caret.html#caret-cv", "caret.html#ejemplo-ajuste-con-loess", "ejemplos-de-algoritmos.html", "ejemplos-de-algoritmos.html#regresi\u00f3n-lineal", "ejemplos-de-algoritmos.html#la-funci\u00f3n-predict", "ejemplos-de-algoritmos.html#ejercicios-50", "ejemplos-de-algoritmos.html#regresi\u00f3n-log\u00edstica", "ejemplos-de-algoritmos.html#modelos-lineales-generalizados", "ejemplos-de-algoritmos.html#regresi\u00f3n-log\u00edstica-con-m\u00e1s-de-un-predictor", "ejemplos-de-algoritmos.html#ejercicios-51", "ejemplos-de-algoritmos.html#k-vecinos-m\u00e1s-cercanos-knn", "ejemplos-de-algoritmos.html#ejercicios-52", "ejemplos-de-algoritmos.html#modelos-generativos", "ejemplos-de-algoritmos.html#naive-bayes", "ejemplos-de-algoritmos.html#controlando-la-prevalencia", "ejemplos-de-algoritmos.html#an\u00e1lisis-discriminante-cuadr\u00e1tico", "ejemplos-de-algoritmos.html#an\u00e1lisis-discriminante-lineal", "ejemplos-de-algoritmos.html#conexi\u00f3n-a-distancia", "ejemplos-de-algoritmos.html#estudio-de-caso-m\u00e1s-de-tres-clases", "ejemplos-de-algoritmos.html#ejercicios-53", "ejemplos-de-algoritmos.html#\u00e1rboles-de-clasificaci\u00f3n-y-regresi\u00f3n-cart", "ejemplos-de-algoritmos.html#la-maldici\u00f3n-de-la-dimensionalidad", "ejemplos-de-algoritmos.html#motivaci\u00f3n-cart", "ejemplos-de-algoritmos.html#\u00e1rboles-de-regresi\u00f3n", "ejemplos-de-algoritmos.html#\u00e1rboles-de-clasificaci\u00f3n-decisi\u00f3n", "ejemplos-de-algoritmos.html#bosques-aleatorios", "ejemplos-de-algoritmos.html#ejercicios-54", "machine-learning-en-la-pr\u00e1ctica.html", "machine-learning-en-la-pr\u00e1ctica.html#preprocesamiento", "machine-learning-en-la-pr\u00e1ctica.html#k-vecino-m\u00e1s-cercano-y-bosque-aleatorio", "machine-learning-en-la-pr\u00e1ctica.html#importancia-variable", "machine-learning-en-la-pr\u00e1ctica.html#evaluaciones-visuales", "machine-learning-en-la-pr\u00e1ctica.html#conjuntos", "machine-learning-en-la-pr\u00e1ctica.html#ejercicios-55", "sets-grandes-de-datos.html", "sets-grandes-de-datos.html#matrix-algebra", "sets-grandes-de-datos.html#notaci\u00f3n-2", "sets-grandes-de-datos.html#convertir-un-vector-en-una-matriz", "sets-grandes-de-datos.html#res\u00famenes-de-filas-y-columnas", "sets-grandes-de-datos.html#apply", "sets-grandes-de-datos.html#filtrar-columnas-basado-en-res\u00famenes", "sets-grandes-de-datos.html#indexaci\u00f3n-con-matrices", "sets-grandes-de-datos.html#binarizar-los-datos", "sets-grandes-de-datos.html#vectorizaci\u00f3n-para-matrices", "sets-grandes-de-datos.html#operaciones-de-\u00e1lgebra-matricial", "sets-grandes-de-datos.html#ejercicios-56", "sets-grandes-de-datos.html#distancia", "sets-grandes-de-datos.html#distancia-euclidiana", "sets-grandes-de-datos.html#distancia-en-dimensiones-superiores", "sets-grandes-de-datos.html#ejemplo-de-distancia-euclidiana", "sets-grandes-de-datos.html#predictor-space", "sets-grandes-de-datos.html#distancia-entre-predictores", "sets-grandes-de-datos.html#ejercicios-57", "sets-grandes-de-datos.html#reducci\u00f3n-de-dimensiones", "sets-grandes-de-datos.html#preservando-la-distancia", "sets-grandes-de-datos.html#transformaciones-lineales-avanzado", "sets-grandes-de-datos.html#transformaciones-ortogonales-avanzado", "sets-grandes-de-datos.html#pca", "sets-grandes-de-datos.html#ejemplo-de-lirios", "sets-grandes-de-datos.html#ejemplo-de-mnist", "sets-grandes-de-datos.html#ejercicios-58", "sets-grandes-de-datos.html#sistemas-de-recomendaci\u00f3n", "sets-grandes-de-datos.html#datos-de-movielens", "sets-grandes-de-datos.html#sistemas-de-recomendaci\u00f3n-como-un-desaf\u00edo-de-machine-learning", "sets-grandes-de-datos.html#netflix-loss-function", "sets-grandes-de-datos.html#un-primer-modelo", "sets-grandes-de-datos.html#modelando-los-efectos-de-pel\u00edculas", "sets-grandes-de-datos.html#efectos-de-usuario", "sets-grandes-de-datos.html#ejercicios-59", "sets-grandes-de-datos.html#regularizaci\u00f3n", "sets-grandes-de-datos.html#motivaci\u00f3n", "sets-grandes-de-datos.html#m\u00ednimos-cuadrados-penalizados", "sets-grandes-de-datos.html#c\u00f3mo-elegir-los-t\u00e9rminos-de-penalizaci\u00f3n", "sets-grandes-de-datos.html#ejercicios-60", "sets-grandes-de-datos.html#factorizaci\u00f3n-de-matrices", "sets-grandes-de-datos.html#factor-analysis", "sets-grandes-de-datos.html#conexi\u00f3n-a-svd-y-pca", "sets-grandes-de-datos.html#ejercicios-61", "clustering.html", "clustering.html#agrupaci\u00f3n-jer\u00e1rquica", "clustering.html#k-means", "clustering.html#mapas-de-calor", "clustering.html#filtrando-atributos", "clustering.html#ejercicios-62", "introducci\u00f3n-a-las-herramientas-de-productividad.html", "installing-r-rstudio.html", "installing-r-rstudio.html#instalando-r", "installing-r-rstudio.html#instalaci\u00f3n-de-rstudio", "accediendo-al-terminal-e-instalando-git.html", "accediendo-al-terminal-e-instalando-git.html#terminal-on-mac", "accediendo-al-terminal-e-instalando-git.html#instalando-git-en-la-mac", "accediendo-al-terminal-e-instalando-git.html#instalaci\u00f3n-de-git-y-git-bash-en-windows", "accediendo-al-terminal-e-instalando-git.html#terminal-on-windows", "unix.html", "unix.html#convenci\u00f3n-de-nomenclatura", "unix.html#the-terminal", "unix.html#filesystem", "unix.html#directorios-y-subdirectorios", "unix.html#el-directorio-home", "unix.html#working-directory", "unix.html#paths", "unix.html#comandos-de-unix", "unix.html#ls-listado-de-contenido-del-directorio", "unix.html#mkdir-y-rmdir-crear-y-eliminar-un-directorio", "unix.html#cd-navegando-por-el-sistema-de-archivos-cambiando-directorios", "unix.html#algunos-ejemplos", "unix.html#m\u00e1s-comandos-de-unix", "unix.html#mv-mover-archivos", "unix.html#cp-copiando-archivos", "unix.html#rm-eliminar-archivos", "unix.html#less-mirando-un-archivo", "unix.html#prep-project", "unix.html#unix-avanzado", "unix.html#argumentos", "unix.html#obtener-ayuda", "unix.html#el-pipe", "unix.html#comodines", "unix.html#variables-de-entorno", "unix.html#shells", "unix.html#ejecutables", "unix.html#permisos-y-tipos-de-archivo", "unix.html#comandos-que-deben-aprender", "unix.html#manipulaci\u00f3n-de-archivos-en-r", "git.html", "git.html#por-qu\u00e9-usar-git-y-github", "git.html#cuentas-github", "git.html#github-repos", "git.html#git-overview", "git.html#clonar", "git.html#init", "git.html#rstudio-git", "proyectos-reproducibles-con-rstudio-y-r-markdown.html", "proyectos-reproducibles-con-rstudio-y-r-markdown.html#proyectos-de-rstudio", "proyectos-reproducibles-con-rstudio-y-r-markdown.html#r-markdown", "proyectos-reproducibles-con-rstudio-y-r-markdown.html#el-encabezado", "proyectos-reproducibles-con-rstudio-y-r-markdown.html#fragmentos-de-c\u00f3digo-r", "proyectos-reproducibles-con-rstudio-y-r-markdown.html#opciones-globales", "proyectos-reproducibles-con-rstudio-y-r-markdown.html#knitr", "proyectos-reproducibles-con-rstudio-y-r-markdown.html#m\u00e1s-sobre-r-markdown", "proyectos-reproducibles-con-rstudio-y-r-markdown.html#organizing", "proyectos-reproducibles-con-rstudio-y-r-markdown.html#crear-directorios-en-unix", "proyectos-reproducibles-con-rstudio-y-r-markdown.html#crear-un-proyecto-en-rstudio", "proyectos-reproducibles-con-rstudio-y-r-markdown.html#editar-algunos-scripts-de-r", "proyectos-reproducibles-con-rstudio-y-r-markdown.html#crear-m\u00e1s-directorios-usando-unix", "proyectos-reproducibles-con-rstudio-y-r-markdown.html#agregar-un-archivo-readme", "proyectos-reproducibles-con-rstudio-y-r-markdown.html#inicializando-un-directorio-git", "proyectos-reproducibles-con-rstudio-y-r-markdown.html#add-commit-y-push-archivos-con-rstudio", "https://github.com/rafalab/dslibro", "./", "sets-grandes-de-datos.html#sets-grandes-de-datos", "sets-grandes-de-datos.html#matrix-algebra", "sets-grandes-de-datos.html#cb1176-1", "sets-grandes-de-datos.html#cb1176-2", "sets-grandes-de-datos.html#cb1176-3", "sets-grandes-de-datos.html#cb1177-1", "sets-grandes-de-datos.html#cb1177-2", "sets-grandes-de-datos.html#cb1178-1", "sets-grandes-de-datos.html#cb1178-2", "sets-grandes-de-datos.html#notaci\u00f3n-2", "sets-grandes-de-datos.html#cb1179-1", "sets-grandes-de-datos.html#cb1179-2", "sets-grandes-de-datos.html#cb1180-1", "sets-grandes-de-datos.html#cb1180-2", "sets-grandes-de-datos.html#cb1180-3", "sets-grandes-de-datos.html#cb1180-4", "sets-grandes-de-datos.html#cb1180-5", "sets-grandes-de-datos.html#cb1180-6", "sets-grandes-de-datos.html#cb1180-7", "sets-grandes-de-datos.html#cb1180-8", "sets-grandes-de-datos.html#cb1180-9", "sets-grandes-de-datos.html#cb1181-1", "sets-grandes-de-datos.html#cb1181-2", "sets-grandes-de-datos.html#cb1182-1", "sets-grandes-de-datos.html#cb1182-2", "sets-grandes-de-datos.html#cb1183-1", "sets-grandes-de-datos.html#cb1183-2", "sets-grandes-de-datos.html#cb1184-1", "sets-grandes-de-datos.html#cb1184-2", "sets-grandes-de-datos.html#convertir-un-vector-en-una-matriz", "sets-grandes-de-datos.html#cb1185-1", "sets-grandes-de-datos.html#cb1185-2", "sets-grandes-de-datos.html#cb1185-3", "sets-grandes-de-datos.html#cb1185-4", "sets-grandes-de-datos.html#cb1185-5", "sets-grandes-de-datos.html#cb1185-6", "sets-grandes-de-datos.html#cb1185-7", "sets-grandes-de-datos.html#cb1185-8", "sets-grandes-de-datos.html#cb1185-9", "sets-grandes-de-datos.html#cb1186-1", "sets-grandes-de-datos.html#cb1186-2", "sets-grandes-de-datos.html#cb1186-3", "sets-grandes-de-datos.html#cb1186-4", "sets-grandes-de-datos.html#cb1186-5", "sets-grandes-de-datos.html#cb1186-6", "sets-grandes-de-datos.html#cb1187-1", "sets-grandes-de-datos.html#cb1187-2", "sets-grandes-de-datos.html#cb1188-1", "sets-grandes-de-datos.html#cb1188-2", "sets-grandes-de-datos.html#cb1188-3", "sets-grandes-de-datos.html#cb1188-4", "sets-grandes-de-datos.html#cb1188-5", "sets-grandes-de-datos.html#cb1188-6", "sets-grandes-de-datos.html#cb1188-7", "sets-grandes-de-datos.html#cb1188-8", "sets-grandes-de-datos.html#cb1189-1", "sets-grandes-de-datos.html#cb1190-1", "sets-grandes-de-datos.html#cb1190-2", "sets-grandes-de-datos.html#res\u00famenes-de-filas-y-columnas", "sets-grandes-de-datos.html#cb1191-1", "sets-grandes-de-datos.html#cb1192-1", "sets-grandes-de-datos.html#cb1193-1", "sets-grandes-de-datos.html#cb1193-2", "sets-grandes-de-datos.html#apply", "sets-grandes-de-datos.html#cb1194-1", "sets-grandes-de-datos.html#cb1195-1", "sets-grandes-de-datos.html#filtrar-columnas-basado-en-res\u00famenes", "sets-grandes-de-datos.html#cb1196-1", "sets-grandes-de-datos.html#cb1196-2", "sets-grandes-de-datos.html#cb1197-1", "sets-grandes-de-datos.html#cb1198-1", "r-basics.html#matrices", "sets-grandes-de-datos.html#cb1199-1", "sets-grandes-de-datos.html#cb1200-1", "sets-grandes-de-datos.html#cb1201-1", "sets-grandes-de-datos.html#cb1201-2", "sets-grandes-de-datos.html#cb1201-3", "sets-grandes-de-datos.html#cb1202-1", "sets-grandes-de-datos.html#cb1202-2", "sets-grandes-de-datos.html#cb1202-3", "sets-grandes-de-datos.html#cb1202-4", "sets-grandes-de-datos.html#cb1203-1", "sets-grandes-de-datos.html#cb1203-2", "sets-grandes-de-datos.html#cb1203-3", "sets-grandes-de-datos.html#cb1203-4", "sets-grandes-de-datos.html#indexaci\u00f3n-con-matrices", "sets-grandes-de-datos.html#cb1204-1", "sets-grandes-de-datos.html#cb1204-2", "sets-grandes-de-datos.html#cb1204-3", "sets-grandes-de-datos.html#cb1205-1", "sets-grandes-de-datos.html#cb1206-1", "sets-grandes-de-datos.html#cb1206-2", "sets-grandes-de-datos.html#cb1207-1", "sets-grandes-de-datos.html#cb1207-2", "sets-grandes-de-datos.html#cb1207-3", "sets-grandes-de-datos.html#cb1207-4", "sets-grandes-de-datos.html#cb1207-5", "sets-grandes-de-datos.html#cb1207-6", "sets-grandes-de-datos.html#cb1207-7", "sets-grandes-de-datos.html#cb1207-8", "sets-grandes-de-datos.html#cb1207-9", "sets-grandes-de-datos.html#cb1208-1", "sets-grandes-de-datos.html#cb1208-2", "sets-grandes-de-datos.html#cb1208-3", "sets-grandes-de-datos.html#cb1208-4", "sets-grandes-de-datos.html#cb1208-5", "sets-grandes-de-datos.html#cb1208-6", "sets-grandes-de-datos.html#cb1208-7", "sets-grandes-de-datos.html#cb1208-8", "sets-grandes-de-datos.html#cb1208-9", "sets-grandes-de-datos.html#binarizar-los-datos", "sets-grandes-de-datos.html#cb1209-1", "sets-grandes-de-datos.html#cb1209-2", "sets-grandes-de-datos.html#cb1209-3", "sets-grandes-de-datos.html#cb1210-1", "sets-grandes-de-datos.html#vectorizaci\u00f3n-para-matrices", "sets-grandes-de-datos.html#cb1211-1", "sets-grandes-de-datos.html#cb1212-1", "sets-grandes-de-datos.html#cb1213-1", "sets-grandes-de-datos.html#cb1214-1", "sets-grandes-de-datos.html#cb1214-2", "sets-grandes-de-datos.html#operaciones-de-\u00e1lgebra-matricial", "sets-grandes-de-datos.html#cb1215-1", "sets-grandes-de-datos.html#cb1216-1", "sets-grandes-de-datos.html#cb1217-1", "sets-grandes-de-datos.html#cb1218-1", "sets-grandes-de-datos.html#ejercicios-56", "sets-grandes-de-datos.html#distancia", "sets-grandes-de-datos.html#distancia-euclidiana", "sets-grandes-de-datos.html#distancia-en-dimensiones-superiores", "sets-grandes-de-datos.html#cb1219-1", "sets-grandes-de-datos.html#cb1219-2", "sets-grandes-de-datos.html#cb1219-3", "sets-grandes-de-datos.html#cb1219-4", "sets-grandes-de-datos.html#cb1219-5", "sets-grandes-de-datos.html#cb1219-6", "sets-grandes-de-datos.html#cb1219-7", "sets-grandes-de-datos.html#cb1219-8", "sets-grandes-de-datos.html#cb1219-9", "sets-grandes-de-datos.html#ejemplo-de-distancia-euclidiana", "sets-grandes-de-datos.html#cb1220-1", "sets-grandes-de-datos.html#cb1220-2", "sets-grandes-de-datos.html#cb1221-1", "sets-grandes-de-datos.html#cb1221-2", "sets-grandes-de-datos.html#cb1221-3", "sets-grandes-de-datos.html#cb1222-1", "sets-grandes-de-datos.html#cb1222-2", "sets-grandes-de-datos.html#cb1223-1", "sets-grandes-de-datos.html#cb1223-2", "sets-grandes-de-datos.html#cb1223-3", "sets-grandes-de-datos.html#cb1223-4", "sets-grandes-de-datos.html#cb1224-1", "sets-grandes-de-datos.html#cb1224-2", "sets-grandes-de-datos.html#cb1224-3", "sets-grandes-de-datos.html#cb1224-4", "sets-grandes-de-datos.html#cb1224-5", "sets-grandes-de-datos.html#cb1224-6", "sets-grandes-de-datos.html#cb1224-7", "sets-grandes-de-datos.html#cb1224-8", "sets-grandes-de-datos.html#cb1224-9", "sets-grandes-de-datos.html#cb1225-1", "sets-grandes-de-datos.html#cb1225-2", "sets-grandes-de-datos.html#cb1225-3", "sets-grandes-de-datos.html#cb1226-1", "sets-grandes-de-datos.html#cb1226-2", "sets-grandes-de-datos.html#cb1226-3", "sets-grandes-de-datos.html#cb1226-4", "sets-grandes-de-datos.html#cb1226-5", "sets-grandes-de-datos.html#cb1227-1", "sets-grandes-de-datos.html#cb1228-1", "sets-grandes-de-datos.html#predictor-space", "sets-grandes-de-datos.html#distancia-entre-predictores", "sets-grandes-de-datos.html#cb1229-1", "sets-grandes-de-datos.html#cb1229-2", "sets-grandes-de-datos.html#cb1229-3", "sets-grandes-de-datos.html#ejercicios-57", "sets-grandes-de-datos.html#cb1230-1", "sets-grandes-de-datos.html#cb1231-1", "sets-grandes-de-datos.html#cb1232-1", "sets-grandes-de-datos.html#reducci\u00f3n-de-dimensiones", "sets-grandes-de-datos.html#preservando-la-distancia", "sets-grandes-de-datos.html#cb1233-1", "sets-grandes-de-datos.html#cb1233-2", "sets-grandes-de-datos.html#cb1233-3", "sets-grandes-de-datos.html#cb1233-4", "sets-grandes-de-datos.html#cb1233-5", "sets-grandes-de-datos.html#cb1233-6", "sets-grandes-de-datos.html#cb1234-1", "sets-grandes-de-datos.html#cb1234-2", "sets-grandes-de-datos.html#cb1234-3", "sets-grandes-de-datos.html#cb1234-4", "sets-grandes-de-datos.html#cb1234-5", "sets-grandes-de-datos.html#cb1235-1", "sets-grandes-de-datos.html#cb1236-1", "sets-grandes-de-datos.html#cb1236-2", "sets-grandes-de-datos.html#cb1237-1", "sets-grandes-de-datos.html#cb1238-1", "sets-grandes-de-datos.html#cb1238-2", "sets-grandes-de-datos.html#transformaciones-lineales-avanzado", "sets-grandes-de-datos.html#transformaciones-ortogonales-avanzado", "sets-grandes-de-datos.html#cb1239-1", "sets-grandes-de-datos.html#cb1239-2", "sets-grandes-de-datos.html#cb1240-1", "sets-grandes-de-datos.html#cb1240-2", "sets-grandes-de-datos.html#cb1241-1", "sets-grandes-de-datos.html#cb1241-2", "sets-grandes-de-datos.html#cb1242-1", "sets-grandes-de-datos.html#cb1242-2", "sets-grandes-de-datos.html#cb1243-1", "sets-grandes-de-datos.html#cb1243-2", "sets-grandes-de-datos.html#cb1244-1", "sets-grandes-de-datos.html#cb1244-2", "sets-grandes-de-datos.html#pca", "sets-grandes-de-datos.html#cb1245-1", "sets-grandes-de-datos.html#cb1245-2", "sets-grandes-de-datos.html#cb1246-1", "sets-grandes-de-datos.html#cb1246-2", "sets-grandes-de-datos.html#cb1246-3", "sets-grandes-de-datos.html#cb1246-4", "sets-grandes-de-datos.html#cb1247-1", "sets-grandes-de-datos.html#cb1247-2", "sets-grandes-de-datos.html#cb1247-3", "sets-grandes-de-datos.html#cb1248-1", "sets-grandes-de-datos.html#cb1248-2", "sets-grandes-de-datos.html#cb1248-3", "sets-grandes-de-datos.html#cb1248-4", "sets-grandes-de-datos.html#cb1248-5", "sets-grandes-de-datos.html#cb1249-1", "sets-grandes-de-datos.html#cb1249-2", "sets-grandes-de-datos.html#cb1249-3", "sets-grandes-de-datos.html#cb1249-4", "sets-grandes-de-datos.html#cb1250-1", "sets-grandes-de-datos.html#cb1250-2", "sets-grandes-de-datos.html#cb1250-3", "sets-grandes-de-datos.html#cb1250-4", "sets-grandes-de-datos.html#factor-analysis", "sets-grandes-de-datos.html#ejemplo-de-lirios", "sets-grandes-de-datos.html#cb1251-1", "sets-grandes-de-datos.html#cb1251-2", "sets-grandes-de-datos.html#cb1251-3", "sets-grandes-de-datos.html#cb1252-1", "sets-grandes-de-datos.html#cb1252-2", "sets-grandes-de-datos.html#cb1252-3", "sets-grandes-de-datos.html#cb1253-1", "sets-grandes-de-datos.html#cb1253-2", "sets-grandes-de-datos.html#cb1253-3", "sets-grandes-de-datos.html#cb1253-4", "sets-grandes-de-datos.html#cb1253-5", "sets-grandes-de-datos.html#cb1253-6", "sets-grandes-de-datos.html#cb1254-1", "sets-grandes-de-datos.html#cb1254-2", "sets-grandes-de-datos.html#cb1254-3", "sets-grandes-de-datos.html#cb1254-4", "sets-grandes-de-datos.html#cb1254-5", "sets-grandes-de-datos.html#cb1254-6", "sets-grandes-de-datos.html#cb1254-7", "sets-grandes-de-datos.html#cb1255-1", "sets-grandes-de-datos.html#cb1255-2", "sets-grandes-de-datos.html#cb1255-3", "sets-grandes-de-datos.html#cb1255-4", "sets-grandes-de-datos.html#cb1256-1", "sets-grandes-de-datos.html#cb1256-2", "sets-grandes-de-datos.html#ejemplo-de-mnist", "sets-grandes-de-datos.html#cb1257-1", "sets-grandes-de-datos.html#cb1257-2", "sets-grandes-de-datos.html#cb1258-1", "sets-grandes-de-datos.html#cb1258-2", "sets-grandes-de-datos.html#cb1259-1", "sets-grandes-de-datos.html#cb1259-2", "sets-grandes-de-datos.html#cb1260-1", "sets-grandes-de-datos.html#cb1260-2", "sets-grandes-de-datos.html#cb1260-3", "sets-grandes-de-datos.html#cb1260-4", "sets-grandes-de-datos.html#cb1260-5", "sets-grandes-de-datos.html#cb1261-1", "sets-grandes-de-datos.html#cb1261-2", "sets-grandes-de-datos.html#cb1261-3", "sets-grandes-de-datos.html#cb1261-4", "sets-grandes-de-datos.html#cb1261-5", "sets-grandes-de-datos.html#cb1262-1", "sets-grandes-de-datos.html#cb1262-2", "sets-grandes-de-datos.html#cb1262-3", "sets-grandes-de-datos.html#cb1262-4", "sets-grandes-de-datos.html#cb1262-5", "sets-grandes-de-datos.html#cb1263-1", "sets-grandes-de-datos.html#cb1263-2", "sets-grandes-de-datos.html#cb1264-1", "sets-grandes-de-datos.html#cb1264-2", "sets-grandes-de-datos.html#cb1264-3", "sets-grandes-de-datos.html#cb1264-4", "sets-grandes-de-datos.html#ejercicios-58", "sets-grandes-de-datos.html#cb1265-1", "sets-grandes-de-datos.html#cb1265-2", "sets-grandes-de-datos.html#sistemas-de-recomendaci\u00f3n", "#fn120", "http://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/", "http://www.netflixprize.com/assets/GrandPrize2009_BPC_BellKor.pdf", "sets-grandes-de-datos.html#datos-de-movielens", "#fn121", "sets-grandes-de-datos.html#cb1266-1", "sets-grandes-de-datos.html#cb1266-2", "sets-grandes-de-datos.html#cb1266-3", "sets-grandes-de-datos.html#cb1267-1", "sets-grandes-de-datos.html#cb1267-2", "sets-grandes-de-datos.html#cb1267-3", "sets-grandes-de-datos.html#cb1267-4", "sets-grandes-de-datos.html#cb1267-5", "sets-grandes-de-datos.html#cb1267-6", "sets-grandes-de-datos.html#cb1267-7", "sets-grandes-de-datos.html#cb1267-8", "sets-grandes-de-datos.html#cb1267-9", "sets-grandes-de-datos.html#cb1267-10", "sets-grandes-de-datos.html#cb1268-1", "sets-grandes-de-datos.html#cb1268-2", "sets-grandes-de-datos.html#cb1268-3", "sets-grandes-de-datos.html#cb1268-4", "sets-grandes-de-datos.html#cb1268-5", "sets-grandes-de-datos.html#sistemas-de-recomendaci\u00f3n-como-un-desaf\u00edo-de-machine-learning", "sets-grandes-de-datos.html#cb1269-1", "sets-grandes-de-datos.html#cb1269-2", "sets-grandes-de-datos.html#cb1269-3", "sets-grandes-de-datos.html#cb1269-4", "sets-grandes-de-datos.html#cb1269-5", "sets-grandes-de-datos.html#cb1269-6", "sets-grandes-de-datos.html#cb1270-1", "sets-grandes-de-datos.html#cb1270-2", "sets-grandes-de-datos.html#cb1270-3", "sets-grandes-de-datos.html#netflix-loss-function", "sets-grandes-de-datos.html#cb1271-1", "sets-grandes-de-datos.html#cb1271-2", "sets-grandes-de-datos.html#cb1271-3", "sets-grandes-de-datos.html#un-primer-modelo", "sets-grandes-de-datos.html#cb1272-1", "sets-grandes-de-datos.html#cb1272-2", "sets-grandes-de-datos.html#cb1272-3", "sets-grandes-de-datos.html#cb1273-1", "sets-grandes-de-datos.html#cb1273-2", "sets-grandes-de-datos.html#cb1273-3", "sets-grandes-de-datos.html#cb1274-1", "sets-grandes-de-datos.html#cb1274-2", "sets-grandes-de-datos.html#cb1274-3", "sets-grandes-de-datos.html#cb1275-1", "sets-grandes-de-datos.html#modelando-los-efectos-de-pel\u00edculas", "sets-grandes-de-datos.html#cb1276-1", "sets-grandes-de-datos.html#cb1277-1", "sets-grandes-de-datos.html#cb1277-2", "sets-grandes-de-datos.html#cb1277-3", "sets-grandes-de-datos.html#cb1277-4", "sets-grandes-de-datos.html#cb1278-1", "sets-grandes-de-datos.html#cb1279-1", "sets-grandes-de-datos.html#cb1279-2", "sets-grandes-de-datos.html#cb1279-3", "sets-grandes-de-datos.html#cb1279-4", "sets-grandes-de-datos.html#cb1279-5", "sets-grandes-de-datos.html#efectos-de-usuario", "sets-grandes-de-datos.html#cb1280-1", "sets-grandes-de-datos.html#cb1280-2", "sets-grandes-de-datos.html#cb1280-3", "sets-grandes-de-datos.html#cb1280-4", "sets-grandes-de-datos.html#cb1280-5", "sets-grandes-de-datos.html#cb1280-6", "sets-grandes-de-datos.html#cb1281-1", "sets-grandes-de-datos.html#cb1282-1", "sets-grandes-de-datos.html#cb1282-2", "sets-grandes-de-datos.html#cb1282-3", "sets-grandes-de-datos.html#cb1282-4", "sets-grandes-de-datos.html#cb1283-1", "sets-grandes-de-datos.html#cb1283-2", "sets-grandes-de-datos.html#cb1283-3", "sets-grandes-de-datos.html#cb1283-4", "sets-grandes-de-datos.html#cb1283-5", "sets-grandes-de-datos.html#cb1283-6", "sets-grandes-de-datos.html#cb1283-7", "sets-grandes-de-datos.html#ejercicios-59", "sets-grandes-de-datos.html#cb1284-1", "sets-grandes-de-datos.html#regularizaci\u00f3n", "sets-grandes-de-datos.html#motivaci\u00f3n", "sets-grandes-de-datos.html#cb1285-1", "sets-grandes-de-datos.html#cb1285-2", "sets-grandes-de-datos.html#cb1285-3", "sets-grandes-de-datos.html#cb1285-4", "sets-grandes-de-datos.html#cb1285-5", "sets-grandes-de-datos.html#cb1285-6", "sets-grandes-de-datos.html#cb1285-7", "sets-grandes-de-datos.html#cb1285-8", "sets-grandes-de-datos.html#cb1285-9", "sets-grandes-de-datos.html#cb1285-10", "sets-grandes-de-datos.html#cb1285-11", "sets-grandes-de-datos.html#cb1286-1", "sets-grandes-de-datos.html#cb1286-2", "sets-grandes-de-datos.html#cb1286-3", "sets-grandes-de-datos.html#cb1287-1", "sets-grandes-de-datos.html#cb1287-2", "sets-grandes-de-datos.html#cb1287-3", "sets-grandes-de-datos.html#cb1287-4", "sets-grandes-de-datos.html#cb1287-5", "sets-grandes-de-datos.html#cb1287-6", "sets-grandes-de-datos.html#cb1287-7", "sets-grandes-de-datos.html#cb1287-8", "sets-grandes-de-datos.html#cb1287-9", "sets-grandes-de-datos.html#cb1287-10", "sets-grandes-de-datos.html#cb1287-11", "sets-grandes-de-datos.html#cb1287-12", "sets-grandes-de-datos.html#cb1287-13", "sets-grandes-de-datos.html#cb1287-14", "sets-grandes-de-datos.html#cb1288-1", "sets-grandes-de-datos.html#cb1288-2", "sets-grandes-de-datos.html#cb1288-3", "sets-grandes-de-datos.html#cb1288-4", "sets-grandes-de-datos.html#cb1288-5", "sets-grandes-de-datos.html#cb1288-6", "sets-grandes-de-datos.html#cb1288-7", "sets-grandes-de-datos.html#cb1288-8", "sets-grandes-de-datos.html#cb1288-9", "sets-grandes-de-datos.html#cb1288-10", "sets-grandes-de-datos.html#cb1288-11", "sets-grandes-de-datos.html#cb1288-12", "sets-grandes-de-datos.html#cb1288-13", "sets-grandes-de-datos.html#cb1288-14", "sets-grandes-de-datos.html#cb1289-1", "sets-grandes-de-datos.html#cb1289-2", "sets-grandes-de-datos.html#cb1289-3", "sets-grandes-de-datos.html#cb1289-4", "sets-grandes-de-datos.html#cb1289-5", "sets-grandes-de-datos.html#cb1289-6", "sets-grandes-de-datos.html#cb1289-7", "sets-grandes-de-datos.html#cb1289-8", "sets-grandes-de-datos.html#cb1289-9", "sets-grandes-de-datos.html#cb1289-10", "sets-grandes-de-datos.html#cb1289-11", "sets-grandes-de-datos.html#cb1289-12", "sets-grandes-de-datos.html#cb1289-13", "sets-grandes-de-datos.html#cb1289-14", "sets-grandes-de-datos.html#cb1289-15", "sets-grandes-de-datos.html#cb1289-16", "models.html#bayesian-statistics", "sets-grandes-de-datos.html#m\u00ednimos-cuadrados-penalizados", "sets-grandes-de-datos.html#cb1290-1", "sets-grandes-de-datos.html#cb1290-2", "sets-grandes-de-datos.html#cb1290-3", "sets-grandes-de-datos.html#cb1290-4", "sets-grandes-de-datos.html#cb1290-5", "sets-grandes-de-datos.html#cb1291-1", "sets-grandes-de-datos.html#cb1291-2", "sets-grandes-de-datos.html#cb1291-3", "sets-grandes-de-datos.html#cb1291-4", "sets-grandes-de-datos.html#cb1291-5", "sets-grandes-de-datos.html#cb1292-1", "sets-grandes-de-datos.html#cb1292-2", "sets-grandes-de-datos.html#cb1292-3", "sets-grandes-de-datos.html#cb1292-4", "sets-grandes-de-datos.html#cb1292-5", "sets-grandes-de-datos.html#cb1292-6", "sets-grandes-de-datos.html#cb1292-7", "sets-grandes-de-datos.html#cb1292-8", "sets-grandes-de-datos.html#cb1292-9", "sets-grandes-de-datos.html#cb1292-10", "sets-grandes-de-datos.html#cb1292-11", "sets-grandes-de-datos.html#cb1292-12", "sets-grandes-de-datos.html#cb1293-1", "sets-grandes-de-datos.html#cb1293-2", "sets-grandes-de-datos.html#cb1293-3", "sets-grandes-de-datos.html#cb1293-4", "sets-grandes-de-datos.html#cb1293-5", "sets-grandes-de-datos.html#cb1293-6", "sets-grandes-de-datos.html#cb1293-7", "sets-grandes-de-datos.html#cb1293-8", "sets-grandes-de-datos.html#cb1293-9", "sets-grandes-de-datos.html#cb1293-10", "sets-grandes-de-datos.html#cb1293-11", "sets-grandes-de-datos.html#cb1293-12", "sets-grandes-de-datos.html#cb1293-13", "sets-grandes-de-datos.html#cb1293-14", "sets-grandes-de-datos.html#cb1293-15", "sets-grandes-de-datos.html#cb1293-16", "sets-grandes-de-datos.html#cb1293-17", "sets-grandes-de-datos.html#cb1293-18", "sets-grandes-de-datos.html#cb1294-1", "sets-grandes-de-datos.html#cb1294-2", "sets-grandes-de-datos.html#cb1294-3", "sets-grandes-de-datos.html#cb1294-4", "sets-grandes-de-datos.html#cb1294-5", "sets-grandes-de-datos.html#cb1294-6", "sets-grandes-de-datos.html#c\u00f3mo-elegir-los-t\u00e9rminos-de-penalizaci\u00f3n", "sets-grandes-de-datos.html#cb1296-1", "sets-grandes-de-datos.html#cb1296-2", "sets-grandes-de-datos.html#cb1296-3", "sets-grandes-de-datos.html#cb1296-4", "sets-grandes-de-datos.html#cb1296-5", "sets-grandes-de-datos.html#cb1296-6", "sets-grandes-de-datos.html#cb1296-7", "sets-grandes-de-datos.html#cb1296-8", "sets-grandes-de-datos.html#cb1296-9", "sets-grandes-de-datos.html#cb1296-10", "sets-grandes-de-datos.html#cb1296-11", "sets-grandes-de-datos.html#cb1296-12", "sets-grandes-de-datos.html#cb1296-13", "sets-grandes-de-datos.html#cb1296-14", "sets-grandes-de-datos.html#cb1296-15", "sets-grandes-de-datos.html#cb1296-16", "sets-grandes-de-datos.html#cb1296-17", "sets-grandes-de-datos.html#cb1296-18", "sets-grandes-de-datos.html#cb1297-1", "sets-grandes-de-datos.html#cb1297-2", "sets-grandes-de-datos.html#cb1297-3", "sets-grandes-de-datos.html#cb1297-4", "sets-grandes-de-datos.html#cb1297-5", "sets-grandes-de-datos.html#cb1297-6", "sets-grandes-de-datos.html#cb1297-7", "sets-grandes-de-datos.html#cb1297-8", "sets-grandes-de-datos.html#cb1297-9", "sets-grandes-de-datos.html#cb1297-10", "sets-grandes-de-datos.html#cb1297-11", "sets-grandes-de-datos.html#cb1297-12", "sets-grandes-de-datos.html#cb1297-13", "sets-grandes-de-datos.html#cb1297-14", "sets-grandes-de-datos.html#cb1297-15", "sets-grandes-de-datos.html#cb1297-16", "sets-grandes-de-datos.html#cb1297-17", "sets-grandes-de-datos.html#cb1297-18", "sets-grandes-de-datos.html#cb1297-19", "sets-grandes-de-datos.html#cb1297-20", "sets-grandes-de-datos.html#cb1297-21", "sets-grandes-de-datos.html#cb1297-22", "sets-grandes-de-datos.html#cb1297-23", "sets-grandes-de-datos.html#cb1297-24", "sets-grandes-de-datos.html#cb1297-25", "sets-grandes-de-datos.html#cb1297-26", "sets-grandes-de-datos.html#cb1298-1", "sets-grandes-de-datos.html#cb1298-2", "sets-grandes-de-datos.html#cb1298-3", "sets-grandes-de-datos.html#ejercicios-60", "sets-grandes-de-datos.html#cb1299-1", "sets-grandes-de-datos.html#cb1299-2", "sets-grandes-de-datos.html#cb1300-1", "sets-grandes-de-datos.html#cb1300-2", "sets-grandes-de-datos.html#cb1300-3", "sets-grandes-de-datos.html#cb1300-4", "sets-grandes-de-datos.html#cb1300-5", "sets-grandes-de-datos.html#cb1300-6", "sets-grandes-de-datos.html#cb1301-1", "sets-grandes-de-datos.html#cb1302-1", "sets-grandes-de-datos.html#cb1302-2", "sets-grandes-de-datos.html#cb1302-3", "sets-grandes-de-datos.html#cb1302-4", "sets-grandes-de-datos.html#cb1302-5", "sets-grandes-de-datos.html#cb1303-1", "sets-grandes-de-datos.html#factorizaci\u00f3n-de-matrices", "sets-grandes-de-datos.html#cb1304-1", "sets-grandes-de-datos.html#cb1304-2", "sets-grandes-de-datos.html#cb1304-3", "sets-grandes-de-datos.html#cb1304-4", "sets-grandes-de-datos.html#cb1304-5", "sets-grandes-de-datos.html#cb1304-6", "sets-grandes-de-datos.html#cb1304-7", "sets-grandes-de-datos.html#cb1304-8", "sets-grandes-de-datos.html#cb1304-9", "sets-grandes-de-datos.html#cb1304-10", "sets-grandes-de-datos.html#cb1305-1", "sets-grandes-de-datos.html#cb1305-2", "sets-grandes-de-datos.html#cb1305-3", "sets-grandes-de-datos.html#cb1305-4", "sets-grandes-de-datos.html#cb1305-5", "sets-grandes-de-datos.html#cb1305-6", "sets-grandes-de-datos.html#cb1305-7", "sets-grandes-de-datos.html#cb1305-8", "sets-grandes-de-datos.html#cb1306-1", "sets-grandes-de-datos.html#cb1306-2", "sets-grandes-de-datos.html#cb1307-1", "sets-grandes-de-datos.html#cb1307-2", "sets-grandes-de-datos.html#cb1307-3", "sets-grandes-de-datos.html#cb1307-4", "sets-grandes-de-datos.html#cb1307-5", "sets-grandes-de-datos.html#cb1307-6", "sets-grandes-de-datos.html#cb1307-7", "sets-grandes-de-datos.html#cb1307-8", "sets-grandes-de-datos.html#cb1307-9", "sets-grandes-de-datos.html#cb1307-10", "sets-grandes-de-datos.html#cb1307-11", "sets-grandes-de-datos.html#cb1307-12", "sets-grandes-de-datos.html#cb1307-13", "sets-grandes-de-datos.html#cb1308-1", "sets-grandes-de-datos.html#cb1308-2", "sets-grandes-de-datos.html#cb1308-3", "sets-grandes-de-datos.html#cb1308-4", "sets-grandes-de-datos.html#cb1308-5", "sets-grandes-de-datos.html#cb1308-6", "sets-grandes-de-datos.html#cb1308-7", "sets-grandes-de-datos.html#cb1308-8", "sets-grandes-de-datos.html#cb1308-9", "sets-grandes-de-datos.html#cb1308-10", "sets-grandes-de-datos.html#cb1308-11", "sets-grandes-de-datos.html#factor-analysis", "sets-grandes-de-datos.html#cb1309-1", "sets-grandes-de-datos.html#cb1309-2", "sets-grandes-de-datos.html#cb1309-3", "sets-grandes-de-datos.html#cb1309-4", "sets-grandes-de-datos.html#cb1309-5", "sets-grandes-de-datos.html#cb1309-6", "sets-grandes-de-datos.html#cb1309-7", "sets-grandes-de-datos.html#cb1309-8", "sets-grandes-de-datos.html#cb1309-9", "sets-grandes-de-datos.html#cb1309-10", "sets-grandes-de-datos.html#cb1309-11", "sets-grandes-de-datos.html#cb1309-12", "sets-grandes-de-datos.html#cb1309-13", "sets-grandes-de-datos.html#cb1309-14", "sets-grandes-de-datos.html#cb1310-1", "sets-grandes-de-datos.html#cb1310-2", "sets-grandes-de-datos.html#cb1310-3", "sets-grandes-de-datos.html#cb1310-4", "sets-grandes-de-datos.html#cb1310-5", "sets-grandes-de-datos.html#cb1310-6", "sets-grandes-de-datos.html#cb1310-7", "sets-grandes-de-datos.html#cb1311-1", "sets-grandes-de-datos.html#cb1311-2", "sets-grandes-de-datos.html#cb1311-3", "sets-grandes-de-datos.html#cb1312-1", "sets-grandes-de-datos.html#cb1312-2", "sets-grandes-de-datos.html#cb1312-3", "sets-grandes-de-datos.html#pca", "sets-grandes-de-datos.html#cb1313-1", "sets-grandes-de-datos.html#cb1313-2", "sets-grandes-de-datos.html#cb1313-3", "sets-grandes-de-datos.html#cb1313-4", "sets-grandes-de-datos.html#cb1313-5", "sets-grandes-de-datos.html#cb1313-6", "sets-grandes-de-datos.html#cb1313-7", "sets-grandes-de-datos.html#cb1313-8", "sets-grandes-de-datos.html#cb1313-9", "sets-grandes-de-datos.html#cb1313-10", "sets-grandes-de-datos.html#cb1313-11", "sets-grandes-de-datos.html#cb1313-12", "sets-grandes-de-datos.html#cb1313-13", "sets-grandes-de-datos.html#cb1313-14", "sets-grandes-de-datos.html#cb1314-1", "sets-grandes-de-datos.html#cb1314-2", "sets-grandes-de-datos.html#cb1314-3", "sets-grandes-de-datos.html#cb1314-4", "sets-grandes-de-datos.html#cb1314-5", "sets-grandes-de-datos.html#cb1314-6", "sets-grandes-de-datos.html#cb1314-7", "sets-grandes-de-datos.html#cb1314-8", "sets-grandes-de-datos.html#cb1314-9", "sets-grandes-de-datos.html#cb1315-1", "sets-grandes-de-datos.html#cb1315-2", "sets-grandes-de-datos.html#cb1315-3", "sets-grandes-de-datos.html#cb1315-4", "sets-grandes-de-datos.html#cb1315-5", "sets-grandes-de-datos.html#cb1315-6", "sets-grandes-de-datos.html#cb1315-7", "sets-grandes-de-datos.html#cb1315-8", "sets-grandes-de-datos.html#cb1315-9", "sets-grandes-de-datos.html#cb1315-10", "sets-grandes-de-datos.html#cb1315-11", "sets-grandes-de-datos.html#cb1316-1", "sets-grandes-de-datos.html#cb1316-2", "sets-grandes-de-datos.html#cb1316-3", "sets-grandes-de-datos.html#cb1316-4", "sets-grandes-de-datos.html#cb1317-1", "sets-grandes-de-datos.html#cb1317-2", "sets-grandes-de-datos.html#cb1317-3", "sets-grandes-de-datos.html#cb1317-4", "sets-grandes-de-datos.html#conexi\u00f3n-a-svd-y-pca", "sets-grandes-de-datos.html#cb1318-1", "sets-grandes-de-datos.html#cb1318-2", "sets-grandes-de-datos.html#cb1319-1", "sets-grandes-de-datos.html#cb1319-2", "sets-grandes-de-datos.html#cb1320-1", "sets-grandes-de-datos.html#cb1320-2", "sets-grandes-de-datos.html#cb1321-1", "sets-grandes-de-datos.html#ejercicios-61", "sets-grandes-de-datos.html#cb1326-1", "sets-grandes-de-datos.html#cb1326-2", "sets-grandes-de-datos.html#cb1326-3", "sets-grandes-de-datos.html#cb1326-4", "sets-grandes-de-datos.html#cb1326-5", "sets-grandes-de-datos.html#cb1326-6", "sets-grandes-de-datos.html#cb1326-7", "sets-grandes-de-datos.html#cb1326-8", "sets-grandes-de-datos.html#cb1326-9", "sets-grandes-de-datos.html#cb1326-10", "sets-grandes-de-datos.html#cb1326-11", "sets-grandes-de-datos.html#cb1327-1", "sets-grandes-de-datos.html#cb1327-2", "sets-grandes-de-datos.html#cb1327-3", "sets-grandes-de-datos.html#cb1327-4", "sets-grandes-de-datos.html#cb1327-5", "sets-grandes-de-datos.html#cb1327-6", "sets-grandes-de-datos.html#cb1327-7", "sets-grandes-de-datos.html#cb1327-8", "sets-grandes-de-datos.html#cb1327-9", "sets-grandes-de-datos.html#cb1327-10", "sets-grandes-de-datos.html#cb1327-11", "sets-grandes-de-datos.html#cb1328-1", "sets-grandes-de-datos.html#cb1328-2", "sets-grandes-de-datos.html#cb1328-3", "sets-grandes-de-datos.html#cb1329-1", "sets-grandes-de-datos.html#cb1329-2", "sets-grandes-de-datos.html#cb1330-1", "sets-grandes-de-datos.html#cb1330-2", "sets-grandes-de-datos.html#cb1331-1", "sets-grandes-de-datos.html#cb1332-1", "sets-grandes-de-datos.html#cb1332-2", "sets-grandes-de-datos.html#cb1332-3", "sets-grandes-de-datos.html#cb1333-1", "sets-grandes-de-datos.html#cb1334-1", "sets-grandes-de-datos.html#cb1334-2", "sets-grandes-de-datos.html#cb1334-3", "sets-grandes-de-datos.html#cb1335-1", "sets-grandes-de-datos.html#cb1336-1", "sets-grandes-de-datos.html#cb1336-2", "sets-grandes-de-datos.html#cb1336-3", "https://grouplens.org/datasets/movielens/20m/", "http://bits.blogs.nytimes.com/2009/09/21/netflix-awards-1-million-prize-and-starts-a-new-contest/", "sets-grandes-de-datos.html#fnref120", "https://grouplens.org/", "sets-grandes-de-datos.html#fnref121", "machine-learning-en-la-pr\u00e1ctica.html", "clustering.html"]}