{"title": "PDF", "author": "PDF", "url": "https://rua.ua.es/dspace/bitstream/10045/11456/1/Tesis_vazquez.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "id": "PDF", "license": "PDF", "body": "PDF", "comments": "PDF", "commentsbody": "PDF", "raw_text": "PDF", "text": " \n \n \nResoluci\u00f3n de la ambig\u00fcedad sem\u00e1ntica mediante m\u00e9todos basados en conocimiento y \nsu aportaci\u00f3n a tareas de PLN \n \nSonia V\u00e1zquez P\u00e9rez\n  \n                             Resoluci\u00b4 on de la ambig\u00a8 uedad\nsem\u00b4 antica mediante m\u00b4 etodos\nbasados en conocimiento y su\naportaci\u00b4 on a tareas de PLN\nTesis Doctoral\nAutora: Sonia V\u00b4 azquez P\u00b4 erez\nDirector:\nDr. Andr\u00b4 es Montoyo Guijarro\nDepartamento de Lenguajes y Sistemas Inform\u00b4 aticos\nUniversidad de Alicante\nAlicante, 2009\nA mi familia\nAgradecimientos\nEn primer lugar me gustar\u00b4 \u0131a dar mi m\u00b4 as sincero agradecimien-\nto a todas las personas que me han animado y apoyado en la\nrealizaci\u00b4 on de esta Tesis. En especial, me gustar\u00b4 \u0131a agradecer a\nmi director, Andr\u00b4 es Montoyo, todo el tiempo que ha dedicado a\ndirigir mis investigaciones y todos los consejos que me ha dado\ndurante toda mi trayectoria como investigadora, los cuales, me\nhan llevado hasta este punto.\nTambi\u00b4 en quisiera hacer menci\u00b4 on especial a todos mis com-\npa\u02dc neros del Grupo de Procesamiento del Lenguaje Natural de la\nUniversidad de Alicante, que han aportado su granito de arena en\nesta Tesis y cuyos consejos han sido fundamentales para la \ufb01na-\nlizaci\u00b4 on de este trabajo. Muchos de los avances de esta tesis han\nsido gracias a los trabajos realizados en colaboraci\u00b4 on con distintos\nmiembros del grupo de donde han surgido muy buenas ideas.\nPara terminar, no podr\u00b4 \u0131a haber llegado hasta aqu\u00b4 \u0131 sin el apoyo\nque toda mi familia me ha brindado durante todos estos a\u02dc nos y\nsobretodo, gracias a mi marido por su comprensi\u00b4 on y paciencia\nen este largo camino que sin \u00b4 el habr\u00b4 \u0131a sido, sin duda, muy duro.\nAlicante, 2009\nSonia V\u00b4 azquez\n\u00b4Indice general\n1. Introducci\u00b4 on : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 1\n1.1. Problem\u00b4 atica en PLN . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2. Estructura de un sistema de PLN . . . . . . . . . . . . . . . . 6\n1.3. Objetivo de la Tesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n1.4. Organizaci\u00b4 on de la Tesis . . . . . . . . . . . . . . . . . . . . . . . . 10\n2. Estado del arte : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 11\n2.1. Descripci\u00b4 on del problema . . . . . . . . . . . . . . . . . . . . . . . 11\n2.2. Aplicaciones de WSD . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.3. Sistemas iniciales: el comienzo . . . . . . . . . . . . . . . . . . . 14\n2.4. Clasi\ufb01caci\u00b4 on de sistemas en WSD . . . . . . . . . . . . . . . . 15\n2.5. M\u00b4 etodos basados en conocimiento . . . . . . . . . . . . . . . . 16\n2.5.1. Algoritmo de Lesk . . . . . . . . . . . . . . . . . . . . . . . . 18\n2.5.2. Variaciones del algoritmo de Lesk . . . . . . . . . . . 20\n2.5.2.1.Simulated Annealing . . . . . . . . . . . . . . . . 21\n2.5.2.2.Algoritmo de Lesk simpli\ufb01cado . . . . . . . 22\n2.5.2.3.Espacios sem\u00b4 anticos aumentados . . . . . 24\n2.5.3. Similitud sem\u00b4 antica . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.3.1.Medidas de similitud sem\u00b4 antica . . . . . . 25\n2.5.3.2.Similitud sem\u00b4 antica en un contexto local 28\n2.5.3.3.Similitud sem\u00b4 antica en un contexto\nglobal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\nX \u00b4Indice general\n2.5.4. Preferencias de selecci\u00b4 on . . . . . . . . . . . . . . . . . . . 31\n2.5.4.1.Adquisici\u00b4 on de preferencias de selecci\u00b4 on 31\n2.5.4.2.Usando preferencias de selecci\u00b4 on para\nWSD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n2.5.5. Heur\u00b4 \u0131sticas para Word Sense Disambiguation .33\n2.5.5.1.Sentido m\u00b4 as frecuente . . . . . . . . . . . . . . . 33\n2.5.5.2.Un sentido por discurso . . . . . . . . . . . . . 36\n2.5.5.3.Un sentido por colocaci\u00b4 on . . . . . . . . . . . 36\n2.6. M\u00b4 etodos no supervisados basados en corpus . . . . . . . 37\n2.6.1. M\u00b4 etodos distribucionales . . . . . . . . . . . . . . . . . . . 39\n2.6.1.1.Discriminaci\u00b4 on basada en tipos . . . . . . . 40\n2.6.1.2.Discriminaci\u00b4 on basada en tokens . . . . . 44\n2.7. M\u00b4 etodos supervisados basados en corpus . . . . . . . . . . 45\n2.7.1. El proceso de clasi\ufb01caci\u00b4 on en aprendizaje su-\npervisado . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\n2.7.1.1.Ejemplo: WSD con aprendizaje autom\u00b4 ati-\nco. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n2.7.2. Clasi\ufb01caci\u00b4 on de m\u00b4 etodos de aprendizaje su-\npervisado . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n2.7.2.1.M\u00b4 etodos probabil\u00b4 \u0131sticos . . . . . . . . . . . . . 52\n2.7.2.2.M\u00b4 etodos basados en reglas de discri-\nminaci\u00b4 on . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n2.7.2.3.Bootstrapping . . . . . . . . . . . . . . . . . . . . . 55\n2.7.2.4.M\u00b4 etodos basados en redes neuronales .56\n2.8. M\u00b4 etodos h\u00b4 \u0131bridos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n2.9. Otra clasi\ufb01caci\u00b4 on de sistemas WSD . . . . . . . . . . . . . . . 59\n2.10.Aplicaciones actuales . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n3. Problem\u00b4 atica en la evaluaci\u00b4 on de sistemas de WSD 63\n3.1. Contexto del problema . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n3.1.1. Mejoras en los criterios de evaluaci\u00b4 on . . . . . . . . 64\n3.1.2. Distancia sem\u00b4 antica . . . . . . . . . . . . . . . . . . . . . . . 66\n3.2. Un marco com\u00b4 un para la evaluaci\u00b4 on de sistemas . . . . 68\n4. Recursos : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 71\n4.1. WordNet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n4.2. WordNet Domains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n\u00b4Indice general XI\n4.3. Extended WordNet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\n4.4. SUMO (Suggested Upper Merged Ontology) . . . . . . . 90\n4.5. An\u00b4 alisis de la Sem\u00b4 antica Latente (LSA) . . . . . . . . . . . 96\n5. M\u00b4 etodos : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 103\n5.1. WSD basado en conocimiento: DRelevant . . . . . . . . . 103\n5.1.1. Obtenci\u00b4 on y categorizaci\u00b4 on de contextos . . . . . 105\n5.1.2. Extracci\u00b4 on de contextos . . . . . . . . . . . . . . . . . . . 106\n5.1.3. Obtenci\u00b4 on de las palabras signi\ufb01cativas . . . . . . 108\n5.1.4. Similitud sem\u00b4 antica . . . . . . . . . . . . . . . . . . . . . . . 110\n5.1.4.1.Perfeccionamiento de la Informaci\u00b4 on\nMutua . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\n5.1.5. Vectores de co-ocurrencia . . . . . . . . . . . . . . . . . . 116\n5.1.5.1.WND y SUMO como caracter\u00b4 \u0131sticas . .118\n5.1.6. M\u00b4 etricas sobre vectores . . . . . . . . . . . . . . . . . . . . 119\n5.1.7. Determinaci\u00b4 on del sentido correcto . . . . . . . . . . 123\n5.1.7.1.Ejemplo ilustrativo sobre WND . . . . . . 124\n5.1.8. Extended WordNet y Dominios Relevantes . . .128\n5.2. WSD basado en conocimiento: DLSA . . . . . . . . . . . . . 131\n5.2.1. Base de datos l\u00b4 exica como fuente de conoci-\nmiento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132\n5.2.2. LSA aplicado a WSD . . . . . . . . . . . . . . . . . . . . . . 133\n5.2.2.1.Heur\u00b4 \u0131stica 1: Ratio de Asociaci\u00b4 on . . . . . 134\n5.2.2.2.Heur\u00b4 \u0131stica 2: Similitud LSA . . . . . . . . . . 135\n5.2.2.3.Heur\u00b4 \u0131stica 3: Similitud LSA \u00a3Ratio\nde Asociaci\u00b4 on . . . . . . . . . . . . . . . . . . . . . . 135\n5.2.2.4.Ejemplo ilustrativo . . . . . . . . . . . . . . . . . 135\n5.2.3. LSA aplicado a NED . . . . . . . . . . . . . . . . . . . . . . 137\n5.3. WSD basado en reglas ling\u00a8 u\u00b4 \u0131sticas sobre corpus . . . .138\n5.3.1. Obtenci\u00b4 on de informaci\u00b4 on ling\u00a8 u\u00b4 \u0131stica . . . . . . . . 139\n5.3.1.1.Adquisici\u00b4 on de informaci\u00b4 on paradigm\u00b4 ati-\nca. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139\n5.3.1.2.Discriminadores de sentidos . . . . . . . . . . 140\n5.3.1.3.Identi\ufb01caci\u00b4 on de patrones sintagm\u00b4 aticos 143\n5.3.2. Prueba de conmutabilidad . . . . . . . . . . . . . . . . . 145\n5.3.3. Heur\u00b4 \u0131sticas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\n5.3.4. Ejemplo de aplicaci\u00b4 on . . . . . . . . . . . . . . . . . . . . . 148\nXII \u00b4Indice general\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on : : : : : : : : : : : : : : : : : : : 151\n6.1. Competiciones de evaluaci\u00b4 on . . . . . . . . . . . . . . . . . . . . 151\n6.1.1. SENSEVAL: Evaluation Exercises for the Se-\nmantic Analysis of Text . . . . . . . . . . . . . . . . . . . 152\n6.1.2. SENSEVAL-2: Second International Works-\nhop on Evaluating Word Sense Disambigua-\ntion Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153\n6.1.3. SENSEVAL-3: Evaluation exercises for Word\nSense Disambiguation . . . . . . . . . . . . . . . . . . . . . 154\n6.1.4. SENSEVAL-4/SEMEVAL-1: 4th Internatio-\nnal Workshop on Semantic Evaluations . . . . . . 158\n6.2. Participaci\u00b4 on en Senseval . . . . . . . . . . . . . . . . . . . . . . . 159\n6.2.1. DRelevant: All Words . . . . . . . . . . . . . . . . . . . . . 160\n6.2.1.1.Experimento 1: Oraci\u00b4 on como contexto 160\n6.2.1.2.Experimento 2: Ventana de 100 pala-\nbras como contexto . . . . . . . . . . . . . . . . . 161\n6.2.1.3.Experimento 3: Reducci\u00b4 on y agrupa-\nci\u00b4 on de los dominios . . . . . . . . . . . . . . . . 162\n6.2.1.4.Experimento 4: Desambiguaci\u00b4 on a ni-\nvel de dominio . . . . . . . . . . . . . . . . . . . . . 163\n6.2.1.5.Comparativa con otros sistemas . . . . . . 164\n6.2.2. DRelevant mejorado con Extended WordNet .167\n6.2.3. R2D2: English All Words y English Lexical\nSample . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168\n6.2.3.1.R2D2: English All Words . . . . . . . . . . . . 168\n6.2.3.2.R2D2: English Lexical Sample . . . . . . . 172\n6.2.4. DLSA: English Lexical Sample . . . . . . . . . . . . . 175\n6.2.4.1.Matriz conceptual NVAR . . . . . . . . . . . . 176\n6.2.4.2.Matriz conceptual N-V-A . . . . . . . . . . . . 178\n6.2.4.3.Comparativa con otros sistemas . . . . . . 179\n6.2.5. SenseDiscrim: Spanish Lexical Sample . . . . . . . 181\n6.2.5.1.Evaluaci\u00b4 on de los resultados . . . . . . . . . 184\n6.2.6. Web People Search . . . . . . . . . . . . . . . . . . . . . . . . 185\n6.2.6.1.Evaluaci\u00b4 on de los sistemas de la tarea\nWePS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\n6.3. Participaci\u00b4 on en iCLEF . . . . . . . . . . . . . . . . . . . . . . . . . 195\n6.3.1. Desarrollo de los experimentos . . . . . . . . . . . . . . 196\n\u00b4Indice general XIII\n6.3.1.1.M\u00b4 etodo interactivo I: Dominios Rele-\nvantes . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197\n6.3.1.2.M\u00b4 etodo interactivo II: Patrones sint\u00b4 actico-\nsem\u00b4 anticos . . . . . . . . . . . . . . . . . . . . . . . . 198\n6.3.2. Resultados . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200\n6.3.2.1.Media por usuario . . . . . . . . . . . . . . . . . . 201\n6.3.3. Interpretaci\u00b4 on de resultados y trabajo futuro .201\n6.4. Participaci\u00b4 on en Textual Entailment Recognition . . .202\n6.4.1. RTE2 PASCAL . . . . . . . . . . . . . . . . . . . . . . . . . . . 203\n6.4.1.1.Utilizaci\u00b4 on de diferentes corpus para\nLSA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204\n6.4.1.2.Utilizaci\u00b4 on de la medida del coseno . . .206\n6.4.1.3.Combinaci\u00b4 on de LSA y coseno con un\nsistema de aprendizaje . . . . . . . . . . . . . . 206\n6.4.1.4.Comparativa con otros sistemas par-\nticipantes . . . . . . . . . . . . . . . . . . . . . . . . . 208\n6.4.2. AVE CLEF2006 . . . . . . . . . . . . . . . . . . . . . . . . . . 208\n6.4.2.1.M\u00b4 odulo de solapamiento de palabras:\nSistema MLEnt . . . . . . . . . . . . . . . . . . . . 210\n6.4.2.2.M\u00b4 odulo de similitud sem\u00b4 antica: LSA . .212\n6.4.2.3.M\u00b4 odulo combinatorio . . . . . . . . . . . . . . . 214\n6.4.2.4.Evaluaci\u00b4 on de resultados . . . . . . . . . . . . 215\n6.4.2.5.Comparativa con otros sistemas par-\nticipantes . . . . . . . . . . . . . . . . . . . . . . . . . 219\n6.4.3. Detecci\u00b4 on de par\u00b4 afrasis . . . . . . . . . . . . . . . . . . . . 219\n6.4.3.1.Utilizaci\u00b4 on de WordNet Domains y\nSUMO . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221\n6.4.3.2.Ejemplo ilustrativo . . . . . . . . . . . . . . . . . 222\n6.4.3.3.Evaluaci\u00b4 on . . . . . . . . . . . . . . . . . . . . . . . . 223\n6.5. Integraci\u00b4 on de DRelevant en un sistema\nbasado en aprendizaje . . . . . . . . . . . . . . . . . . . . . . . . . . 227\n6.5.1. Sistema de aprendizaje inicial . . . . . . . . . . . . . . 227\n6.5.2. Nuevas caracter\u00b4 \u0131sticas usando DRelevant . . . . . 228\n6.5.3. Resultados . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229\n6.5.4. Test de McNemar . . . . . . . . . . . . . . . . . . . . . . . . . 231\nXIV\n7. Conclusiones y trabajos futuros : : : : : : : : : : : : : : : : : : 233\n7.1. Aportaciones . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233\n7.1.1. Estudio del estado del arte . . . . . . . . . . . . . . . . . 234\n7.1.2. Estudio de los sistemas de evaluaci\u00b4 on en WSD 234\n7.1.3. Descripci\u00b4 on de los recursos l\u00b4 exicos utilizados . .234\n7.1.4. De\ufb01nici\u00b4 on de los m\u00b4 etodos evaluados . . . . . . . . . 235\n7.1.5. Evaluaci\u00b4 on y aplicaci\u00b4 on de los sistemas de\nWSD a tareas de PLN . . . . . . . . . . . . . . . . . . . . . 235\n7.2. Trabajos Futuros . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 236\n7.3. Producci\u00b4 on cient\u00b4 \u0131\ufb01ca . . . . . . . . . . . . . . . . . . . . . . . . . . . 237\nA. Acr\u00b4 onimos : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 243\nBibliograf\u00b4 \u0131a : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 247\n\u00b4Indice de tablas\n2.1. Clasi\ufb01caci\u00b4 on de m\u00b4 etodos de WSD . . . . . . . . . . . . . . . . 17\n2.2. Algoritmo de Lesk . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.3. De\ufb01niciones para \u201c pine\u201d y \u201c cone\u201d. . . . . . . . . . . . . . . 20\n2.4. Solapamiento entre \u201c pine\u201d y \u201c cone\u201d. . . . . . . . . . . . . . 20\n2.5. Algoritmo simpli\ufb01cado de Lesk . . . . . . . . . . . . . . . . . . 22\n2.6. Algoritmo de Lesk basado en corpus . . . . . . . . . . . . . 23\n2.7. Tabla 2 x2 para log-likelihood ratio . . . . . . . . . . . . . . . 41\n2.8. Sentidos del verbo \u201cto know\u201d en WordNet 1.6 . . . . . 49\n2.9. Clasi\ufb01caci\u00b4 on seg\u00b4 un listas de decisi\u00b4 on de la palabra\n\u201cknow\u201d . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n2.10. Utilizaci\u00b4 on de WSD en aplicaciones de PLN . . . . . . . 61\n3.1. Distribuci\u00b4 on de probabilidades asignadas por dife-\nrentes sistemas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\n3.2. Jerarqu\u00b4 \u0131a de sentidos y matriz de distancia sem\u00b4 anti-\nca para \u201cbank\u201d . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n4.1. Conceptos en la cima de la jerarqu\u00b4 \u0131a de WordNet . .76\n4.2. Relaciones existentes para bank#1 . . . . . . . . . . . . . . . 79\n4.3. De\ufb01niciones para la palabra \u201cbolsa\u201d del RAE . . . . . . 80\n4.4. Relaciones entre diferentes categor\u00b4 \u0131as sint\u00b4 acticas\nmediante el uso de dominios. . . . . . . . . . . . . . . . . . . . . 82\n4.5. Reducci\u00b4 on de la polisemia mediante el uso de do-\nminios . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\nXVI \u00b4Indice de tablas\n4.6. Excellent#1: An\u00b4 alisis sint\u00b4 actico, formas l\u00b4 ogicas y\nanotaci\u00b4 on sem\u00b4 antica. . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\n4.7. Matriz Mw\u00a3c. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n4.8. C\u00b4 alculo similitud PMI para TOEFL . . . . . . . . . . . . . . 102\n4.9. Resultado LSA sobre TOEFL . . . . . . . . . . . . . . . . . . . 102\n4.10. Comparativa LSA y PMI sobre TOEFL . . . . . . . . . . 102\n5.1. Contextos asociados a diferentes sentidos de la pa-\nlabra \u201dcrane\u201d . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\n5.2. Frecuencia de \u201cplant\u201d en WordNet Domains . . . . . . . 111\n5.3. IM de la palabra \u201cdrink\u201d con sus posibles objetos\ndirectos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\n5.4. IM para \u201cplant\u201d en WND . . . . . . . . . . . . . . . . . . . . . . 115\n5.5. RA para \u201cplant\u201d en WND . . . . . . . . . . . . . . . . . . . . . . 115\n5.6. Vectores de co-ocurrencia Brown Corpus . . . . . . . . . . 117\n5.7. Glosas para \u201cimage\u201d . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\n5.8. Discriminadores de Sentidos para \u201c\u00b4 organo\u201d . . . . . . . . 150\n6.1. Medida de la e\ufb01ciencia utilizando como contexto la\noraci\u00b4 on . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161\n6.2. Medida de la e\ufb01ciencia utilizando como contexto\nuna ventana de 100 palabras . . . . . . . . . . . . . . . . . . . . 162\n6.3. Medida de la e\ufb01ciencia reduciendo el nivel de espe-\ncializaci\u00b4 on de los dominios . . . . . . . . . . . . . . . . . . . . . . 163\n6.4. Medida de la e\ufb01ciencia desambiguando a nivel de\ndominio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\n6.5. Comparaci\u00b4 on de los resultados de los distintos sis-\ntemas participantes en la tarea \u201cEnglish all-words\u201d\ndeSenseval-2 .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165\n6.6. Evaluaci\u00b4 on de WSD DRelevant usando Extended\nWordNet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\n6.7. Sistemas participantes en el equipo R2D2 . . . . . . . . . 169\n6.8. Resultados para AllWords con validaci\u00b4 on de res-\npuestas no anotadas . . . . . . . . . . . . . . . . . . . . . . . . . . . 170\n6.9. Resultados para AllWords sin validaci\u00b4 on de res-\npuestas no anotadas . . . . . . . . . . . . . . . . . . . . . . . . . . . 171\n\u00b4Indice de tablas XVII\n6.10. Sistemas participantes en la tarea English Lexical\nSample de Senseval-3 . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\n6.10. Sistemas participantes en la tarea English Lexical\nSample de Senseval-3 (continuaci\u00b4 on) . . . . . . . . . . . . . 173\n6.10. Sistemas participantes en la tarea English Lexical\nSample de Senseval-3 (continuaci\u00b4 on) . . . . . . . . . . . . . 174\n6.10. Sistemas participantes en la tarea English Lexical\nSample de Senseval-3 (continuaci\u00b4 on) . . . . . . . . . . . . . 175\n6.11. DLSA aplicado sobre todas las categor\u00b4 \u0131as NVAR . . .177\n6.12. Resultados ELS sobre nombres . . . . . . . . . . . . . . . . . . 179\n6.13. Resultados ELS sobre verbos . . . . . . . . . . . . . . . . . . . . 180\n6.14. Resultados ELS sobre adjetivos . . . . . . . . . . . . . . . . . . 181\n6.15. DLSA aplicado sobre cada categor\u00b4 \u0131a por separado . .181\n6.16. Sistemas no supervisados en la tarea ELS de Senseval-\n3. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182\n6.17. Resultados del sistema SenseDiscrim para los nom-\nbres de la tarea Spanish Lexical Sample de Senseval-\n3. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184\n6.18. Resultados de los sistemas participantes en la tarea\nSpanish Lexical Sample Senseval-3 . . . . . . . . . . . . . 185\n6.19. Nombres ambiguos en WePS . . . . . . . . . . . . . . . . . . . . 190\n6.20. Resultados evaluaci\u00b4 on WePS . . . . . . . . . . . . . . . . . . . . 193\n6.21. Resultados evaluaci\u00b4 on sistemas WePS . . . . . . . . . . . . 194\n6.22. Resultados usando diferentes corpus y LSA . . . . . . . 205\n6.23. Results for the cosine measure . . . . . . . . . . . . . . . . . . . 206\n6.24. Resultados para la combinaci\u00b4 on de MLEnt con\nLSA y el coseno . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207\n6.25. Evaluaci\u00b4 on de sistemas en RTE2 . . . . . . . . . . . . . . . . . 209\n6.26. Grado de acuerdo Kappa . . . . . . . . . . . . . . . . . . . . . . . 215\n6.27. Resultados para la evaluaci\u00b4 on de AVE . . . . . . . . . . . . 217\n6.28. Evaluaci\u00b4 on sistemas participantes en AVE . . . . . . . . 220\n6.29. LSA listado con los nuevo dominios relevantes para\ncada texto . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225\n6.30. Representaci\u00b4 on conceptual para identi\ufb01car la par\u00b4 afra-\nsis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226\n6.31. Conjunto de atributos de WSD\nMAX\nENT . . . . . . . 228\nXVIII\n6.32. Enriquecimiento de un sistema basado en aprendi-\nzaje con DRelevant . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230\n6.33. Tabla de contingencia para el test de McNemar . . . .231\n6.34. Notaci\u00b4 on abreviada Tabla de contingencia del test\nde McNemar . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\n6.35. Valores observados antes y despu\u00b4 es de la inclusi\u00b4 on\nde los dominios . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\n\u00b4Indice de \ufb01guras\n1.1. Ambig\u00a8 uedad sint\u00b4 actica . . . . . . . . . . . . . . . . . . . . . . . . . 5\n1.2. Estructura de un sistema de PLN . . . . . . . . . . . . . . . . 6\n2.1. Algoritmo Marcas de Especi\ufb01dad . . . . . . . . . . . . . . . . 29\n2.2. Cadenas l\u00b4 exicas en un contexto global . . . . . . . . . . . . 30\n2.3. Distribuci\u00b4 on de sentidos en Semcor . . . . . . . . . . . . . . . 34\n2.4. Modelo clasi\ufb01cador bayesiano (na\u00a8 \u0131ve) . . . . . . . . . . . . . 53\n4.1. Red sem\u00b4 antica para airplane#1 . . . . . . . . . . . . . . . . . . 77\n4.2. Relaciones sem\u00b4 anticas para bank#1 . . . . . . . . . . . . . . 78\n4.3. Jerarqu\u00b4 \u0131a de WordNet Domains . . . . . . . . . . . . . . . . . 84\n4.4. Conceptos de alto nivel en SUMO . . . . . . . . . . . . . . . 92\n4.5. C\u00b4 odigo de colores en la representaci\u00b4 on gr\u00b4 a\ufb01ca de\nSUMO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92\n4.6. Jerarqu\u00b4 \u0131a SUMO para bank#1 . . . . . . . . . . . . . . . . . . 93\n4.7. Reducci\u00b4 on dimensional de la matriz en LSA . . . . . . . 98\n4.8. Descomposici\u00b4 on de la matriz en LSA . . . . . . . . . . . . . 99\n5.1. WordNet Domains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\n5.2. SUMO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\n5.3. Clasi\ufb01caci\u00b4 on contextual a partir de WordNet Do-\nmains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\n5.4. Clasi\ufb01caci\u00b4 on contextual a partir de SUMO . . . . . . . . 109\n5.5. Determinaci\u00b4 on del signi\ufb01cado de \u201ctecuino\u201d . . . . . . . . 116\nXX\n5.6. Vector de co-ocurrencia usando WND . . . . . . . . . . . . 119\n5.7. Distancia Eucl\u00b4 \u0131dea y Manhattan . . . . . . . . . . . . . . . . . 120\n5.8. Lemas del contexto . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\n5.9. Vector de contexto . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\n5.10. Vectores de sentido para \u201cimage\u201d . . . . . . . . . . . . . . . . 126\n5.11. Resultado del coseno entre VC y VS\u2019s . . . . . . . . . . . . 127\n5.12. Sistema DRelevant . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\n5.13. Extended WordNet para president#3 . . . . . . . . . . . . . 129\n5.14. Extracci\u00b4 on de dominios con Extended WordNet . . . .130\n5.15. Dominios Relevantes (DR) para \u201cpresident\u201d . . . . . . . 131\n5.16. Dominios Relevantes seg\u00b4 un LSA . . . . . . . . . . . . . . . . . 136\n5.17. Vectores de sentidos para \u201cadd\u201d . . . . . . . . . . . . . . . . . 137\n5.18. Selecci\u00b4 on del sentido correcto . . . . . . . . . . . . . . . . . . . . 137\n5.19. Relaciones sintagm\u00b4 aticas y paradigm\u00b4 aticas . . . . . . . . 140\n5.20. EuroWordNet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\n5.21. Prueba de conmutabilidad . . . . . . . . . . . . . . . . . . . . . . 146\n5.22. Arquitectura sistema . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\n5.23. Extracci\u00b4 on de patrones . . . . . . . . . . . . . . . . . . . . . . . . . 149\n5.24. Informaci\u00b4 on paradigm\u00b4 atica . . . . . . . . . . . . . . . . . . . . . . 149\n5.25. Heur\u00b4 \u0131sticas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\n6.1. Sistema de votaci\u00b4 on R2D2 All Words . . . . . . . . . . . . . 169\n6.2. Arquitectura sistema WePS . . . . . . . . . . . . . . . . . . . . . 191\n6.3. P\u00b4 agina web interactiva para dominios relevantes . . .198\n6.4. P\u00b4 agina web interactiva para patrones SSP . . . . . . . . 199\n6.5. Media gen\u00b4 erica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200\n6.6. Media estricta por usuario . . . . . . . . . . . . . . . . . . . . . . 201\n6.7. Media tolerante por usuario . . . . . . . . . . . . . . . . . . . . . 202\n6.8. Comparaci\u00b4 on de las jerarqu\u00b4 \u0131as SUMO y WND . . . . . 222\n6.9. Textos n\u00b4 umero 1634 del corpus . . . . . . . . . . . . . . . . . . 223\n6.10. Los cinco primeros dominios relevantes de cada pa-\nlabra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\n6.11. Anotaci\u00b4 on con DRelevant . . . . . . . . . . . . . . . . . . . . . . . 229\nCap\u0013\u0010tulo 1\nIntroducci\u00b4 on\nDesde la aparici\u00b4 on de las primeras computadoras en los a\u02dc nos\n50, nuestras vidas giran en torno a multitud de dispositivos elec-\ntr\u00b4 onicos que facilitan nuestra existencia. De hecho, en la actuali-\ndad, la gran explosi\u00b4 on de tecnolog\u00b4 \u0131as relacionadas con las comuni-\ncaciones (internet, telefon\u00b4 \u0131a m\u00b4 ovil, etc) ha motivado el desarrollo\nparejo de otras tecnolog\u00b4 \u0131as estrechamente vinculadas a mejorar\nla comunicaci\u00b4 on hombre-m\u00b4 aquina. Actualmente, los dispositivos\nGPS utilizan sistemas de comunicaci\u00b4 on que simulan la voz hu-\nmana, las b\u00b4 usquedas en internet se realizan en cualquier idioma,\nsiendo el buscador capaz de reconocer el idioma y extraer la in-\nformaci\u00b4 on correspondiente, las traducciones de textos se hacen de\nforma autom\u00b4 atica con un software especialmente dise\u02dc nado para\nello, etc. Un ejemplo de c\u00b4 omo han evolucionado los sistemas de\ncomunicaci\u00b4 on son los actuales servicios de informaci\u00b4 on automati-\nzados, donde a trav\u00b4 es del tel\u00b4 efono podemos comprobar en breves\nsegundos si existen atascos, encontrar la farmacia de guardia de\nun municipio, consultar el pron\u00b4 ostico meteorol\u00b4 ogico, etc. Todas\nlas consultas se hacen como si realmente existiera una persona\nal otro lado, pero verdaderamente detr\u00b4 as del auricular hay un\nsistema automatizado muy complejo que procesa la consulta de\nforma autom\u00b4 atica. A simple vista todo parece muy sencillo, se\nhace la pregunta, se procesa y se da la respuesta. Pero de hecho,\nla parte de procesamiento lleva asociada una gran complejidad.\n2\nConcretamente, en el caso de las consultas telef\u00b4 onicas, para que\ntodo funcione correctamente y se obtenga una respuesta satisfac-\ntoria, es necesario realizar previamente una serie de tareas m\u00b4 as\ncomplejas como: determinar el idioma del interlocutor, transfor-\nmar los sonidos en palabras y frases con signi\ufb01cado, realizar el\nan\u00b4 alisis sint\u00b4 actico de la pregunta, detectar los nombres propios,\nseleccionar del sentido correcto de cada palabra dentro de su con-\ntexto, etc. Todas estas tareas requieren de un profundo conoci-\nmiento ling\u00a8 u\u00b4 \u0131stico y a la vez en muchos casos, de un elevado coste\ncomputacional. Estas necesidades han derivado en una disciplina\ndenominada Ling\u00a8 u\u00b4 \u0131stica Computacional o Procesamiento del Len-\nguaje Natural (PLN) que combina la ling\u00a8 u\u00b4 \u0131stica y la inform\u00b4 atica\ncon el \ufb01n de modelar el lenguaje humano desde un punto de vista\ncomputacional.\nUno de los motores principales que ha impulsado la necesi-\ndad actual del tratamiento del lenguaje humano ha sido Internet.\nLa red proporciona una gran cantidad de informaci\u00b4 on sobre mul-\ntitud de tem\u00b4 aticas pero con un problema asociado: la informa-\nci\u00b4 on est\u00b4 a desestructurada y descentralizada. Existen in\ufb01nidad de\np\u00b4 aginas web: de empresas, personales, blogs, foros, p\u00b4 aginas web\ninstitucionales... algunas de ellas est\u00b4 an relacionadas y otras no\ntienen nada en com\u00b4 un. Esta falta de organizaci\u00b4 on requiere la uti-\nlizaci\u00b4 on de alg\u00b4 un tipo de tecnolog\u00b4 \u0131a que gestione de forma e\ufb01caz\ntoda la informaci\u00b4 on disponible para que tanto las b\u00b4 usquedas como\nlas consultas sean efectivas. Esta problem\u00b4 atica ha derivado en la\nutilizaci\u00b4 on de dos tipos de tecnolog\u00b4 \u0131as bien diferenciadas: Tecno-\nlog\u00b4 \u0131as de Procesamiento de Datos y Tecnolog\u00b4 \u0131as de Procesamiento\ndel Lenguaje Natural. Cada una de estas tecnolog\u00b4 \u0131as procesa de\nforma diferente la informaci\u00b4 on. A diferencia de las Tecnolog\u00b4 \u0131as de\nProcesamiento de Datos que se ocupan de reducir el espacio ocu-\npado, almacenar de forma \u00b4 optima los datos, ahorrar tiempos de\nrespuesta en la b\u00b4 usqueda de alg\u00b4 un tipo de informaci\u00b4 on, etc, las\nTecnolog\u00b4 \u0131as de Procesamiento del Lenguaje Natural necesitan un\nconocimiento m\u00b4 as profundo del lenguaje para poder procesar la\ninformaci\u00b4 on. Esta diferencia puede verse m\u00b4 as clara con el siguiente\nejemplo:\n1. Introducci\u00b4 on 3\nSupongamos que tenemos un programa que puede contar el\nn\u00b4 umero de l\u00b4 \u0131neas, de palabras o de bytes en un \ufb01chero de texto.\nDentro de este programa se utilizan dos t\u00b4 ecnicas distintas. Mien-\ntras que para contar l\u00b4 \u0131neas y n\u00b4 umero de bytes no es necesario\nning\u00b4 un conocimiento ling\u00a8 u\u00b4 \u0131stico (procesamiento de datos), para\ncontar las palabras s\u00b4 \u0131 es necesario un conocimiento de qu\u00b4 e signi\ufb01ca\nrealmente ser una palabra (procesamiento del lenguaje natural).\nEste es un peque\u02dc no ejemplo muy simple y muy pobre en cono-\ncimiento ling\u00a8 u\u00b4 \u0131stico de aplicaci\u00b4 on de procesamiento del lenguaje\nnatural. Por supuesto, actualmente se han desarrollado multitud\nde aplicaciones mucho m\u00b4 as complejas que abordan diferentes tipos\nde problemas. Entre este tipo de aplicaciones encontramos: tra-\nductores autom\u00b4 aticos, motores de b\u00b4 usqueda, sistemas de di\u00b4 alo-\ngo, etc. Todos estos sistemas deben profundizar mucho m\u00b4 as en\nel conocimiento ling\u00a8 u\u00b4 \u0131stico para su correcto funcionamiento. Por\nejemplo, un sistema de traducci\u00b4 on autom\u00b4 atica deber\u00b4 \u0131a ser capaz\nde traducir correctamente \u201c I\u2019m in bed because I have a cold \u201d por\n\u201cEstoy en cama porque estoy resfriado\u201d y no por \u201cEstoy en cama\nporque tengo un fr\u00b4 \u0131o\u201d. La forma de determinar el signi\ufb01cado de la\npalabra \u201c cold\u201d es utilizar las palabras del contexto que la rodean,\npara poder decidir qu\u00b4 e sentido es el m\u00b4 as apropiado. Por tanto,\ncuando necesitamos un conocimiento m\u00b4 as preciso del lenguaje, de\nlas relaciones entre palabras o de las expresiones en diferentes con-\ntextos, hablamos de Tecnolog\u00b4 \u0131as de Procesamiento del Lenguaje\nNatural (PLN).\n1.1 Problem\u00b4 atica en PLN\nUno de los principales problemas encontrados al tratar tex-\nto no pre-formateado: di\u00b4 alogos, consultas telef\u00b4 onicas... es la am-\nbig\u00a8 uedad. En el lenguaje humano podemos encontrar m\u00b4 ultiples\nexpresiones y palabras que pueden tener varios signi\ufb01cados distin-\ntos dependiendo de las circunstancias de uso. Estas caracter\u00b4 \u0131sticas\nhacen que el lenguaje natural se distinga de los lenguajes arti\ufb01cia-\nles por su riqueza (en vocabulario y construcciones), \ufb02exibilidad\n(reglas con m\u00b4 ultiples excepciones), ambig\u00a8 uedad (pudiendo darse\n4 1.1 Problem\u00b4 atica en PLN\ndiversos signi\ufb01cados de una palabra o una frase seg\u00b4 un el contex-\nto), indeterminaci\u00b4 on (permitiendo referencias y elipsis) y distintas\ninterpretaciones del sentido literal seg\u00b4 un la situaci\u00b4 on o el contex-\nto en que se produce. Lo que son ventajas para la comunicaci\u00b4 on\nhumana se convierten en problemas a la hora de un tratamien-\nto computacional, ya que implican conocimiento y procesos de\nrazonamiento que son dif\u00b4 \u0131ciles de formalizar. Debido a estas ca-\nracter\u00b4 \u0131sticas del lenguaje natural, es necesario utilizar una serie\nde t\u00b4 ecnicas de PLN para trabajar con texto y expresiones huma-\nnas que permitan resolver a partir de un an\u00b4 alisis dirigido por el\ndominio, el uso, el contexto, etc, los distintos problemas de inter-\npretaci\u00b4 on que puedan aparecer.\nEn el campo del PLN el problema de la ambig\u00a8 uedad puede\ntratarse desde distintas perspectivas. Desde la ambig\u00a8 uedad debida\na palabras polis\u00b4 emicas, hasta la ambig\u00a8 uedad producida por las\ndistintas interpretaciones que pueda tener una oraci\u00b4 on. Dentro del\nPLN, por tanto, podemos distinguir tres tipos de ambig\u00a8 uedad:\nAmbig\u00a8 uedad l\u00b4 exica Una misma palabra puede pertenecer a di-\nferentes categor\u00b4 \u0131as gramaticales.\nPor ejemplo:\nLa palabra \u201cpara\u201d puede ser: preposici\u00b4 on, forma del verbo\nparar o forma del verbo parir.\nAmbig\u00a8 uedad sint\u00b4 actica o ambig\u00a8 uedad estructural Aparece\ncuando debido a la forma en que se asocian los distintos cons-\ntituyentes de una oraci\u00b4 on, podemos interpretarla de varias for-\nmas distintas. Siendo a veces casi imposible de solucionar.\nPor ejemplo:\nJuan vio a su hermana con unos prism\u00b4 aticos (\u00bfJuan us\u00b4 o los\nprism\u00b4 aticos para ver a su hermana o Juan vio que su hermana\nten\u00b4 \u0131a unos prism\u00b4 aticos?)\nAmbig\u00a8 uedad sem\u00b4 antica Dentro de este tipo de ambig\u00a8 uedad\npodemos diferenciar tres clases:\n1.Ambig\u00a8 uedad debida a las palabras polis\u00b4 emicas. En este\ncaso, una misma palabra puede tener distintos signi\ufb01cados\ndependiendo del uso que se le est\u00b4 e dando en cada momento.\n1. Introducci\u00b4 on 5\n \n \n \n \n \n \n \n \n \n \n \n          Juan  vio  a    su   hermana   con  unos prism\u00e1ticos \n  Juan   vio  a    su   hermana  con  unos prism\u00e1ticos \nFigura 1.1. Ambig\u00a8 uedad sint\u00b4 actica\nPor ejemplo:\nEntr\u00b4 o en el banco . (Entidad \ufb01nanciera)\nSe sent\u00b4 o en el banco del parque. (Asiento)\n2.Ambig\u00a8 uedad debida a encontrar una misma estructura\nsint\u00b4 actica con diferentes signi\ufb01cados.\nPor ejemplo:\nTodos los estudiantes de secundaria hablan dos lenguas .\n(\u00bfCada estudiante habla dos lenguas o s\u00b4 olo se hablan dos\nlenguas determinadas?)\n3.Ambig\u00a8 uedad referencial. En este caso, es necesario el an\u00b4 ali-\nsis del texto m\u00b4 as all\u00b4 a de los l\u00b4 \u0131mites de la frase, determinan-\ndo los antecedentes referenciales de los pronombres.\nPor ejemplo:\nEl jam\u00b4 on est\u00b4 a en el armario. S\u00b4 acalo .Ci\u00b4 erralo .(\u00bfHacen\nreferencia al jam\u00b4 on o al armario?)\nLa resoluci\u00b4 on de los diferentes tipos de ambig\u00a8 uedades requie-\nre mucho conocimiento y es necesario aplicar diferentes t\u00b4 ecnicas\npara solucionar cada caso. Podemos utilizar modelos de Markov\n(Markov (1971 )) para resolver la ambig\u00a8 uedad l\u00b4 exica, gram\u00b4 aticas\nprobabil\u00b4 \u0131sticas para resolver la ambig\u00a8 uedad sint\u00b4 actica o t\u00b4 ecnicas\nbasadas en conocimiento o aprendizaje autom\u00b4 atico para resolver\nla ambig\u00a8 uedad sem\u00b4 antica. El tratamiento de la ambig\u00a8 uedad, es\npor tanto, una tarea necesaria para cualquier sistema de PLN,\n6 1.2 Estructura de un sistema de PLN\npero esta tarea no funciona de forma independiente, se comple-\nmenta con otras tareas como el an\u00b4 alisis sint\u00b4 atico que le suministra\ninformaci\u00b4 on muy valiosa. De esta forma, podemos decir que la ta-\nrea de resoluci\u00b4 on de la ambig\u00a8 uedad es una tarea intermedia que\ncompleta un sistema de PLN.\n1.2 Estructura de un sistema de PLN\nSi se analizan en profundidad los actuales sistemas de PLN to-\ndos ellos comparten una serie de m\u00b4 odulos b\u00b4 asicos para su correcto\nfuncionamiento. La Figura 1.2muestra la estructura general de\nun sistema de PLN.\n \nTexto \nAn\u00e1lisis \nL\u00e9xico \nAn\u00e1lisis \nSint\u00e1ctico An\u00e1lisis \nSem\u00e1ntico \nUnidades \nl\u00e9xicas \n(palabras) \n\u00c1rbol sint\u00e1ctico \n(Sujeto, predicado, \nN, V, Adj, Adv) \nSignificado \n(polisemia) Gram\u00e1tica Diccionario \nOntolog\u00eda \nsem\u00e1ntica \nFigura 1.2. Estructura de un sistema de PLN\nComo se puede apreciar en la Figura 1.2y suponiendo que\nestamos procesando texto, tenemos tres m\u00b4 odulos principales:\n1. Introducci\u00b4 on 7\nM\u00b4 odulo de an\u00b4 alisis l\u00b4 exico. La principal tarea de este m\u00b4 odulo\nes detectar palabras, es decir, la menor unidad existente con\nsigni\ufb01cado. Dentro del l\u00b4 exico de un lenguaje es necesario de-\ntectar adem\u00b4 as de las palabras simples, las palabras compues-\ntas, frases hechas, siglas, pr\u00b4 estamos idiom\u00b4 aticos, etc. Adem\u00b4 as\ntambi\u00b4 en es necesario diferenciar entre la forma (la palabra tal\ncomo aparece) y el lema (la forma can\u00b4 onica de la palabra).\nEl objetivo \ufb01nal de este m\u00b4 odulo es asociar a cada palabra su\nlema correspondiente, etiquetar cada palabra con sus posibles\ncategor\u00b4 \u0131as l\u00b4 exicas (N, V, Adj, Adv) y a\u02dc nadir algunos rasgos\ngramaticales (g\u00b4 enero, n\u00b4 umero, tiempo verbal...)\nM\u00b4 odulo de an\u00b4 alisis sint\u00b4 actico. Este m\u00b4 odulo se ocupa de rea-\nlizar el an\u00b4 alisis sint\u00b4 actico de tal forma que selecciona la eti-\nqueta gramatical m\u00b4 as apropiada para cada palabra, realiza un\n\u201cchunking\u201d del texto (divide el texto en segmentos analiza-\nbles), utiliza formas l\u00b4 ogicas para el an\u00b4 alisis, etc.\nM\u00b4 odulo de an\u00b4 alisis sem\u00b4 antico. El \u00b4 ultimo m\u00b4 odulo es el que si-\ngue al an\u00b4 alisis sint\u00b4 actico. En este caso se ocupa de asignar\nel sentido correspondiente a cada palabra (resolver la am-\nbig\u00a8 uedad sem\u00b4 antica). Este m\u00b4 odulo puede funcionar en paralelo\ncon el m\u00b4 odulo de an\u00b4 alisis sint\u00b4 actico o posteriormente. En cual-\nquier caso, existen diferentes t\u00b4 ecnicas aplicables para resolver\nla ambig\u00a8 uedad: l\u00b4 ogica de predicados, redes sem\u00b4 anticas, grafos\nde dependencias conceptuales, etc.\nSeg\u00b4 un la Figura 1.2, los distintos m\u00b4 odulos de un sistema de\nPLN necesitan fuentes externas tales como diccionarios, gram\u00b4 ati-\ncas u ontolog\u00b4 \u0131as, que se adec\u00b4 uen al idioma o al dominio de los\ntextos a tratar. Estas fuentes externas de conocimiento dotan al\nsistema de la informaci\u00b4 on necesaria para poder establecer las re-\nglas de la gram\u00b4 atica, el dominio de aplicaci\u00b4 on de los textos, las\nrelaciones entre palabras a partir de una jerarqu\u00b4 \u0131a, etc.\nComo veremos m\u00b4 as adelante, todos los recursos l\u00b4 exicos uti-\nlizados por un sistema de PLN est\u00b4 an basados en teor\u00b4 \u0131as psico-\nling\u00a8 u\u00b4 \u0131sticas adaptadas al idioma de estudio. En nuestro caso, se\nhan utilizado diversos recursos l\u00b4 exicos externos para realizar la\n8 1.3 Objetivo de la Tesis\ntarea de desambiguaci\u00b4 on, que como indica la Figura 1.2se realiza\nen el m\u00b4 odulo de an\u00b4 alisis sem\u00b4 antico.\n1.3 Objetivo de la Tesis\nDada la necesidad actual de tratamiento del lenguaje natural\ny descubierta la problem\u00b4 atica de la ambig\u00a8 uedad intr\u00b4 \u0131nseca en el\nlenguaje humano, es necesario el tratamiento de forma e\ufb01caz de\neste problema.\nComo se ha mencionado anteriormente, existen distintos tipos\nde ambig\u00a8 uedad: l\u00b4 exica, sint\u00b4 actica y sem\u00b4 antica. El tratamiento de\nlos distintos tipos de ambig\u00a8 uedad requiere de la aplicaci\u00b4 on de\nt\u00b4 ecnicas de PLN espec\u00b4 \u0131\ufb01cas. Por tanto, es dif\u00b4 \u0131cil intentar abarcar\nla resoluci\u00b4 on de todos los tipos de ambig\u00a8 uedad utilizando una mis-\nma t\u00b4 ecnica, y es por ello, que esta Tesis est\u00b4 a centrada \u00b4 unicamente\nen la resoluci\u00b4 on de la ambig\u00a8 uedad sem\u00b4 antica, que est\u00b4 a vinculada\na la aparici\u00b4 on de palabras polis\u00b4 emicas en el lenguaje.\nEl objetivo principal de esta Tesis es desarrollar distintos m\u00b4 eto-\ndos de resoluci\u00b4 on de la ambig\u00a8 uedad sem\u00b4 antica basados en cono-\ncimiento. Cuando hablamos de m\u00b4 etodos basados en conocimien-\nto hacemos referencia a aquellos m\u00b4 etodos que no necesitan de\ncorpus extensos para poder funcionar, sino que utilizan recursos\nl\u00b4 exicos como diccionarios u ontolog\u00b4 \u0131as para extraer las relaciones\nexistentes entre palabras y construir estructuras de datos con in-\nformaci\u00b4 on relevante que determine la similitud entre diferentes\ncontextos, palabras, etc. Se ha demostrado que los resultados ob-\ntenidos con m\u00b4 etodos basados en conocimiento son relativamente\nm\u00b4 as bajos que los de otros m\u00b4 etodos basados en t\u00b4 ecnicas de apren-\ndizaje, pero la ventaja de los m\u00b4 etodos basados en conocimiento\nradica en que su aplicaci\u00b4 on es muy \u00b4 util en el caso de estudio de\nlenguas minoritarias, ya que encontrar corpus extensos de estas\nlenguas es muy complicado.\nEn esta Tesis se presentan varios m\u00b4 etodos basados en cono-\ncimiento con distintos enfoques, aplicados a la desambiguaci\u00b4 on\nautom\u00b4 atica:\n1. Introducci\u00b4 on 9\nWSD DRelevant. Basado en la utilizaci\u00b4 on de las categor\u00b4 \u0131as\nsem\u00b4 anticas de WordNet Domains. El objetivo de este m\u00b4 etodo\nes la determinaci\u00b4 on del sentido correcto de las palabras a partir\ndel establecimiento del dominio contextual donde aparecen. El\nproceso comienza mediante la obtenci\u00b4 on de un nuevo recurso\nl\u00b4 exico (Dominios Relevantes) basado en la frecuencia de apa-\nrici\u00b4 on de las palabras junto a diferentes dominios en WordNet.\nEste recurso es la base de todo el proceso de desambiguaci\u00b4 on\ncentrado en medidas de frecuencia y co-ocurrencia.\nWSD DLSA. Basado en la utilizaci\u00b4 on de la t\u00b4 ecnica del An\u00b4 alisis\nde la Sem\u00b4 antica Latente. Se construye un espacio sem\u00b4 antico\ncon las diferentes categor\u00b4 \u0131as de WordNet Domains. El obje-\ntivo de este m\u00b4 etodo es establecer aquellas relaciones ocultas\nentre palabras que no pertenecen al mismo dominio o categor\u00b4 \u0131a\nsem\u00b4 antica pero s\u00b4 \u0131 tienen alguna relaci\u00b4 on contextual.\nWSD SenseDiscrim. Basado en la utilizaci\u00b4 on de patrones y dis-\ncriminadores de sentidos. El objetivo de este m\u00b4 etodo es extraer\nocurrencias de patrones l\u00b4 exicos a partir de diferentes contex-\ntos y determinar el sentido de las palabras presentes en dichos\npatrones utilizando la jerarqu\u00b4 \u0131a de WordNet.\nTodos los m\u00b4 etodos descritos se basan en la premisa de que las\npalabras que aparecen en un mismo contexto tienden a estar re-\nlacionadas sem\u00b4 anticamente. Es decir, es m\u00b4 as probable que una\npalabra que aparezca en contextos similares tenga el mismo senti-\ndo, que esa misma palabra, en contextos dispares tenga el mismo\nsigni\ufb01cado.\nAsimismo, la ambig\u00a8 uedad en el lenguaje no es un problema\naislado en PLN, sino que afecta a diferentes \u00b4 areas: traducci\u00b4 on\nautom\u00b4 atica, extracci\u00b4 on de informaci\u00b4 on, recuperaci\u00b4 on de documen-\ntos, etc. Consecuentemente, en esta Tesis se han aplicado las t\u00b4 ecni-\ncas de desambiguaci\u00b4 on autom\u00b4 atica propuestas, sobre algunas apli-\ncaciones \ufb01nales de PLN. Entre estas aplicaciones destacamos la\ndetecci\u00b4 on de par\u00b4 afrasis e implicaci\u00b4 on textual o la desambiguaci\u00b4 on\ny discriminaci\u00b4 on de entidades. El objetivo principal en este \u00b4 area,\nes demostrar que la inclusi\u00b4 on de sistemas de resoluci\u00b4 on autom\u00b4 ati-\nca de la ambig\u00a8 uedad, es necesaria para la obtenci\u00b4 on de buenos\n10\nresultados. Adem\u00b4 as, el recurso l\u00b4 exico obtenido a partir de los do-\nminios relevantes de WordNet, es una herramienta muy \u00b4 util y que\nproporciona informaci\u00b4 on bene\ufb01ciosa para diferentes aplicaciones\nde PLN.\n1.4 Organizaci\u00b4 on de la Tesis\nEsta Tesis se ha estructurado en siete cap\u00b4 \u0131tulos:\nCap\u00b4 \u0131tulo 1: Introducci\u00b4 on.\nPresentaci\u00b4 on de la problem\u00b4 atica en el Procesamiento del Len-\nguaje Natural debida a la ambig\u00a8 uedad del lenguaje, objetivos y\nestructura de la Tesis.\nCap\u00b4 \u0131tulo 2: Estado del arte.\nDescripci\u00b4 on de la evoluci\u00b4 on de los sistemas de desambiguaci\u00b4 on\nautom\u00b4 atica, clasi\ufb01caci\u00b4 on y comparaci\u00b4 on de sistemas.\nCap\u00b4 \u0131tulo 3: Problem\u00b4 atica en la evaluaci\u00b4 on de sistemas de\nWSD.\nDescripci\u00b4 on de los distintos tipos de anotaciones utilizados pa-\nra etiquetar los sentidos de las palabras, corpus, etc. Problemas\nde establecimiento de los sentidos correctos de las palabras y\ndiferentes medidas de evaluaci\u00b4 on utilizadas.\nCap\u00b4 \u0131tulo 4: Recursos.\nDescripci\u00b4 on de los recursos l\u00b4 exicos utilizados. Estudio de las ven-\ntajas e inconvenientes de cada recurso. Combinaci\u00b4 on de recursos\ncon el objetivo de mejorar los resultados obtenidos.\nCap\u00b4 \u0131tulo 5: M\u00b4 etodos.\nDescripci\u00b4 on de los m\u00b4 etodos desarrollados. Aplicaci\u00b4 on a diversas\ntareas de PLN.\nCap\u00b4 \u0131tulo 6: Evaluaci\u00b4 on.\nRealizaci\u00b4 on de diversos experimentos para la evaluaci\u00b4 on de los\nm\u00b4 etodos. Comparativa de los resultados obtenidos con diferen-\ntes aproximaciones.\nCap\u00b4 \u0131tulo 7: Conclusiones y trabajos futuros.\nAportaci\u00b4 on de esta Tesis al campo de la desambiguaci\u00b4 on autom\u00b4 ati-\nca y propuesta de trabajos futuros. Relaci\u00b4 on de publicaciones\nderivadas de la consecuci\u00b4 on de esta Tesis.\nCap\u0013\u0010tulo 2\nEstado del arte\nEn este cap\u00b4 \u0131tulo se presenta una breve introducci\u00b4 on al proble-\nma de la ambig\u00a8 uedad sem\u00b4 antica junto con las distintas aplicacio-\nnes en las que es necesario la aplicaci\u00b4 on de t\u00b4 ecnicas para resolver\neste tipo de ambig\u00a8 uedad. Adem\u00b4 as se establece la evoluci\u00b4 on de los\ndiferentes sistemas de resoluci\u00b4 on de la ambig\u00a8 uedad sem\u00b4 antica y\nsu clasi\ufb01caci\u00b4 on a partir de los recursos que utilizan.\n2.1 Descripci\u00b4 on del problema\nEs muy com\u00b4 un encontrar en cualquier idioma palabras con\nm\u00b4 ultiples signi\ufb01cados; por ejemplo, \u201c\ufb02ojo\u201d puede signi\ufb01car algo\nque est\u00b4 a poco apretado o alguien que es un cobarde. El signi\ufb01ca-\ndo particular de una palabra viene determinado por el contexto\nque la rodea y en muchas ocasiones por la situaci\u00b4 on en que se\nemplea. Si por ejemplo, decimos: \u201cTe has dejado los cordones de\nlos zapatos demasiado \ufb02ojos \u201d, en este caso, sabemos exactamente\nel signi\ufb01cado asociado a esta palabra.\nEl procedimiento para decidir los signi\ufb01cados de las palabras\na partir del contexto que las rodea se conoce como \u201cdesambigua-\nci\u00b4 on\u201d o \u201cWord Sense Disambiguation\u201d (WSD).\nEn procesamiento del lenguaje natural las investigaciones en\nWSD han existido desde la aparici\u00b4 on de este \u00b4 area de investigaci\u00b4 on.\n12 2.2 Aplicaciones de WSD\nEs m\u00b4 as, WSD se ha considerado como una tarea completamen-\nte distinta a otras dirigidas al usuario \ufb01nal, como por ejemplo,\nTraducci\u00b4 on Autom\u00b4 atica. De hecho, para obtener un buen sistema\nde Traducci\u00b4 on Autom\u00b4 atica es necesario resolver el problema de\nla ambig\u00a8 uedad, y poder proporcionar de esta forma, una buena\ncomprensi\u00b4 on del lenguaje.\nA continuaci\u00b4 on se van a describir algunas de los m\u00b4 etodos\nm\u00b4 as conocidos para resolver el problema de WSD. Adem\u00b4 as, se\nmostrar\u00b4 an los avances m\u00b4 as recientes en este campo, dentro de\nuna de las competiciones m\u00b4 as importantes: Senseval (Kilgarri\ufb00\n(1998b )).\n2.2 Aplicaciones de WSD\nEn traducci\u00b4 on autom\u00b4 atica la desambiguaci\u00b4 on es uno de los\nprincipales problemas que necesitan tratamiento. Aunque este es\nuno de los principales usos de WSD tambi\u00b4 en deben considerar-\nse otras muchas aplicaciones de PLN que necesitan resolver este\nproblema. Recientemente han aparecido nuevas \u00b4 areas de cono-\ncimiento y el tratamiento autom\u00b4 atico para la resoluci\u00b4 on de la\nambig\u00a8 uedad es muy necesario. Entre estas nuevas \u00b4 areas de co-\nnocimiento encontramos por ejemplo la bioinform\u00b4 atica y la Web\nSem\u00b4 antica.\nA continuaci\u00b4 on vamos a ver qu\u00b4 e necesidades tienen las diferen-\ntes tareas de PLN y de qu\u00b4 e forma se aplica la desambiguaci\u00b4 on\nautom\u00b4 atica para su correcto funcionamiento:\nTraducci\u00b4 on autom\u00b4 atica (TA). WSD es necesaria para la\nselecci\u00b4 on de la correcta traducci\u00b4 on de palabras que pueden tener\ndistintas acepciones seg\u00b4 un el sentido asignado. Por ejemplo, en\nun texto que necesite ser traducido del ingl\u00b4 es al franc\u00b4 es pode-\nmos encontrar la palabra \u201c change \u201d que puede ser traducida como\n\u201cchangement \u201d (transformaci\u00b4 on) o \u201c monnaie \u201d (dinero suelto). En\nTA, los sentidos se representan a menudo como palabras en el len-\nguaje de traducci\u00b4 on destino. Sin embargo, muchos modelos de TA\nno utilizan WSD expl\u00b4 \u0131citamente. En muchos casos el vocabulario\nes pre-desambiguado para un dominio determinado, se desarrollan\n2. Estado del arte 13\nreglas hechas a mano o WSD est\u00b4 a almacenado en un modelo de\ntraducci\u00b4 on estad\u00b4 \u0131stico ( Brown et al. (1991 )).\nRecuperaci\u00b4 on de Informaci\u00b4 on (RI). En este caso, la am-\nbig\u00a8 uedad debe ser resuelta en algunas cuestiones. Por ejemplo,\nsi tenemos una cuesti\u00b4 on en la que aparece la palabra \u201c depres-\nsion\u201d, el sistema de RI podr\u00b4 \u0131a devolver documentos que hablan\nsobre enfermedades, el tiempo o econom\u00b4 \u0131a. Un problema similar\naparece asociado a nombres propios tales como \u201c Raleigh \u201d (bici-\ncleta, persona, ciudad, etc). Los sistemas actuales de RI no utili-\nzan expl\u00b4 \u0131citamente WSD, \u00b4 unicamente se basan en que el usuario\nd\u00b4 e el su\ufb01ciente contexto en la pregunta para extraer \u00b4 unicamente\nlos documentos relevantes al sentido correcto (ej \u201c tropical depres-\nsion\u201d). Experimentos recientes sugieren que un sistema \ufb01able de\nRI necesitar\u00b4 \u0131a al menos un 90 % de precisi\u00b4 on en WSD ( Sanderson\n(1994 )). Recientemente, se ha comprobado que WSD mejora la\n\u201ccross-lingual IR\u201d y la clasi\ufb01caci\u00b4 on de documentos ( Vossen et al.\n(2006 ),Bloehdorn y Hotho (2004 ),Clough y Stevenson (2004 )).\nOtras aplicaciones relacionadas con clasi\ufb01caci\u00b4 on de documentos y\n\u201ccross-lingual IR\u201d incluyen recomendaci\u00b4 on de noticias, alertas y\nposicionamiento autom\u00b4 atico de publicidad.\nExtracci\u00b4 on de Informaci\u00b4 on (EI) y Miner\u00b4 \u0131a de Textos.\nWSD es necesaria para el correcto an\u00b4 alisis de los textos en muchas\naplicaciones. Por ejemplo, las investigaciones en bioinform\u00b4 atica\nrequieren establecer las relaciones entre genes y productos gen\u00b4 eti-\ncos para ser catalogados a trav\u00b4 es de la amplia literatura cient\u00b4 \u0131\ufb01ca.\nSin embargo, los genes y sus prote\u00b4 \u0131nas a menudo tienen el mis-\nmo nombre. De forma m\u00b4 as general, la Web Sem\u00b4 antica requiere\nanotaci\u00b4 on autom\u00b4 atica de documentos de acuerdo a una ontolog\u00b4 \u0131a\nde referencia: todas las referencias textuales deben estar asigna-\ndas a conceptos y estructuras de eventos en la ontolog\u00b4 \u0131a ( Dill\net al. (2003 )). La clasi\ufb01caci\u00b4 on de entidades, la determinaci\u00b4 on de\nco-referencias y la expansi\u00b4 on de acr\u00b4 onimos (MG como magnesio\no miligramos) puede tambi\u00b4 en clasi\ufb01carse como un problema de\nWSD para nombres propios. Actualmente, WSD est\u00b4 a empezando\na aplicarse en estas \u00b4 areas.\nLexicograf\u00b4 \u0131a. La lexicograf\u00b4 \u0131a moderna est\u00b4 a basada en corpus,\npor tanto, WSD y lexicograf\u00b4 \u0131a pueden trabajar conjuntamente,\n14 2.3 Sistemas iniciales: el comienzo\nde forma que WSD proporcione grupos e indicadores contextuales\nsigni\ufb01cativos de sentidos a los lexic\u00b4 ografos, los cuales, producir\u00b4 an\nmejores inventarios de sentidos y de corpus anotados para WSD.\nA pesar de este amplio rango de aplicaciones donde WSD mues-\ntra un gran potencial para ser de utilidad, a\u00b4 un no se ha demostra-\ndo que proporcione mejoras signi\ufb01cativas en este tipo de aplica-\nciones. Existen varios resultados aislados que muestran muy pocas\nmejoras y en algunos casos puede perjudicar el rendimiento como\nmuestra un experimento realizado sobre RI ( Sanderson (1994 )).\nExisten varias posibles razones para esto. En primer lugar, el do-\nminio de una aplicaci\u00b4 on a menudo restringe el n\u00b4 umero de sentidos\nque una palabra puede tener (por ejemplo, no esperar\u00b4 \u0131amos tener\n\u201cbanco\u201d con el sentido \u201cConjunto de peces que van juntos en gran\nn\u00b4 umero\u201d en un documento que hable sobre \ufb01nanzas), por tanto,\nlos lexicones pueden construirse adaptados al dominio. En segun-\ndo lugar, WSD todav\u00b4 \u0131a no est\u00b4 a lo su\ufb01cientemente desarrollada\ncomo para mostrar un efecto signi\ufb01cativo. En tercer lugar, tratar\nla WSD como un m\u00b4 odulo espec\u00b4 \u0131\ufb01co, signi\ufb01ca que no puede inte-\ngrarse apropiadamente dentro de una aplicaci\u00b4 on particular o ser\nentrenada dentro de un dominio espec\u00b4 \u0131\ufb01co. Muchas aplicaciones\ncomo TA, no tienen un lugar para un m\u00b4 odulo de WSD, por tanto,\no la aplicaci\u00b4 on o el m\u00b4 odulo de WSD deben ser redise\u02dc nados.\nA pesar de todo ello, queda patente que las aplicaciones requie-\nren de WSD de alguna forma. Por ejemplo, en RI, una cuesti\u00b4 on de\ndos palabras puede desambiguarse impl\u00b4 \u0131citamente, debido a que\nambas palabras se utilizan juntas en los textos con su correspon-\ndiente sentido asociado (por ejemplo, \u201c tropical depression \u201d). El\ntrabajo en WSD puede servir para explorar y remarcar las carac-\nter\u00b4 \u0131sticas particulares que proporcionen mejores resultados para\nuna desambiguaci\u00b4 on m\u00b4 as precisa.\n2.3 Sistemas iniciales: el comienzo\nToda \u00b4 area de investigaci\u00b4 on tiene sus comienzos y por supuesto\nen WSD tambi\u00b4 en existieron los primeros sistemas desarrollados\nalrededor de los a\u02dc nos 70 y 80.\n2. Estado del arte 15\nUno de los primeros sistemas que trataron de resolver el pro-\nblema de la ambig\u00a8 uedad l\u00b4 exica fue el creado por ( Wilks (1972 )).\nEn este caso, se utilizaron restricciones de selecci\u00b4 on organizadas\njer\u00b4 arquicamente junto con representaciones sem\u00b4 anticas complejas\ndenominadas f\u00b4 ormulas.\nEn este sistema, la hip\u00b4 otesis era que para cada uno de los di-\nferentes sentidos de una palabra exist\u00b4 \u0131a una f\u00b4 ormula asociada. El\nsistema inclu\u00b4 \u0131a una jerarqu\u00b4 \u0131a de ocho caracter\u00b4 \u0131sticas sem\u00b4 anticas:\nHUMAN ,WANT ,ABSTRACT , etc. Las f\u00b4 ormulas para los ad-\njetivos conten\u00b4 \u0131an las preferencias sem\u00b4 anticas de los nombres a los\nque pod\u00b4 \u0131an acompa\u02dc nar, al igual que las f\u00b4 ormulas para los verbos\nque conten\u00b4 \u0131an las preferencias de los nombres con los que estaban\nrelacionados. La polisemia ven\u00b4 \u0131a determinada al asignar m\u00b4 as de\nuna f\u00b4 ormula a una misma palabra. La forma de obtener los senti-\ndos de cada palabra era obteniendo una f\u00b4 ormula para cada una de\nlas palabras, que maximizara el n\u00b4 umero de preferencias para una\nfrase determinada. De esta forma, se pod\u00b4 \u0131a establecer el sentido\nde todas las palabras de una frase simult\u00b4 aneamente. Finalmente,\nla evaluaci\u00b4 on del sistema se realiz\u00b4 o sobre textos obtenidos a partir\nde art\u00b4 \u0131culos de peri\u00b4 odicos.\nOtro sistema realizado en 1980 ( S.(1980 )) ten\u00b4 \u0131a como hip\u00b4 otesis\nque el conocimiento humano sobre el lenguaje se debe principal-\nmente al conocimiento sobre palabras m\u00b4 as que al conocimiento de\nreglas ( Small y Rieger (1982 )). Sin embargo, este punto de vista\nes poco convencional y no se han realizado estudios que sostengan\nesta teor\u00b4 \u0131a psicoling\u00a8 u\u00b4 \u0131stica.\n2.4 Clasi\ufb01caci\u00b4 on de sistemas en WSD\nDesde los primeros sistemas de WSD hasta la actualidad han\nsurgido nuevas propuestas y distintos enfoques para resolver es-\nte problema. Una forma muy extendida de clasi\ufb01car los sistemas\nde WSD es bas\u00b4 andose en la principal fuente de conocimiento uti-\nlizada para establecer los diferentes sentidos. En primer lugar,\ntenemos los m\u00b4 etodos que utilizan diccionarios, tesauros y bases\nde conocimiento l\u00b4 exicas, sin utilizar ning\u00b4 un corpus (etiquetado o\n16 2.5 M\u00b4 etodos basados en conocimiento\nno). Este tipo de m\u00b4 etodos son los denominados \u201c dictionary-based \u201d\no \u201cknowledge-based \u201d. Por otra parte, tenemos aquellos m\u00b4 etodos\nque evitan casi completamente la informaci\u00b4 on externa y traba-\njan directamente con corpus sin etiquetar, son los denominados\nm\u00b4 etodos no supervisados. Dentro de esta categor\u00b4 \u0131a encontramos\nlos m\u00b4 etodos que utilizan \u201c word-aligned corpora \u201d para acumular\n\u201ccross-linguistic evidence \u201d para discriminaci\u00b4 on de sentidos. Fi-\nnalmente, tenemos los sistemas supervisados y semi-supervisados,\nestos m\u00b4 etodos utilizan corpus anotados sem\u00b4 anticamente como en-\ntrenamiento, o como fuente de datos en un sistema de \u201c bootstrap-\nping\u201d.\nCasi todas las aproximaciones de aprendizaje supervisado se\nhan aplicado a WSD, incluyendo algoritmos agregativos y discri-\nminativos y t\u00b4 ecnicas asociativas tales como selecci\u00b4 on de carac-\nter\u00b4 \u0131sticas, optimizaci\u00b4 on de par\u00b4 ametros, etc.\nLos m\u00b4 etodos no supervisados tienen la ventaja de evitar el\ncuello de botella existente en la adquisici\u00b4 on de nuevo conocimien-\nto (anotaci\u00b4 on manual) ( Boguraev y Briscoe (1989 ),Pustejovsky\n(1991 )) y han obtenido buenos resultados ( Sch\u00a8 utze (1998 )). Estos\nm\u00b4 etodos son capaces de inducir sentidos de palabras, a partir de\ntextos de entrenamiento, agrupando (mediante clusters) ocurren-\ncias de palabras y clasi\ufb01cando entonces nuevas ocurrencias en los\nclusters inducidos.\nLas propuestas basadas en conocimiento de los a\u02dc nos 1970 y\n1980 est\u00b4 an todav\u00b4 \u0131a en proceso de investigaci\u00b4 on. Las principales\nt\u00b4 ecnicas utilizan restricciones de selecci\u00b4 on, el solapamiento de tex-\ntos y medidas de similitud sem\u00b4 antica. Actualmente, la tendencia\nes hacer una inferencia sem\u00b4 antica general utilizando bases de co-\nnocimiento, obteniendo como resultado una desambiguaci\u00b4 on.\nEn la Tabla 2.1tenemos un resumen de las distintas aproxi-\nmaciones a WSD.\n2.5 M\u00b4 etodos basados en conocimiento\nEn esta categor\u00b4 \u0131a encontramos diferentes algoritmos para la\netiquetaci\u00b4 on autom\u00b4 atica de sentidos. Normalmente, el rendimien-\n2. Estado del arte 17\nM\u00b4 etodos\nProcedimiento\nBasados en\nconocimiento\nCreaci\u00b4 on de reglas de desambiguaci\u00b4 on\nRestricciones de selecci\u00b4 on (o preferencias), utilizadas\npara \ufb01ltrar sentidos incongruentes\nComparaci\u00b4 on de las de\ufb01niciones de los diccionarios con\nel contexto (m\u00b4 etodo de Lesk)\nSelecci\u00b4 on del sentido m\u00b4 as similar al contexto, utilizando\nmedidas de similitud sem\u00b4 antica\nUn sentido por discurso y otras heur\u00b4 \u0131sticas\nBasados en corpus\nno supervisados\nM\u00b4 etodos no supervisados que clasi\ufb01can palabras o con-\ntextos en diferentes clusters, obteniendo los diferentes\nsentidos\nUtilizaci\u00b4 on de corpus paralelos para inferir sentidos en-\ntre diferentes idiomas\nBasados en corpus\nsupervisados\nAprendizaje autom\u00b4 atico supervisado, utilizando corpus\nde entrenamiento etiquetados manualmente\nM\u00b4 etodos de bootstrapping (semi-supervisados)\nM\u00b4 etodos h\u00b4 \u0131bridos\nUtilizaci\u00b4 on de t\u00b4 ecnicas de clustering no supervisadas\ncombinadas con m\u00b4 etodos basados en conocimiento\nUtilizaci\u00b4 on de m\u00b4 etodos basados en conocimiento para\nbuscar ejemplos que sirvan de entrenamiento en m\u00b4 eto-\ndos supervisados\nUtilizaci\u00b4 on de corpus paralelos combinados con m\u00b4 eto-\ndos basados en conocimiento\nTabla 2.1. Clasi\ufb01caci\u00b4 on de m\u00b4 etodos de WSD\nto de estos m\u00b4 etodos basados en conocimiento, es menor en com-\nparaci\u00b4 on con los m\u00b4 etodos basados en corpus. Pero con la salvedad\nde que los m\u00b4 etodos basados en conocimiento tienen una amplia\ncobertura ya que pueden aplicarse a cualquier tipo de texto en\ncomparaci\u00b4 on con los basados en corpus que s\u00b4 olo se pueden aplicar\na aquellas palabras de las que se dispone de corpus anotados.\nA continuaci\u00b4 on vamos a enumerar diferentes t\u00b4 ecnicas utiliza-\ndas por los m\u00b4 etodos basados en conocimiento, aplicables sobre\ncualquier base de conocimiento l\u00b4 exica que de\ufb01na sentidos de pa-\nlabras y relaciones entre ellas. La base de conocimiento l\u00b4 exica m\u00b4 as\nutilizada es WordNet ( Miller (1995 )). Vamos a describir 4 tipos\ndiferentes de m\u00b4 etodos basados en conocimiento:\n1.El algoritmo de Lesk, en el cual, los sentidos de las palabras\nde un contexto se identi\ufb01can bas\u00b4 andose en una medida de so-\nlapamiento contextual entre las de\ufb01niciones de un diccionario.\n18 2.5 M\u00b4 etodos basados en conocimiento\n2.Medidas de similitud sem\u00b4 antica extra\u00b4 \u0131das a trav\u00b4 es de redes\nsem\u00b4 anticas. Esta categor\u00b4 \u0131a incluye m\u00b4 etodos que tratan de en-\ncontrar la distancia sem\u00b4 antica existente entre diferentes con-\nceptos. Dependiendo del tama\u02dc no del contexto estas medidas\nse dividen en dos grandes categor\u00b4 \u0131as:\nM\u00b4 etodos aplicables a un contexto local, donde las medidas\nde similitud sem\u00b4 antica se utilizan para desambiguar palabras\nconectadas por relaciones sint\u00b4 acticas o por su localizaci\u00b4 on.\nM\u00b4 etodos aplicables a contextos globales, donde las cade-\nnas l\u00b4 exicas son derivadas bas\u00b4 andose en medidas de simili-\ntud sem\u00b4 antica (una cadena l\u00b4 exica es un hilo de signi\ufb01cado\nextra\u00b4 \u0131do a trav\u00b4 es del texto total).\n3.Preferencias de selecci\u00b4 on adquiridas de forma autom\u00b4 atica o\nsemi-autom\u00b4 atica, como una forma de restringir los posibles\nsentidos de una palabra, basados en la relaci\u00b4 on que \u00b4 esta tiene\ncon otras palabras en el contexto.\n4.M\u00b4 etodos heur\u00b4 \u0131sticos, que consisten en reglas que pueden asig-\nnar un sentido a ciertas categor\u00b4 \u0131as de palabras, incluyendo:\nEl sentido m\u00b4 as frecuente.\nUn sentido por colocaci\u00b4 on.\nUn sentido por discurso.\nEstos cuatro tipos de m\u00b4 etodos se van a tratar en detalle en las\nsiguientes secciones.\n2.5.1 Algoritmo de Lesk\nEl algoritmo de Lesk ( Lesk (1986 )) es uno de los primeros algo-\nritmos desarrollados para la desambiguaci\u00b4 on sem\u00b4 antica de todas\nlas palabras en cualquier texto. El \u00b4 unico recurso requerido por el\nalgoritmo es un conjunto de entradas de un diccionario, una por\ncada posible sentido y conocimiento sobre el contexto inmediato\ndonde se desarrolla la desambiguaci\u00b4 on.\nAunque este algoritmo se considera un m\u00b4 etodo basado en dic-\ncionarios, tambi\u00b4 en es el punto de partida para los algoritmos ba-\nsados en corpus. Casi todos los algoritmos supervisados se basan\nde alguna forma en solapamiento contextual, midiendo ese solapa-\n2. Estado del arte 19\nmiento entre el contexto de una palabra ambigua y los contextos\nespec\u00b4 \u0131\ufb01cos para cada uno de los sentidos de esa palabra.\nLa principal idea de este algoritmo es desambiguar palabras\nencontrando el solapamiento entre las de\ufb01niciones de sus sentidos.\nEn otras palabras, dadas dos palabras, W1yW2, cada una con sus\nrespectivos sentidos Nw1yNw2de\ufb01nidos en un diccionario, para\ncada par de posibles sentidos Wi\n1yWj\n2,i= 1::Nw1,j= 1::Nw2,\nprimero se determina el solapamiento con las correspondientes\nde\ufb01niciones contando el n\u00b4 umero de palabras que tienen en com\u00b4 un.\nA continuaci\u00b4 on, el par de sentidos con el mayor solapamiento es\nseleccionado y entonces se le asigna un sentido a cada palabra del\npar inicial. En la Tabla 2.2se muestran los principales puntos de\neste algoritmo.\n(1) Para cada sentido ideW1\n(2) Para cada sentido jdeW2\n(3) Calcular el solapamiento( i; j), el n\u00b4 umero de palabras en com\u00b4 un entre las\nde\ufb01niciones del sentido iy el sentido j\n(4) Encontrar iyjtales que el solapamiento( i; j) sea el m\u00b4 aximo\n(5) Asignar el sentido iaW1y el sentido jaW2\nTabla 2.2. Algoritmo de Lesk\nUn ejemplo representativo de este algoritmo ser\u00b4 \u0131a el siguiente:\nConsideremos que queremos desambiguar las palabras \u201c pine\u201d\ny \u201ccone\u201d, mediante el par de palabras \u201c pine cone \u201d. El diccionario\nOxford Advanced Learner\u2019s de\ufb01ne cuatro sentidos para \u201c pine\u201d y\ntres sentidos para \u201c cone\u201d, tal y como muestra la Tabla 2.3.\nEn la Tabla 2.4podemos ver el solapamiento existente entre\ncada sentido de \u201c pine\u201d y cada sentido de \u201c cone\u201d.\nLa primera de\ufb01nici\u00b4 on de \u201c pine\u201d y la tercera de \u201c cone\u201d tienen el\nm\u00b4 aximo solapamiento entre todas las posibles combinaciones de\nsentidos, con dos palabras en com\u00b4 un: \u201c evergreen \u201d y \u201c tree\u201d, por\nlo tanto, estos son los sentidos seleccionados por el algoritmo de\nLesk.\nEste algoritmo fue evaluado sobre un conjunto de pares de pa-\nlabras ambiguas manualmente anotados, utilizando el diccionario\n20 2.5 M\u00b4 etodos basados en conocimiento\npine\n1* seven kinds of evergreen tree with needle-shaped leaves\n2 pine\n3 waste away through sorrow or illness\n4 pine for something, pine to do something\ncone\n1 solid body which narrows to a point\n2 something of this shape, whether solid or hollow\n3* fruit of certain evergreen trees (\ufb01r, pine)\nTabla 2.3. De\ufb01niciones para \u201c pine\u201d y \u201c cone\u201d\nPine #1TCone #1 = 0\nPine #2TCone #1 = 0\nPine #3TCone #1 = 0\nPine #4TCone #1 = 0\nPine #1TCone #2 = 0\nPine #2TCone #2 = 0\nPine #3TCone #2 = 1\nPine #4TCone #2 = 0\nPine #1TCone #3 = 2\nPine #2TCone #3 = 1\nPine #3TCone #3 = 0\nPine #4TCone #3 = 1\nTabla 2.4. Solapamiento entre \u201c pine\u201d y \u201c cone\u201d\nOxford Advanced Learner\u2019s, obteniendo una precisi\u00b4 on entre 50 y\n70 % ( Lesk (1986 )).\n2.5.2 Variaciones del algoritmo de Lesk\nDesde el planteamiento inicial del algoritmo de Lesk en 1986\nse han propuesto varias variantes del algoritmo, incluyendo:\nVersiones del algoritmo que tratan de resolver el problema de\nla explosi\u00b4 on combinatoria cuando se consideran m\u00b4 as de dos pa-\nlabras.\nVersiones del algoritmo donde cada palabra de un contexto de-\nterminado es desambiguada individualmente midiendo el sola-\npamiento entre cada de\ufb01nici\u00b4 on del diccionario y el contexto en\nel cual aparece.\n2. Estado del arte 21\nAlternativas donde el espacio sem\u00b4 antico de una palabra es\naumentado con de\ufb01niciones de palabras relacionadas sem\u00b4 anti-\ncamente.\n2.5.2.1 Simulated Annealing.\nUna de las principales desventajas del algoritmo de Lesk ini-\ncial, es que conlleva una explosi\u00b4 on combinatoria cuando se trata\nde aplicar a la desambiguaci\u00b4 on de m\u00b4 as de dos palabras. Por ejem-\nplo, podemos considerar el texto \u201cI saw a man who is 98 years\nold and can still walk and tell jokes\u201d , con nueve palabras a de-\nsambiguar, cada una de ellas con sus correspondientes sentidos:\n\u201csee(26)\u201d, \u201c man(11)\u201d, \u201c year(4)\u201d, \u201c old(8)\u201d, \u201c can(5)\u201d, \u201c still(4)\u201d,\n\u201cwalk(10)\u201d, \u201c tell(8)\u201d, \u201c joke(3)\u201d. Un total de 43929600 combina-\nciones de sentidos pueden ser posibles para este texto, por lo tanto,\nel algoritmo de Lesk original no es una aproximaci\u00b4 on \u00b4 optima para\neste problema.\nUna soluci\u00b4 on posible ser\u00b4 \u0131a utilizar el algoritmo \u201csimulated an-\nnealing\u201d , propuesto por Cowie et al. ( Cowie et al. (1992 )). En esta\npropuesta, se de\ufb01ne una funci\u00b4 on Eque re\ufb02eja las combinaciones\nde sentidos en un texto, y cuyo valor m\u00b4 \u0131nimo se corresponde con\nla selecci\u00b4 on de los sentidos correctos. Para una combinaci\u00b4 on dada\nde sentidos, se extraen todas las de\ufb01niciones correspondientes de\nun diccionario y cada palabra que aparece en una de estas de\ufb01-\nniciones recibe un valor igual a su n\u00b4 umero de ocurrencias. Unien-\ndo todos estos valores se obtiene la \u201credundancia\u201d del texto. La\nfunci\u00b4 on Ese de\ufb01ne entonces como la inversa de la redundancia,\nsiendo el objetivo \ufb01nal encontrar la combinaci\u00b4 on de sentidos que\nminimice esta funci\u00b4 on. Para este prop\u00b4 osito, se determina una com-\nbinaci\u00b4 on inicial de sentidos (por ejemplo, se recogen los sentidos\nm\u00b4 as frecuentes para cada palabra), y entonces se realizan varias\niteraciones, donde el sentido de una palabra aleatoria en el tex-\nto se reemplaza con otro sentido distinto, y la nueva selecci\u00b4 on se\nconsidera correcta \u00b4 unicamente si reduce el valor de la funci\u00b4 on E.\nLas iteraciones terminan cuando no existe ning\u00b4 un cambio en la\ncon\ufb01guraci\u00b4 on de los sentidos. La evaluaci\u00b4 on de este m\u00b4 etodo so-\nbre 50 frases de ejemplo consigui\u00b4 o un 47 % de precisi\u00b4 on a nivel\n22 2.5 M\u00b4 etodos basados en conocimiento\nde sentidos y un 72 % de precisi\u00b4 on a nivel de hom\u00b4 ografos. Este\nm\u00b4 etodo fue re-implementado por Stevenson y Wilks ( Stevenson y\nWilks (2001 )) obteniendo un valor similar de precisi\u00b4 on, en torno a\nun 65 ;24 % en un corpus etiquetado con los sentidos del Longman\nDictionary of Contemporary English1(LDOCE).\n2.5.2.2 Algoritmo de Lesk simpli\ufb01cado.\nOtra versi\u00b4 on del algoritmo de Lesk, que tambi\u00b4 en trata de re-\nsolver el problema de la explosi\u00b4 on combinatoria, es una variaci\u00b4 on\nsimpli\ufb01cada que utiliza un proceso separado de desambiguaci\u00b4 on\npara cada palabra ambigua del texto de entrada. En este algorit-\nmo simpli\ufb01cado, el sentido correcto de cada palabra en un texto,\nse determina individualmente, encontrando el sentido que lleva al\nm\u00b4 aximo solapamiento entre las de\ufb01niciones del diccionario y el\ncontexto actual. Esta aproximaci\u00b4 on toma cada palabra de forma\nindividual, sin tener en cuenta el sentido de las otras palabras que\naparecen junto a ella. En la tabla 2.5se muestran los principales\npasos de este algoritmo simpli\ufb01cado.\n(1) Para cada sentido ideW\n(2) Determinar el Solapamiento( i), el n\u00b4 umero de palabras en com\u00b4 un entre la\nde\ufb01nici\u00b4 on del sentido iy el contexto donde aparece la palabra\n(3) Encontrar el sentido icon el m\u00b4 aximo Solapamiento( i)\n(4) Asignar el sentido iaW\nTabla 2.5. Algoritmo simpli\ufb01cado de Lesk\nUn estudio realizado por ( Vasilescu et al. (2004 )) ha demos-\ntrado que el algoritmo simpli\ufb01cado de Lesk mejora la de\ufb01nici\u00b4 on\noriginal del algoritmo en t\u00b4 erminos de precisi\u00b4 on y e\ufb01ciencia. Su\nevaluaci\u00b4 on se realiz\u00b4 o utilizando los datos de la tarea \u201cEnglish all-\nwords\u201d deSenseval-2 , obteniendo un 58 % de precisi\u00b4 on con el\nalgoritmo simpli\ufb01cado, por encima del 42 % obtenido por el algo-\nritmo original.\n1http://www.longman.com/ldoce\n2. Estado del arte 23\nOtra versi\u00b4 on del algoritmo de Lesk utiliza corpus anotados pa-\nra resolver la ambig\u00a8 uedad de una palabra determinada. En este\ncaso, esta versi\u00b4 on tiene la capacidad de aumentar el contexto de\nuna palabra con ejemplos adicionales etiquetados. Por lo tanto, el\nsentido seleccionado para la aparici\u00b4 on de una palabra en un nue-\nvo contexto, ser\u00b4 a aquel que tenga mayor solapamiento con alg\u00b4 un\ncontexto pre-etiquetado anteriormente.\nEn la tabla 2.6se muestran los pasos del algoritmo de Lesk\nbasado en corpus, suponiendo que se dispone de ejemplos etique-\ntados de la palabra a desambiguar.\n(1) Para sentido ideW\n(2) Se establece Peso( i) a 0\n(3) Para cada palabra \u00b4 unica wen contexto de W\n(4) si waparece en los ejemplos etiquetados o en la de\ufb01nici\u00b4 on del\ndiccionario del sentido i\n(5) Seleccionar el sentido icon el mayor Peso( i)\nTabla 2.6. Algoritmo de Lesk basado en corpus\nElPeso de una palabra se de\ufb01ne usando una medida extra\u00b4 \u0131da\nde los m\u00b4 etodos de Recuperaci\u00b4 on de Informaci\u00b4 on: Peso (w) es la\ninversa de la frecuencia en documentos (idf) de la palabra sobre los\nejemplos y las de\ufb01niciones del diccionario. El idf de una palabra\nes log( p(w)), donde p(w) se de\ufb01ne como la fracci\u00b4 on de ejemplos y\nde\ufb01niciones que incluyen la palabra w.\nEsta nueva aproximaci\u00b4 on ha conseguido los mejores resultados\nen comparaci\u00b4 on con los m\u00b4 etodos de aprendizaje supervisado. En\nSenseval-1 (Kilgarri\ufb00 y Rosenzweig (2000 )) la aproximaci\u00b4 on del\nalgoritmo de Lesk basada en corpus obtuvo un 69 ;1 % de preci-\nsi\u00b4 on comparado con el 56 ;6 % obtenido utilizando la heur\u00b4 \u0131stica\ndel sentido m\u00b4 as frecuente. En Senseval-2 (Kilgari\ufb00 (2001 )) el\nalgoritmo de Lesk consigui\u00b4 o resultados similares: 51 ;2 % precisi\u00b4 on\ncomparado con el 64 ;2 % conseguido por el mejor sistema super-\nvisado.\n24 2.5 M\u00b4 etodos basados en conocimiento\n2.5.2.3 Espacios sem\u00b4 anticos aumentados.\nOtra variante del algoritmo de Lesk es la propuesta por Ba-\nnerjee y Pedersen ( Banerjee y Pedersen (2002 )) denominada Al-\ngoritmo de Lesk Adaptado . En esta propuesta se utilizan junto\ncon las de\ufb01niciones de la palabra ambigua, las de\ufb01niciones de pa-\nlabras relacionas. En este caso, se utiliza una funci\u00b4 on similar a\nla empleada por ( Cowie et al. (1992 )) para determinar el valor\npara cada combinaci\u00b4 on posible de sentidos en un texto, y tratar\nde identi\ufb01car la combinaci\u00b4 on que lleva al m\u00b4 aximo valor.\nEn esta aproximaci\u00b4 on se tienen en cuenta conceptos relaciona-\ndos con la palabra ambigua utilizando la jerarqu\u00b4 \u0131a de WordNet:\nhiper\u00b4 onimos, hip\u00b4 onimos, hol\u00b4 onimos, mer\u00b4 onimos, trop\u00b4 onimos. Se\nutilizan relaciones de atributos y sus correspondientes de\ufb01nicio-\nnes, para construir un contexto m\u00b4 as amplio a partir de las de\ufb01ni-\nciones sem\u00b4 anticas.\n2.5.3 Similitud sem\u00b4 antica\nEn la t\u00b4 ecnica basada en similitudes sem\u00b4 anticas, la premisa ini-\ncial es que las palabras de un texto deben relacionarse seg\u00b4 un sus\nsentidos para obtener un discurso coherente ( Halliday y Hasan\n(1976 )). Esta premisa es una propiedad natural del lenguaje hu-\nmano y al mismo tiempo la base para el desarrollo de los sistemas\nde desambiguaci\u00b4 on autom\u00b4 aticos. Se puede a\ufb01rmar, por tanto, que\nlas palabras que comparten un contexto similar est\u00b4 an normal-\nmente relacionadas y por consiguiente, se pueden seleccionar sus\nsentidos a partir de la distancia sem\u00b4 antica ( Rada et al. (1989 )).\nEsta premisa se restringe a un peque\u02dc no grupo de palabras ex-\ntra\u00b4 \u0131das del contexto m\u00b4 as cercano a la palabra ambigua o a las pa-\nlabras relacionadas sint\u00b4 acticamente con la palabra ambigua. Este\ntipo de m\u00b4 etodos extrae el contexto local y no introduce infor-\nmaci\u00b4 on contextual adicional obtenida a partir de una ventana de\ncierto tama\u02dc no.\nExisten otros m\u00b4 etodos que utilizan un contexto global y tratan\nde construir hilos de conocimiento a trav\u00b4 es del texto completo,\nutilizando para ello ventanas centradas en la palabra ambigua.\n2. Estado del arte 25\nAl igual que suced\u00b4 \u0131a con el algoritmo de Lesk, estos m\u00b4 etodos\nsufren de un gran coste computacional cuando tratan m\u00b4 as de dos\npalabras. Para resolver este problema se pueden aplicar las mis-\nmas soluciones propuestas para el algoritmo de Lesk, como por\nejemplo el algoritmo propuesto por ( Agirre y Rigau (1996 )).\n2.5.3.1 Medidas de similitud sem\u00b4 antica.\nExisten diferentes medidas de similitud que tratan de cuanti-\n\ufb01car el grado en que dos palabras est\u00b4 an relacionadas sem\u00b4 antica-\nmente. Muchas de estas medidas se basan en redes sem\u00b4 anticas y\nsiguen la metodolog\u00b4 \u0131a original propuesta por ( Rada et al. (1989 )).\nA continuaci\u00b4 on se muestran una serie de medidas de similitud\naplicadas sobre la jerarqu\u00b4 \u0131a de WordNet. La mayor\u00b4 \u0131a de estas\nmedidas toman como entrada un par de conceptos y devuelven\nun valor que indica el grado de similitud entre ambas palabras.\n1.(Leacock et al. (1998 )). Esta medida determina el camino\nm\u00b4 \u0131nimo entre las dos palabras de entrada. Este valor se nor-\nmaliza atendiendo a la profundidad de la taxonom\u00b4 \u0131a. En la\nEcuaci\u00b4 on ( 2.1)Camino (C1; C2) representa la longitud del ca-\nmino que conecta los dos conceptos (es decir, el n\u00b4 umero de\narcos en la red sem\u00b4 antica que son atravesados para llegar de\nC1aC2, yDes la profundidad total de la taxonom\u00b4 \u0131a.\nSimilitud (C1; C2) =\u00a1log\u00b5Camino (C1; C2)\n2D\u00b6\n(2.1)\n2.(Hirst y St-Onge (1998 )). A\u02dc naden a la medida de similitud\nla direcci\u00b4 on de los enlaces que forman el camino. Adem\u00b4 as de\nla longitud, el camino no deber\u00b4 \u0131a \u201ccambiar de direcci\u00b4 on fre-\ncuentemente\u201d. En la Ecuaci\u00b4 on ( 2.2)Cykson constantes, el\nCamino se de\ufb01ne como en la ecuaci\u00b4 on ( 2.1) ydrepresenta el\nn\u00b4 umero de cambios de direcci\u00b4 on.\nSimilitud (C1; C2) =C\u00a1Camino (C1; C2)\u00a1kd (2.2)\n26 2.5 M\u00b4 etodos basados en conocimiento\n3.(Resnik (1995b )). De\ufb01ne el t\u00b4 ermino de contenido de informa-\nci\u00b4 on, que es una medida de la especi\ufb01caci\u00b4 on de un concep-\nto determinado, y est\u00b4 a de\ufb01nida en base a su probabilidad de\nocurrencia en un corpus extenso.\nIC(C) =\u00a1log(P(C)) (2.3)\nDado un corpus, P(C) es la probabilidad de encontrar una\ninstancia de tipo C. El valor para P(C) es mayor para con-\nceptos listados en la parte superior de la jerarqu\u00b4 \u0131a y llega a su\nm\u00b4 aximo valor para el concepto que se encuentra en la cima (si\nla jerarqu\u00b4 \u0131a tiene tiene una \u00b4 unica cima, entonces el valor para\neste concepto es 1).\nResnik de\ufb01ne una medida de similitud sem\u00b4 antica entre dos\npalabras utilizando el \u201cLowest Common Subsumer\u201d (LCS). El\nLCS es el primer concepto de la red sem\u00b4 antica que contiene a\nlas dos palabras, es decir, el primer nodo com\u00b4 un para el cual\nexiste un camino desde la palabra W1y la palabra W2. En la\nEcuaci\u00b4 on ( 2.4) se muestra esta medida.\nSimilitud (C1; C2) =IC(LCS(C1; C2)) (2.4)\n4.(Jiang y Conrath (1997 )) presentan una alternativa a la medi-\nda de Resnik utilizando la diferencia existente en el contenido\nde informaci\u00b4 on de los dos conceptos para indicar su similitud.\nComo muestra la Ecuaci\u00b4 on ( 2.5).\nSimilitud (C1; C2) = 2 x IC(LCS(C1; C2))\n\u00a1(IC(C1) +IC(C2)) (2.5)\nAdem\u00b4 as de esta aproximaci\u00b4 on ( Lin(1998b )) desarrolla otra\nf\u00b4 ormula que combina la informaci\u00b4 on de LCS con la informaci\u00b4 on\nde los conceptos involucrados, seg\u00b4 un la ecuaci\u00b4 on ( 2.6).\nSimilitud (C1; C2) =2 xIC(LCS(C1; C2))\nIC(C1) +IC(C2)(2.6)\n2. Estado del arte 27\n5.(Mihalcea y Moldovan (1999 )) introducen una nueva f\u00b4 ormula\npara medir la similitud sem\u00b4 antica entre jerarqu\u00b4 \u0131as indepen-\ndientes, incluyendo jerarqu\u00b4 \u0131as para diferentes categor\u00b4 \u0131as l\u00b4 exi-\ncas. Todas las medidas de similitud comentadas anteriormente\ns\u00b4 olo se pueden aplicar a conceptos que est\u00b4 an expl\u00b4 \u0131citamente co-\nnectados por alg\u00b4 un arco en la red sem\u00b4 antica. Con esta nueva\nmedida Mihalcea y Moldovan crean caminos virtuales entre\ndiferentes jerarqu\u00b4 \u0131as a trav\u00b4 es de las de\ufb01niciones de las glosas\nen WordNet. En la Ecuaci\u00b4 on ( 2.7)jCD 12jes el n\u00b4 umero de pa-\nlabras comunes a las de\ufb01niciones en la jerarqu\u00b4 \u0131a de C1yC2.\ndescendientes (C2) es el n\u00b4 umero de conceptos en la jerarqu\u00b4 \u0131a\ndeC2. YWkes un peso asociado con cada concepto determi-\nnado como la profundidad del concepto dentro de la jerarqu\u00b4 \u0131a.\nSimilitud (C1; C2) =PjCD12j\nk=1Wk\nlog(descendientes (C2))(2.7)\nEsta medida de similitud funciona bastante bien para la de-\nsambiguaci\u00b4 on de nombres y verbos conectados por una rela-\nci\u00b4 on sint\u00b4 actica (por ejemplo, verbo-objeto).\n6.(Agirre y Rigau (1996 )) introducen la noci\u00b4 on de densidad\nconceptual, de\ufb01nida como el solapamiento entre la jerarqu\u00b4 \u0131a\nsem\u00b4 antica enraizada por un concepto C, y las palabras en el\ncontexto de C. En la Ecuaci\u00b4 on ( 2.8),mes el n\u00b4 umero total de\nsentidos en el contexto de Cencontrados en la jerarqu\u00b4 \u0131a cuya\nra\u00b4 \u0131z es C, ydescendientes (C) representa el total del n\u00b4 umero\nde conceptos en la jerarqu\u00b4 \u0131a enraizada por C.Wkes un peso\nasociado con cada concepto en la jerarqu\u00b4 \u0131a ( nhyp es el n\u00b4 umero\nde hip\u00b4 onimos para un nodo determinado en la jerarqu\u00b4 \u0131a, y el\nvalor \u00b4 optimo para \u00aefue determinado emp\u00b4 \u0131ricamente a 0 ;20).\nDC(C) =Pm\nk=0Wk\ndescendientes (C); donde W k=nhypk\u00ae(2.8)\nPara identi\ufb01car el sentido de una palabra en un determinado\ncontexto, la f\u00b4 ormula de la densidad conceptual se aplica a to-\ndos los posibles sentidos de la palabra, escogiendo el sentido\ncuya densidad conceptual sea mayor.\n28 2.5 M\u00b4 etodos basados en conocimiento\n2.5.3.2 Similitud sem\u00b4 antica en un contexto local.\nLa aplicaci\u00b4 on de las medidas de similitud mostradas anterior-\nmente sobre cualquier texto, no es un proceso sencillo. General-\nmente, en un texto encontramos m\u00b4 as de dos palabras ambiguas,\npor tanto, debemos tratar con conjuntos de palabras ambiguas\ndonde la distancia de una palabra al resto de palabras en el con-\ntexto in\ufb02uye sobre el sentido adoptado.\nLos trabajos desarrollados dentro de este \u00b4 area utilizan un con-\ntexto local restringiendo as\u00b4 \u0131 el n\u00b4 umero de palabras ambiguas den-\ntro del mismo contexto. ( Patwardhan et al. (2003 )) aplican la pri-\nmera medida de similitud de la lista anterior para decidir el senti-\ndo correcto de las 1723 instancias de nombres de la tarea \u201cEnglish\nLexical Sample\u201d deSenseval-2 . En este estudio, se utiliza un va-\nlor acumulativo a\u02dc nadiendo las distancias sem\u00b4 anticas de la palabra\na desambiguar junto con las palabras vecinas (una palabra a la\nizquierda y una palabra a la derecha). El sentido elegido es aquel\ncuyo valor acumulado es mayor. Tras el proceso de evaluaci\u00b4 on se\ndetermin\u00b4 o que entre las medidas de similitud propuestas, ( Jiang\ny Conrath (1997 )) alcanzaban la mejor puntuaci\u00b4 on y ( Hirst y St-\nOnge (1998 )) proporcionaban el mejor funcionamiento a trav\u00b4 es de\nvarias palabras.\nLas dependencias sint\u00b4 acticas son otra posible restricci\u00b4 on a con-\nsiderar. En este caso, ( Stetina et al. (1998 )) proponen un m\u00b4 etodo\nbasado en las relaciones sint\u00b4 acticas de palabras y una medida muy\nsimple que de\ufb01ne que dos palabras son similares si pertenecen al\nmismo synset de WordNet.\nEn (Montoyo (2002 )) se propone la identi\ufb01caci\u00b4 on del sentido\ncorrecto de las palabras a trav\u00b4 es del algoritmo de Marcas de Espe-\nci\ufb01dad . Este algoritmo utiliza la taxonom\u00b4 \u0131a de nombres de Word-\nNet, sus relaciones de hiponimia e hiperonimia, para desambiguar\npalabras dentro de un contexto local (oraci\u00b4 on). La hip\u00b4 otesis en la\nque se basa este algoritmo es que las palabras que aparecen en\nun mismo contexto tienen sus sentidos relacionados entre s\u00b4 \u0131, y\npor tanto, puede existir un concepto dentro de la red sem\u00b4 anti-\nca que relacione todas las palabras del contexto. Este concepto\nsuperior es la denominada Marca de Especi\ufb01dad (ME). El proce-\n2. Estado del arte 29\nso de desambiguaci\u00b4 on es el siguiente: a trav\u00b4 es de la jerarqu\u00b4 \u0131a de\nWordNet y de las palabras del contexto, se obtiene el conjunto de\nhiper\u00b4 onimos/hip\u00b4 onimos que comparten las palabras. Usando esta\ninformaci\u00b4 on se trata de determinar el concepto superior (ME) que\nengloba el mayor n\u00b4 umero de palabras del contexto con sus respec-\ntivos sentidos. Si como resultado para la ME inicial a\u00b4 un existen\npalabras ambiguas en el contexto, se va descendiendo por la jerar-\nqu\u00b4 \u0131a obteniendo nuevas ME, de forma que se seleccionar\u00b4 a aquella\nME que maximice el n\u00b4 umero de palabras del contexto no ambi-\nguas. La Figura 2.1muestra su funcionamiento.\n \n {entity#1} \n{object#1} \n{artifact#1} {life form#1} \n{plant#2} \n{perennial#1} {vascular plant#1} \n{woody plant#1} \n{tree#1} {Structure#1} \n{building complex#1} \n{plant#1} {natural object#1} \n{plant part#1} \n{plant organ#1} \n{leaf#1} {substance#1} \n{material#1} \n{paper#1} \n{sheet#2} \n{leaf#2} {part#4} \n{section#4} \n{leaf#3} Marca \nEspeecificidad \nInicial (MEI) \nME ME \n(*) \nContexto: plant, tree, leaf, perennial \nFigura 2.1. Algoritmo Marcas de Especi\ufb01dad\n2.5.3.3 Similitud sem\u00b4 antica en un contexto global.\nLas cadenas l\u00b4 exicas son una de las estructuras de conocimien-\nto m\u00b4 as comunes. Una cadena l\u00b4 exica es una secuencia de palabras\nrelacionadas sem\u00b4 anticamente, lo cual crea un contexto y contri-\nbuye a la continuidad del conocimiento y de la coherencia de un\ndiscurso ( Halliday y Hasan (1976 )). Estas estructuras han sido\nconsideradas muy \u00b4 utiles en diferentes tareas de procesamiento del\nlenguaje natural, incluyendo resumen autom\u00b4 atico, categorizaci\u00b4 on\nde textos y desambiguaci\u00b4 on autom\u00b4 atica. Las cadenas l\u00b4 exicas se\n30 2.5 M\u00b4 etodos basados en conocimiento\nextraen independientemente de la estructura gramatical del texto\ny pueden abarcar grandes distancias dentro del texto.\nUn algoritmo gen\u00b4 erico de creaci\u00b4 on de cadenas l\u00b4 exicas se divide\nen tres pasos (Figura 2.2):\n1.Seleccionar las palabras candidatas del texto. \u00b4Estas son pa-\nlabras a partir de las cuales podemos establecer similitudes\nsem\u00b4 anticas y por tanto, la mayor parte del tiempo pertenecen\na la misma categor\u00b4 \u0131a l\u00b4 exica.\n2.Para cada una de estas palabras candidatas, y para cada sen-\ntido, se busca una cadena que reciba el sentido de la palabra\ncandidata, bas\u00b4 andose en una medida de similitud entre los\nconceptos que ya est\u00b4 an en la cadena y el sentido de la palabra\ncandidata.\n3.Si esa cadena se encuentra, se inserta la palabra dentro de la\ncadena, en otro caso, se crea una nueva cadena.\nTodas las cadenas que superan un cierto umbral son seleccio-\nnadas.\n \n \nA very long train traveling along the rails with a constant velocity v in a \ncertain direcction \u2026. \n \n \n \ntrain      #1: public transport          #1: change location  #2: a bar of  \n                      steel for trains \n \n     #2: order set of things        \n      #3: piece of cloth \n \n \ntravel      #2: undergo transportation \n \nrail       #1: a barrier \n  \n     #3 a small bird \nFigura 2.2. Cadenas l\u00b4 exicas en un contexto global\n2. Estado del arte 31\n2.5.4 Preferencias de selecci\u00b4 on\nAlgunos de los algoritmos creados inicialmente para WSD se\nbasan en preferencias de selecci\u00b4 on como una forma de restringir\nlos posibles sentidos de una palabra en un contexto determinado.\nLas preferencias de selecci\u00b4 on capturan informaci\u00b4 on sobre las\nposibles relaciones entre diferentes categor\u00b4 \u0131as de palabras seg\u00b4 un el\npropio sentido com\u00b4 un. Por ejemplo, COMER-COMIDA o BEBER-\nL\u00b4IQUIDOS, son muestras de tales restricciones sem\u00b4 anticas, las\ncuales pueden ser utilizadas para desechar sentidos incorrectos y\nseleccionar s\u00b4 olo aquellos sentidos que se corresponden con los sen-\ntidos obtenidos siguiendo las reglas. Por ejemplo, dada la frase\n\u201cMary drunk burgundy\u201d , el sentido para \u201cburgundy\u201d que lo de\ufb01ne\ncomo un color, no tiene cabida en este contexto porque el verbo\n\u201cdrink\u201d requiere de un l\u00b4 \u0131quido como objeto directo.\n2.5.4.1 Adquisici\u00b4 on de preferencias de selecci\u00b4 on.\nA pesar de que las preferencias de selecci\u00b4 on son intuitivas,\nes muy dif\u00b4 \u0131cil ponerlas en pr\u00b4 actica para resolver el problema de\nWSD. Supongamos, por ejemplo, que queremos obtener un cor-\npus anotado sem\u00b4 anticamente. En este caso, el principal problema\nes la relaci\u00b4 on circular entre las preferencias de selecci\u00b4 on y WSD,\nya que, aprender restricciones sem\u00b4 anticas requiere conocimiento\nsobre los sentidos involucrados en una relaci\u00b4 on y viceversa. En\n(Brockmann y Lapata (2003 )) se realiz\u00b4 o un estudio sobre m\u00b4 eto-\ndos que utilizan preferencias de selecci\u00b4 on junto con una evaluaci\u00b4 on\nde los resultados obtenidos de forma autom\u00b4 atica frente a los re-\nsultados anotados por un ser humano.\nOtra alternativa para obtener preferencias de selecci\u00b4 on es par-\ntir de corpus no anotados sem\u00b4 anticamente. De esta forma se pue-\nden utilizar t\u00b4 ecnicas estad\u00b4 \u0131sticas para establecer relaciones entre\npalabras:\nContador de frecuencia:\nCont\nfrec(W1; W2; R) (2.9)\n32 2.5 M\u00b4 etodos basados en conocimiento\nSe determina cu\u00b4 antas veces co-ocurre la palabra W1con la pa-\nlabra W2mediante la relaci\u00b4 on R.\nProbabilidad condicional:\nP(W1jW2; R) =Cont\nfrec(W1; W2)\nCont\nfrec(W2; R)(2.10)\nSe determina la probabilidad de aparici\u00b4 on de la relaci\u00b4 on entre\ndos palabras W1; W2, con respecto a la probabilidad de aparici\u00b4 on\nde esa misma relaci\u00b4 on Rcon respecto a una de las dos palabras\nen todo el corpus.\nRelaciones palabra-clase ( Resnik (1993 )):\nSe cuanti\ufb01ca la contribuci\u00b4 on de una clase sem\u00b4 antica utilizando\ntodos los conceptos que comparte esa clase.\nA(W1; C2; R) =P(C2jW1; R) logP(C2jW1;R)\nP(C2)\nX\nC2P(C2jW1; R) logP(C2jW1; R)\nP(C2)(2.11)\nDonde:\nP(C2jW1; R) =Cont\nfrec(W1; C2; R)\nCont\nfrec(W1; R)(2.12)\nCont\nfrec(W1; C2; R) =X\nW22C2Cont\nfrec(W1; W2; R)\nCont\nfrec(W2)(2.13)\nOtros algoritmos utilizados para adquirir preferencias de se-\nlecci\u00b4 on son los propuestos por: ( Agirre y Martinez (2001 )) donde\nse utilizan relaciones clase-clase, como por ejemplo, \u201cingerir co-\nmida\u201d es una relaci\u00b4 on clase-clase para \u201ccomer pollo\u201d o tambi\u00b4 en\nson utilizadas las redes bayesianas propuestas por ( Ciaramita y\nJohnson (2000 )).\n2. Estado del arte 33\n2.5.4.2 Usando preferencias de selecci\u00b4 on para WSD.\nUna vez obtenidas las preferencias de selecci\u00b4 on \u00b4 estas pueden\nser integradas en un algoritmo de WSD de la siguiente forma.\n1.Aprendizaje de un conjunto de preferencias de selecci\u00b4 on para\nuna determinada relaci\u00b4 on sint\u00b4 actica R\n2.Dado un par de palabras W1\u00a1W2conectadas mediante una\nrelaci\u00b4 on R\n3.Encontrar todas las preferencias de selecci\u00b4 on W1\u00a1Cpalabra-\nclase o C1\u00a1C2claseclase que se puedan aplicar\n4.Seleccionar el sentido de W1yW2basados en la clase sem\u00b4 anti-\nca elegida\nPor ejemplo, si tratamos de desambiguar la palabra \u201ccaf\u00b4 e\u201d en\n\u201cbeber caf\u00b4 e\u201d, los posibles sentidos de caf\u00b4 e son: 1. bebida, 2. \u00b4 arbol\ny 3. color. Utilizando la preferencia de selecci\u00b4 on \u201cbeber bebida\u201d\nse seleccionar\u00b4 \u0131a el sentido caf\u00b4 e#1.\n2.5.5 Heur\u00b4 \u0131sticas para Word Sense Disambiguation\nUna forma sencilla de establecer el sentido correcto de las pa-\nlabras en un texto es utilizar heur\u00b4 \u0131sticas basadas en propiedades\nling\u00a8 u\u00b4 \u0131sticas aprendidas a trav\u00b4 es de textos. Una de las heur\u00b4 \u0131sticas\nm\u00b4 as utilizadas como baseline es la denominada \u201csentido m\u00b4 as fre-\ncuente\u201d. Adem\u00b4 as de esta heur\u00b4 \u0131stica, existen otras dos com\u00b4 unmente\nutilizadas cuya base es la suposici\u00b4 on de que una palabra siempre\ntiene el mismo sentido en: todas sus ocurrencias en un mismo dis-\ncurso (\u201cun sentido por discurso\u201d) o en la misma colocaci\u00b4 on (\u201cun\nsentido por colocaci\u00b4 on\u201d) o en el mismo dominio.\n2.5.5.1 Sentido m\u00b4 as frecuente.\nEntre todos los posibles sentidos que puede tener una palabra,\ngeneralmente existe uno que ocurre m\u00b4 as a menudo que los otros\nsentidos. Por lo tanto, un sistema muy simple de desambiguaci\u00b4 on\nser\u00b4 \u0131a aquel que asignara a cada palabra su sentido m\u00b4 as frecuente.\n34 2.5 M\u00b4 etodos basados en conocimiento\nEste m\u00b4 etodo se utiliza a menudo como baseline para WSD, y\nde acuerdo a ( Gale et al. (1992b )) \u201clos sistemas deber\u00b4 \u0131an llegar\ncomo m\u00b4 \u0131nimo a este baseline\u201d.\nEn el gr\u00b4 a\ufb01co de la Figura 2.3se muestra la distribuci\u00b4 on de sen-\ntidos en el corpus Semcor. Los sentidos de cada categor\u00b4 \u0131a han sido\nobtenidos a partir de la distribuci\u00b4 on proporcionada por WordNet.\n \n \n0 0,1 0,2 0,3 0,4 0,5 0,6 0,7 0,8 0,9 \n1 2 3 4 5 6 7 8 9 10 \nSentido Frecuencia Nombre \nVerbo \nAdjetivo \nAdverbio \nFigura 2.3. Distribuci\u00b4 on de sentidos en Semcor\nComo se puede apreciar, el sentido m\u00b4 as frecuente para todas\nlas categor\u00b4 \u0131as l\u00b4 exicas es el n\u00b4 umero 1.\nAunque conceptualmente es muy sencillo, y casi trivial de im-\nplementar, hay un inconveniente asociado a este m\u00b4 etodo: no siem-\npre disponemos de la distribuci\u00b4 on de las ocurrencias de los sen-\ntidos en todos los lenguajes, ya que, no existen su\ufb01cientes textos\ndisponibles para extraer esa distribuci\u00b4 on. Adem\u00b4 as, un cambio en el\ndominio generalmente altera la distribuci\u00b4 on de los sentidos, dismi-\nnuyendo as\u00b4 \u0131 los resultados obtenidos por esta heur\u00b4 \u0131stica ( Mart\u00b4 \u0131nez\ny Agirre (2000 )).\nPara solventar el problema de la ausencia de textos que permi-\ntan obtener la distribuci\u00b4 on de los sentidos, existe una alternativa.\n2. Estado del arte 35\nEl m\u00b4 etodo de ( McCarthy et al. (2004 )) propone la forma de utili-\nzar una medida de similitud entre distintos sentidos de una pala-\nbra y palabras similares para determinar el sentido predominante\nen un dominio determinado.\nEl algoritmo utilizado por este m\u00b4 etodo se compone de tres\npasos:\n1.Dada una palabra wencontrar las top kpalabras similares.\nNw=fn1; n2; :::; n kgcon sus respectivos valores de similitud\nfdvs(w; n 1); dvs(w; n 2); :::; dvs (w; n k)g\n2.Para cada sentido wsidew, identi\ufb01car la similitud con las\npalabras njusando el sentido de njque maximice el valor de\nsimilitud.\n3.Ordenar los sentidos wsibas\u00b4 andose en el valor de similitud\ntotal.\nSimilitud (wsi) =X\nnj2Nwdvs(w; n j)wnvs (wsi; nj)\nX\nws0\ni2sentidos (w)wnvs (ws0\ni; nj)0\n(2.14)\nDonde wnvs (wsi; nj) = m\u00b4 ax\nnsx2sentidos (nj)(wnvs (wsi; nsx))\nPor ejemplo, supongamos que queremos determinar el sentido\nde la palabra \u201cpipe\u201d en un texto determinado. Los posibles sen-\ntidos de pipe son:\npipe#1: tobacco pipe.\npipe#2: tube of metal or plastic.\nLas palabras similares detectadas en el texto son las siguientes:\nN=ftube, cable, wire, tank, hole, cylinder, \ufb01tting, ... g\nPara cada palabra Nse calcula el valor de similitud con el sen-\ntido pipe#i (escogiendo el valor de similitud que maximiza el par).\npipe#1 - tube#3 = 0 ;3\n36 2.5 M\u00b4 etodos basados en conocimiento\npipe#2 - tube#1 = 0 ;6\nSe establece el valor de similitud total de cada sentido de pi-\npe#i:\nsimilitud(pipe#1) = 0 ;25\nsimilitud(pipe#2) = 0 ;73\nEste m\u00b4 etodo fue presentado en la tarea de \u201cEnglish all-words\u201d\ndeSenseval-2 obteniendo un 64 % de precisi\u00b4 on sobre los nom-\nbres.\n2.5.5.2 Un sentido por discurso.\nEsta heur\u00b4 \u0131stica fue introducida por ( Gale et al. (1992a )), donde\nse establece que una palabra tiende a preservar su sentido a trav\u00b4 es\nde todas sus ocurrencias en un discurso determinado. Esta medida\npermite establecer el sentido de una misma palabra identi\ufb01c\u00b4 andolo\nuna \u00b4 unica vez.\nEsta heur\u00b4 \u0131stica funciona bien con palabras que tienen senti-\ndos bien diferenciados. En el caso en que tengamos palabras con\nsentidos con una diferencia muy sutil, este m\u00b4 etodo obtiene peores\nresultados. En el estudio realizado por ( Krovetz (1998 )) se demos-\ntr\u00b4 o que palabras polis\u00b4 emicas con sentidos muy similares, pueden\ntener m\u00b4 as de un sentido por discurso. En concreto, utilizaron el\ncorpus de Semcor, probando que el 70 % de las palabras en este\ncorpus ten\u00b4 \u0131a un sentido por discurso.\n2.5.5.3 Un sentido por colocaci\u00b4 on.\nEsta heur\u00b4 \u0131stica tiene una hip\u00b4 otesis similar a la heur\u00b4 \u0131stica de\nun sentido por discurso, pero aplicada en un \u00b4 ambito diferente.\nFue presentada por ( Yarowsky (1993 )), y supone que una palabra\ntiende a tener el mismo sentido cuando se utiliza en la misma\ncolocaci\u00b4 on. Es decir, las palabras cercanas dan pistas acerca del\nsentido de una palabra. Adem\u00b4 as, se ha determinado que este efec-\n2. Estado del arte 37\nto es mayor para colocaciones adyacentes y empieza a decrecer\ncuando la distancia entre palabras aumenta.\nPor ejemplo, la palabra \u201cplant\u201d en la colocaci\u00b4 on \u201cindustrial\nplant\u201d mantiene su sentido en todas las ocurrencias, independien-\ntemente del contexto en el que aparezca esta colocaci\u00b4 on.\nSe desarrollaron distintos experimentos con palabras con sen-\ntidos bien diferenciados y con sentidos muy pr\u00b4 oximos entre s\u00b4 \u0131. Al\nigual que en el caso anterior, los resultados empeoran cuando se\nconsideran palabras con sentidos con diferencias sutiles ( Mart\u00b4 \u0131nez\ny Agirre (2000 )).\n2.6 M\u00b4 etodos no supervisados basados en\ncorpus\nEl desarrollo de m\u00b4 etodos que tratan de resolver el problema\nde la ambig\u00a8 uedad l\u00b4 exica ha supuesto la aparici\u00b4 on de diferentes\nalgoritmos que utilizan una serie de recursos diferentes. Podemos\nencontrar desde sistemas que utilizan t\u00b4 ecnicas de enriquecimiento\nde conocimiento utilizando diccionarios, tesauros o jerarqu\u00b4 \u0131as de\nconceptos (los llamados basados en conocimiento), hasta sistemas\nque utilizan la informaci\u00b4 on de textos anotados sem\u00b4 anticamente\n(los llamados sistemas supervisados basados en corpus). El \u00b4 unico\ninconveniente de estos sistemas es que es necesario la creaci\u00b4 on de\ntextos, diccionarios u otras fuentes de informaci\u00b4 on, de forma ma-\nnual. Esto supone un gran costo en su obtenci\u00b4 on y mantenimiento,\nadem\u00b4 as de generar di\ufb01cultades cuando se tratan de anotar textos\nmuy extensos, de un nuevo dominio o de un lenguaje diferente.\nPara evitar esta dependencia se han desarrollado dos aproxi-\nmaciones diferentes. La primera de ellas trata de establecer distin-\nciones entre sentidos bas\u00b4 andose en su distribuci\u00b4 on, determinando\npor tanto que, palabras que aparecen en contextos similares deben\ntener sentidos similares ( Harris (1968 ),Miller y Charles (1991 )).\nLa segunda aproximaci\u00b4 on est\u00b4 a basada en equivalencias de traduc-\nci\u00b4 on en corpus paralelos, los cuales identi\ufb01can traducciones de una\npalabra en un lenguaje determinado cuya traducci\u00b4 on depende del\nsentido de esa palabra en el lenguaje origen. Estas traducciones\n38 2.6 M\u00b4 etodos no supervisados basados en corpus\ndependientes del sentido de una palabra pueden ser utilizadas co-\nmo una recopilaci\u00b4 on de sentidos para esa palabra en el lenguaje\norigen.\nUna de las claves de los m\u00b4 etodos basados en distribuci\u00b4 on, es que\nno utilizan ning\u00b4 un recopilatorio de sentidos, \u00b4 unicamente clasi\ufb01can\npalabras bas\u00b4 andose en sus contextos observados en los corpus. Es-\nta es una alternativa a los m\u00b4 etodos que dependen de la anotaci\u00b4 on\nde corpus y que est\u00b4 an restringidos a aquellas palabras que un ex-\nperto ha clasi\ufb01cado para sus distintos sentidos. En todo caso, a\npesar de que exista un repertorio de sentidos, su utilidad depende\nde las aplicaciones sobre las que se aplique.\nLas aproximaciones distribucionales no asignan sentidos a las\npalabras, pero s\u00b4 \u0131 permiten discriminar entre los sentidos de una\npalabra identi\ufb01cando clusters en contextos similares, donde cada\ncluster muestra que una palabra se est\u00b4 a utilizando con un sentido\ndeterminado. Estos m\u00b4 etodos presentan una aproximaci\u00b4 on diferen-\nte a la tarea tradicional de WSD, la cual clasi\ufb01ca palabras con\nrespecto a un repertorio de sentidos existente.\nLos m\u00b4 etodos basados en equivalencias de traducci\u00b4 on se ba-\nsan en el hecho de que los sentidos diferentes de una palabra en\nun lenguaje origen se pueden traducir en palabras diferentes en\nel lenguaje destino. Estas aproximaciones tienen dos propieda-\ndes. Primero, autom\u00b4 aticamente derivan un repertorio de sentidos\nque hace distinciones relevantes para los problemas de traduc-\nci\u00b4 on autom\u00b4 atica. Segundo, un corpus etiquetado basado en estas\ndistinciones puede ser creado autom\u00b4 aticamente y utilizado como\ncorpus de entrenamiento para los m\u00b4 etodos tradicionales de apren-\ndizaje supervisado.\nUna de las ventajas de utilizar m\u00b4 etodos no supervisados ba-\nsados en corpus, es que no se basan en ning\u00b4 un diccionario, repo-\nsitorio de sentidos, tesauro, etc. De forma que no est\u00b4 an restrin-\ngidos a la interpretaci\u00b4 on de sentidos que el autor del diccionario\nhaya impuesto. Ya que, es muy habitual que diferentes dicciona-\nrios aporten una distinci\u00b4 on de sentidos m\u00b4 as \ufb01na o m\u00b4 as compacta,\nseg\u00b4 un la \ufb01nalidad para la que est\u00b4 en creados. Al evitar hacer uso\nde estos recursos, se garantiza la adaptabilidad de estos sistemas a\ndiferentes campos o \u00b4 ambitos. Otra ventaja no menos importante,\n2. Estado del arte 39\nes que estos m\u00b4 etodos son independientes del lenguaje. Es decir,\nson f\u00b4 acilmente adaptables a cualquier idioma que disponga de un\ncorpus sobre el que obtener informaci\u00b4 on.\n2.6.1 M\u00b4 etodos distribucionales\nEste tipo de m\u00b4 etodos identi\ufb01can las palabras que suelen apare-\ncer en contextos similares, sin necesidad de utilizar un repositorio\nde sentidos. En ( Sch\u00a8 utze (1998 )) por ejemplo, se realiza el proce-\nso de desambiguaci\u00b4 on en dos pasos. El primer paso, es construir\nclusters que comparten caracter\u00b4 \u0131sticas similares. El segundo pa-\nso, es etiquetar cada cluster con una de\ufb01nici\u00b4 on que establezca el\nsentido de la palabra dentro de ese contexto. Esta es una visi\u00b4 on\ncompletamente diferente del concepto general de WSD, donde los\nsentidos se suponen conocidos antes de comenzar el proceso de\ndesambiguaci\u00b4 on.\nEsta nueva visi\u00b4 on de \u201cdiscriminaci\u00b4 on y etiquetaci\u00b4 on\u201d corres-\nponde a la forma ideal de obtener la de\ufb01nici\u00b4 on de una palabra\n(lexicograf\u00b4 \u0131a). Un lexic\u00b4 ografo, seleccionar\u00b4 \u0131a diferentes contextos\nde una palabra determinada, a partir de un corpus extenso y re-\npresentativo para el usuario \ufb01nal. Por ejemplo, si hablamos de un\ndiccionario para ni\u02dc nos, el corpus consistir\u00b4 \u0131a en textos escritos para\nni\u02dc nos. Y si hablamos de un diccionario sobre un dominio espec\u00b4 \u0131\ufb01-\nco el corpus deber\u00b4 \u0131an ser textos de esa especialidad en particular.\nDe esta forma el lexic\u00b4 ografo, dividir\u00b4 \u0131a los contextos en los que\naparece la palabra a estudiar en diferentes clusters, discriminan-\ndo los diferentes sentidos que puede adoptar esa palabra, sin tener\nninguna idea preconcebida de cu\u00b4 antos sentidos puede adoptar.\nEl resultado de la discriminaci\u00b4 on es un n\u00b4 umero determinado\nde clusters que establecen los diferentes sentidos de la palabra,\nobtenidos \u00b4 estos a partir del corpus de entrada. A partir de aqu\u00b4 \u0131,\nse debe estudiar cada cluster y obtener una de\ufb01nici\u00b4 on que act\u00b4 ue\ncomo una etiqueta o un sentido espec\u00b4 \u0131\ufb01co para la palabra. Esta\n\u00b4 ultima parte, la de asignar una de\ufb01nici\u00b4 on concreta a la palabra\nen cada cluster es la m\u00b4 as problem\u00b4 atica, dado que en muchas oca-\nsiones es dif\u00b4 \u0131cil establecer una de\ufb01nici\u00b4 on a partir de los contextos.\nUna posible soluci\u00b4 on ser\u00b4 \u0131a identi\ufb01car el conjunto de palabras que\n40 2.6 M\u00b4 etodos no supervisados basados en corpus\naparecen en un cluster y utilizarlas como una aproximaci\u00b4 on al\nsentido de la palabra. Por ejemplo, si tenemos la palabra \u201cl\u00b4 \u0131nea\u201d\ny un cluster con: \u201ctel\u00b4 efono\u201d, \u201cllamada\u201d, \u201cocupada\u201d, \u201cm\u00b4 ovil\u201d. En\neste caso, estas palabras son indicativas del sentido asociado a\neste cluster.\nDe esta forma, si los m\u00b4 etodos no supervisados basados en cor-\npus son desarrollados e\ufb01cientemente, el resultado podr\u00b4 \u0131a llegar a\nser un proceso independiente del lenguaje que resuelve el proble-\nma de la ambig\u00a8 uedad sin tener que recurrir a un repositorio de\nsentidos.\nExisten dos aproximaciones distintas para los m\u00b4 etodos distri-\nbucionales:\nDiscriminaci\u00b4 on basada en tipos. Estos m\u00b4 etodos identi\ufb01can con-\njuntos (o clusters) de palabras que pueden estar relacionadas\nentre s\u00b4 \u0131 debido a su aparici\u00b4 on en contextos similares. Nor-\nmalmente se basan en medidas de similitud entre vectores de\nco-ocurrencia.\nDiscriminaci\u00b4 on basada en tokens. Estos m\u00b4 etodos agrupan to-\ndos los contextos donde una palabra determinada aparece,\nbas\u00b4 andose en la similitud de estos contextos.\n2.6.1.1 Discriminaci\u00b4 on basada en tipos.\nEn el caso de los m\u00b4 etodos de discriminaci\u00b4 on basados en tipos,\nes necesario disponer de corpus extensos para poder extraer la\nsimilitud entre diferentes contextos donde aparece la palabra a\ndesambiguar. En estos m\u00b4 etodos la representaci\u00b4 on m\u00b4 as utilizada\nse basa normalmente en la contabilizaci\u00b4 on de co-ocurrencias o en\nmedidas de asociaci\u00b4 on entre palabras. Usando esta informaci\u00b4 on\nes posible identi\ufb01car otras palabras que aparecen en contextos\nsimilares y por tanto pueden tener sentidos similares. De esta\nforma, se pueden extraer los distintos sentidos que puede adoptar\nuna palabra polis\u00b4 emica.\nPor ejemplo, si seleccionamos la palabra \u201cl\u00b4 \u0131nea\u201d que puede te-\nner varios sentidos (l\u00b4 \u0131nea telef\u00b4 onica, trazo, premio en el juego del\nbingo, etc), y \u00b4 esta aparece en dos contextos distintos: contex-\nto1(dibujo, trazo, color, coordenada) y contexto2 (auricular,\n2. Estado del arte 41\ntel\u00b4 efono, comunicar, llamada). Podemos establecer a partir de las\npalabras extra\u00b4 \u0131das del contexto, que en el primer caso \u201cl\u00b4 \u0131nea\u201d ha-\nce referencia a un trazo en un dibujo, y en el segundo caso, hace\nreferencia a una l\u00b4 \u0131nea telef\u00b4 onica.\nComo ya se ha mencionado anteriormente, los m\u00b4 etodos distri-\nbucionales basados en tipos necesitan de corpus bastante extensos.\nEs por ello, que la representaci\u00b4 on del espacio contextual se rea-\nlizar\u00b4 a en matrices de NxN dimensiones, donde N, es el n\u00b4 umero\nde palabras en el corpus. Cada celda de esta matriz contiene el\nn\u00b4 umero de veces que las palabras representadas en cada columna\ny \ufb01la co-ocurren dentro de una ventana de un tama\u02dc no especi\ufb01ca-\ndo. Cuando no importa el orden en el que aparecen las palabras la\nfrecuencia ser\u00b4 a la misma, pero si hablamos de bigramas, donde el\norden s\u00b4 \u0131 importa, el valor de las celdas ser\u00b4 a distinto. Por tanto, si\nel orden no importa, se tendr\u00b4 a una matriz cuadrada y sim\u00b4 etrica.\nSin embargo, si tenemos en cuenta el orden de aparici\u00b4 on de las\npalabras, tendremos una matriz rectangular y no sim\u00b4 etrica.\nPara estas matrices de co-ocurrencia, las celdas pueden alma-\ncenar el n\u00b4 umero de veces que dos palabras co-ocurren, o tambi\u00b4 en\npueden tomar valores m\u00b4 as complejos. Por ejemplo, las celdas de\nuna matriz de co-ocurrencia pueden contener el valor de diferen-\ntes medidas de asociaci\u00b4 on como: log-likelihood ratio ( Rayson y\nGarside (2000 )) o Informaci\u00b4 on Mutua ( Church y Hanks (1990 )).\nEstas medidas indican el grado en que dos palabras co-ocurren\ncon respecto a las dem\u00b4 as palabras del corpus.\nEn el caso de la medida del log-likelihood ratio partimos de\nuna tabla 2 \u00a32 como sigue a continuaci\u00b4 on 2.7.\nCorpus1\nCorpus2\nTotal\nFrecuencia de la palabra\na\nb\na+b\nFrecuencia de otras palabras\nc\u00a1a\nd\u00a1b\nc+d\u00a1a\u00a1b\nTotal\nc\nd\nc+d\nTabla 2.7. Tabla 2 x2 para log-likelihood ratio\nEn la Tabla 2.7se extraen las frecuencias relativas de una pa-\nlabra entre dos corpus. Se denota por cal n\u00b4 umero de palabras\n42 2.6 M\u00b4 etodos no supervisados basados en corpus\ntotal del corpus1 y por dal n\u00b4 umero de palabras total del corpus2\n(Nen total). Los valores de aybson denotados como valores ob-\nservados ( O). Por \u00b4 ultimo, queda por de\ufb01nir los valores esperados\n(E), seg\u00b4 un la F\u00b4 ormula 2.15.\nEi=NiX\niOi\nX\niNi(2.15)\nPara la Tabla 2.7N1=cyN2=d. Por lo tanto, para la\npalabra que estamos tratando:\nE1=c\u00a4(a+b)\n(c+d)y E 2=d\u00a4(a+b)\n(c+d)(2.16)\nLos c\u00b4 alculos para obtener los valores esperados tienen en cuenta\nel tama\u02dc no de los dos corpus. Por tanto, no es necesario normalizar\nlos valores, pudiendo aplicar a continuaci\u00b4 on la medida del log-\nlikelihood seg\u00b4 un la F\u00b4 ormula 2.17.\n\u00a12 ln\u00b8= 2X\niOiln\u00b5Oi\nEi\u00b6\n(2.17)\nLa F\u00b4 ormula 2.17es equivalente a calcular el log-likelihood ratio\nG2como sigue:\nG2= 2\u00a4\u00b5\na\u00a4ln\u00b5a\nE1\u00b6\u00b6\n+\u00b5\nb\u00a4ln\u00b5b\nE2\u00b6\u00b6\n(2.18)\nSi los valores esperados y los observados son comparables, el\nvalor de G2estar\u00b4 a pr\u00b4 oximo a 0, lo que signi\ufb01ca que la palabra\nha aparecido junto a otra por casualidad, y no est\u00b4 an relacionadas\nentre s\u00b4 \u0131. Si se obtiene un valor mayor que 0, signi\ufb01ca que los valores\nobservados di\ufb01eren en gran medida de los valores esperados, por\nlo que las palabras estar\u00b4 an fuertemente relacionadas entre s\u00b4 \u0131.\n2. Estado del arte 43\nUna vez decidido el tipo de medida a utilizar para establecer\nla co-ocurrencia entre distintas palabras y construida la matriz de\nco-ocurrencia, cada palabra ser\u00b4 a representada como un vector de\nN-dimensiones. A partir de cada vector obtenido, se puede medir\nla similitud contextual entre dos palabras obteniendo el coseno\nentre los vectores. Para el c\u00b4 alculo del coseno entre dos vectores se\nutiliza la F\u00b4 ormula 2.19.\ncos(\u00a1 !x ;\u00a1 !y) =\u00a1 !x\u00a2\u00a1 !y\nj\u00a1 !xj \u00a3 j\u00a1 !yj(2.19)\nContinuando con la de\ufb01nici\u00b4 on de m\u00b4 etodos distribucionales ba-\nsados en tipos, encontramos distintos algoritmos que pueden ser\naplicados. En esta secci\u00b4 on vamos a tratar dos de estos algoritmos:\nAn\u00b4 alisis de la Sem\u00b4 antica Latente (LSA) ( Deerwester et al. (1990 ))\ny Clustering by Committee (CBC) ( Pantel y Lin (2002 )).\nMediante el algoritmo de LSA se representa un corpus en un\nespacio multidimensional, usando vectores. Cada vector represen-\ntar\u00b4 a el contexto en el cual aparece una palabra. En el caso de\nLSA no se hacen distinciones entre los distintos sentidos de una\npalabra polis\u00b4 emica, es decir, se formar\u00b4 a un \u00b4 unico vector para ca-\nda palabra, aunque \u00b4 esta tenga varios sentidos diferentes. Usando\nla informaci\u00b4 on del contexto, se podr\u00b4 a determinar, por ejemplo,\nque palabras como: coche, autom\u00b4 ovil, auto... est\u00b4 an relacionadas\nsem\u00b4 anticamente.\nCuando hablamos de LSA, debemos pensar en la representa-\nci\u00b4 on del conocimiento como matrices de [ palabras-contextos ].\nPara medir el grado de similitud de una palabra con respecto a\notras palabras del contexto, se utiliza la medida del coseno entre\nvectores. Adem\u00b4 as de poder comparar palabras y contextos, tam-\nbi\u00b4 en se puede medir el grado de similitud entre oraci\u00b4 on-oraci\u00b4 on,\ncontexto-contexto... simplemente calculando el vector resultado\nde la uni\u00b4 on de cada uno de los vectores que conforman las pala-\nbras de la oraci\u00b4 on, del contexto, etc.\nMediante el algoritmo de CBC se pueden detectar clusters de\npalabras relacionadas con los distintos sentidos de una palabra\npolis\u00b4 emica. Por ejemplo, para la palabra \u201cmu\u02dc neca\u201d el algoritmo\n44 2.6 M\u00b4 etodos no supervisados basados en corpus\nde CBC podr\u00b4 \u0131a identi\ufb01car dos clusters, uno asociado con el sen-\ntido de juguete, con palabras como juego, entretenimiento, ni\u02dc nos,\ncochecito, etc, y otro cluster asociado con el sentido de parte del\ncuerpo humano, con palabras como brazo, extremidad, articula-\nci\u00b4 on, etc. Por lo tanto, con el algoritmo de CBC se pueden detec-\ntar palabras sin\u00b4 onimas asociadas a los diferentes sentidos de una\npalabra.\nAmbos algoritmos, tanto LSA como CBC, utilizan representa-\nciones multidimensionales de co-ocurrencia de palabras.\n2.6.1.2 Discriminaci\u00b4 on basada en tokens.\nEl objetivo de este tipo de m\u00b4 etodos es agrupar los contextos\nen los que una palabra aparece bajo el mismo sentido.\nA continuaci\u00b4 on se van a describir m\u00b4 etodos que utilizan ca-\nracter\u00b4 \u0131sticas de primer y segundo orden. Las caracter\u00b4 \u0131sticas de\nprimer orden ocurren directamente en un contexto que est\u00b4 a sien-\ndo clasi\ufb01cado, mientras que las caracter\u00b4 \u0131sticas de segundo orden\nson aquellas que ocurren junto con una de primer orden, pero no\nocurren en el contexto que est\u00b4 a siendo clasi\ufb01cado.\nEn primer lugar, es necesario establecer c\u00b4 omo se van a repre-\nsentar los contextos que van a ser clasi\ufb01cados en clusters. Al igual\nque para los sistemas supervisados, los contextos contienen la pa-\nlabra a desambiguar con la excepci\u00b4 on de que \u00b4 esta no tiene asigna-\ndo ning\u00b4 un sentido. La premisa de los m\u00b4 etodos basados en tokens\nes que si una palabra aparece en contextos similares \u00b4 esta ha de\ntener el mismo sentido.\nUno de los primeros m\u00b4 etodos que utiliz\u00b4 o discriminaci\u00b4 on basa-\nda en tokens fue una adaptaci\u00b4 on del algoritmo de LSA usando\ncaracter\u00b4 \u0131sticas de segundo orden ( Sch\u00a8 utze (1998 )). En este caso,\nla representaci\u00b4 on de la matriz de co-ocurrencia en lugar de uti-\nlizar palabras utiliza contextos completos usando co-ocurrencias\nde segundo orden de caracter\u00b4 \u0131sticas l\u00b4 exicas. Una palabra tiene\nuna co-ocurrencia de segundo orden con otra, cuando ambas no\naparecen juntas pero ambas s\u00b4 \u0131 aparecen junto a otra palabra fre-\ncuentemente. Por ejemplo, en \u201cpolic\u00b4 \u0131a de tr\u00b4 a\ufb01co\u201d y \u201caccidente\nde tr\u00b4 a\ufb01co\u201d, la palabra \u201cpolic\u00b4 \u0131a\u201d es una co-ocurrencia de segundo\n2. Estado del arte 45\norden de \u201caccidente\u201d, porque ambas co-ocurren en primer orden\ncon \u201ctr\u00b4 a\ufb01co\u201d.\nOtro m\u00b4 etodo que utiliza esta aproximaci\u00b4 on es el de ( Peder-\nsen y Bruce (1997 )). En este caso, utilizan un conjunto reducido\nde caracter\u00b4 \u0131sticas de primer orden para crear matrices que mues-\ntran la similitud entre contextos. Estas caracter\u00b4 \u0131sticas se extraen\na partir de las palabras que se encuentran alrededor de la pa-\nlabra a desambiguar e incluyen etiquetas sint\u00b4 acticas y palabras\nco-ocurrentes.\nEl problema de este tipo de m\u00b4 etodos es la forma de evaluaci\u00b4 on\nde los resultados. Debido a que la discriminaci\u00b4 on no parte de\nun conjunto preestablecido de sentidos, no se puede evaluar la\nforma en que los nuevos sentidos son descubiertos, sobretodo si se\nest\u00b4 a trabajando en un dominio espec\u00b4 \u0131\ufb01co.\n2.7 M\u00b4 etodos supervisados basados en corpus\nLos m\u00b4 etodos supervisados realizan la desambiguaci\u00b4 on de for-\nma autom\u00b4 atica a partir de modelos o reglas obtenidas a partir de\ntextos anotados previamente. Cuando hablamos de textos ano-\ntados, nos referimos a textos cuyo contenido ha sido etiquetado\nde forma manual. En este caso, la etiquetaci\u00b4 on se corresponde\ntanto a la parte de sem\u00b4 antica como a la parte sint\u00b4 actica. Ya que,\ncomo se coment\u00b4 o anteriormente se debe identi\ufb01car el tipo de cate-\ngor\u00b4 \u0131a sint\u00b4 actica de una palabra, para poder establecer su sentido\nsem\u00b4 antico.\nEn l\u00b4 \u0131neas generales los pasos a seguir por un m\u00b4 etodo supervi-\nsado son los siguientes:\n1.Seleccionar un conjunto de ejemplos que muestren las distintas\nclasi\ufb01caciones de cada elemento.\n2.Identi\ufb01car patrones asociados a cada elemento.\n3.Generalizar los patrones en reglas.\n4.Aplicar las reglas para clasi\ufb01car nuevos elementos.\nDentro de este tipo de m\u00b4 etodos cabe destacar las t\u00b4 ecnicas basa-\ndas en Aprendizaje Autom\u00b4 atico (Machine learning systems) ( Mit-\n46 2.7 M\u00b4 etodos supervisados basados en corpus\nchell (1997b ),Mitchell (1997a )). Estas t\u00b4 ecnicas han sido amplia-\nmente utilizadas en tareas de PLN obteniendo un \u00b4 exito conside-\nrable.\nLos problemas iniciales de PLN sobre los que fueron aplicados\neste tipo de m\u00b4 etodos estad\u00b4 \u0131sticos y de aprendizaje autom\u00b4 atico,\nfueron aquellos vinculados a la resoluci\u00b4 on de la ambig\u00a8 uedad l\u00b4 exi-\nca. En este tipo de tareas, se debe seleccionar de entre un conjunto\nde alternativas, la interpretaci\u00b4 on correcta para una palabra en un\ncontexto determinado. Podemos destacar tareas tales como: selec-\nci\u00b4 on de palabras en reconocimiento de voz, traducci\u00b4 on autom\u00b4 ati-\nca, desambiguaci\u00b4 on autom\u00b4 atica, resoluci\u00b4 on de co-referencias, etc.\nEste tipo de tareas se consideran adecuadas para un sistema de\naprendizaje autom\u00b4 atico porque pueden ser vistas como problemas\nde clasi\ufb01caci\u00b4 on, donde el sistema de aprendizaje trata de etique-\ntar (clasi\ufb01car) una serie de elementos, utilizando una de entre\nvarias categor\u00b4 \u0131as (clases). En este caso, la base de conocimiento\ndel sistema est\u00b4 a formada por ejemplos previamente etiquetados.\nActualmente, las t\u00b4 ecnicas de aprendizaje autom\u00b4 atico han sido\naplicadas a otros problemas de PLN, los cuales, no se reducen a\nun simple problema de clasi\ufb01caci\u00b4 on. Dentro de estas nuevas apli-\ncaciones encontramos: etiquetaci\u00b4 on de secuencias (con entidades,\ncategor\u00b4 \u0131as sint\u00b4 acticas, etc) y asignaci\u00b4 on de estructuras jer\u00b4 arquicas\n(\u00b4 arboles sint\u00b4 acticos, conceptos complejos en extracci\u00b4 on de infor-\nmaci\u00b4 on, etc). En estos casos, se parte de un problema complejo\nque puede ser descompuesto en esquemas de decisi\u00b4 on simples o\nse pueden generalizar los conjuntos de clasi\ufb01caci\u00b4 on para trabajar\ndirectamente con representaciones y salidas complejas.\nEn relaci\u00b4 on a WSD, en los \u00b4 ultimos diez a\u02dc nos, la t\u00b4 ecnica de\naprendizaje supervisado, a partir de ejemplos, ha sido una de las\nque mejores resultados ha obtenido. En este caso, los modelos\nestad\u00b4 \u0131sticos o de clasi\ufb01caci\u00b4 on se obtienen a partir de corpus ano-\ntados sem\u00b4 anticamente. Normalmente, los m\u00b4 etodos supervisados\nhan obtenido mejores resultados que los no supervisados. Esta\na\ufb01rmaci\u00b4 on queda demostrada a la vista de los resultados conse-\nguidos en las \u00b4 ultimas competiciones realizadas para la evaluaci\u00b4 on\nde m\u00b4 etodos de an\u00b4 alisis sem\u00b4 antico ( ACL (2001 ),ACL (2004 )). Sin\nembargo, estos m\u00b4 etodos tienen un grave problema, la necesidad\n2. Estado del arte 47\nde disponer de corpus lo bastante extensos para poder entrenar\nlos sistemas. A menudo, escasean los corpus anotados debido a\nsu costoso proceso de anotaci\u00b4 on manual, es el conocido problema\ndel cuello de botella de la adquisici\u00b4 on de conocimiento. Esta res-\ntricci\u00b4 on afecta en gran medida a los sistemas, ya que no tienen la\nmateria prima necesaria para poder trabajar.\n2.7.1 El proceso de clasi\ufb01caci\u00b4 on en aprendizaje\nsupervisado\nEl objetivo principal en el aprendizaje supervisado para la ta-\nrea de clasi\ufb01caci\u00b4 on consiste en inducir a partir de un conjunto de\nentrenamiento C, una aproximaci\u00b4 on (o hip\u00b4 otesis) hde una fun-\nci\u00b4 on no conocida fque mapea a partir de un espacio de entrada\nEa un espacio de salida S= 1; :::; K .\nEl conjunto de entrenamiento contiene mejemplos de entre-\nnamiento, C= (\u00a1 !e1; y1); :::;(\u00a1 !em; ym), pares (\u00a1 !e ; y). Donde\u00a1 !e\npertenece a Eyy=f(\u00a1 !e). El componente\u00a1 !ede cada ejemplo es\nnormalmente un vector\u00a1 !e= (e1; :::; e n), cuyos componentes, lla-\nmados atributos (features) describen informaci\u00b4 on relevante acerca\ndel ejemplo. Los valores del espacio de salida Sasociados con ca-\nda ejemplo de entrenamiento se llaman clases (categor\u00b4 \u0131as). Por\nlo tanto, cada ejemplo de entrenamiento est\u00b4 a completamente des-\ncrito por un conjunto de pares atributo-valor y una etiqueta de\nclase.\nSeg\u00b4 un la teor\u00b4 \u0131a del aprendizaje estad\u00b4 \u0131stico ( Vapnik (1998 )), la\nfunci\u00b4 on fse considera como una funci\u00b4 on de distribuci\u00b4 on de pro-\nbabilidad P(X; Y) y los ejemplos de entrenamiento se consideran\ncomo una muestra de esa distribuci\u00b4 on. Adem\u00b4 as, Xse identi\ufb01ca\nnormalmente con <n, y cada ejemplo\u00a1 !xcomo un punto en <n\ncon un valor real en cada dimensi\u00b4 on. Estas son las dos posibles\nnotaciones que podemos encontrar en este tipo de sistemas.\nDado un conjunto de entrenamiento C, un algoritmo de apren-\ndizaje induce un clasi\ufb01cador denotado como h, el cual es utili-\nzado como una hip\u00b4 otesis sobre la verdadera funci\u00b4 on f. A partir\nde aqu\u00b4 \u0131 el algoritmo de aprendizaje puede seleccionar entre un\nconjunto de posibles funciones H, a las que se llama espacio de\n48 2.7 M\u00b4 etodos supervisados basados en corpus\nhip\u00b4 otesis . Los algoritmos de aprendizaje se diferencian en base a\ndos rasgos: el tipo de espacio de hip\u00b4 otesis que manejan: funciones\nlineales, funciones radiales, etc. O el tipo de algoritmo de selecci\u00b4 on\nque utilizan para decidir cu\u00b4 al de las hip\u00b4 otesis es la mejor con res-\npecto al corpus de entrenamiento: simplicidad, margen m\u00b4 aximo,\netc.\nDados nuevos vectores\u00a1 !x,hse utiliza para predecir los corres-\npondientes valores y. En este caso, se clasi\ufb01can los nuevos ejem-\nplos, y el resultado se prevee que coincida con fen la mayor\u00b4 \u0131a\nde los casos, o de forma equivalente, que conlleve al menor n\u00b4 ume-\nro de errores. La forma de estimar el grado de error en aquellos\nejemplos nunca vistos anteriormente se denomina error de gene-\nralizaci\u00b4 on . Este tipo de errores no pueden ser minimizados por el\nalgoritmo de aprendizaje, dado que la funci\u00b4 on fo la distribuci\u00b4 on\nP(X; Y) son desconocidas. Por lo tanto, es necesario un principio\nde inducci\u00b4 on. La forma m\u00b4 as com\u00b4 un de proceder es minimizar el\ndenominado error de entrenamiento , es decir, el n\u00b4 umero de errores\nque encontramos en el conjunto de entrenamiento. Esta acci\u00b4 on se\nconoce como la minimizaci\u00b4 on del riesgo emp\u00b4 \u0131rico y proporciona\nuna buena estimaci\u00b4 on del error de generalizaci\u00b4 on con los su\ufb01cien-\ntes ejemplos de entrenamiento. Sin embargo, para dominios con\npocos ejemplos de entrenamiento, podemos ajustar demasiado los\ndatos de entrenamiento y generalizar err\u00b4 oneamente. El riesgo de\najuste se ve incrementado cuando tenemos datos at\u00b4 \u0131picos y ruido.\n2.7.1.1 Ejemplo: WSD con aprendizaje autom\u00b4 atico.\nSupongamos que se quieren desambiguar las diferentes ocurren-\ncias del verbo \u201cto know\u201d en diferentes contextos. En este caso,\nse considerar\u00b4 an los diferentes sentidos del verbo como las dis-\ntintas clases del problema de clasi\ufb01caci\u00b4 on (espacio de salida Y).\nAdem\u00b4 as, cada ocurrencia del verbo en un corpus previamente ano-\ntado sem\u00b4 anticamente, ser\u00b4 a codi\ufb01cada como un ejemplo ( xi) para\nla tarea de entrenamiento. En la Tabla 2.8el verbo \u201cto know\u201d\ntiene once sentidos diferentes seg\u00b4 un las de\ufb01niciones de WordNet\n1.6, con sus correspondientes dominios de WordNet Domains.\n2. Estado del arte 49\nSynset\nDominio\nGlosa\n00401762\nknow#1\npsychology\nbe cognizant or aware of a fact or a speci\ufb01c piece\nof information; possess knowledge or information\nabout; \u201cI know that the President lied to the peo-\nple\u201d; \u201cI want to know who is winning the game!\u201d;\n\u201cI know it\u2019s time\u201d\n00402497\nknow#2\npsychology\nknow how to do or perform something; \u201cShe knows\nhow to knit\u201d; \u201cDoes your husband know how to\ncook?\u201d\n00402210\nknow#3\npsychology\nbe aware of the truth of something; have a belief\nor faith in something; regard as true beyond any\ndoubt; \u201cI know that I left the key on the table\u201d;\n\u201cGalileo knew that the earth moves around the\nsun\u201d\n00401559\nknow#4\nfactotum\nbe familiar or acquainted with a person or an ob-\nject; \u201cShe doesn\u2019t know this composer\u201d; \u201cDo you\nknow my sister?\u201d \u201cWe know this movie\u201d\n00402992\nknow#5\npsychology\nhave \ufb01rsthand knowledge of states, situations,\nemotions, or sensations; \u201cI know the feeling!\u201d \u201cha-\nve you ever known hunger?\u201d\n00400501\nknow#6\nfactotum\ndiscern; \u201cHis greed knew no limits\u201d\n00402658\nknow#7\nfactotum\nhave \ufb01xed in the mind; \u201cI know Latin\u201d; \u201cThis stu-\ndent knows her irregular verbs\u201d; \u201cDo you know the\npoem well anough to recite it?\u201d\n00977560\nknow#8\nsexuality\nhave sexual intercourse with; \u201cThis student sleeps\nwith everyone in her dorm\u201d; \u201cAdam knew Eve\u201d\n(know is archaic); \u201cWere you ever intimate with\nthis man?\u201d\n00411402\nknow#9\npsychology\nknow the nature or character of; \u201cwe all knew her\nas a big show-o\ufb00\u201d\n00411252\nknow#10\nfactotum\nbe able to distinguish. recognize as being di\ufb00erent;\n\u201cThe child knows right from wrong\u201d\n00411122\nknow#11\nfactotum\nperceive as familiar; \u201cI know this voice!\u201d\nTabla 2.8. Sentidos del verbo \u201cto know\u201d en WordNet 1.6\nGeneralmente, las de\ufb01niciones de los sentidos de una palabra,\ntienen asociados ejemplos con informaci\u00b4 on relevante del contexto\ndonde suele utilizarse. Esta informaci\u00b4 on puede usarse para extraer\ncaracter\u00b4 \u0131sticas ( \u201cfeatures\u201d ), como por ejemplo bigramas, trigra-\nmas, relaciones sint\u00b4 acticas, etc. Estas caracter\u00b4 \u0131sticas son utiliza-\ndas para codi\ufb01car los ejemplos de entrenamiento mediante vec-\ntores de ndimensiones, donde nes el n\u00b4 umero de caracter\u00b4 \u0131sticas\n50 2.7 M\u00b4 etodos supervisados basados en corpus\nutilizado. En el caso de los algoritmos de aprendizaje autom\u00b4 atico,\nes imprescindible obtener la informaci\u00b4 on del contexto que rodea\na la palabra ambigua para poder construir los vectores de carac-\nter\u00b4 \u0131sticas. Normalmente, es necesario realizar un pre-proceso para\npoder construir estos vectores. Es preciso por una parte, obte-\nner las palabras con contenido sem\u00b4 antico que rodean a la palabra\nambigua, para ello, se establecen ventanas contextuales de dife-\nrente tama\u02dc no, tambi\u00b4 en se utilizan analizadores sint\u00b4 acticos para\nestudiar los patrones de relaciones sint\u00b4 acticas, se detectan las pa-\nlabras compuestas, etc. Este pre-proceso es necesario para una\ncorrecta de\ufb01nici\u00b4 on de las caracter\u00b4 \u0131sticas y determinar\u00b4 a el buen\nfuncionamiento del algoritmo de aprendizaje autom\u00b4 atico.\nLos conjuntos de caracter\u00b4 \u0131sticas m\u00b4 as utilizados en aprendizaje\nautom\u00b4 atico se pueden clasi\ufb01car en tres grupos:\nCaracter\u00b4 \u0131sticas locales Las caracter\u00b4 \u0131sticas locales engloban: n-\ngramas de etiquetas sint\u00b4 acticas, lemas, palabras junto con su\nposici\u00b4 on respecto a la palabra a desambiguar. En alguna oca-\nsi\u00b4 on las caracter\u00b4 \u0131sticas locales incluyen sacos de palabras o\nlemas situados en el entorno de la palabra ambigua. Mediante\nestas caracter\u00b4 \u0131sticas se puede capturar el conocimiento sobre\ncolocaciones, relaciones sint\u00b4 acticas, etc.\nCaracter\u00b4 \u0131sticas generales Mediante las caracter\u00b4 \u0131sticas genera-\nles se pueden representar contextos mucho m\u00b4 as generales. La\nrepresentaci\u00b4 on de estas caracter\u00b4 \u0131sticas se realiza mediante sa-\ncos de palabras (ventana amplia de palabras, oraciones, p\u00b4 arra-\nfos, documentos...). Usando este tipo de caracter\u00b4 \u0131sticas se pue-\nde capturar el dominio sem\u00b4 antico de un fragmento de texto o\nde un documento.\nDependencias sint\u00b4 acticas Al nivel de una oraci\u00b4 on, las depen-\ndencias sint\u00b4 acticas se pueden utilizar para modelar relaciones\nentre diferentes argumentos.\nAdem\u00b4 as de los vectores de caracter\u00b4 \u0131sticas tambi\u00b4 en se suelen\nutilizar listas de decisi\u00b4 on. En este caso, el algoritmo de aprendizaje\nse basa en una serie de reglas del tipo:\nif(caracteristica =valor )then clase\n2. Estado del arte 51\nEn el caso de algoritmos basados en listas de decisi\u00b4 on, cada vez\nque se trata de clasi\ufb01car un nuevo ejemplo x, se van ejecutando\npor orden el listado de reglas hasta que se encuentre una que se\npueda aplicar sobre el nuevo ejemplo.\nSuponiendo que se han obtenido una serie de reglas de decisi\u00b4 on\na partir de varios ejemplos de entrenamiento, se podr\u00b4 \u0131a ejecutar\nun algoritmo de decisi\u00b4 on sobre el siguiente ejemplo: \u201cThere is not-\nhing in the whole range of human experience more widely known\nand universally felt than spirit\u201d . La Tabla 2.9muestra las reglas\naplicadas junto con una probabilidad de certidumbre para cada\nregla.\nCaracter\u00b4 \u0131stica\nValor\nSentido\nProbabilidad\n\u00a7ventana de 3 palabras\n\u201cwidely\u201d\n4\n2;99\nbigrama\n\u201cwidely known\u201d\n4\n2;99\nbigrama\n\u201cknown and\u201d\n4\n1;09\nventana\n\u201cwhole\u201d\n1\n0;91\nventana\n\u201cwidely\u201d\n4\n0;69\nventana\n\u201cknown\u201d\n4\n0;43\nTabla 2.9. Clasi\ufb01caci\u00b4 on seg\u00b4 un listas de decisi\u00b4 on de la palabra \u201cknow\u201d\nEn este ejemplo, se puede observar que la lista de decisi\u00b4 on\n\u00b4 unicamente establece valores positivos para los sentidos 1 y 4 de\n\u201cknow\u201d . Usando esta informaci\u00b4 on, se podr\u00b4 \u0131a proponer como sen-\ntido correcto de \u201cknow\u201d el 4, debido a que la mayor\u00b4 \u0131a de reglas\napuntan a este sentido.\nPara \ufb01nalizar, recordar que cuando se habla de \u201caprendizaje\nsupervisado\u201d se parte de un corpus de entrenamiento previamente\nanotado en base a una serie de clases sem\u00b4 anticas. Mientras que\ncuando se habla de \u201caprendizaje no supervisado\u201d no existe anota-\nci\u00b4 on previa y el objetivo \ufb01nal es, a partir de similitudes sem\u00b4 anticas\nobtener una serie de clusters para poder ser interpretados como\nclases sem\u00b4 anticas.\n52 2.7 M\u00b4 etodos supervisados basados en corpus\n2.7.2 Clasi\ufb01caci\u00b4 on de m\u00b4 etodos de aprendizaje\nsupervisado\nA continuaci\u00b4 on se van a describir algunos de los distintos m\u00b4 eto-\ndos de aprendizaje supervisado utilizados en WSD. Estos m\u00b4 etodos\nson clasi\ufb01cados atendiendo a la forma que tienen de adquirir los\nmodelos de clasi\ufb01caci\u00b4 on.\n2.7.2.1 M\u00b4 etodos probabil\u00b4 \u0131sticos.\nLos m\u00b4 etodos estad\u00b4 \u0131sticos normalmente estiman un conjunto de\npar\u00b4 ametros que determinan la probabilidad condicional de las ca-\ntegor\u00b4 \u0131as y los contextos (descritos mediante caracter\u00b4 \u0131sticas). Estos\npar\u00b4 ametros se utilizan para asignar a cada nuevo ejemplo una ca-\ntegor\u00b4 \u0131a que maximice la probabilidad condicional a partir de las\ncaracter\u00b4 \u0131sticas observadas anteriormente.\nEl clasi\ufb01cador m\u00b4 as simple que existe es el denominado Na\u00a8 \u0131ve\nBayes Classi\ufb01er (NBC) ( Duda et al. (2001 )). En este modelo, hay\nun nodo que representa la variable de clase Cy un nodo para cada\natributo xidel ejemplo (ver Figura 2.4). Se parte de la hip\u00b4 otesis\nde que los valores de los atributos se generan independientemente\na partir de la clase Cde acuerdo con las distribuciones indivi-\nduales P(xijC). Para predecir la clase de un ejemplo, se elige la\nque maximiza la probabilidad de haber generado el ejemplo ob-\nservado. Para ello, se utiliza una f\u00b4 ormula derivada a partir del\nteorema de Bayes. Este algoritmo ha sido usado en distintas ta-\nreas de PLN para resolver diversos problemas (categorizaci\u00b4 on de\ndocumentos ( Lewis y Ringuette (1994 )), correcci\u00b4 on ortogr\u00b4 a\ufb01ca\n(Golding (1995 )), resoluci\u00b4 on de la ambig\u00a8 uedad sem\u00b4 antica ( Lea-\ncock et al. (1998 ),Escudero et al. (2000 )) ...) y a pesar de su\nextrema simplicidad, ha obtenido resultados notables. Adem\u00b4 as,\nutilizando el NBC se puede combinar informaci\u00b4 on estad\u00b4 \u0131stica de\ndistintas fuentes, siempre que sean independientes.\nLa f\u00b4 ormula general para obtener la clasi\ufb01caci\u00b4 on seg\u00b4 un el clasi-\n\ufb01cador bayesiano es la siguiente:\n2. Estado del arte 53\n \n \n \nC \nX1 X2 X3 X4 Xn \u2026 \nFigura 2.4. Modelo clasi\ufb01cador bayesiano (na\u00a8 \u0131ve)\nP(CjX1; X2; X3; :::; X n) =P(X1; X2; X3; :::; X njC)\u00a3P(C)\nP(X1; X2; X3; :::; X n)\n(2.20)\nDado que los atributos son independientes con respecto a la\nclase Cse cumple que:\nP(X1; X2; X3; :::; X njC) =Y\niP(XijC) (2.21)\nDe esta forma, el clasi\ufb01cador bayesiano na\u00a8 \u0131ve obtiene el si-\nguiente resultado:\nvalor = arg m\u00b4 ax\nvalor2CP(X1jC)\u00a3:::\u00a3P(XnjC)\u00a3P(C) (2.22)\nPara el caso de WSD el sentido correcto para una palabra\ncualquiera Cser\u00b4 \u0131a aquel que hiciera m\u00b4 aximo el resultado de la\nEcuaci\u00b4 on 2.22.\nPor ejemplo, supongamos que tenemos 2000 instancias de la\npalabra \u201cbank\u201d : 1500 para bank#1 (\ufb01nancial) y 500 para bank#2\n(river). En este caso, las probabilidades para cada sentido ser\u00b4 \u0131an:\nP(S= 1) = 1500 =2000 = 0 ;75\nP(S= 2) = 500 =2000 = 0 ;25\n54 2.7 M\u00b4 etodos supervisados basados en corpus\nDada la palabra \u201ccredit\u201d \u00b4 esta aparece 200 veces con bank#1 y\n4 veces con bank#2.\nP(X1=credit ) = 204 =2000 = 0 ;102\nP(X1=creditjC= 1) = 200 =1500 = 0 ;133\nP(X1=creditjC= 2) = 4 =500 = 0 ;08\nDado un texto que contiene la palabra \u201ccredit\u201d :\nP(C= 1jX1=credit ) = (0 ;133\u00a30;75)=0;102 = 0 ;978\nP(C= 2jX1=credit ) = (0 ;08\u00a30;25)=0;102 = 0 ;20\nPor tanto, se deducir\u00b4 \u0131a que el sentido correcto para \u201cbank\u201d es\nel n\u00b4 umero 1.\nLa efectividad del clasi\ufb01cador bayesiano \u201cnaive\u201d ha sido pro-\nbada en diferentes estudios ( Mooney (1996 ),Pedersen (1997 )) que\ndemuestran que este clasi\ufb01cador es tan bueno como cualquier otro\nm\u00b4 etodo.\n2.7.2.2 M\u00b4 etodos basados en reglas de discriminaci\u00b4 on.\nEste tipo de m\u00b4 etodos utilizan las llamadas listas de decisi\u00b4 on\n(Rivest (1987 )) o \u00b4 arboles de decisi\u00b4 on ( Quillian (1986 ),Quillian\n(1993 )) donde se utilizan reglas asociadas a cada uno de los di-\nferentes sentidos de una palabra. En este caso, dado un ejemplo\na clasi\ufb01car, el sistema selecciona una o m\u00b4 as reglas que son sa-\ntisfechas por las caracter\u00b4 \u0131sticas del ejemplo y asigna un sentido\nbas\u00b4 andose en sus predicciones.\nConcretamente, una lista de decisi\u00b4 on es un conjunto ordena-\ndo de reglas de la forma (condici\u00b4 on, clase, peso). Un ejemplo de\neste tipo de listas se encuentra en la Secci\u00b4 on 2.7.1.1 . Una lista\nde decisi\u00b4 on con reglas a las que se le asignan pesos establece que\nlas reglas con condiciones excepcionales se sit\u00b4 uan al principio de\nla lista con un peso elevado, las reglas con condiciones generales\nse sit\u00b4 uan al \ufb01nal con un peso bajo y la \u00b4 ultima condici\u00b4 on de la\nlista es una condici\u00b4 on por defecto que acepta el resto de casos no\ncontemplados. Los pesos se establecen de acuerdo a una funci\u00b4 on\nque mide el grado de asociaci\u00b4 on entre la condici\u00b4 on y una categor\u00b4 \u0131a\n2. Estado del arte 55\nparticular a partir de un corpus de entrenamiento. Para clasi\ufb01car\nun nuevo ejemplo, cada regla de la lista se comprueba secuencial-\nmente y la categor\u00b4 \u0131a de la primera regla que cumple la condici\u00b4 on\nse asigna al nuevo ejemplo.\nEn (Yarowsky (1994b ) se utilizan listas de decisi\u00b4 on para re-\nsolver un tipo espec\u00b4 \u0131\ufb01co de ambig\u00a8 uedad: los acentos en espa\u02dc nol\ny franc\u00b4 es. En un trabajo posterior se aplicaron listas de decisi\u00b4 on\npara WSD ( Yarowsky (1995 )). En este estudio, cada condici\u00b4 on de\nla lista se correspond\u00b4 \u0131a con una caracter\u00b4 \u0131stica ( \u201cfeature\u201d ), donde\nlos valores eran los sentidos de las palabras y los pesos se calcu-\nlaban de acuerdo a una f\u00b4 ormula que estimaba la probabilidad de\nun sentido con respecto a una determinada caracter\u00b4 \u0131stica.\nEn (Mart\u00b4 \u0131nez et al. (2002 ),Mart\u00b4 \u0131nez (2004 )) las listas de de-\ncisi\u00b4 on se emplean en un sistema de WSD junto con una serie\nde nuevas caracter\u00b4 \u0131sticas sint\u00b4 acticas (relaciones gramaticales ins-\ntanciadas, relaciones gramaticales...) y sem\u00b4 anticas (modelos de\npreferencias de selecci\u00b4 on). Este sistema se ha empleado para de-\nsambiguar textos en Euskera e Ingl\u00b4 es.\nEn el caso de los \u00b4 arboles de decisi\u00b4 on las reglas de clasi\ufb01caci\u00b4 on\nse generan en forma de una estructura n-aria de ramas de un\n\u00b4 arbol. Cada rama de un \u00b4 arbol de decisi\u00b4 on representa una regla\nque comprueba un conjunto de caracter\u00b4 \u0131sticas (nodos internos)\ny hace una predicci\u00b4 on de la clase del nodo terminal. Este tipo\nde estructuras no se han empleado frecuentemente en WSD. En\n(Mooney (1996 )) se utiliz\u00b4 o el algoritmo de ( Quinlan (1993 )) y se\nrealiz\u00b4 o un estudio comparativo con varios algoritmos de aprendi-\nzaje autom\u00b4 atico para WSD. Este estudio concluy\u00b4 o que los \u00b4 arboles\nde decisi\u00b4 on no estaban entre los algoritmos que mejor resolv\u00b4 \u0131an\nel problema de WSD. A pesar de ello, en Senseval-1 (Yarowsky\n(2000a )) present\u00b4 o un sistema modi\ufb01cado de listas de decisi\u00b4 on con\nalgunas ramas condicionales que obtuvo muy buenos resultados\nen la tarea \u201cEnglish Lexical Sample\u201d .\n2.7.2.3 Bootstrapping.\nComo se ha comentado anteriormente, el problema de los\nm\u00b4 etodos basados en aprendizaje autom\u00b4 atico es la escasez de cor-\n56 2.7 M\u00b4 etodos supervisados basados en corpus\npus anotados sem\u00b4 anticamente. Para evitar este problema exis-\nte un m\u00b4 etodo que requiere de un m\u00b4 \u0131nimo conjunto de elementos\nanotados (sistemas m\u00b4 \u0131nimamente supervisados), es el denomina-\ndo m\u00b4 etodo \u201cde semilla\u201d o bootstrapping ( Abney (2002 ),Abney\n(2004 )). La idea de este m\u00b4 etodo es que a partir de un m\u00b4 \u0131nimo\nconjunto de ejemplos anotados se pueden realizar sucesivos apren-\ndizajes que se alimentan incrementalmente con el conocimiento\nadquirido en el anterior. El t\u00b4 ermino \u201csemilla\u201d proviene del ini-\ncio de tal proceso iterativo, que no necesita m\u00b4 as que una m\u00b4 \u0131nima\ncantidad de conocimiento previo para comenzar el aprendizaje.\nExisten diferentes aproximaciones del m\u00b4 etodo de bootstrap-\nping: co-training y self-training.\nLa idea b\u00b4 asica para ambas aproximaciones es la siguiente:\nSe parte de un conjunto EEde Ejemplos de Entrenamiento\netiquetados y de un conjunto ENde Ejemplos No Etiquetados.\nSe dispone de CiClasi\ufb01cadores.\nPaso 1. Crear un conjunto de ejemplos NE0, eligiendo Pejem-\nplos aleatorios de NE.\nPaso 2. Bucle de Iiteraciones:\n- Entrenar los clasi\ufb01cadores Cisobre el conjunto etiquetado\nEEy etiquetar el conjunto no etiquetado NE0.\n- Seleccionar los Mmejores ejemplos y a\u02dc nadirlos al conjunto\nEE, manteniendo la distribuci\u00b4 on de EE.\n- Rellenar el conjunto NE0con ejemplos de NE, manteniendo\nNE0en un tama\u02dc no constante P.\nUn ejemplo del m\u00b4 etodo co-training lo encontramos en ( Blum y\nMitchell (1998 )) donde se utilizan dos clasi\ufb01cadores. Y un ejem-\nplo del m\u00b4 etodo self-training lo encontramos en ( Nigam y Ghani\n(2000 )) donde se utiliza un \u00b4 unico clasi\ufb01cador.\n2.7.2.4 M\u00b4 etodos basados en redes neuronales.\nOtro tipo de m\u00b4 etodos utilizados para WSD son aquellos ba-\nsados en redes neuronales, algoritmos gen\u00b4 eticos, etc ( Veronis y\nIde(1990 ),Towell y Voorhees (1998 )). Una Red Neuronal Arti-\n\ufb01cial (RNA) es un modelo de procesamiento de informaci\u00b4 on que\nest\u00b4 a inspirado en un sistema nervioso biol\u00b4 ogico ( Group (1986 )).\n2. Estado del arte 57\n\u00b4Este se compone de un gran n\u00b4 umero de elementos de procesamien-\nto interconectados (neuronas) trabajando conjuntamente para re-\nsolver problemas espec\u00b4 \u0131\ufb01cos. Las RNA aprenden con ejemplos, es\npor tanto necesaria la utilizaci\u00b4 on de un proceso de aprendizaje\npara su con\ufb01guraci\u00b4 on. La principal ventaja de las RNA radica en\nla resoluci\u00b4 on de problemas demasiado complejos para tecnolog\u00b4 \u0131as\nconvencionales, problemas que no tienen un algoritmo de soluci\u00b4 on\nespec\u00b4 \u0131\ufb01co o que es muy dif\u00b4 \u0131cil de encontrar. Entre estos proble-\nmas se encuentran el reconocimiento de patrones y pron\u00b4 osticos,\nclasi\ufb01caci\u00b4 on de datos, optimizaci\u00b4 on... Sin embargo, en el \u00b4 ambito\ndel procesamiento del lenguaje natural a\u00b4 un no han sido su\ufb01cien-\ntemente explotadas ( Valdivia et al. (2002 )).\nEn (Garc\u00b4 \u0131a (2006 )) se propone un sistema de WSD basado\nen el modelo de red neural de Kohonen ( Kohonen (1989 )), en su\nvariante de Aprendizaje por Cuanti\ufb01caci\u00b4 on Vectorial (Learning\nVector Quanti\ufb01cation o LVQ). Como recursos ling\u00a8 u\u00b4 \u0131sticos para el\naprendizaje de la red se utiliza el corpus de Semcor, que est\u00b4 a eti-\nquetado con los sentidos de WordNet y el conjunto de p\u00b4 arrafos\narti\ufb01ciales generado a partir de todas las relaciones de WordNet.\nAdem\u00b4 as, integra el modelo de espacio vectorial (con vectores ob-\ntenidos a partir de Semcor) con LVQ para de\ufb01nir las categor\u00b4 \u0131as de\nla red. Este sistema particip\u00b4 o en la tarea English Lexical Sample\ndeSenseval-2 obteniendo una precisi\u00b4 on del 59 %.\n2.8 M\u00b4 etodos h\u00b4 \u0131bridos\nLos m\u00b4 etodos que se encuentran dentro de este grupo son aque-\nllos que no pueden englobarse exactamente dentro de los grupos\nanteriores. Es decir, son aquellos que utilizan en el proceso de de-\nsambiguaci\u00b4 on tanto fuentes de conocimiento externas como corpus\nanotados o no anotados.\nUn m\u00b4 etodo que combina la utilizaci\u00b4 on de diccionarios con cor-\npus no anotados es el ideado por ( Luk(1995 )). Este m\u00b4 etodo utiliza\nlas de\ufb01niciones de LDOCE para extraer las palabras que identi\ufb01-\ncan cada sentido, construyendo as\u00b4 \u0131 para cada sentido una lista de\npalabras representativas. Utilizando esta informaci\u00b4 on y las oracio-\n58 2.8 M\u00b4 etodos h\u00b4 \u0131bridos\nnes del Brown Corpus2(Francis y Kucera (1979 )) no anotado, se\nexpande el conjunto de palabras representativas obtenido a partir\nde LDOCE, de la siguiente forma: se extraen pares de palabras\nde cada oraci\u00b4 on del Brown Corpus y se determinan los concep-\ntos co-ocurrentes mediante un algoritmo que obtiene una tabla de\ndatos conceptuales co-ocurrentes. Esto permite producir un siste-\nma que utiliza la informaci\u00b4 on de recursos l\u00b4 exicos como un medio\npara reducir la gran cantidad de texto necesaria de los corpus de\nentrenamiento.\nEl proceso de desambiguaci\u00b4 on de una palabra polis\u00b4 emica W\nsobre un contexto C(la oraci\u00b4 on que contiene a la palabra), co-\nmienza dando valores a cada sentido SdeW, seg\u00b4 un la f\u00b4 ormula:\nscore (S; C) =score (CS; C0)\u00a1score (CS; GlobalCS ) (2.23)\nDonde CSes el conjunto de palabras representativas de LDO-\nCE pertenecientes al sentido S,C0es el conjunto ampliado de\npalabras representativas y GlobalCS contiene las de\ufb01niciones de\ncada concepto. A partir de estos valores y utilizando la Informa-\nci\u00b4 on Mutua entre las diferentes conjuntos de palabras represen-\ntativas, se selecciona el sentido con mayor valor de Informaci\u00b4 on\nMutua.\nEste sistema obtuvo un 77 % de precisi\u00b4 on sobre las 12 palabras\nutilizadas en el trabajo de ( Yarowsky (1992 )).\nOtros m\u00b4 etodos destacables de este tipo son los publicados en:\nMcRoy (1992 ),Dagan et al. (1991 ) yDagan et al. (1994 ).\nExisten tambi\u00b4 en otros m\u00b4 etodos que utilizan la combinaci\u00b4 on\nde tesauros y corpus no anotados, como es el caso del m\u00b4 etodo\nideado en ( Yarowsky (1992 )). Este m\u00b4 etodo emplea la t\u00b4 ecnica de\nbootstrapping utilizando las palabras de las categor\u00b4 \u0131as del Roget\u2019s\nThesaurus3, consider\u00b4 andolas etiquetadas sem\u00b4 anticamente y esta\ninformaci\u00b4 on se va aumentando utilizando un corpus no anotado.\nAdem\u00b4 as podemos encontrar tambi\u00b4 en m\u00b4 etodos que combinan\ndiferentes fuentes l\u00b4 exicas estructuradas con corpus: Lin(1997 ),\n2http://nora.hd.uib.no/whatis.html\n3http://www.gutenberg.org/etext/22\n2. Estado del arte 59\nAgirre y Mart\u00b4 \u0131nez (2000 ). M\u00b4 etodos que combinan WordNet y cor-\npus:Resnik (1995b ),Stetina et al. (1998 ), etc\nEn de\ufb01nitiva, el n\u00b4 umero de sistemas de WSD surgidos a partir\nde la combinaci\u00b4 on de diferentes fuentes de conocimiento es muy\namplio y ser\u00b4 \u0131a imposible citarlos exhaustivamente.\n2.9 Otra clasi\ufb01caci\u00b4 on de sistemas WSD\nDada la gran cantidad de m\u00b4 etodos propuestos actualmente pa-\nra WSD existe una clasi\ufb01caci\u00b4 on m\u00b4 as general que engloba \u00b4 unica-\nmente dos tipos de sistemas: sistemas supervisados y sistemas no\nsupervisados.\nEsta clasi\ufb01caci\u00b4 on es la utilizada en la competici\u00b4 on Senseval\npara la evaluaci\u00b4 on de los distintos sistemas de WSD presentados.\nComo ya se ha comentado en los puntos anteriores, cuando se ha-\nbla de sistemas supervisados se hace referencia a aquellos sistemas\nque necesitan de corpus de entrenamiento anotados sem\u00b4 antica-\nmente. En cambio, los sistemas no supervisados son aquellos que\nno necesitan esa anotaci\u00b4 on para poder funcionar correctamente.\n2.10 Aplicaciones actuales\nAunque no deja de ser importante en el Procesamiento del Len-\nguaje Natural, WSD se considera una tarea intermedia ( Wilks y\nStevenson (1998 )), al igual que otras tareas como: part-of-speech\ntagging o an\u00b4 alisis sint\u00b4 actico. Decimos que es una tarea interme-\ndia porque sus resultados \u00b4 unicamente proporcionan informaci\u00b4 on\nling\u00a8 u\u00b4 \u0131stica y nada tienen que ver con lo que el usuario \ufb01nal deman-\nda en \u00b4 ultima instancia. Otras tareas, las llamadas tareas \ufb01nales,\ncomo la traducci\u00b4 on autom\u00b4 atica, extracci\u00b4 on de informaci\u00b4 on y siste-\nmas de di\u00b4 alogo, ofrecen unos resultados requeridos por el usuario,\nal que poco le importa el fondo ling\u00a8 u\u00b4 \u0131stico sobre el que este tipo de\ntareas se apoya. La mayor\u00b4 \u0131a de estas tareas \ufb01nales requieren dife-\nrentes m\u00b4 odulos que implementen una serie de tareas intermedias\nnecesarias para el correcto funcionamiento de la aplicaci\u00b4 on.\n60 2.10 Aplicaciones actuales\nEsencialmente, existen dos tareas \ufb01nales que realmente obtie-\nnen bene\ufb01cios por la utilizaci\u00b4 on de un m\u00b4 odulo de WSD. Estamos\nhablando de traducci\u00b4 on autom\u00b4 atica y recuperaci\u00b4 on de informa-\nci\u00b4 on. A pesar de que en recuperaci\u00b4 on de informaci\u00b4 on no est\u00b4 an\ndemostrados los bene\ufb01cios de aplicar WSD s\u00b4 \u0131 se hace patente la\nnecesidad de su utilizaci\u00b4 on. Por ejemplo, cuando realizamos una\nb\u00b4 usqueda sobre el \u201c\u00b4 aguila imperial\u201d, queremos \u00b4 unicamente aque-\nllos documentos que hablen sobre el ave rapaz, y no sobre peces\nde la especie raya o sobre un tipo de moneda espa\u02dc nola o mexicana.\nEn 1992 y 1997 ( Krovets y Croft (1992 ),Krovets (1997 )), en unos\nestudios realizados con un corpus desambiguado manualmente, se\ncomprob\u00b4 o que un sistema de WSD podr\u00b4 \u0131a mejorar la recupera-\nci\u00b4 on de informaci\u00b4 on en un 2 %. Otro estudio similar fue el realiza-\ndo por Sanderson ( Sanderson (1994 )), en este caso, se efectuaron\nuna serie experimentos similares a los realizados por Krovets. La\n\u00b4 unica diferencia fue que en este caso la ambig\u00a8 uedad fue introdu-\ncida arti\ufb01cialmente en los textos. En este caso, se demostr\u00b4 o que\nel funcionamiento del sistema mejoraba para aquellas consultas\nque conten\u00b4 \u0131an menos de cinco palabras. En ( Pekar et al. (2006 ))\nse realiza un estudio para mejorar la traducci\u00b4 on de palabras poco\nfrecuentes a partir de una extensi\u00b4 on de la medida de similitud\nde co-ocurrencia de palabras ( Dagan et al. (1999 )). Sin embar-\ngo, otros autores han corroborado que WSD contribuye de forma\nsatisfactoria a mejorar los resultados de un sistema de RI. Esta\na\ufb01rmaci\u00b4 on viene corroborada por Sch\u00a8 utze y Pedersen ( Sch\u00a8 utze\ny Pedersen (1995 )), quienes demostraron que con la aplicaci\u00b4 on\nde WSD mejoraban el sistema de RI en un 14 %. Otros autores\n(Jing y Tzoukermann (1999 )) tambi\u00b4 en han demostrado que WSD\nmejora hasta en un 8 ;6 % los resultados en la recuperaci\u00b4 on de in-\nformaci\u00b4 on. En este caso, utilizan un algoritmo de desambiguaci\u00b4 on\nque eval\u00b4 ua la similitud en el contexto local de la consulta, la simi-\nlitud de la informaci\u00b4 on en el corpus y las relaciones morfol\u00b4 ogicas\nentre palabras.\nAdem\u00b4 as de poder ayudar a las tareas anteriormente mencio-\nnadas, WSD tambi\u00b4 en puede ser muy \u00b4 util para otras tareas. En el\nestudio realizado por Yarowsky ( Yarowsky (1996 )) se demuestra\nc\u00b4 omo WSD puede utilizarse para sistemas de s\u00b4 \u0131ntesis de habla\n2. Estado del arte 61\no para encontrar la pronunciaci\u00b4 on correcta de hom\u00b4 ofonos, como\npor ejemplo, \u201clead\u201d y\u201clive\u201d . Tambi\u00b4 en ( Connine (1990 )) demues-\ntra que un sistema de WSD puede ayudar en el reconocimiento de\nvoz a identi\ufb01car el item l\u00b4 exico correcto para palabras con id\u00b4 enti-\ncas propiedades fon\u00b4 eticas, como \u201cbase\u201d y \u201cbass\u201d o\u201csealing\u201d y\n\u201cceiling\u201d . M\u00b4 as all\u00b4 a de todas estas aplicaciones WSD tambi\u00b4 en se\npuede utilizar en otras muchas tareas de procesamiento de textos\n(Yarowsky (1994b ),Yarowsky (1994a )).\nEn la Tabla 2.10 se muestran algunas de las aplicaciones ac-\ntuales que pueden obtener bene\ufb01cios tras utilizar un buen sistema\nde WSD.\nAplicaci\u00b4 on\nEjemplo de uso de WSD\nTraducci\u00b4 on autom\u00b4 atica\nTraducci\u00b4 on de la palabra \u201cbill\u201d Ingl\u00b4 es-Espa\u02dc nol\nResultado: \u00bfEs un \u201cpico\u201d o una \u201ccuenta\u201d?\nRecuperaci\u00b4 on de\ninformaci\u00b4 on\nEncontrar todas las p\u00b4 aginas web que hablen de \u201ccric-\nket\u201d\nResultado: \u00bfEl deporte o el insecto?\nB\u00b4 usqueda de respuestas\n\u00bfCu\u00b4 al es la opini\u00b4 on de George Miller sobre el control\nde armas?\nResultado: \u00bfEl psic\u00b4 ologo o el congresista?\nAdquisici\u00b4 on de\nconocimiento\nA\u02dc nadir a la base de conocimiento: Herb Bergson es\nel alcalde de Duluth\nResultado: \u00bfMinnesota o Georgia?\nTabla 2.10. Utilizaci\u00b4 on de WSD en aplicaciones de PLN\nCap\u0013\u0010tulo 3\nProblem\u00b4 atica en la evaluaci\u00b4 on de\nsistemas de WSD\nEn este cap\u00b4 \u0131tulo se describe la problem\u00b4 atica asociada a la eva-\nluaci\u00b4 on de sistemas de desambiguaci\u00b4 on autom\u00b4 atica. Los problemas\nen esta tarea est\u00b4 an centrados en el tipo de anotaci\u00b4 on utilizado pa-\nra etiquetar los sentidos de cada palabra, los corpus utilizados,\nel criterio de selecci\u00b4 on del sentido correcto de una palabra y las\nmedidas de evaluaci\u00b4 on utilizadas.\n3.1 Contexto del problema\nEn (Wilks y Stevenson (1998 )) Yorick Wilks y Mark Stevenson,\na\ufb01rman que existen diferentes niveles y tipos de desambiguaci\u00b4 on,\ndependiendo de la proporci\u00b4 on de palabras desambiguadas y el tipo\nde anotaci\u00b4 on utilizado. Adem\u00b4 as, para la tarea de desambiguaci\u00b4 on\nautom\u00b4 atica se utilizan distintos tipos de fuentes de informaci\u00b4 on\ndesde los Machine Readable Dictionaries (MRDs) como LDOCE\ny WordNet hasta los corpus anotados manualmente. Cada clase\nde sistema de WSD junto con los recursos que utiliza requiere un\ncorpus de evaluaci\u00b4 on diferente. Por ejemplo, un corpus anotado\nen base a un diccionario particular no podr\u00b4 a ser utilizado por otro\nsistema que asigna los sentidos de otro diccionario distinto. Este\n64 3.1 Contexto del problema\ntipo de problemas derivan en una escasez de evaluaci\u00b4 on compara-\ntiva entre distintos sistemas.\nPara tratar de uni\ufb01car criterios de evaluaci\u00b4 on y establecer\nuna comparativa entre distintos sistemas siguiendo los mismos\nest\u00b4 andares, se cre\u00b4 o una competici\u00b4 on llamada Senseval (Evalua-\ntion Exercises for the Semantic Analysis of Text). Su primera\nedici\u00b4 on fue en 1998 donde se evaluaron distintos sistemas en dis-\ntintas lenguas: Ingl\u00b4 es, Franc\u00b4 es e Italiano. A partir de los resultados\nobtenidos y viendo el inter\u00b4 es creado tras la competici\u00b4 on, se han\nrealizado nuevas ediciones (cada 3 a\u02dc nos), para evaluar la evoluci\u00b4 on\nde los sistemas de desambiguaci\u00b4 on autom\u00b4 atica.\nA continuaci\u00b4 on se describir\u00b4 an las di\ufb01cultades para la evaluaci\u00b4 on\ny comparaci\u00b4 on de sistemas encontradas hasta la fecha y que han\ndado lugar a la organizaci\u00b4 on de Senseval .\n3.1.1 Mejoras en los criterios de evaluaci\u00b4 on\nPreviamente a Senseval la evaluaci\u00b4 on est\u00b4 andar de los siste-\nmas de desambiguaci\u00b4 on autom\u00b4 atica era un simple mapeo exacto\nentre la anotaci\u00b4 on obtenida por el sistema y los sentidos correctos.\nDe forma que la f\u00b4 ormula utilizada era la siguiente:\ncorrectas % = 100 \u00a3#sentidos anotados correctamente\n#sentidos anotados total(3.1)\nSin embargo, esta forma de evaluaci\u00b4 on no es del todo adecua-\nda teniendo en cuenta que un sistema puede devolver una pro-\nbabilidad distinta para cada uno de los sentidos de una palabra\npolis\u00b4 emica. Por ejemplo, considerando el siguiente fragmento:\n\u201c... bought an interest in Lydak Corp ...\u201d\nSupongamos que la palabra ambigua \u201cinterest\u201d es desambigua-\nda por cuatro sistemas distintos, los cuales, asignan las siguientes\nprobabilidades a los distintos sentidos de \u201cinterest\u201d (ver Tabla\n3.1).\nTal y como se aprecia en la Tabla 3.1, todos los sistemas selec-\ncionan el sentido incorrecto de \u201cinterest#1\u201d en lugar de \u201cinter-\nest#2\u201d . Sin embargo, el Sistema 1 es capaz de dar una probabili-\ndad bastante elevada para el sentido correcto #2. A pesar de ello,\n3. Problem\u00b4 atica en la evaluaci\u00b4 on de sistemas de WSD 65\nSentido\nSistema 1\nSistema 2\nSistema 3\nSistema 4\n#1 monetary (e.g. on a loan)\n47\n85\n28\n100\n#2 stake or share (correcto\n42\n5\n24\n0\n#3 bebe\ufb01t/advantage/sake\n6\n5\n24\n0\n#4 intellectual curiosity\n5\n5\n24\n0\nTabla 3.1. Distribuci\u00b4 on de probabilidades asignadas por diferentes sistemas\ncon la forma de evaluaci\u00b4 on dada en la Ecuaci\u00b4 on 3.1el Sistema 1\nse penaliza de igual forma que el resto de sistemas, a\u00b4 un teniendo\nen cuenta que ha sido capaz de predecir el sentido correcto con\nuna probabilidad bastante alta.\nPara evitar que los sistemas que obtienen distintas probabili-\ndades para los sentidos de una palabra se penalicen de igual forma\nque los que s\u00b4 olo seleccionan un \u00b4 unico sentido, se utiliza otro tipo\nde medida adaptable a todo tipo de sistemas: la entrop\u00b4 \u0131a cruzada.\nEn este caso, se eval\u00b4 ua la efectividad de las predicciones de un sis-\ntema con distintas probabilidades para los distintos sentidos. La\nf\u00b4 ormula de la entrop\u00b4 \u0131a cruzada es la siguiente:\nEntropia cruzada =\u00a11\nNNX\ni=1log2PrS(scijwi; context i) (3.2)\nDonde Nes el n\u00b4 umero de instancias de test y Prses la pro-\nbabilidad asignada por el sistema Sal sentido correcto scide la\npalabra wien el contexto context i. Mediante esta nueva forma de\nevaluaci\u00b4 on, los sistemas que asignen una probabilidad bastante\nelevada al sentido correcto, obtendr\u00b4 an mejores resultados que los\ndem\u00b4 as.\nLa entrop\u00b4 \u0131a cruzada como medida de evaluaci\u00b4 on es muy \u00b4 util\ncuando se tratan palabras con una distinci\u00b4 on de sentidos muy\n\ufb01na, donde es posible anotar varios sentidos y que todos se consi-\nderen correctos. Una variante de la f\u00b4 ormula de la entrop\u00b4 \u0131a cruzada\nser\u00b4 \u0131a utilizar la misma f\u00b4 ormula obviando el t\u00b4 ermino logar\u00b4 \u0131tmico\nquedando tal y como muestra la Ecuaci\u00b4 on 3.3.\n66 3.1 Contexto del problema\nEntropia cruzada adapt =1\nNNX\ni=1PrS(scijwi; context i) (3.3)\nEsta nueva medida puede ser utilizada por cualquier sistema,\nindependientemente de que asigne probabilidades a cada posible\nsentido o no. En el caso de sistemas que s\u00b4 olo dan como resultado\nun \u00b4 unico sentido, esta nueva f\u00b4 ormula es equivalente a la 3.1, que\n\u00b4 unicamente ten\u00b4 \u0131a en cuenta el sentido con mayor probabilidad.\n3.1.2 Distancia sem\u00b4 antica\nOtro problema en el proceso de evaluaci\u00b4 on de sistemas de de-\nsambiguaci\u00b4 on autom\u00b4 atica, es que muchas medidas de evaluaci\u00b4 on\nno tienen en cuenta la distancia sem\u00b4 antica entre sentidos a la ho-\nra de decidir si las palabras est\u00b4 an anotadas correctamente. Esta\nsituaci\u00b4 on es m\u00b4 as evidente cuando hablamos de jerarqu\u00b4 \u0131as de sen-\ntidos. La Tabla 3.2muestra un ejemplo de agrupaci\u00b4 on de sentidos\njer\u00b4 arquica para \u201cbank\u201d y su correspondiente matriz de distancia\nsem\u00b4 antica.\nI. Bank - Repository\nI.1 Financial bank\nI.1a I.1b I.2 II.1 II.2 III\nI.1a - the institution\nI.1a 0 1 2 4 4 4\nI.1b - the building\nI.1b 1 0 2 4 4 4\nI.2 General Supply/Reserve\nI.2 2 2 0 4 4 4\nII Bank - Geographical\nII.1 4 4 4 0 1 4\nII.1 Shoreline\nII.2 4 4 4 1 0 4\nII.2 Ridge/Embankment\nIII 4 4 4 4 4 0\nIII Bank - Array/Group/Row\nTabla 3.2. Jerarqu\u00b4 \u0131a de sentidos y matriz de distancia sem\u00b4 antica para \u201cbank\u201d\nSi en el proceso de anotaci\u00b4 on se produjera un error al anotar\nuna palabra con el sentido correspondiente a un hermano dentro\nde la jerarqu\u00b4 \u0131a de sentidos, la penalizaci\u00b4 on deber\u00b4 \u0131a ser m\u00b4 as baja\nque si ese error se debiera a una anotaci\u00b4 on entre sentidos que no\nest\u00b4 an relacionados de ninguna forma. La soluci\u00b4 on podr\u00b4 \u0131a ser em-\nplear una matriz que establezca la distancia sem\u00b4 antica entre sen-\n3. Problem\u00b4 atica en la evaluaci\u00b4 on de sistemas de WSD 67\ntidos de forma que cada celda ( sentido 1; sentido 2), contendr\u00b4 a el\nvalor de la distancia entre sentidos. Cuanto m\u00b4 as grande sea el va-\nlor de la celda, mayor ser\u00b4 a la distancia sem\u00b4 antica entre los sentidos\nque representa. En la parte derecha de la Tabla 3.2se muestra un\nejemplo de matriz de distancia sem\u00b4 antica para \u201cbank\u201d .\nUna forma de evaluar los sistemas usando distancias sem\u00b4 anti-\ncas es modi\ufb01cando la f\u00b4 ormula de la entrop\u00b4 \u0131a cruzada, de forma\nque se trate de minimizar la distancia entre el sentido asignado\n(sai) y el sentido correcto ( sci), sobre los Nejemplos, tal y como\nmuestra la Ecuaci\u00b4 on 3.4.\nEntropia cruzada dist =1\nNNX\ni=1Distancia (sci; sai) (3.4)\nAdem\u00b4 as de tratar de minimizar la distancia sem\u00b4 antica entre\nsentidos, tambi\u00b4 en se podr\u00b4 \u0131a medir la e\ufb01ciencia de los sistemas\npenalizando las probabilidades asignadas a sentidos incorrectos\nseg\u00b4 un la Ecuaci\u00b4 on 3.5.\nEficiencia dist =1\nNNX\ni=1SiX\nj=1Distancia (sci; sj)\u00a3PrS(sjjwi; context i)\n(3.5)\nDonde para cada ejemplo i, se consideran todos los posibles\nsentidos ( sj) de la palabra wi, midiendo las probabilidades que el\nsistema Sha asignado a sentidos incorrectos PrS(sjjwi; context i)\npor la distancia sem\u00b4 antica de estos sentidos respecto al sentido\ncorrecto.\nEn (Melamed y Resnik (2000 )) se propuso una variante de estas\nideas para Senseval , donde se utiliz\u00b4 o el diccionario HECTOR\n(Atkins (1992 )). La propuesta fue un esquema de distribuci\u00b4 on de\nprobabilidades a trav\u00b4 es de los distintos niveles de la jerarqu\u00b4 \u0131a de\nsentidos, donde adem\u00b4 as se pod\u00b4 \u0131an incluir como respuestas v\u00b4 alidas\nvarios sentidos.\nEnSenseval la evaluaci\u00b4 on de sistemas se ha hecho utilizando\ndiferentes pautas, variando el nivel de granularidad (sentidos de\n68 3.2 Un marco com\u00b4 un para la evaluaci\u00b4 on de sistemas\nbajo nivel frente a sentidos de alto nivel), etiquetaci\u00b4 on \u00b4 unica de\nsentidos y etiquetaci\u00b4 on m\u00b4 ultiple de sentidos. En la pr\u00b4 actica, la\nmayor\u00b4 \u0131a de sistemas que han participado en Senseval no obtie-\nnen un conjunto de probabilidades para todos los sentidos, por\nello, la evaluaci\u00b4 on normalmente se realiza utilizando la variante\nde la entrop\u00b4 \u0131a cruzada para un solo sentido seg\u00b4 un la Ecuaci\u00b4 on 3.3\ncomentada anteriormente.\n3.2 Un marco com\u00b4 un para la evaluaci\u00b4 on de\nsistemas\nComo ya se ha comentado en el cap\u00b4 \u0131tulo anterior, los sistemas\nde WSD supervisados y no supervisados tienen diferentes necesi-\ndades en cuanto a recursos necesarios para su evaluaci\u00b4 on. A pesar\nde que los sistemas no supervisados pueden ser evaluados con\nun corpus etiquetado como Semcor, que contiene una gran canti-\ndad de palabras polis\u00b4 emicas, los sistemas supervisados necesitan\nde corpus m\u00b4 as extensos para realizar su correspondiente entrena-\nmiento y evaluaci\u00b4 on. Para establecer una gu\u00b4 \u0131a de las necesidades\ntanto de sistemas supervisados como de sistemas no supervisa-\ndos se ha desarrollado un protocolo utilizado en Senseval con\nalgunas modi\ufb01caciones:\n1.Obtener un corpus extenso sin anotar (Por ejemplo, de N=1\nbill\u00b4 on de palabras).\n2.Determinar el repositorio de sentidos a utilizar (WordNet,\nLDOCE) y sobre el cual se evaluar\u00b4 an los distintos sistemas.\n3.Seleccionar un subconjunto de palabras R < N (por ejemplo,\n100 millones) en un corpus no anotado y proporcionarlo a los\nparticipantes.\n4.Seleccionar un peque\u02dc no subconjunto de palabras S < R < N\n(por ejemplo, 10 millones), como conjunto de test. Generar el\ntest como sigue: (a) Seleccionar un conjunto M(por ejemplo,\n100) palabras ambiguas. Estas palabras ser\u00b4 an la base para la\nevaluaci\u00b4 on y no ser\u00b4 an reveladas hasta el momento de distribuir\nel corpus de test. (b) Para cada una de las Mpalabras, anotar\n3. Problem\u00b4 atica en la evaluaci\u00b4 on de sistemas de WSD 69\ntodas las instancias de cada palabra en el corpus de test. (c)\nPara cada una de las Mpalabras, evaluar la anotaci\u00b4 on hecha\npor diferentes anotadores y establecer un acuerdo. (d) Para\ncada una de las Mpalabras, estudiar los casos en los que los\nanotadores no se ponen de acuerdo y tomar una decisi\u00b4 on, por\nvotaci\u00b4 on si fuera necesario.\n5.Advertir a los participantes de no modi\ufb01car el c\u00b4 odigo de sus\nsistemas a partir de este punto.\n6.Proporcionar a cada participante el corpus de test.\n7.Evaluar cada sistema considerando todas las instancias de las\nMpalabras anotadas para la evaluaci\u00b4 on. Comparar anotacio-\nnes de sentidos exactas, entrop\u00b4 \u0131a cruzada, etc.\n8.Almacenar el corpus utilizado como test para que sea emplea-\ndo por sistemas de WSD supervisados. A partir de este punto\npodr\u00b4 an participar utilizando el corpus de test como corpus de\nentrenamiento.\n9.Para la siguiente evaluaci\u00b4 on de sistemas ir al paso 3.\nConcretamente en Senseval se adoptaron algunos aspectos\nde este protocolo. El corpus del Paso 1 fueron 17 millones de pa-\nlabras extra\u00b4 \u0131das del British National Corpus1, que hasta ahora ha\nido increment\u00b4 andose hasta 100 millones de palabras. El reposito-\nrio de sentidos seleccionado del Paso 2 fue la base de datos HEC-\nTOR ( Senseval-1 . Como el proceso de evaluaci\u00b4 on inclu\u00b4 \u0131a tanto\nsistemas supervisados como no supervisados, los corpus de entre-\nnamiento incluyeron tanto instancias anotadas como no anotadas\n(al contrario que en el Paso 3), para un conjunto de 29 palabras\nambiguas. Para el proceso de creaci\u00b4 on del corpus de test del Paso\n4, se seleccionaron 34 palabras ambiguas distribuidas en 8448 ins-\ntancias. Los participantes fueron advertidos de no modi\ufb01car sus\nsistemas tal y como estaba especi\ufb01cado en el Paso 5.\nLa gran diferencia con el protocolo seguido en Senseval fue\ncon respecto a los Pasos 6 y 7, donde los participantes no sab\u00b4 \u0131an\nqu\u00b4 e palabras iban a ser utilizadas para la evaluaci\u00b4 on. Por ello, se\nhicieron dos grupos, uno para evaluar a los sistemas que s\u00b4 olo de-\nsambiguaron las palabras del conjunto de test, y otro con los siste-\n1http://www.natcorp.ox.ac.uk/\n70\nmas que desambiguaron todas las palabras con contenido sem\u00b4 anti-\nco.\nLos resultados obtenidos indicaron que los sistemas m\u00b4 as e\ufb01-\ncientes eran aquellos que utilizaban corpus de entrenamiento para\naprender clasi\ufb01cadores especialmente dise\u02dc nados para las palabras\ndel corpus de test.\nEn el Cap\u00b4 \u0131tulo 6 se describen en profundidad todas las edicio-\nnes de Senseval hasta la actualidad y algunos de los sistemas\nm\u00b4 as relevantes en la tarea de WSD.\nCap\u0013\u0010tulo 4\nRecursos\nA continuaci\u00b4 on se van a describir los recursos utilizados como\nbase para el desarrollo de nuestros m\u00b4 etodos de desambiguaci\u00b4 on y\npara la creaci\u00b4 on del nuevo recurso l\u00b4 exico Dominios Relevantes. La\nelecci\u00b4 on de estos recursos se debe al conjunto de caracter\u00b4 \u0131sticas\n(relaciones sem\u00b4 anticas entre palabras, conexi\u00b4 on con varios idio-\nmas, adquisici\u00b4 on de conocimiento a trav\u00b4 es de relaciones entre pa-\nlabras, etc) que los hacen id\u00b4 oneos para la tarea de WSD.\n4.1 WordNet\nWordNet ( Fellbaum (1998 )) fue concebido como un dicciona-\nrio electr\u00b4 onico siguiendo principios psicoling\u00a8 u\u00b4 \u0131sticos. Su contenido\nse organiza mediante una base de datos l\u00b4 exica donde se agrupan\nconjuntos de palabras (nombres, verbos, adjetivos y adverbios) en\ngrupos de sin\u00b4 onimos llamados synsets: un synset se codi\ufb01ca co-\nmo un n\u00b4 umero \u00b4 unico de ocho d\u00b4 \u0131gitos. Dentro de la base de datos,\ncada synset representa un concepto distinto y entre cada uno de\nellos existen conexiones que expresan relaciones sem\u00b4 anticas, con-\nceptuales o l\u00b4 exicas. El resultado de este conjunto de conexiones\nes una extensa red navegable que proporciona un gran n\u00b4 umero de\ninter-relaciones entre palabras. Entre este conjunto de relaciones\nencontramos las siguientes:\n72 4.1 WordNet\nSinonimia. Dentro de la misma categor\u00b4 \u0131a sint\u00b4 actica (nombre,\nverbo, adjetivo o adverbio), son sin\u00b4 onimas aquellas palabras\nque pueden sustituirse dentro de un contexto determinado sin\nalterar su signi\ufb01cado. Por ejemplo, en las frases: \u201cMe pas\u00b4 o una\nhoja en blanco\u201d y \u201cMe pas\u00b4 o un folio en blanco\u201d. Las palabras\n\u201choja\u201d y \u201cfolio\u201d son sin\u00b4 onimas porque al sustituir una por la\notra no se altera el signi\ufb01cado de la frase.\nSin\u00b4 onimos para \u201cbank#1\u201d8\n>>>>>>>><\n>>>>>>>>:depository \ufb01nancial institution#1\nbanking concern#1\nbanking company#1\n\ufb01nancial institution#1\n\ufb01nancial organization#1\n\ufb01nancial organisation#1\nAntonimia. Son ant\u00b4 onimas aquellas palabras con signi\ufb01ca-\ndos opuestos. Por ejemplo: seco/mojado, subir/bajar, avan-\nzar/retroceder . . .\nAnt\u00b4 onimos para \u201cclean#1\u201d8\n>>>>>>>><\n>>>>>>>>:dirty#1\nsoil#1\nbegrime#1\ngrime#1\ncolly#1\nbemire#1\nHiponimia. Mientras que la sinonimia y la antonimia son rela-\nciones l\u00b4 exicas entre palabras, la hiponimia es una relaci\u00b4 on en-\ntre los signi\ufb01cados de las palabras. Estas relaciones se dan \u00b4 uni-\ncamente para los nombres. Por ejemplo: \u201carce\u201d es un hip\u00b4 onimo\nde \u201c\u00b4 arbol\u201d y \u201c\u00b4 arbol\u201d es un hip\u00b4 onimo de \u201cplanta\u201d. Este tipo\nde relaci\u00b4 on se conoce tambi\u00b4 en con el nombre de \u201cIS\nA\u201d. Se\nentiende que \u201cX\u201d es un hip\u00b4 onimo de \u201cY\u201d si \u201cX es un (tipo\nde) Y\u201d .\n4. Recursos 73\nHip\u00b4 onimos para \u201ccat#1\u201d8\n>>>>>><\n>>>>>>:domestic cat#1\nhouse cat#1\nFelis domesticus#1\nFelis catus#1\nwildcat#3\nHiperonimia. Esta relaci\u00b4 on se de\ufb01ne como la inversa de la hi-\nponimia. Es decir, Y es un hiper\u00b4 onimo de X si \u201cX es un\n(tipo de) Y\u201d .\nHiper\u00b4 onimos para \u201dcat#1\u201c8\n>>>>>>>>>>>>>>>>>><\n>>>>>>>>>>>>>>>>>>:feline#1\nfelid#1\ncarnivore#1\nplacental#1\nplacental mammal#1\neutherian#1\neutherian mammal#1\nmammal#1\nmammalian#1\nvertebrate#1\nMeronimia. La sinonimia, antonimia, hiponimia e hiperoni-\nmia son relaciones aplicadas com\u00b4 unmente. Otra relaci\u00b4 on sem\u00b4 anti-\nca es la meronimia, identi\ufb01cada como un tipo de v\u00b4 \u0131nculo\n\u201cHAS\nA\u201d. Una palabra X es mer\u00b4 onima de Y si \u201c X es una\nparte de Y \u201d . Por ejemplo, p\u00b4 arpado, retina o c\u00b4 ornea son\nmer\u00b4 onimos de ojo, porque todos son partes del ojo.\n74 4.1 WordNet\nMer\u00b4 onimos para \u201cbody#1\u201d8\n>>>>>>>>>>>>><\n>>>>>>>>>>>>>:articulatory system#1\ndigestive system#1\ngastrointestinal system#1\nendocrine system#1\nlymphatic system#1\nmusculoskeletal system#1\nsensory system#2\ntrunk#3\nHolonimia. Esta relaci\u00b4 on se de\ufb01ne como la inversa de la mero-\nnimia. Es decir, Y es un hol\u00b4 onimo de X si \u201c X es una parte\nde Y \u201d . Por ejemplo, \u201ccasa\u201d es un hol\u00b4 onimo de \u201cdormitorio\u201d,\n\u201ccomedor\u201d, \u201ccocina\u201d, etc.\nHol\u00b4 onimos para \u201ceye#1\u201d8\n><\n>:visual system#1\nface#1\nhuman face1#1\nTroponimia. La troponimia relaciona verbos y es el equivalen-\nte de la relaci\u00b4 on de hiponimia para los nombres.\nTrop\u00b4 onimos para \u201ceat#1\u201d8\n>>>>>>>>>>><\n>>>>>>>>>>>:wash down#1\ngluttonize#1\ngluttonise#1\nfress#1\nwolf#1\nslurp#1\nfare#2\nEntailment. En esta relaci\u00b4 on un t\u00b4 ermino implica al otro. Por\nejemplo, divorcio/matrimonio.\n4. Recursos 75\nEntailment para \u201ceat#1\u201d8\n>>>>>>>><\n>>>>>>>>:chew#1\nmasticate#2\nmanducate#1\njaw#3\nswallow#1\nget down#4\nAdem\u00b4 as de distinguir mediante synsets los signi\ufb01cados de ca-\nda t\u00b4 ermino, WordNet establece una relaci\u00b4 on de orden entre los\ndiferentes sentidos de las palabras, de acuerdo a su frecuencia de\naparici\u00b4 on. De esta forma, para \u201cplant\u201d en la versi\u00b4 on 2.1 existen\ncuatro signi\ufb01cados diferentes:\n1.f03912097 gplant#1, works#1, industrial plant#1 \u2013 (buil-\ndings for carrying on industrial labor; \u201cthey built a large plant\nto manufacture automobiles\u201d)\n2.f00016858 gplant#2, \ufb02ora#2, plant life#1 \u2013 (a living orga-\nnism lacking the power of locomotion)\n3.f05831211 gplant#3 \u2013 (something planted secretly for disco-\nvery by another; \u201cthe police used a plant to trick the thieves\u201d;\n\u201che claimed that the evidence against him was a plant\u201d)\n4.f10282477 gplant#4 \u2013 (an actor situated in the audience\nwhose acting is rehearsed but seems spontaneous to the audien-\nce)\nCada concepto asociado al t\u00b4 ermino \u201cplant\u201d adem\u00b4 as de tener\nasociado su synset, tambi\u00b4 en tiene asociado un n\u00b4 umero de sentido:\nplant#1, plant#2, plant#3 yplant#4 , estos sentidos indican la\nfrecuencia de aparici\u00b4 on de cada concepto, siendo plant#1 el m\u00b4 as\nfrecuente.\nEstrechamente vinculada a cada synset existe una de\ufb01nici\u00b4 on o\nglosa que de\ufb01ne el concepto representado por el sentido espec\u00b4 \u0131\ufb01co\nde cada t\u00b4 ermino. As\u00b4 \u0131 para plant#1 su glosa asociada es \u201cbuil-\ndings for carrying on industrial labor\u201d . Adem\u00b4 as, en la mayor\u00b4 \u0131a de\nt\u00b4 erminos (synsets), se sit\u00b4 ua la palabra en un contexto (oraci\u00b4 on),\n76 4.1 WordNet\nejempli\ufb01cando de esta forma su uso: \u201cthey built a large plant to\nmanufacture automobiles\u201d .\nLos conceptos situados en lo alto de la jerarqu\u00b4 \u0131a de WordNet\nde los que derivan el resto de conceptos, son los mostrados en la\nTabla 4.1.\nConcepto\nDe\ufb01nici\u00b4 on\nentity\nthat which is perceived or known or inferred to have its own\ndistinct existence (living or nonliving)\npsychological\nfeature\na feature of the mental life of a living organism\nabstraction\na general concept formed by extracting common features\nfrom speci\ufb01c examples\nstate\nthe way something is with respect to its main attributes;\n\u201cthe current state of knowledge\u201d; \u201chis state of health\u201d; \u201cin\na weak \ufb01nancial state\u201d\nevent\nsomething that happens at a given place and time\nact, human\naction, human\nactivity\nsomething that people do or cause to happen\ngroup, grou-\nping\nany number of entities (members) considered as a unit\npossession\nanything owned or possessed\nphenomenon\nany state or process known through the senses rather than\nby intuition or reasoning\nTabla 4.1. Conceptos en la cima de la jerarqu\u00b4 \u0131a de WordNet\nEn la Figura 4.1tenemos una representaci\u00b4 on de la red sem\u00b4 anti-\nca para la palabra \u201caircraft\u201d con sentido 1. En esta imagen se pue-\nde observar la extensi\u00b4 on de las diferentes dimensiones que puede\ntener un concepto en WordNet.\nOtro ejemplo de las relaciones sem\u00b4 anticas existentes en Word-\nNet lo encontramos en la Figura 4.2, donde se muestra un extracto\nde la relaciones existentes para \u201cbank#1\u201d .\nComo se puede apreciar en la Figura 4.2, para bank#1 exis-\nten una serie de sin\u00b4 onimos: banking\ncompany, banking\nconcern y\ndepository\n\ufb01nantial\ninstitution . As\u00b4 \u0131 como una serie de hip\u00b4 onimos\nrepresentados mediante \ufb02echas de color verde, mer\u00b4 onimos repre-\n4. Recursos 77\nFigura 4.1. Red sem\u00b4 antica para airplane#1\nsentados mediante \ufb02echas de color amarillo y hol\u00b4 onimos represen-\ntados mediante \ufb02echas de color morado.\nUna representaci\u00b4 on m\u00b4 as detallada de esta versi\u00b4 on gr\u00b4 a\ufb01ca de las\nrelaciones existentes para bank#1 se muestra en la Tabla 4.2.\n4.2 WordNet Domains\nWordNet Domains extiende la informaci\u00b4 on proporcionada por\nWordNet mediante la inclusi\u00b4 on de \u201cSubject Field Codes\u201d (SFC) ,\nes decir, conjuntos de palabras relevantes para un dominio es-\npec\u00b4 \u0131\ufb01co. Una representaci\u00b4 on de este tipo de informaci\u00b4 on la encon-\ntramos en las etiquetas de campo sem\u00b4 antico, de uso com\u00b4 un en to-\ndo tipo de diccionarios, por ejemplo: Matem \u0013aticas ,Bot\u0013anica ,\netc. Por un lado, estas etiquetas clari\ufb01can a qu\u00b4 e contexto se re\ufb01ere\nla de\ufb01nici\u00b4 on que sigue, por ejemplo, la palabra \u201canillo\u201d , pertene-\nce a diferentes contextos, tales como, Arquitectura \u201cCornisa\ncircular u ovalada\u201d, Bot\u0013anica \u201cCada uno de los c\u00b4 \u0131rculos le\u02dc nosos\n78 4.2 WordNet Domains\nFigura 4.2. Relaciones sem\u00b4 anticas para bank#1\n4. Recursos 79\nRelaciones\nPalabras\nGlosa\nSin\u00b4 onimos\nDepository\n\ufb01nancial\ninstitution\nBank\nBanking\nconcern\nBanking\ncompany\nA \ufb01nancial institution that accepts de-\nposits and channels the money into len-\nding activities; \u201che cashed a check at the\nbank\u201d; \u201cthat bank holds the mortgage\non my home\u201d\nHip\u00b4 onimos\nCredit\nunion\nA cooperative depository \ufb01nancial insti-\ntution whose members can obtain loans\nfrom their combined savings\nHome\nLoan\nBank\nOne of 11 regional banks that monitor\nand make short-term credit advances to\nthrift institutions in their region\nFederal\nReserve\nBank\nOne of 12 regional banks that monitor\nand act as depositories for banks in their\nregion\nMember\nbank\nA bank that is a member of the Federal\nReserve System\nAgent\nbank\nA bank that acts as an agent for a fo-\nreign bank\nCommercial\nbank\nA \ufb01nancial institution that accepts de-\nmand deposits and makes loans and pro-\nvides other services for the public\n. . .\n. . .\nMer\u00b4 onimos\nFinancial\ninstitution\nan institution (public or private) that\ncollects funds (from the public or other\ninstitutions) and invests them in \ufb01nan-\ncial assets)\nHol\u00b4 onimos\nBanking\nindustry\nbanks collectively\nTabla 4.2. Relaciones existentes para bank#1\nconc\u00b4 entricos que forman el tronco de un \u00b4 arbol\u201d y Matem \u0013aticas\n\u201cConjunto de elementos entre los que se de\ufb01nen dos reglas de\ncomposici\u00b4 on\u201d. Por otro lado, estas etiquetas permiten la b\u00b4 usque-\nda r\u00b4 apida de la acepci\u00b4 on deseada, por ejemplo, si buscamos el\nsigni\ufb01cado de \u201cdisco\u201d dentro del contexto de la Inform \u0013atica no\nes necesario ir leyendo todas las acepciones una por una hasta dar\ncon la que deseamos, simplemente basta con mirar la etiqueta del\ncampo sem\u00b4 antico que precede a cada de\ufb01nici\u00b4 on hasta dar con la\nque nos interesa, en este caso, Inform \u0013atica .\nDada su utilidad, los SFC ya han sido usados en Ling\u00a8 u\u00b4 \u0131stica\ny en Lexicograf\u00b4 \u0131a para marcar los usos t\u00b4 ecnicos de las palabras.\nAunque \u00b4 esta es una informaci\u00b4 on muy \u00b4 util para establecer una\n80 4.2 WordNet Domains\ndiscriminaci\u00b4 on de sentidos, en los diccionarios generalmente se\nemplea s\u00b4 olo para una peque\u02dc na parte del l\u00b4 exico. Un ejemplo lo\ntenemos en la entrada para la palabra \u201cbolsa\u201d , (Tabla 4.3), en el\nDiccionario de la Lengua de la Real Academia Espa\u02dc nola (R.A.E).\nDe\ufb01niciones de la palabra Bolsa en el R.A.E.\n1.f. Especie de talega o saco de tela u otro material, que sirve para llevar o\nguardar algo.\n2.f. Saco peque\u02dc no de cuero en que se echa dinero, y que se ata o cierra.\n3.f. Recipiente de material resistente para guardar, en viajes o traslados, ropa\nu otras cosas, y que se puede llevar a mano o colgado del hombro. Bolsa de\ndeporte.\n4.f.folgo.\n5.f. Arruga que hace un vestido cuando viene ancho o no ajusta bien al cuerpo,\no la que forman dos telas cosidas cuando una es m\u00b4 as larga o ha dado de s\u00b4 \u0131 m\u00b4 as\nque la otra.\n6.f. Abultamiento de la piel debajo de los ojos.\n7.f. Acumulaci\u00b4 on de un \ufb02uido en un determinado lugar.\n8.f. Caudal o dinero de una persona. A Juan se le acab\u00b4 o la bolsa.\n9.f. Pieza de estera en forma de saco, que pende entre los varales del carro o\ngalera, y debajo de la zaga de los coches o calesas, para colocar efectos.\n10.f. Taleguilla de tafet\u00b4 an o moar\u00b4 e negro con una cinta en la parte superior que\nusaban los hombres para llevar recogido el pelo.\n11.f.Dep. Premio en met\u00b4 alico que recibe el ganador de un combate de boxeo.\n12.f.Dep. Cantidad que se ofrece a quien participa en otras competiciones.\n13.f.Ingen. Parte de un criadero donde el mineral est\u00b4 a reunido con mayor\nabundancia.\n14.f.Med. Cavidad llena de pus, linfa, etc.\n15.f.Mil.Situaci\u00b4 on en que queda un ej\u00b4 ercito o una parte de \u00b4 el al ser comple-\ntamente rodeado por las fuerzas enemigas.\n16.f.Am. Cen. yM\u00b4 ex. Bolsillo de las prendas de vestir.\n17.f. pl. Cavidades del escroto en las cuales se alojan los test\u00b4 \u0131culos.\n18.f. pl. u. c. sing. m. vulg. Ven. Persona imb\u00b4 ecil, lerda.\nTabla 4.3. De\ufb01niciones para la palabra \u201cbolsa\u201d del RAE\nCon el \ufb01n incorporar la informaci\u00b4 on de las etiquetas sem\u00b4 anticas\na WordNet se construy\u00b4 o un nuevo recurso llamado WordNet Do-\nmains ( Magnini y Cavaglia (2000 )). Mediante WordNet Domains\nse pretend\u00b4 \u0131a mejorar la distinci\u00b4 on de los sentidos en WordNet,\nagrupando en muchos casos distintos sentidos bajo un mismo do-\nminio o categor\u00b4 \u0131a sem\u00b4 antica.\n4. Recursos 81\nMediante WordNet Domains, se intenta extender la cobertura\nde las etiquetas de dominio, dentro de una base de datos l\u00b4 exi-\nca ya existente: WordNet. En WordNet Domains los synsets de\nWordNet han sido anotados mediante un proceso semiautom\u00b4 atico\ncon una o varias etiquetas de dominio, seleccionadas de entre un\nconjunto de 200 etiquetas organizadas jer\u00b4 arquicamente.\nLa anotaci\u00b4 on de WordNet mediante SFC\u2019s viene motivada por:\nCrear nuevas relaciones entre palabras. Mediante las eti-\nquetas de dominio se pueden establecer relaciones entre pala-\nbras que pertenecen a distintas categor\u00b4 \u0131as, ya que, por ejem-\nplo, en WordNet1.61, no encontramos relaciones entre nom-\nbres y verbos.\nAnotar a nivel sem\u00b4 antico. Debido a que los dominios se aso-\ncian a synsets, la anotaci\u00b4 on se realiza a nivel sem\u00b4 antico y no\na nivel de palabra.\nObtener recursos multiling\u00a8 ues. LosSFC\u2019s son b\u00b4 asicamen-\nte independientes del lenguaje, por lo que se pueden incluir\nen recursos multiling\u00a8 ues tales como, EuroWordNet ( Vossen\n(1998 )).\nLa informaci\u00b4 on aportada por los SFC\u2019s es complementaria a\nla informaci\u00b4 on que tiene WordNet. La primera caracter\u00b4 \u0131stica que\na\u02dc naden a WordNet es que dentro de un mismo dominio pueden\nincluirse synsets que pertenecen a diferentes categor\u00b4 \u0131as sint\u00b4 acticas.\nPor ejemplo, con el dominio Music se han anotado pala-\nbras pertenecientes a diferentes categor\u00b4 \u0131as sint\u00b4 acticas, tal como\nse muestra en la Tabla 4.4.\nUna segunda caracter\u00b4 \u0131stica que aportan los dominios a Word-\nNet es que dentro de un mismo dominio pueden aparecer sentidos\nde palabras pertenecientes a diferentes subjerarqu\u00b4 \u0131as de WordNet,\nes decir, descendientes de diferentes ra\u00b4 \u0131ces o de diferentes \ufb01cheros\nlexicogr\u00b4 a\ufb01cos. Por ejemplo, el dominio Sport contiene sentidos\ncomo athlete#1 , que deriva de life\nform#1 ,game\nequipment#1 ,\nderivado de physical\nobject#1 ,sport#1 derivado de act#2 ypla-\nying\n\ufb01eld#1 , derivado de location#1 .\n1En la versi\u00b4 on 2.0. ya se pueden establecer este tipo de relaciones\n82 4.2 WordNet Domains\nDominio Music\nCategor\u00b4 \u0131a\nPalabras\nGlosas\nNombres\nalbum#1\none or more phonograph records or tape recor-\ndings issued together\nband#2\ninstrumentalists not including string players\nbar#3\nnotation for a repeating pattern of musical beats;\nwritten followed by a vertical bar\nVerbos\ncompose#2\nwrite music; \u201dBeethoven composed nine sympho-\nnies\u201d\ndrum#2\nplay the drums\nmodulate#1\nchange the key of, in music; \u201cmodulate the me-\nlody\u201d\nAdjetivos\nbowed#2\n(music) of a stringed instrument; sounded by stro-\nking with a bow\nchromatic#1\n(music) based on a scale consisting of 12 semito-\nnes; \u201ca chromatic scale\u201d\nAdverbios\nfugally#1\n(music) in a fugal style\npresto#2\n(music) at a very fast tempo (faster than allegro)\nTabla 4.4. Relaciones entre diferentes categor\u00b4 \u0131as sint\u00b4 acticas mediante el uso de\ndominios.\nLa tercera y \u00b4 ultima caracter\u00b4 \u0131stica que a\u02dc naden los dominios a\nWordNet, es la posibilidad de reducir el nivel de polisemia de\nlas palabras, es decir, dentro de un mismo dominio se pueden\nagrupar diferentes sentidos pertenecientes a una misma palabra.\nPor ejemplo, los dominios asociados a la palabra \u201cman\u201d , que en\nWordNet tiene 10 sentidos, son los que se muestran en la Tabla\n4.5.\nSi se anotan los sentidos utilizando dominios tal y como apa-\nrecen en la Tabla 4.5, se puede reducir el nivel de polisemia de 10\nsentidos a 4 sentidos, agrupando aquellos sentidos que pertenecen\na un mismo dominio. En este caso, se agrupar\u00b4 \u0131an dentro de un\n\u00b4 unico sentido todos aquellos conceptos pertenecientes al dominio\nPerson :\nman#1,3,5,6,7,8,9 )Person\nman#2 )Military\nman#4 )Factotum\nman#10 )Play\n4. Recursos 83\nPalabra\nDominio\nGlosa\nman#1\nperson\nan adult male person (as opposed to a woman);\n\u201cthere were two women and six men on the bus\u201d\nman#2\nmilitary\nsomeone who serves in the armed forces; \u201ctwo men\nstood sentry duty\u201d\nman#3\nperson\nthe generic use of the word to refer to any human\nbeing; \u201cit was every man for himself\u201d\nman#4\nfactotum\nall of the inhabitants of the earth; \u201call the world\nloves a lover\u201d\nman#5\nbiology, person\nany living or extinct member of the family Homi-\nnidae\nman#6\nperson\na male subordinate; \u201cthe chief stationed two men\noutside the building\u201d; \u201che awaited word from his\nman in Havana\u201d\nman#7\nperson\nan adult male person who has a manly character\n(virile and courageous competent); \u201cthe army will\nmake a man of you\u201d\nman#8\nperson\n(informal) a male person who plays a signi\ufb01cant\nrole (husband or lover or boyfriend) in the life of\na particular woman; \u201cshe takes good care of her\nman\u201d\nman#9\nperson\na manservant who acts as a personal attendant to\nhis employer; \u201cJeeves was Bertie Wooster\u2019s man\u201d\nman#10\nplay\na small object used in playing certain board ga-\nmes; \u201che taught me to set up the men on the chess\nboard\u201d; \u201che sacri\ufb01ced a piece to get a strategic ad-\nvantage\u201d\nTabla 4.5. Reducci\u00b4 on de la polisemia mediante el uso de dominios\nLos dominios se han estructurado desde dos puntos de vista\ndiferentes: jer\u00b4 arquicamente y sem\u00b4 anticamente.\nEstructuraci\u00b4 on jer\u00b4 arquica. En la jerarqu\u00b4 \u0131a de dominios en-\ncontramos diferentes niveles de especi\ufb01caci\u00b4 on. Por ejemplo,\ndentro del nivel 1 podemos encontrar dominios de tipo Bo-\ntany, Linguistics, History y Religion . Sin embargo,\ndentro del nivel 2 encontramos dominios de tipo Building\nIndustry,\nDentistry, Football y Photography . Cuanto m\u00b4 as pro-\nfundizamos es los niveles de la jerarqu\u00b4 \u0131a, mayor es el nivel de\nespecializaci\u00b4 on de los dominios.\nEn la \ufb01gura 4.3se muestra un peque\u02dc no fragmento de la jerar-\nqu\u00b4 \u0131a de WordNet Domains.\n84 4.2 WordNet Domains\n \nDoctrines Archaeology \nAstrology \nHistory Heraldry \nLinguistics Grammar \nPsychology Psychoanalysis \nArt Dance \nDrawing Painting \nPhilately \nMusic \nPhotography \nPlastic_arts Jewellery \nNumismatics \nSculpture \nTheatre \nReligion Mythology \nOccultism \nRoman_catholic \nTheology \nFigura 4.3. Jerarqu\u00b4 \u0131a de WordNet Domains\n4. Recursos 85\nEstructuraci\u00b4 on sem\u00b4 antica. Adem\u00b4 as de la estructuraci\u00b4 on jer\u00b4 arqui-\nca, los dominios se organizan en familias. Una familia es un\nconjunto de dominios sem\u00b4 anticamente relacionados entre los\nque no existen relaciones de inclusi\u00b4 on. Mientras que la organi-\nzaci\u00b4 on jer\u00b4 arquica es \ufb01ja, la organizaci\u00b4 on por familias se puede\nreorganizar permitiendo la creaci\u00b4 on de nuevas relaciones in-\nterdisciplinarias.\nEntre el conjunto de SFC\u2019s encontramos una etiqueta de do-\nminio denominada Factotum . Este dominio se ha creado exclu-\nsivamente para englobar dos tipos de synsets:\nSynsets gen\u00b4 ericos. Estos synsets son aquellos que dif\u00b4 \u0131cilmen-\nte se pueden clasi\ufb01car dentro de alg\u00b4 un dominio en particular.\nPor ejemplo: act#2: something that people do or cause to hap-\npen act#5: a manifestation of insincerity; \u201dhe put on quite an\nact for her bene\ufb01t\u201d\nStop senses. Son aquellos synsets que aparecen frecuentemen-\nte en diferentes contextos, tales como n\u00b4 umeros, d\u00b4 \u0131as de la se-\nmana, colores, etc. Estos synsets pertenecen normalmente a\npalabras monos\u00b4 emicas.\nEl proceso de anotaci\u00b4 on de los synsets de WordNet1.6 mediante\nSFC\u2019s se divide en tres pasos:\nPaso 1. Un n\u00b4 umero reducido de synsets pertenecientes a los\nniveles m\u00b4 as altos de la jerarqu\u00b4 \u0131a de WordNet son anotados\nmanualmente mediante los SFC\u2019s.\nPaso 2. A partir de la anotaci\u00b4 on obtenida en el paso 1, se ejecu-\nta un proceso autom\u00b4 atico que explota las relaciones de Word-\nNet (hiponimia, troponimia, meronimia, antonimia, etc), para\nextender la anotaci\u00b4 on manual a todos aquellos synsets alcan-\nzables.\nPaso 3. El \u00b4 ultimo paso es realizar la evaluaci\u00b4 on de los resul-\ntados obtenidos por el proceso autom\u00b4 atico. Las anotaciones\nerr\u00b4 oneas son detectadas, se corrigen y se vuelve a lanzar el\nproceso del paso 2 a partir de los nuevos valores.\n86 4.3 Extended WordNet\n4.3 Extended WordNet\nExtended WordNet ( Harabagiu et al. (1999 )) es un nuevo re-\ncurso l\u00b4 exico creado en la Universidad de Texas que trata de me-\njorar la informaci\u00b4 on proporcionada por WordNet en sus distintas\nversiones, agregando informaci\u00b4 on sem\u00b4 antica a las glosas. Esta nue-\nva informaci\u00b4 on se extrae \u00b4 unicamente de la parte de la de\ufb01nici\u00b4 on\nde las glosas, descartando los ejemplos y las aclaraciones entre\npar\u00b4 entesis que puedan aparecer. Por ejemplo, pensemos en la glo-\nsa de la palabra \u201cman\u201d :an adult male person who has a manly\ncharacter (virile and courageous competent); \u201cthe army will make\na man of you\u201d . En este caso, \u00b4 unicamente se tendr\u00b4 \u0131a en cuenta la\ninformaci\u00b4 on proporcionada en la de\ufb01nici\u00b4 on \u201can adult male per-\nson who has a manly character\u201d , omitiendo la aclaraci\u00b4 on entre\npar\u00b4 entesis y la frase de ejemplo para este sentido.\nPara ampliar y mejorar la informaci\u00b4 on proporcionada por\nWordNet se realizan tres tipos de an\u00b4 alisis diferentes sobre las glo-\nsas:\nAn\u00b4 alisis sint\u00b4 actico. Para obtener el an\u00b4 alisis sint\u00b4 actico de las\nglosas se ha utilizado una versi\u00b4 on mejorada del etiquetador\nde Brill ( Brill (1995 )). Esta nueva versi\u00b4 on ha sido entrenada\nsobre WordNet. El resultado obtenido (palabras con su cate-\ngor\u00b4 \u0131a sint\u00b4 actica, g\u00b4 enero, n\u00b4 umero,...), se utiliza como entrada\npara dos tipos distintos de analizadores sint\u00b4 acticos. Estos ana-\nlizadores se integran en un esquema de votaci\u00b4 on para tratar\nde mejorar la calidad de los resultados. Aunque este an\u00b4 ali-\nsis sint\u00b4 actico, se podr\u00b4 \u0131a haber aplicado directamente sobre las\nglosas de WordNet sin un preproceso inicial, se consider\u00b4 o ne-\ncesario un tratamiento previo de las glosas para obtener unos\nresultados m\u00b4 as precisos. Este tratamiento previo consiste en\nextender el contenido de las glosas de la siguiente forma:\n\u00b2Adverbios. Las glosas pertenecientes a adverbios se extien-\nden a\u02dc nadiendo (el adverbio + is) al principio de la glosa y\nun punto al \ufb01nal de la de\ufb01nici\u00b4 on. Por ejemplo, para el ad-\nverbio \u201centirely\u201d su glosa quedar\u00b4 \u0131a como sigue: entirely is\nwithout any others being included or involved .\n4. Recursos 87\n\u00b2Adjetivos. Las glosas pertenecientes a adjetivos se extien-\nden a\u02dc nadiendo (el adjetivo + is something ) al principio de la\nglosa y un punto al \ufb01nal de la de\ufb01nici\u00b4 on. Por ejemplo, para\nel adjetivo \u201cin\ufb01nite\u201d su glosa quedar\u00b4 \u0131a como sigue: in\ufb01nite\nis something total and all-embracing .\n\u00b2Verbos. Las glosas pertenecientes a verbos se extienden\na\u02dc nadiendo ( to+ el verbo + is to) al principio de la glosa\ny un punto al \ufb01nal de la de\ufb01nici\u00b4 on. Por ejemplo, para el\nverbo \u201chiccup\u201d su glosa quedar\u00b4 \u0131a como sigue: to hiccup is\ntobreathe spasmodically , and make a sound .\n\u00b2Nombres. Las glosas pertenecientes a nombres se extien-\nden a\u02dc nadiendo (el nombre + is) al principio de la glosa y un\npunto al \ufb01nal de la de\ufb01nici\u00b4 on. Por ejemplo, para el nombre\n\u201cspace\u201d su glosa quedar\u00b4 \u0131a como sigue: space is the unlimi-\nted 3-dimensional expanse in which everything is located .\nAn\u00b4 alisis l\u00b4 ogico. Muchas aplicaciones necesitan hacer uso de la\ninformaci\u00b4 on pragm\u00b4 atica contenida en los textos. Debido a es-\nta necesidad, Extended WordNet incorpora informaci\u00b4 on l\u00b4 ogica\na las glosas. Utilizando las glosas conceptuales originales de\nWordNet, \u00b4 estas se transforman en su forma l\u00b4 ogica correspon-\ndiente. La forma l\u00b4 ogica obtenida es un paso intermedio entre\nel an\u00b4 alisis sint\u00b4 actico y una forma sem\u00b4 antica. Es decir, esta\ntransformaci\u00b4 on codi\ufb01ca las relaciones sint\u00b4 acticas siguientes:\n1) sujetos sint\u00b4 acticos, 2) objetos sint\u00b4 acticos, 3) enlaces prepo-\nsicionales, 4) nominales complejos y 5) adjuntos adjetivales y\nadverbiales.\nAn\u00b4 alisis sem\u00b4 antico. En WordNet existen m\u00b4 as de 115000 glo-\nsas. Estas de\ufb01niciones (glosas) se encuentran repartidas de la\nsiguiente forma: unas 79000 est\u00b4 an asociadas a nombres, alre-\ndedor de 13000 a verbos, sobre 18000 a adjetivos y por \u00b4 ultimo\nunas 3500 a adverbios. En la tarea de an\u00b4 alisis sem\u00b4 antico se\nhan utilizado dos tipos de anotaci\u00b4 on: autom\u00b4 atica y manual.\nEn la anotaci\u00b4 on autom\u00b4 atica han intervenido dos sistemas: uno\ndise\u02dc nado de forma espec\u00b4 \u0131\ufb01ca para desambiguar las glosas de\nWordNet, llamado XWN\nWSD y un sistema propio para de-\nsambiguar texto libre. Para decidir el sentido asociado a cada\nuna de las palabras de la glosa, se ha empleado un sistema\n88 4.3 Extended WordNet\nde votaci\u00b4 on entre los dos m\u00b4 etodos autom\u00b4 aticos. De forma que\nla precisi\u00b4 on estimada cuando los dos m\u00b4 etodos etiquetan una\npalabra con el mismo sentido es del 90 %. Existen tres cate-\ngor\u00b4 \u0131as de anotaci\u00b4 on sem\u00b4 antica ordenadas seg\u00b4 un su \ufb01abilidad:\n\u201cGOLD\u201d, \u201cSILVER\u201d y \u201cNORMAL\u201d. Cuando el sentido selec-\ncionado para una palabra se etiqueta como \u201cGOLD\u201d quiere\ndecir esa anotaci\u00b4 on se ha comprobado de forma manual. Cuan-\ndo un sentido aparece con la etiqueta \u201cSILVER\u201d signi\ufb01ca que\nha sido etiquetado de forma consensuada por los dos m\u00b4 eto-\ndos autom\u00b4 aticos de desambiguaci\u00b4 on. Y por \u00b4 ultimo cuando un\nsentido aparece junto a la etiqueta \u201cNORMAL\u201d quiere decir\nque se ha seleccionado el sentido proporcionado por el sistema\nautom\u00b4 atico XWN\nWSD. Cabe considerar que los verbos \u201cto\nbe\u201d y \u201cto have\u201d se han tratado de forma especial y no se han\ndesambiguado de forma autom\u00b4 atica. El procedimiento segui-\ndo para obtener la desambiguaci\u00b4 on de las glosas de WordNet\nconsta de dos fases:\n1.El primer paso consta de la realizaci\u00b4 on de un preproceso\nsobre las glosas de WordNet para separar la parte de la\nde\ufb01nici\u00b4 on de la parte de ejemplos. Tambi\u00b4 en se realiza la\ntokenizaci\u00b4 on, el an\u00b4 alisis sint\u00b4 actico usando el etiquetador de\nBrill y la identi\ufb01caci\u00b4 on de conceptos compuestos.\n2.El segundo paso, una vez realizado el preproceso, es asignar\na cada palabra de la glosa su correspondiente sentido. En\nesta fase, se utiliza la categor\u00b4 \u0131a sint\u00b4 actica obtenida en la\nfase previa para establecer el sentido correspondiente, ya\nque, una misma palabra puede actuar como nombre, verbo,\nadjetivo o adverbio, y por tanto, puede adoptar distintos\nsigni\ufb01cados dependiendo de su categor\u00b4 \u0131a.\nPara poder realizar correctamente el proceso de desam-\nbiguaci\u00b4 on se han empleado distintas heur\u00b4 \u0131sticas (m\u00b4 etodo\nXWN\nWSD):\n\u00b2Palabras monos\u00b4 emicas: Se identi\ufb01can y se etiquetan con\nel sentido 1.\n\u00b2Misma familia jer\u00b4 arquica: Se identi\ufb01can aquellas pala-\nbras de la glosa que pertenecen a la misma jerarqu\u00b4 \u0131a\nque el synset de la glosa.\n4. Recursos 89\n\u00b2Paralelismo l\u00b4 exico: Se identi\ufb01can aquellas palabras que\npertenecen a la misma categor\u00b4 \u0131a sint\u00b4 actica y que est\u00b4 an\nseparadas por comas o conjunciones. Cuando es posible,\nse trata de seleccionar los sentidos que pertenecen a la\nmisma jerarqu\u00b4 \u0131a.\n\u00b2B\u00b4 usqueda en Semcor: Dada una palabra de la glosa se\nforman dos parejas: palabra-palabra\nsiguiente\nde\nla\nglosa\npalabra\nanterior\nde\nla\nglosa-palabra. Estos dos pares de\npalabras se buscan en el corpus de Semcor ( G. Miller\ny Bunker (1993 )). Si para estos pares de palabras el\nsentido asignado es siempre el mismo y el n\u00b4 umero de\nocurrencias supera un cierto umbral, se le asigna ese\nsentido.\n\u00b2Dominio asociado: Cada glosa de WordNet se ha anota-\ndo con un dominio ( Magnini y Strapparava (2000 )). Si\nla palabra de la glosa tiene alg\u00b4 un sentido anotado con\nel mismo dominio que el de la glosa, se selecciona ese\nsentido.\n\u00b2...\nMediante estas heur\u00b4 \u0131sticas se han desambiguado el 64 % de\nlas palabras de WordNet con un 75 % de precisi\u00b4 on. El resto\nde las palabras se han etiquetado con el sentido#1 (el m\u00b4 as\nfrecuente). Adem\u00b4 as del m\u00b4 etodo anterior, se ha utilizado otro\nm\u00b4 etodo autom\u00b4 atico para el proceso de desambiguaci\u00b4 on, el\ncual, utiliza como base texto libre. Para su aplicaci\u00b4 on fue\nnecesaria la transformaci\u00b4 on de las glosas en oraciones com-\npletas. De esta forma, se obtuvo una cobertura de un 100 %\ny una precisi\u00b4 on del 70 %. Las palabras que se etiquetaron\ncon el mismo sentido por los dos sistemas obtuvieron un\n90 % de precisi\u00b4 on.\nEn la Tabla 4.6aparece el resultado obtenido tras realizar los\ntres tipos de an\u00b4 alisis sobre la glosa asociada al adjetivo \u201cexce-\nllent\u201d .\n90 4.4 SUMO (Suggested Upper Merged Ontology)\n1. excellent, \ufb01rst-class, fantabulous \u2013 (of the highest quality; \u201cmade\nan excellent speech\u201d; \u201cthe school has excellent teachers\u201d; \u201ca \ufb01rst-class\nmind\u201d)\n(TOP (S (NP (JJ excellent))\n(VP (VBZ is)\n(NP (NP (NN something))\n(PP (IN of)\n(NP (DT the) (JJS highest) (NN quality)))))\n(. . . )))\nexcellent: JJ(x1) \u00a1!of: IN(x1, x2) highest: JJ(x1)\nquality: NN(x1)\n<wf pos=\u201cIN\u201d >of< =wf>\n<wf pos=\u201cDT\u201d >the< =wf>\n<wf pos=\u201cJJS\u201d lemma=\u201chigh\u201d quality=\u201csilver\u201d wnsn=\u201c1\u201d >highest\n< =wf>\n<wf pos=\u201cNN\u201d lemma=\u201cquality\u201d quality=\u201cnormal\u201d wnsn=\u201c2\u201d >qua-\nlity< =wf>\nTabla 4.6. Excellent#1: An\u00b4 alisis sint\u00b4 actico, formas l\u00b4 ogicas y anotaci\u00b4 on sem\u00b4 antica.\n4.4 SUMO (Suggested Upper Merged\nOntology)\nLa ontolog\u00b4 \u0131a SUMO (Suggested Upper Merged Ontology) es\nuna ontolog\u00b4 \u0131a de nivel superior ( Niles y Pease (2001 )). Esta on-\ntolog\u00b4 \u0131a proporciona de\ufb01niciones para t\u00b4 erminos de prop\u00b4 osito gene-\nral y puede actuar como base para ontolog\u00b4 \u0131as de dominios m\u00b4 as\nespec\u00b4 \u0131\ufb01cos. SUMO fue creada a partir de la combinaci\u00b4 on de dife-\nrentes contenidos ontol\u00b4 ogicos en una \u00b4 unica estructura cohesiva y\nactualmente existen alrededor de 1000 t\u00b4 erminos y 4000 aserciones.\nLos contenidos a partir de los cuales se obtuvo SUMO proceden\nde: Ontolingua2, John Sowa\u2019s upper level ontology3y las onto-\nlog\u00b4 \u0131as desarrolladas por ITBM-CNR (Unrestricted-Time, Repre-\nsentation, Anatomy, Biologic-Functions, and Biologic-Substances).\nEl lenguaje de representaci\u00b4 on utilizado es una versi\u00b4 on de KIF\n(Knowledge Interchange Format) ( Genesereth (1991 )), llamada\nSUO-KIF.\n2http://www.ksl.stanford.edu/software/ontolingua/\n3http://www.jfsowa.com/ontology/\n4. Recursos 91\nEl proceso de creaci\u00b4 on de esta ontolog\u00b4 \u0131a consta de varios pasos.\nPrimero, se identi\ufb01caron todos los contenidos ontol\u00b4 ogicos de alto\nnivel. Estos contenidos inclu\u00b4 \u0131an las librer\u00b4 \u0131as de ontolog\u00b4 \u0131as dispo-\nnibles en el servidor Ontolingua y ITBM-CNR, la ontolog\u00b4 \u0131a de\nJohn Sowa, la ontolog\u00b4 \u0131a de Russell y Norvig ( Russell y Norvig\n(1995 )), los axiomas temporales de James Allen ( Allen (1984 )) y\notras representaciones. Una vez extra\u00b4 \u0131do todo el contenido rele-\nvante se transform\u00b4 o al lenguaje SUO-KIF. Una vez realizada la\ntraducci\u00b4 on, el paso m\u00b4 as complicado fue la creaci\u00b4 on de una \u00b4 uni-\nca ontolog\u00b4 \u0131a que combinara todo el contenido recopilado. Para\nllevar a t\u00b4 ermino este proceso, en primer lugar, se dividieron los\nconceptos en dos grupos: conceptos de alto nivel y conceptos de\nbajo nivel. En el primer grupo, se mantuvo la ontolog\u00b4 \u0131a de John\nSowa y la ontolog\u00b4 \u0131a de Russell y Norvig. En el segundo grupo se\nincluy\u00b4 o el resto. Tras la divisi\u00b4 on las dos ontolog\u00b4 \u0131as de alto nivel\nambas se combinaron para obtener una \u00b4 unica estructura concep-\ntual. El resto del contenido de las clases de bajo nivel fue a\u02dc nadido\ntras la combinaci\u00b4 on. La forma de incluir las clases de bajo nivel\ny los problemas a los que se tuvo que hacer frente est\u00b4 an descritos\nen (Niles y Pease (2001 )).\nPara comprender la estructura y el contenido de SUMO pode-\nmos extraer los conceptos de m\u00b4 as alto nivel, tal y como muestra\nla Figura 4.4.\nAl igual que en la mayor\u00b4 \u0131a de jerarqu\u00b4 \u0131as el concepto de m\u00b4 as alto\nnivel es \u201centity\u201d y bajo este concepto se encuentran \u201cphysical\u201d y\n\u201cabstract\u201d .\nEn la Figura 4.6se muestra un ejemplo de la jerarqu\u00b4 \u0131a de\nconceptos y relaciones existentes en SUMO para bank#1.\nEn esta representaci\u00b4 on gr\u00b4 a\ufb01ca existe un c\u00b4 odigo de colores aso-\nciado a las distintas clases de elementos y sus relaciones seg\u00b4 un la\nFigura 4.5.\n92 4.4 SUMO (Suggested Upper Merged Ontology)\n  Entity \n      Physical \nObject \nSelfConnectedObject \n       ContinuousObject \n       CorpuscularObject \nCollection \nProcess \n      Abstract \nSetClass \nRelation \nProposition \nQuantity \nNumber \nPhysicalQuantity \nAttribute \n \n \n \nFigura 4.4. Conceptos de alto nivel en SUMO\nFigura 4.5. C\u00b4 odigo de colores en la representaci\u00b4 on gr\u00b4 a\ufb01ca de SUMO\n4. Recursos 93\nFigura 4.6. Jerarqu\u00b4 \u0131a SUMO para bank#1\n94 4.4 SUMO (Suggested Upper Merged Ontology)\nLa ontolog\u00b4 \u0131a SUMO tambi\u00b4 en se ha enlazado con los synsets\nde WordNet ( Niles y Pease (2003 )). De la misma forma que los\nSubject Field Codes se integraron en WordNet Domains, los di-\nferentes conceptos de la ontolog\u00b4 \u0131a de SUMO se han enlazado con\nlos synsets de WordNet.\nEn el proceso de anotaci\u00b4 on de WordNet con la ontolog\u00b4 \u0131a SUMO\nse han utilizado tres tipos de relaciones: sinonimia, hiperonimia\ne instanciaci\u00b4 on. A continuaci\u00b4 on se muestra un ejemplo para cada\nuna de este tipo de relaciones:\nSinonimia. En caso de utilizar relaciones de sinonimia, veamos\nel ejemplo de la palabra \u201cplant\u201d cuyo synset en WordNet 1.6\nes 00008864.\n00008864 03 n 03 plant 0 \ufb02ora 0 plant\nlife 0 027 @ . . .\n\u2014 a living organism lacking the power of locomotion\nEn este caso, el synset 00008864 es sin\u00b4 onimo del concepto de\nla ontolog\u00b4 \u0131a SUMO Plant . Por tanto, la entrada en WordNet\nse ampl\u00b4 \u0131a de la siguiente forma:\n00008864 03 n 03 plant 0 \ufb02ora 0 plant\nlife 0 027 @ . .\n. \u2014 a living organism lacking the power of locomotion\n& %Plant=\nEl pre\ufb01jo \u201c& %\u201d indica que el concepto se ha obtenido a partir\nde SUMO y el signo \u201c=\u201d indica que el mapeo ha utilizado una\nrelaci\u00b4 on de sinonimia.\nHiperonimia. En caso de que un synset de WordNet no tenga\nuna correspondencia exacta con un concepto de la ontolog\u00b4 \u0131a\nde SUMO, se utiliza la relaci\u00b4 on de hiperonimia. Supongamos\nque tenemos la palabra \u201cChristian\nScience\u201d , cuya entrada en\nWordNet 1.6 es la siguiente:\n04719796 09 n 01 Christian\nScience 0 001 @ 04718274\nn 0000 \u2014 religious system based on teachings of Mary\nBaker Eddy emphasizing spiritual healing\nEn este caso, no existe un concepto espec\u00b4 \u0131\ufb01co para \u201cChris-\n4. Recursos 95\ntian\nScience\u201d , sin embargo, la ontolog\u00b4 \u0131a contiene conceptos\nm\u00b4 as generales, dentro de los cuales se puede incluir este syn-\nset. La anotaci\u00b4 on quedar\u00b4 \u0131a de la siguiente forma:\n04719796 09 n 01 Christian\nScience 0 001 @ 04718274\nn 0000 \u2014 religious system based on teachings\nof Mary Baker Eddy emphasizing spiritual healing\n& %ReligiousOrganization+\nDonde el su\ufb01jo + indica que el concepto de la ontolog\u00b4 \u0131a es\nun hiper\u00b4 onimo del synset.\nInstanciaci\u00b4 on. Esta \u00b4 ultima relaci\u00b4 on indica que el synset de\nWordNet es miembro de un concepto de la ontolog\u00b4 \u0131a. Veamos\nel siguiente ejemplo para la palabra \u201cUnderground\nRailroad\u201d :\n00034393 04 n 02 Underground\nRailroad 0 Under-\nground\nRailway 0 001 @ 00032687 n 0000 \u2014 abolitionists\nsecret aid to escaping slaves; pre \u00a1Civil War in US\nEn este caso, el concepto m\u00b4 as apropiado para el synset es Or-\nganization . Por tanto, el synset asociado a Underground\nRailway ,\nes una organizaci\u00b4 on particular. Este tipo de relaci\u00b4 on se mues-\ntra de la siguiente forma:\n00034393 04 n 02 Underground\nRailroad 0 Under-\nground\nRailway 0 001 @ 00032687 n 0000 \u2014 abolitio-\nnists secret aid to escaping slaves; pre \u00a1Civil War in US\n& %Organization@\nDonde el s\u00b4 \u0131mbolo \u201c@\u201d indica una relaci\u00b4 on de instanciaci\u00b4 on\nrespecto al synset.\nMediante la inclusi\u00b4 on de los conceptos de la ontolog\u00b4 \u0131a SUMO\nen WordNet, se pueden establecer relaciones entre synsets y ca-\ntegor\u00b4 \u0131as sint\u00b4 acticas al igual que suced\u00b4 \u0131a con WordNet Domains.\nAdem\u00b4 as, mediante el uso de un algoritmo de desambiguaci\u00b4 on se\npueden asignar a un contexto determinado los conceptos de SU-\nMO relacionados. De esta forma, la representaci\u00b4 on conceptual\n96 4.5 An\u00b4 alisis de la Sem\u00b4 antica Latente (LSA)\npuede ser utilizada para facilitar b\u00b4 usquedas sem\u00b4 anticas o clasi-\n\ufb01car documentos.\n4.5 An\u00b4 alisis de la Sem\u00b4 antica Latente (LSA)\nEl An\u00b4 alisis de la Sem\u00b4 antica Latente o Latent Semantic Analysis\n(LSA) es un modelo computacional que explota una caracter\u00b4 \u0131stica\npropia del lenguaje natural: palabras del mismo campo sem\u00b4 antico\ntienden a aparecer juntas o en contextos similares ( Landauer y\nDumais (1997 )).\nLSA tiene sus or\u00b4 \u0131genes en una t\u00b4 ecnica de recuperaci\u00b4 on de in-\nformaci\u00b4 on llamada LSI (Latent Semantic Indexing) ( Furnas et al.\n(1988 ),Deerwester et al. (1990 )). El objetivo de LSI es mejo-\nrar la recuperaci\u00b4 on de documentos reduciendo una gran matriz\nde t\u00b4 ermino-documento en un espacio m\u00b4 as reducido utilizando la\nt\u00b4 ecnica de SVD (Singular Value Decomposition). LSA utiliza la\nmisma metodolog\u00b4 \u0131a pero se diferencia en la representaci\u00b4 on de la\nmatriz. En este caso, LSA utiliza una matriz palabra-contexto.\nLSA representa un texto como una matriz de co-ocurrencia\nM\u00a3N, donde las M\ufb01las se corresponden con palabras, y las N\ncolumnas se corresponden con una unidad de contexto, ya sea, una\nfrase, un p\u00b4 arrafo, etc. Cada celda de la matriz contiene el n\u00b4 umero\nde veces que una palabra determinada en la \ufb01la aparece en el\ncontexto proporcionado por la columna. La Tabla 4.7muestra\nesta representaci\u00b4 on.\nC1\nC2\nC3\nC4\nC5\nW1\n1\n0\n0\n2\n0\nW2\n0\n4\n1\n0\n0\nW3\n2\n0\n0\n1\n0\nTabla 4.7. Matriz Mw\u00a3c\nDonde:\nW:palabras\nC: contextos\n4. Recursos 97\nfij: frecuencia de co-ocurrencia\nLSI y LSA se diferencian principalmente en su de\ufb01nici\u00b4 on de\ncontexto utilizado. Para LSI es un documento, mientras que para\nLSA es m\u00b4 as \ufb02exible, aunque a menudo hace referencia a p\u00b4 arrafos.\nSi la unidad de contexto de LSA es un documento, entonces LSA\ny LSI son esencialmente la misma t\u00b4 ecnica.\nUna vez establecida la frecuencia de co-ocurrencia de cada\nt\u00b4 ermino con respecto a cada contexto, cada \ufb01la se interpreta co-\nmo un vector contextual de ddimensiones. Donde drepresenta el\nn\u00b4 umero de contextos utilizados.\nTras insertar en las celdas correspondientes de la matriz el\nn\u00b4 umero de ocurrencias de cada palabra con respecto al contexto\nde su columna correspondiente, la matriz M\u00a3Nobtenida se des-\ncompone utilizando la t\u00b4 ecnica de Singular Value Decomposition\n(SVD). Mediante SVD se reducen las dimensiones de la matriz\ninicial para que contextos similares sean redistribuidos unos den-\ntro de otros. SVD se basa en el hecho de que cualquier matriz\nrectangular puede ser descompuesta en el producto de otras tres\nmatrices. Esta descomposici\u00b4 on puede obtenerse sin p\u00b4 erdida de in-\nformaci\u00b4 on si no se utilizan m\u00b4 as factores que el m\u00b4 \u0131nimo de Ny\nM. En estos casos, la matriz original puede ser perfectamente\nreconstruida.\nSin embargo, como ocurre normalmente, LSA reduce una ma-\ntriz de miles de dimensiones a unas pocas centenas. De esta forma,\nes pr\u00b4 acticamente imposible reconstruir la matriz original. A pesar\nde que esto pueda sonar a inapropiado, es de hecho esta reduc-\nci\u00b4 on el objetivo de LSA. El efecto de esta acci\u00b4 on se traduce en que\nla p\u00b4 erdida de informaci\u00b4 on producida es debido al ruido. De esta\nforma, la reducci\u00b4 on de la dimensi\u00b4 on produce que las relaciones de\nsimilitud entre palabras y contextos sean mucho m\u00b4 as aparentes.\nLa Figura 4.7representa de forma esquem\u00b4 atica lo que signi\ufb01ca\nla reducci\u00b4 on de dimensiones llevada a cabo por medio de SVD.\nEn la \ufb01gura de la izquierda, cada t\u00b4 ermino est\u00b4 a representado por\ncuatro dimensiones, tantas como documentosp\u00b4 arrafos existen en\nel corpus fd1,d2,d3,d4 g. En la \ufb01gura de la derecha, los t\u00b4 erminos\npasan a estar representados por dos dimensiones abstractas pero\nde una mayor utilidad funcional. A cada t\u00b4 ermino se le in\ufb01ere una\n98 4.5 An\u00b4 alisis de la Sem\u00b4 antica Latente (LSA)\nprobabilidad de estar representado en un concepto. En este caso,\nse observa c\u00b4 omo al t\u00b4 ermino t2 se le in\ufb01ere cierta probabilidad\nde salir en el p\u00b4 arrafo d2 aunque como muestra la \ufb01gura de la\nizquierda, esto no se produzca (se hace patente la caracter\u00b4 \u0131stica\nde relacionar conceptualmente, t\u00b4 erminos con documentos aunque\nno aparezcan en ellos).\n \nt1 t1 \nt3 d1 \nd2 \nd3 \nd4 t2 t2 \nt3 c1 \nc2 c1 \nc2 d1 \nd2 \nd3 \nd4 \nt\u00e9rminosdocumentos t\u00e9rminos conceptos \n documentos T x D T x C C x C D x C \nFigura 4.7. Reducci\u00b4 on dimensional de la matriz en LSA\nEn otras palabras, lo que se persigue al reducir las dimensio-\nnes de la matriz original, no es m\u00b4 as que eliminar el ruido pre-\nsente en las relaciones entre t\u00b4 erminos y contextos. Esto es debido\na que podemos expresar con distintos t\u00b4 erminos el mismo con-\ncepto. Adem\u00b4 as, LSA no tiene en cuenta la estructura ling\u00a8 u\u00b4 \u0131stica\nde los contextos, simplemente las frecuencias de aparici\u00b4 on y co-\nocurrencias de t\u00b4 erminos.\nUna analog\u00b4 \u0131a muy gr\u00b4 a\ufb01ca de c\u00b4 omo funciona la t\u00b4 ecnica, la pro-\nporciona un art\u00b4 \u0131culo de ( Yu et al. (2004 )):\n\u201cImaginemos que tenemos un acuario de peces tropicales y tan\norgullosos estamos de tenerlo que deseamos fotogra\ufb01arlo para una\nrevista especializada. Para capturar la mejor foto, elegiremos el\nmejor \u00b4 angulo que garantice la mejor toma. Adem\u00b4 as, nos asegura-\nremos de que en ella salgan visibles el m\u00b4 aximo n\u00b4 umero de peces sin\nser solapados por otros peces. Tampoco queremos que los peces\nsalgan todos juntos en una masa sino que los queremos mostrar\n4. Recursos 99\nbien distribuidos en el agua. Como nuestro acuario es transparen-\nte, tomaremos diversas fotos desde diferentes puntos de vista y\nelegiremos la que mejor se adapte a lo antes descrito\u201d.\nEn de\ufb01nitiva, lo que hace la t\u00b4 ecnica es mediante la recursivi-\ndad (hacer varias fotograf\u00b4 \u0131as), buscar las dimensiones que mejor\npermitan una diferenciaci\u00b4 on de las \u201cbolsas sem\u00b4 anticas\u201d (peces)\nen las que los t\u00b4 erminos participan. Una vez hecho esto, elegiremos\ns\u00b4 olo las dimensiones que mejor caractericen estas bolsas.\nEn la Figura 4.8se muestra una representaci\u00b4 on de la matriz\noriginal desglosada en dos matrices de vectores singulares y una\nmatriz diagonal de valores singulares. A partir de este desglo-\nse se reducir\u00b4 an las dimensiones seleccionando solamente aquellas\nque mejor representen las diferentes regiones sem\u00b4 anticas. Estudios\nrealizados han demostrado que la reducci\u00b4 on a 300 dimensiones\nproporciona los mejores resultados Turney (2004 ).\n \n \n \n   \n \n \n \n \n \n \n \n \n \n  \n \n  \nD x C \nConceptos \nC x C \n(diagonal) = \nT\u00e9rminos \n* * \nT x C T x D c2 Reducci\u00f3n \ndimensional Documento A Documento A \nc1 T\u00e9rminos Documentos Conceptos Documentos t1 t2 t3 \nFigura 4.8. Descomposici\u00b4 on de la matriz en LSA\nEn de\ufb01nitiva, la t\u00b4 ecnica SVD devolver\u00b4 a un desglose de las re-\nlaciones que se mantienen en la matriz original. De esta forma,\n100 4.5 An\u00b4 alisis de la Sem\u00b4 antica Latente (LSA)\npodremos reconstruir la matriz inicial pero tomando en conside-\nraci\u00b4 on s\u00b4 olo las dimensiones que hacen m\u00b4 as fuerte la relaci\u00b4 on entre\nt\u00b4 erminos y documentos. Esto se har\u00b4 a tomando los valores singu-\nlares m\u00b4 as altos y volviendo a multiplicar las tres matrices pero\nreduciendo sus dimensiones a las mismas que valores singulares\nhayamos considerado.\nEn (Landauer y Dumais (1997 )) se evalu\u00b4 o la habilidad de LSA\npara reconocer sin\u00b4 onimos. En este estudio, se utiliz\u00b4 o el Test of\nEnglish as a Foreign Language (TOEFL) como base para la eva-\nluaci\u00b4 on del funcionamiento de LSA. El TOEFL es una prueba\nque consiste en dada una palabra clave, seleccionar de entre cua-\ntro opciones (palabras) distintas, cu\u00b4 al es m\u00b4 as similar a la palabra\nclave. Por ejemplo, si \u201cdistant\u201d es la palabra clave en cuesti\u00b4 on y\nlas cuatro opciones son: 1. \u201cimpossible\u201d , 2.\u201cfaraway\u201d , 3.\u201cobser-\nvable\u201d , 4.\u201cfearful\u201d . En este caso, se deber\u00b4 \u0131a seleccionar la opci\u00b4 on\n2 como la m\u00b4 as similar en cuanto a signi\ufb01cado.\nPara poder aplicar LSA sobre el tipo de informaci\u00b4 on proporcio-\nnada por TOEFL y construir la matriz contextual, se utiliz\u00b4 o como\ncorpus la versi\u00b4 on electr\u00b4 onica de la Grolier\u2019s Academic American\nEncyclopedia. En esta enciclopedia hab\u00b4 \u0131an alrededor de 30473\nart\u00b4 \u0131culos, para cada uno de los cuales se extrajeron los primeros\n2000 caracteres, con una media de 151 palabras por art\u00b4 \u0131culo. Una\nvez obtenida esta informaci\u00b4 on, los datos se introdujeron en la ma-\ntriz contextual, teniendo \u00b4 esta una columna por art\u00b4 \u0131culo (30473\ncolumnas) y alrededor de 60768 \ufb01las, donde cada \ufb01la se corres-\npond\u00b4 \u0131a con una palabra que aparec\u00b4 \u0131a en al menos dos art\u00b4 \u0131culos\n(columnas) de la matriz. Inicialmente, las celdas de la matriz con-\nten\u00b4 \u0131an la frecuencia en que una palabra aparec\u00b4 \u0131a en cada art\u00b4 \u0131cu-\nlo. Posteriormente, estos datos se transformaron seg\u00b4 un la f\u00b4 ormu-\nla ln(1+ frec)=(entrop\u00b4 \u0131a de la palabra sobre todos los contextos).\nLa matriz resultante \ufb01nal fue reducida hasta 300 dimensiones me-\ndiante la t\u00b4 ecnica de SVD, correspondi\u00b4 endose estas dimensiones\ncon los valores singulares m\u00b4 as elevados obtenidos, dando como\nresultado vectores con 300 valores reales para representar cada\npalabra. La similitud entre dos palabras se midi\u00b4 o utilizando el\ncoseno entre vectores, de forma que cuanto m\u00b4 as similares fueran\ndos palabras mayor ser\u00b4 \u0131a el coseno obtenido entre ambas. Por lo\n4. Recursos 101\ntanto, para seleccionar la respuesta correcta de cada pregunta se\ncalcul\u00b4 o el coseno entre la palabra y cada una de las cuatro al-\nternativas. Como resultado, la aplicaci\u00b4 on de LSA sobre el test de\nTOEFL supuso un acierto del 65 %, puntuaci\u00b4 on similar a los resul-\ntados obtenidos por personas de habla no inglesa que realizaron\nel test. Esta misma prueba se realiz\u00b4 o sobre la matriz original de\n30000\u00a360000, en este caso, la precisi\u00b4 on baj\u00b4 o a un 37 %, sugirien-\ndo estos resultados que la descomposici\u00b4 on de la matriz eliminaba\nel ruido presente en la matriz original, proporcionando una mejor\nrepresentaci\u00b4 on de las similitudes entre palabras.\nEl test TOEFL fue utilizado de nuevo por ( Turney (2001 )) pa-\nra evaluar los resultados de un sistema que empleaba una t\u00b4 ecnica\ndistinta a LSA. En este caso, el sistema empleado calculaba los\nvalores de la Pointwise Mutual Information (PMI) entre la pala-\nbra dada y sus cuatro posibilidades, utilizando los resultados de\nla b\u00b4 usqueda en Alta Vista como base para establecer la frecuencia\nde aparici\u00b4 on de las palabras. La estrategia utilizada para calcular\nel grado de similitud entre la palabra clave y las cuatro opciones\nse muestra en la Tabla 4.8. En este ejemplo se trata de averiguar\nla palabra m\u00b4 as similar a \u201clevied\u201d de entre estas 4 opciones: \u201cim-\nposed\u201d ,\u201cbelieved\u201d ,\u201crequested\u201d ,\u201ccorrelated\u201d . Seg\u00b4 un los resultados\nobtenidos la palabra con mayor similitud sem\u00b4 antica es \u201cimposed\u201d .\nEste mismo ejemplo aplicando la t\u00b4 ecnica de LSA obtiene el\nmismo resultado, tal y como muestra la Tabla 4.9.\nEs interesante destacar que a pesar de utilizar diferentes fuen-\ntes de informaci\u00b4 on ambas aproximaciones obtienen el mismo re-\nsultado. La comparativa sobre las 80 preguntas del TOEFL para\ncada aproximaci\u00b4 on se muestra en la Tabla 4.10.\nComo demuestran los resultados, PMI mejora en un 10 % los\nresultados de LSA. Pero la interpretaci\u00b4 on de estos resultados es\ncomplicada debido a que ambas t\u00b4 ecnicas utilizan fuentes de in-\nformaci\u00b4 on muy distintas y PMI utiliza un contexto mucho m\u00b4 as\npeque\u02dc no que LSA.\nEstos ejemplos, sirven para mostrar dos aproximaciones basa-\ndas en la utilizaci\u00b4 on de grandes cantidades de informaci\u00b4 on para\nestablecer relaciones sem\u00b4 anticas obteniendo resultados muy posi-\n102\nB\u00b4 usqueda\nResultados\nimposed AND NOT (imposed NEAR \u201dnot\u201d)\n1,147,535\nbelieved AND NOT (believed NEAR \u201dnot\u201d)\n2,246,982\nrequested AND NOT (requested NEAR \u201dnot\u201d)\n7,457,552\ncorrelated AND NOT (correlated NEAR \u201dnot\u201d)\n296,631\n(levied NEAR imposed) AND NOT ((levied OR imposed) NEAR\n\u201dnot\u201d)\n2,299\n(levied NEAR believed) AND NOT ((levied OR believed) NEAR\n\u201dnot\u201d)\n80\n(levied NEAR requested) AND NOT ((levied OR requested) NEAR\n\u201dnot\u201d)\n216\n(levied NEAR correlated) AND NOT ((levied OR requested) NEAR\n\u201dnot\u201d)\n3\nSelecci\u00b4 on\nSimilitud\np(leviedjimposed )\n0.0020034\np(leviedjbelieved )\n0.0000356\np(leviedjrequested )\n0.0000290\np(leviedjcorrelated )\n0.0000101\nTabla 4.8. C\u00b4 alculo similitud PMI para TOEFL\nSelecci\u00b4 on\nResultado LSA\nimposed\n0.70\nbelieved\n0.09\nrequested\n0.05\ncorrelated\n-0.03\nTabla 4.9. Resultado LSA sobre TOEFL\nP(pal\nclavejopcion )\nRespuestas correctas\nPorcentaje\nPMI\n59/80\n73.75 %\nLSA\n51.5/80\n64.4 %\nPersona de habla no inglesa\n51.6/80\n64.5 %\nTabla 4.10. Comparativa LSA y PMI sobre TOEFL\ntivos. En el siguiente cap\u00b4 \u0131tulo estas t\u00b4 ecnicas han sido adaptadas\ny utilizadas en distintos m\u00b4 etodos de desambiguaci\u00b4 on autom\u00b4 atica.\nCap\u0013\u0010tulo 5\nM\u00b4 etodos\nEn este cap\u00b4 \u0131tulo se describen los m\u00b4 etodos desarrollados a par-\ntir de los estudios realizados en esta tesis: WSD DRelevant, WSD\nDLSA y WSD SenseDiscrim. Todos los m\u00b4 etodos descritos a con-\ntinuaci\u00b4 on se clasi\ufb01can dentro del grupo de m\u00b4 etodos basados en\nconocimiento, ya que, la informaci\u00b4 on necesaria para su correcto\nfuncionamiento procede de corpus y recursos l\u00b4 exicos y no requie-\nren ning\u00b4 un proceso de aprendizaje. Adem\u00b4 as de la descripci\u00b4 on de\ncada m\u00b4 etodo tambi\u00b4 en se presentan las diferentes aproximaciones\nrealizadas, as\u00b4 \u0131 como la utilizaci\u00b4 on de los diferentes recursos des-\ncritos en el cap\u00b4 \u0131tulo anterior.\n5.1 WSD basado en conocimiento: DRelevant\nEl m\u00b4 etodo desarrollado en esta secci\u00b4 on se clasi\ufb01ca dentro de los\nm\u00b4 etodos no supervisados basados en conocimiento. Dentro de esta\ncategor\u00b4 \u0131a encontramos aquellos m\u00b4 etodos que necesitan de infor-\nmaci\u00b4 on externa procedente de diversas fuentes, ya sea de diccio-\nnarios electr\u00b4 onicos, corpus generales, corpus especializados, etc.\nA partir de esta informaci\u00b4 on los m\u00b4 etodos no supervisados pueden\nobtener los datos necesarios para construir sus propias fuentes de\nconocimiento y relacionar de esta forma palabras a partir de sus\ncontextos y sus apariciones junto a otras palabras sem\u00b4 anticamente\nrelacionadas.\n104 5.1 WSD basado en conocimiento: DRelevant\nLa idea principal en la que se basa la implementaci\u00b4 on del m\u00b4 eto-\ndo descrito a continuaci\u00b4 on, es en la utilizaci\u00b4 on de una serie de\ncategor\u00b4 \u0131as sem\u00b4 anticas asociadas a los sentidos de las palabras co-\nmo una aproximaci\u00b4 on para determinar los sentidos de \u00b4 estas. Es\ndecir, a partir de WordNet Domains que est\u00b4 a etiquetado con una\nserie de categor\u00b4 \u0131as o dominios, se extraen de forma estad\u00b4 \u0131stica los\ncontextos en los que aparecen las distintas palabras a desambi-\nguar, y se determina a qu\u00b4 e categor\u00b4 \u0131a sem\u00b4 antica pertenecen esos\ncontextos.\nLa base te\u00b4 orica en la que se basa este sistema parte de tres\npremisas:\nPrimera: Las palabras que pertenecen a diferentes clases con-\nceptuales o dominios, como ANIMAL o M \u00b4AQUINA, tienden a\naparecer en contextos bien diferenciados.\nSegunda: Los diferentes sentidos de una palabra tienden a per-\ntenecer a clases conceptuales diferentes.\nTercera: Si se puede construir un discriminador de contextos\npara diferentes clases conceptuales entonces podremos distin-\nguir los sentidos de las palabras que pertenecen a esas clases.\nEn la Tabla 5.1podemos apreciar la diferencia existente en-\ntre los contextos donde aparece la palabra \u201ccrane\u201d con el sentido\nasociado de \u201cgr\u00b4 ua\u201d y \u201ccrane\u201d con el sentido de \u201cgrulla\u201d. Ambas\nacepciones de la misma palabra pertenecen a categor\u00b4 \u0131as sem\u00b4 anti-\ncas distintas. La primera acepci\u00b4 on pertenece a la categor\u00b4 \u0131a In-\ndustry y la segunda a Zoology .\nContexto de entrada\nCategor\u00b4 \u0131a\nsem\u00b4 antica\nTreadmills attached to \u201ccranes\u201d were used to lift heavy \u2014 for\nsupplying power for \u201ccranes\u201d, hoists, and lifts \u2014 above this\nheight, a tower \u201ccrane\u201d is often used.\nIndustry\nThis elaborate courtship rituals \u201dcranes\u201d build a nest of vege-\ntation \u2014 are more closely related to \u201ccranes\u201d and rails. They\nran \u2014 low trees. At least \ufb01ve \u201ccrane\u201d species are in danger.\nZoology\nTabla 5.1. Contextos asociados a diferentes sentidos de la palabra \u201dcrane\u201d\n5. M\u00b4 etodos 105\nEn este caso, a partir del contexto que rodea a la palabra \u201ccra-\nne\u201dpodemos seleccionar su sentido correspondiente, utilizando\npara ello la informaci\u00b4 on procedente de las palabras que la rodean.\nLa utilizaci\u00b4 on de las palabras del contexto como fuente de infor-\nmaci\u00b4 on para establecer el sentido de una palabra y las relaciones\nsem\u00b4 anticas entre las palabras del contexto, son la base de nuestro\nm\u00b4 etodo de desambiguaci\u00b4 on autom\u00b4 atica.\n5.1.1 Obtenci\u00b4 on y categorizaci\u00b4 on de contextos\nEl objetivo principal en este punto es poder establecer relacio-\nnes entre palabras a partir de los contextos en los cuales aparecen.\nSi esos contextos se engloban dentro de una categor\u00b4 \u0131a determina-\nda, podemos establecer, analizando la frecuencia de aparici\u00b4 on de\nlas palabras, si \u00b4 estas pertenecen o no a esa categor\u00b4 \u0131a. Para ello, es\nnecesario recopilar cierta informaci\u00b4 on acerca de su frecuencia de\naparici\u00b4 on junto a otras palabras y las categor\u00b4 \u0131as en las que suelen\naparecer.\nLa estrategia seguida para recopilar informaci\u00b4 on relativa a la\nfrecuencia de aparici\u00b4 on consta de tres pasos:\n1.Extraer los contextos representativos para cada categor\u00b4 \u0131a.\n2.Identi\ufb01car las palabras m\u00b4 as destacadas entre los contextos ob-\ntenidos y establecer un determinado peso para cada palabra.\n3.Utilizar los pesos resultantes para poder determinar la cate-\ngor\u00b4 \u0131a apropiada de una palabra polis\u00b4 emica (con m\u00b4 as de un\nsentido) dentro de un nuevo contexto.\nLa existencia de palabras polis\u00b4 emicas supone un problema pa-\nra el establecimiento de los contextos apropiados para cada cate-\ngor\u00b4 \u0131a. Podemos encontrar por ejemplo, instancias de una misma\npalabra que corresponden a sentidos diferentes. En este caso, po-\ndemos adquirir informaci\u00b4 on err\u00b4 onea y que produce ruido debido a\nestas palabras. Normalmente, se puede amortiguar el efecto de es-\ntos errores de clasi\ufb01caci\u00b4 on porque suelen distribuirse entre varias\ncategor\u00b4 \u0131as. Sin embargo, si una misma palabra atiende a varios\nsentidos y \u00b4 estos se distribuyen dentro de la misma categor\u00b4 \u0131a, dar\u00b4 \u0131a\nlugar a una clasi\ufb01caci\u00b4 on err\u00b4 onea. Adem\u00b4 as, puede ser que uno de\n106 5.1 WSD basado en conocimiento: DRelevant\nlos sentidos de la palabra polis\u00b4 emica aparezca con mayor frecuen-\ncia en los contextos extra\u00b4 \u0131dos, siendo este sentido incorrecto a la\ncategor\u00b4 \u0131a que estamos contextualizando.\nPara minimizar los efectos que producen la aparici\u00b4 on de pa-\nlabras muy frecuentes dentro de cada categor\u00b4 \u0131a, se realiza una\nponderaci\u00b4 on de los contextos. Es decir, si una palabra aparece\nmuy frecuentemente en una categor\u00b4 \u0131a no por ello es signi\ufb01cati-\nva de esa categor\u00b4 \u0131a, ya que, esa misma palabra puede aparecer\nmuy frecuentemente junto a otras categor\u00b4 \u0131as. Para evitar este tipo\nde situaciones se utiliza la siguiente ponderaci\u00b4 on: si una palabra\naparece k-veces en el corpus, entonces las palabras que la rodean\ncontribuyen 1 =ka la suma de la frecuencia.\n5.1.2 Extracci\u00b4 on de contextos\nPara poder realizar estimaciones estad\u00b4 \u0131sticas de co-ocurrencia\nde palabras en diferentes contextos, es necesario disponer de un\ncorpus previamente categorizado. El problema que encontramos\nactualmente es que no existen corpus de \u00b4 ambito general lo su-\n\ufb01cientemente extensos para satisfacer la demanda de relaciones\nentre palabras y categor\u00b4 \u0131as. Adem\u00b4 as, la mayor\u00b4 \u0131a de corpus exis-\ntentes se centran en dominios de \u00b4 ambito de aplicaci\u00b4 on espec\u00b4 \u0131\ufb01cos.\nDebido a estas di\ufb01cultades, es necesaria la utilizaci\u00b4 on de alg\u00b4 un\notro recurso que recoja de forma gen\u00b4 erica las distintas relaciones\nentre palabras y su pertenencia a diferentes categor\u00b4 \u0131as sem\u00b4 anticas.\nObservando las prestaciones de distintos recursos electr\u00b4 onicos\ncomo WordNet Domains o SUMO, donde a partir de las de\ufb01nicio-\nnes de un diccionario electr\u00b4 onico se a\u02dc naden etiquetas sem\u00b4 anticas\na las palabras, se ha optado por utilizar estos recursos como cor-\npus para la categorizaci\u00b4 on de contextos. La estructura de estos\nrecursos ya fue presentada en el cap\u00b4 \u0131tulo anterior y a modo de\nrecordatorio se muestra un peque\u02dc no extracto de su con\ufb01guraci\u00b4 on\nen las siguientes \ufb01guras.\nLa Figura 5.1muestra c\u00b4 omo con WordNet Domains a par-\ntir de las distintas categor\u00b4 \u0131as sem\u00b4 anticas Economy ,Industry\nyBotany , se pueden clasi\ufb01car tanto palabras pertenecientes a\n5. M\u00b4 etodos 107\n\u0001\n\u0001\n\u0001\n\u0001\n\u0001\u0002\u0003\u0004\u0005\u0001\n\u0006\u0007\u0004\b\t\u0001\n\u0003\n\n\u0007\u000b\u0004\f\u0001\n\u0002\u0003\u0004\u0005\b\r \u0001\u0002\u0003\u0004\u0005\u0006\u0007 \n\u0003\u0002\u000e\u0007\r\u0002\u0001\n\u0003\u0006\u0007\r\f\u000f\u0010\b\u0001\n\u0011\u000f\u000e\n\u0007\u000b\u0004\f\u0001\n\u0012\u0003\t \b\u0006\u0005\u0004\u0002\u0007 \u0003\n\n\u000b\u0006\u000b\u0013\u0003\f\b\u0011\u0001\n\u0003\u0011\u0011\u000f\f\u000f\u0007\u0004\u0003\u0013\u0001\n\b\n\u0007\u0004\u0007\u0006\u000f\n \t\n\u000b\u0006\f\r\b\u0002\u0007 \n\u0006\u000e\u0002\u0001\u0002\u0003\u000f \n\n\u0002\u0003\t\r\u0001 \n\u0010\u0011\u0012\u0013\u0014\u0015\u0016\u0017\u0018\u0017\u0004\u0002\f\t\u0001\u000f\u0017\u0010\u0011\u0012\u0013\u0014\u0015\u0019\u0017\u0018\u0017\r\u0001\n\u001a\u0007\f\u0005\u000f\u0017\nFigura 5.1. WordNet Domains\n\u0001\n\u0001\u0002\u0003\u0003\u0004\u0005\u0006\u0007\b\u0004\t\n\u0002\u0003\u0004\u000b\n\f\u0001\t\r\u0004\u000e\u000f\u0003\u0010\t\u000b\u0011\u0012\b\u0013\u0014\u000b\n\u0001\n\u0001\n\u0002\u0003\u0004\u0005\u0001\n\u0003\u0006\u0006\u0007\b\u0007\t\u0003\n\u000b\f\u0004\u0001\n\u0003\r\u000e\u0007\u000f\n\b\u0010\u0004\n\u0001\n\u0003\r\b\u000b\u000f\u000f\u000b\f\u0004\u0001\n\u0003\r\u0011\u0003\u0004\u0006\u0010\u0001\u0015\u0013\b\u0016\u0017\u0018\u0011 \n\r\f\u0012\u0004\u0001\n\u0010\u0013\u0014\u0010\u0004\r\u0003\u0002\t\u0010\u0001\n\r\u0010\u0011\u0003\t\u0007\u0010\r\u0001\n\r\u0010\u0015\u0016\u0003\r\u0010\r\u0001\n\u0014\u0016\u000b\u0006\u0010\r\u0001\u0019\u001a\u001b\u0018\u001c\u001d\u001e\u0013\u0011 \u0016\t\u0005\u001f !\u000b\"\u000b\u0016\u0012\u001d#\u001a\u001d\u0015$\u000b\n\u0016\t\u0005\u001f %\u000b\"\u000b\u0019\u0017\u001c\u001d&\u0019\u0001\u001c\u000b\n\u0001\nFigura 5.2. SUMO\ndiferentes categor\u00b4 \u0131as sint\u00b4 acticas, como determinar los diferentes\nsentidos de una palabra polis\u00b4 emica.\nEn la Figura 5.2se muestra c\u00b4 omo en la ontolog\u00b4 \u0131a SUMO tam-\nbi\u00b4 en se pueden agrupar palabras de distintas categor\u00b4 \u0131as sint\u00b4 acticas\ncon la misma etiqueta sem\u00b4 antica ( CurrencyMeasure ). Sal-\nvo que en este caso, no se encuentran verbos relacionados con\nCurrencyMeasure , esto es debido a que esta ontolog\u00b4 \u0131a pre-\nsenta un grado de granularidad m\u00b4 as \ufb01no que el caso de WordNet\nDomains y para verbos que en WordNet domains compart\u00b4 \u0131an la\n108 5.1 WSD basado en conocimiento: DRelevant\netiqueta Economy ahora en SUMO tienen otras categor\u00b4 \u0131as asig-\nnadas: FinancialTransaction :\u201cpay\u201d, \u201camortize\u201d, Getting\n\u201cabsorb\u201d yDecreasing \u201cdiscount\u201d .\nA pesar de sus diferencias en cuanto a anotaci\u00b4 on, mediante\nambos recursos se puede extraer informaci\u00b4 on relacionada con los\ncontextos de cada categor\u00b4 \u0131a, utilizando para ello las glosas de\nWordNet (ya que ambos se basan en su base de datos l\u00b4 exica).\nComo ya se coment\u00b4 o en el cap\u00b4 \u0131tulo anterior, en WordNet, cada\npalabra tiene asociada una de\ufb01nici\u00b4 on (glosa) que puede adem\u00b4 as\nincluir algunos ejemplos de uso de la palabra que se est\u00b4 a de\ufb01nien-\ndo. Por ejemplo, el caso de la palabra \u201cbank\u201d con la categor\u00b4 \u0131a\nEconomy su glosa es: \u201cthe funds held by a gambling house or the\ndealer in some gambling games; \u201che tried to break the bank at\nMonte Carlo\u201d \u201d . En este caso, adem\u00b4 as de dar una de\ufb01nici\u00b4 on para\nuno de los sentidos de \u201cbank\u201d tambi\u00b4 en se proporciona un ejemplo\nde una frase donde se utiliza \u201cbank\u201d con ese sentido.\nPara poder determinar los contextos de cada categor\u00b4 \u0131a se han\nagrupado todas las glosas que tienen asociada una misma eti-\nqueta sem\u00b4 antica. De esta forma, se ha obtenido una clasi\ufb01caci\u00b4 on\npor categor\u00b4 \u0131as de todas las glosas de WordNet, tanto usando las\ncategor\u00b4 \u0131as de WordNet Domains como usando las categor\u00b4 \u0131as de\nSUMO.\n5.1.3 Obtenci\u00b4 on de las palabras signi\ufb01cativas\nUna vez determinados los contextos asociados a cada categor\u00b4 \u0131a,\nes necesario determinar de entre todas las palabras que aparecen\nen las glosas, cu\u00b4 ales son las m\u00b4 as signi\ufb01cativas en relaci\u00b4 on a esa\ncategor\u00b4 \u0131a.\nCuando hablamos de palabras signi\ufb01cativas nos referimos a\naquellas palabras que aparecen m\u00b4 as a menudo en el contexto de\nuna categor\u00b4 \u0131a que en cualquier otra parte del corpus. En este caso,\nse podr\u00b4 \u0131a determinar la importancia de una palabra con respecto\na una categor\u00b4 \u0131a atendiendo a la F\u00b4 ormula 5.1:\nimportancia (w) =P(palabra jcategoria )\nP(palabra )(5.1)\n5. M\u00b4 etodos 109\nWordNet Domains\nEtiqueta: Economy\n01517979\u2014absorb\u2014 take up, as of debts or payments; \u201cabsorb the costs for\nsomething\u201d\n01549722\u2014account\u2014 keep an account of\n00106728\u2014accrue\u2014 grow by addition, as of capital: \u201cThe interest accrues\u201d\n01560796\u2014advance\u2014 pay in advance; \u201cCan you advance me some money?\u201d\n00108725\u2014advance\u2014 rise in rate or price; \u201cThe stock market gained 24 points\ntoday\u201d\n00810882\u2014a\ufb00ord\u2014 be able to spare or give up; \u201cI can\u2019t a\ufb00ord to spend two hours\nwith this person\u201d\n00490924\u2014allow\u2014 give or assign a share of money or time to a particular person\nor cause; \u201cI will earmark this money...\n01585121\u2014allow\u2014 grant as a discount or in exchange; \u201cThe camera store owner\nallowed me $50 on my old camera\u201d\n01606528\u2014amortise\u2014 liquidate gradually\n01606528\u2014amortize\u2014 liquidate gradually\n...\nFigura 5.3. Clasi\ufb01caci\u00b4 on contextual a partir de WordNet Domains\nSUMO\nEtiqueta: FinancialTransaction\n01544212\u2014cash\u2014exchange for cash\n01544212\u2014cash\nin\u2014exchange for cash\n01544337\u2014redeem\u2014convert into cash; of commercial papers\n01544440\u2014redeem\u2014pay o\ufb00, as of loans or promissory notes\n01544440\u2014pay\no\ufb00\u2014pay o\ufb00, as of loans or promissory notes\n01544554\u2014ransom\u2014exchange or buy back for money; under threat\n01544554\u2014redeem\u2014exchange or buy back for money; under threat\n01546904\u2014arbitrage\u2014practice arbitrage, as of stocks\n01547100\u2014turn\nover\u2014do business worth a certain amount of money\n01547218\u2014broker\u2014act as a broker\n...\nFigura 5.4. Clasi\ufb01caci\u00b4 on contextual a partir de SUMO\nLa probabilidad de aparici\u00b4 on de una palabra sobre una cate-\ngor\u00b4 \u0131a P(palabra jcategoria ) normalmente se suele estimar contan-\ndo el n\u00b4 umero de ocurrencias de la palabra en los distintos con-\ntextos de la categor\u00b4 \u0131a (contexto local). Pero esta medida no da\nresultados reales cuando por ejemplo, una palabra es poco fre-\ncuente. Por lo tanto, se puede suavizar el efecto a\u02dc nadiendo la\nfrecuencia global de aparici\u00b4 on de la palabra P(palabra ) (contexto\nglobal) ( Yarowsky (1992 )). De esta forma, se evita obtener esti-\nmaciones err\u00b4 oneas a partir del contexto local, ya que, los errores\nque puedan aparecer dentro del contexto global son irrelevantes.\n110 5.1 WSD basado en conocimiento: DRelevant\nEn la Tabla 5.2se muestra el resultado obtenido tras analizar la\nfrecuencia de aparici\u00b4 on de la palabra \u201cplant\u2019 \u2019 como nombre en\nWordNet Domains.\n5.1.4 Similitud sem\u00b4 antica\nUna vez estimada la importancia de cada palabra sobre cada\ncategor\u00b4 \u0131a del corpus, es necesario establecer una medida que de-\ntermine el grado de similitud sem\u00b4 antica entre cualquier par de\npalabras, es decir, si existe alg\u00b4 un tipo de relaci\u00b4 on que las vincule\nsem\u00b4 anticamente.\nLa similitud entre palabras se de\ufb01ne normalmente en t\u00b4 erminos\nde co-ocurrencia estad\u00b4 \u0131stica. Se debe matizar que la co-ocurrencia\nse puede especi\ufb01car de diferentes formas. De entre todas las for-\nmas posibles tenemos dos tipos principales: la co-ocurrencia me-\ndida a partir de las relaciones entre palabras dentro de un rango\nespec\u00b4 \u0131\ufb01co (ventana) y la co-ocurrencia de palabras como un pa-\ntr\u00b4 on particular de relaciones gramaticales tales como sujeto-verbo\ny verbo-objeto.\nPodemos referirnos a los dos tipos de co-ocurrencia anteriores\ncomo medidas de co-ocurrencia de primer orden. Esta denomina-\nci\u00b4 on nos servir\u00b4 a para distinguirlas de aquellas medidas a las que\ndenominaremos co-ocurrencia de segundo orden (o indirecta). Es-\nte \u00b4 ultimo tipo representa una co-ocurrencia de pares de palabras\nen expresiones comunes. La hip\u00b4 otesis asociada a la co-ocurrencia\nde primer orden es que las palabras relacionadas sem\u00b4 anticamente\ntienden a aparecer en contextos de \u00b4 ambito restringido. Mientras\nque la idea subyacente para la co-ocurrencia de segundo orden\nes que las palabras sem\u00b4 anticamente similares tienen tendencia a\ncompartir contextos similares. Por ejemplo, \u201ccerveza\u201d y \u201cvino\u201d se\nconsideran palabras similares porque est\u00b4 an relacionadas sem\u00b4 anti-\ncamente con el verbo \u201cbeber\u201d, ya que, frecuentemente aparecen\ncomo su objeto directo y por tanto, comparten un contexto simi-\nlar.\nLa co-ocurrencia de un par de palabras (o expresiones) pue-\nde medirse de muchas formas. La medida m\u00b4 as simple es la \u201cba-\nre co-occurrence frequency\u201d . Otras medidas de co-ocurrencia m\u00b4 as\n5. M\u00b4 etodos 111\nDominio\nFrecuencia\nImportancia\nadministration\n4\n0,001025904\nagriculture\n77\n0,019748654\nalimentation\n37\n0,009489613\nanatomy\n42\n0,010771993\nanthropology\n8\n0,002051808\narchaeology\n6\n0,001538856\narchitecture\n1\n0,000256476\nart\n3\n0,000769428\nbiology\n735\n0,188509874\nbody\ncare\n3\n0,000769428\nbotany\n2306\n0,591433701\nbuilding\nindustry\n19\n0,004873044\nchemistry\n85\n0,021800462\ncolor\n13\n0,003334188\ncommerce\n3\n0,000769428\necology\n2\n0,000512952\neconomy\n3\n0,000769428\nelectricity\n1\n0,000256476\nengineering\n1\n0,000256476\nenterprise\n15\n0,00384714\nentomology\n82\n0,021031034\nfactotum\n112\n0,028725314\nfashion\n1\n0,000256476\ngastronomy\n84\n0,021543986\ngenetics\n1\n0,000256476\ngeography\n7\n0,001795332\ngeology\n4\n0,001025904\nindustry\n39\n0,010002565\nmedicine\n49\n0,012567325\nmeteorology\n1\n0,000256476\nmilitary\n1\n0,000256476\nmountaineering\n1\n0,000256476\npharmacy\n30\n0,007694281\nphysics\n1\n0,000256476\nphysiology\n6\n0,001538856\npsychology\n4\n0,001025904\npure\nscience\n1\n0,000256476\nquality\n7\n0,001795332\nreligion\n1\n0,000256476\nsexuality\n1\n0,000256476\ntelecommunication\n2\n0,000512952\ntheatre\n1\n0,000256476\ntime\nperiod\n2\n0,000512952\ntown\nplanning\n1\n0,000256476\ntransport\n2\n0,000512952\nzoology\n83\n0,02128751\nzootechnics\n11\n0,002821236\nTabla 5.2. Frecuencia de \u201cplant\u201d en WordNet Domains\n112 5.1 WSD basado en conocimiento: DRelevant\nso\ufb01sticadas para pares de palabras est\u00b4 an basadas en sus frecuen-\ncias de co-ocurrencia y frecuencias independientes. Una medida\nmuy conocida de co-ocurrencia que fue inicialmente utilizada por\n(Church y Hanks (1990 )) es la llamada Informaci\u00b4 on Mutua (IM)\nde\ufb01nida seg\u00b4 un la ecuaci\u00b4 on 5.2:\nIM(x; y) = log 2P(x; y)\nP(x)P(y)= log 2freq(x;y)\nN\nfreq(x)\nNfreq(y)\nN= log 2freq(x; y)N\nfreq(x)freq(y)\n(5.2)\nEn la f\u00b4 ormula de la IM P(x; y) yfreq(x; y) son la probabilidad\nde co-ocurrencia y la frecuencia de dos eventos xey,P(x) y\nfreq(x) son la probabilidad independiente y frecuencia de x, yN\nes el n\u00b4 umero total de eventos.\nDentro de la lexicograf\u00b4 \u0131a computacional podemos utilizar el\nvalor proporcionado por la IM para establecer si existe alg\u00b4 un tipo\nde relaci\u00b4 on entre diferentes palabras. De forma que:\nSiIM(w1; w2)\u00c00.Signi\ufb01ca que la palabra w1, aparece junto a\nla palabra w2m\u00b4 as a menudo de lo que a simple vista podr\u00b4 \u0131a\nparecer.\nSiIM(w1; w2)\u00bf0.Signi\ufb01ca que la palabra w1, aparece junto a\nla palabra w2menos frecuentemente de lo que cabr\u00b4 \u0131a pensar.\nSiIM(w1; w2)\u00bc0.Indica que no existe ninguna evidencia que\nrelacione la palabra w1con la palabra w2.\nPor ejemplo, en la tabla 5.3se muestra la Informaci\u00b4 on Mu-\ntua de la palabra \u201cdrink\u201d junto con sus posibles objetos directos\nextra\u00b4 \u0131dos de una serie de documentos:\nPodemos observar que existen palabras que aparecen con mu-\ncha frecuencia junto a \u201cdrink\u201d como son: \u201cwater\u201d ,\u201cbeer\u201d ,\u201calco-\nhol\u201d... Pero sin embargo, el valor dado por la IM es menor que\nel obtenido para otras palabras cuya frecuencia de aparici\u00b4 on es\nmenor como: \u201cmartinis\u201d ,\u201ccup of water\u201d ,\u201cchampagne\u201d ... Esta\npeculiaridad es debida a que la IM mide las relaciones sem\u00b4 anti-\ncas entre palabras no s\u00b4 olo a partir de su frecuencia de aparici\u00b4 on\nlocal, sino tambi\u00b4 en de su frecuencia de aparici\u00b4 on global. Debido a\n5. M\u00b4 etodos 113\nObjeto directo\nIM\nFrecuencia\nmartinis\n12;6\n3\ncup of water\n11;6\n3\nchampagne\n10;9\n3\nbeverage\n10;8\n8\ncup of tea\n10;6\n2\ncognac\n10;6\n2\nbeer\n9;9\n29\ncup\n9;7\n6\nco\ufb00ee\n9;7\n12\ntoast\n9;6\n4\nalcohol\n9;4\n20\nwine\n9;3\n10\n\ufb02uid\n9;0\n5\nliquor\n8;9\n4\ntea\n8;9\n5\nmilk\n8;7\n8\njuice\n8;3\n4\nwater\n7;2\n43\nquantity\n7;1\n4\nTabla 5.3. IM de la palabra \u201cdrink\u201d con sus posibles objetos directos\nello, las palabras que aparecen casi exclusivamente junto a otras\ntender\u00b4 an a tener una relaci\u00b4 on sem\u00b4 antica m\u00b4 as fuerte que otras pa-\nlabras demasiado frecuentes en el corpus, lo que indica que tienen\nun uso gen\u00b4 erico y por tanto, una relaci\u00b4 on sem\u00b4 antica m\u00b4 as d\u00b4 ebil.\nLa medida de la Informaci\u00b4 on Mutua ha sido utilizada pa-\nra medir la similitud entre palabras ( Dagan et al. (1993 ), (Lin\n(1998a )), (Pekar y Krkoska (2003 )), extracci\u00b4 on de sin\u00b4 onimos ( Tur-\nney(2001 )) y tambi\u00b4 en para extracci\u00b4 on de colocaciones ( Church\net al. (1991 )).\nEn este trabajo, se utiliza la f\u00b4 ormula de la Informaci\u00b4 on Mutua\nen una forma m\u00b4 as relajada Yarowsky (1992 ), es decir, nos intere-\nsan aquellas palabras que aparecen m\u00b4 as a menudo en el contexto\nde un dominio, con respecto a otros (palabras signi\ufb01cativas con\nrespecto a un dominio).\n114 5.1 WSD basado en conocimiento: DRelevant\nIM(w; D) = log2P(w; D)\nP(w)P(D)= log2P(Djw)\nP(D)= log 2P(wjD)\nP(w)\n(5.3)\nEn la Tabla 5.4se muestran los resultados obtenidos tras el\nc\u00b4 alculo de la Informaci\u00b4 on Mutua de la palabra \u201cplant\u201d en Word-\nNet Domains.\n5.1.4.1 Perfeccionamiento de la Informaci\u00b4 on Mutua.\nEl valor obtenido por la f\u00b4 ormula de la Informaci\u00b4 on Mutua 5.3,\nmide la importancia de las palabras frente a un dominio de WND.\nPero este valor no re\ufb02eja exactamente la relevancia que tiene una\npalabra con respecto a un determinado dominio. Es por tanto\nnecesario establecer la frecuencia local de una palabra con respec-\nto a cada dominio para poder establecer de forma espec\u00b4 \u0131\ufb01ca la\nrelevancia de esa palabra.\nEsta nueva forma de establecer la relevancia de una palabra w\nsobre un dominio Dse mide a trav\u00b4 es de la f\u00b4 ormula del Ratio de\nAsociaci\u00b4 on (RA) ( Rigau (1998 ),Framis (1994 )).\nLa f\u00b4 ormula del Ratio de Asociaci\u00b4 on se muestra en 5.4.\nRA(w; D) =Pr(wjD) log 2Pr(wjD)\nPr(w)(5.4)\nLa Tabla 5.5, muestra el resultado tras la uni\u00b4 on de los dos\nconceptos: importancia (IM) y relevancia (RA) de una palabra\nfrente a un dominio. Los resultados demuestran que existen casos\npara los que la IM asigna mayor peso y que ahora mediante el RA\nquedan relegados a posiciones inferiores. V\u00b4 eanse por ejemplo, los\nresultados referidos al dominio Religion en ambas Tablas 5.4y\n5.5:\nReligion \u00a15;904181(IM)\nReligion \u00a10;000472(RA).\nQueda patente por tanto, la necesidad de identi\ufb01car correcta-\nmente la relevancia de una palabra con respecto a un dominio,\npara as\u00b4 \u0131 evitar una ponderaci\u00b4 on err\u00b4 onea usando la medida IM,\nque no tiene en cuenta la frecuencia local asociada ( P(wjD)).\n5. M\u00b4 etodos 115\nDominio\nIM\nreligion\n5,904181\nmilitary\n5,799872\nphysics\n5,30723\nfashion\n4,950001\nadministration\n4,596772\ntransport\n4,254565\ngeography\n4,220493\ntown planning\n4,076359\ntime period\n3,940711\neconomy\n3,877388\nquality\n3,611403\nelectricity\n3,471225\npsychology\n3,451331\nsexuality\n3,444749\nmeteorology\n3,292426\ngeology\n3,08912\nfactotum\n3,076359\nagriculture\n2,8921\ncommerce\n2,890722\ntheatre\n2,793567\nzootechnics\n2,701343\nart\n2,661958\nbotany\n2,552171\nbiology\n2,449791\narchitecture\n2,345\ntelecommunication\n2,172187\nphysiology\n1,908697\nzoology\n1,611403\nentomology\n1,589572\nbuilding industry\n1,575955\narchaeology\n1,473461\nmountaineering\n1,457541\nalimentation\n1,071378\nanatomy\n0,978776\nmedicine\n0,838633\necology\n0,768773\nbody care\n0,701079\nengineering\n0,65199\nanthropology\n0,545312\npure science\n0,508863\nindustry\n0,459295\npharmacy\n0,389059\nenterprise\n0,323433\ncolor\n0,320542\ngenetics\n0,277378\ngastronomy\n0,211381\nchemistry\n0,017062\nTabla 5.4. IM para \u201cplant\u201d en WND\nDominio\nRA\nagriculture\n0;102860\nbotany\n0;071716\nbiology\n0;064123\nentomology\n0;022920\narchaeology\n0;019603\nmountaineering\n0;019178\nalimentation\n0;010787\necology\n0;006275\nindustry\n0;003025\nbuilding\nindustry\n0;002533\npharmacy\n0;002441\nphysiology\n0;002435\nanatomy\n0;002379\nmedicine\n0;002247\narchitecture\n0;002211\nbody\ncare\n0;002066\nart\n0;002015\nengineering\n0;001988\nenterprise\n0;001939\ncolor\n0;001918\ncommerce\n0;001867\nanthropology\n0;001790\nfactotum\n0;001747\ngeology\n0;001739\nmeteorology\n0;001610\nelectricity\n0;001500\neconomy\n0;001264\ngastronomy\n0;001173\ngenetics\n0;001096\ngeography\n0;001085\nadministration\n0;000910\nfashion\n0;000767\nphysics\n0;000642\nmilitary\n0;000499\nchemistry\n0;000083\npsychology\n0;001512\nzootechnics\n0;084177\nzoology\n0;002527\ntelecommunication\n0;002309\ntheatre\n0;001930\npure\nscience\n0;001713\nsexuality\n0;001516\npsychology\n0;001512\nquality\n0;001416\ntown\nplanning\n0;001158\ntransport\n0;001068\nreligion\n0;000472\nTabla 5.5. RA para \u201cplant\u201d en WND\n116 5.1 WSD basado en conocimiento: DRelevant\n5.1.5 Vectores de co-ocurrencia\nUna vez establecida la medida de co-ocurrencia para determi-\nnar la similitud entre palabras y dominios ( RA(wjD)), es nece-\nsario hallar una forma de obtener una medida de similitud entre\npares de palabras, contextos, etc. Para este tipo de tarea se utili-\nzan los vectores de co-ocurrencia.\nVeamos con un ejemplo sencillo la forma de obtener vectores\nde co-ocurrencia para una palabra determinada. Supongamos que\nencontramos el texto de la Figura 5.5.\n \nA bottle of tecuino is on the table. \n \nEverybody likes tecuino. \n \nTecuino makes you drunk. \n \nWe make tecuino out of corn. Its bottle can be on the table. \n \nLiked by everyone. \n \nMakes you drunk. \n \nMade out of corn. \n TEXTO CONTEXTO \nFigura 5.5. Determinaci\u00b4 on del signi\ufb01cado de \u201ctecuino\u201d\nDada la palabra \u201ctecuino\u201d de la cual no sabemos su signi\ufb01cado,\nse puede inferir su sentido de acuerdo a las palabras que la rodean:\n\u201cYou shall know a word by the company it keeps!\u201d ( Firth (1957 )).\nEn este caso, a partir del contexto podemos deducir que el \u201cte-\ncuino\u201d podr\u00b4 \u0131a ser una bebida alcoh\u00b4 olica hecha de ma\u00b4 \u0131z. Esta idea\nintuitiva puede capturarse utilizando un vector cuyas componen-\ntes podr\u00b4 \u0131an ser las palabras que rodean a la palabra \u201ctecuino\u201d , pa-\nra posteriormente compararlo con vectores de otras palabras como\npor ejemplo \u201cbeer\u201d, \u201cwine\u201d o \u201ctequila\u201d. De esta forma, se podr\u00b4 \u0131a\ndeterminar que cualquier tipo de bebida alcoh\u00b4 olica comparte mu-\nchas de las componentes de la palabra en cuesti\u00b4 on, concluyendo\npor tanto: \u201ctecuino\u201d \u00b4bebida alcoh\u00b4 olica.\nA partir de esta idea intuitiva se puede representar cualquier\npalabra con un vector de caracter\u00b4 \u0131sticas (features). Estas ca-\nracter\u00b4 \u0131sticas pueden ser las palabras del contexto (usando una\nventana de un tama\u02dc no espec\u00b4 \u0131\ufb01co), las categor\u00b4 \u0131as sint\u00b4 acticas, los\n5. M\u00b4 etodos 117\nobjetos directos, etc. Por ejemplo, supongamos que tenemos fi\ncaracter\u00b4 \u0131sticas binarias que indican si una palabra west\u00b4 a (1)\no no (0) en un contexto XdeNpalabras. Podr\u00b4 \u0131amos repre-\nsentar mediante un vector cualquier palabra w, de forma que:\u00a1 !w=ff1; f2; f3; :::f Ng. Si la palabra w=\u201ctecuino\u201d y las pala-\nbras del contexto fueran \u201cbottle\u201d, \u201cdrunk\u201d y\u201cmatrix\u201d , el vector\nobtenido ser\u00b4 \u0131a:\u00a1 !w=f1;1;0; :::g.\nEntonces, dadas cualquier par de palabras ( w1; w2), cada una\nrepresentada por su vector de caracter\u00b4 \u0131sticas (\u00a1 !w1;\u00a1 !w2), se podr\u00b4 \u0131a\ndeterminar su similitud mediante la utilizaci\u00b4 on de una medida que\ncalcule la proximidad de los dos vectores de caracter\u00b4 \u0131sticas.\nEn la Tabla 5.6se muestra de forma intuitiva los vectores de\nco-ocurrencia de cuatro palabras \u201capricot\u201d \u201cpineapple\u201d, \u201cdigital\u201d\ne\u201cinformation\u201d . Estos ejemplos han sido extra\u00b4 \u0131dos utilizando un\ncontexto de dos l\u00b4 \u0131neas del Brown Corpus.\nPartiendo de esta representaci\u00b4 on es evidente la necesidad de\nuna medida que establezca un grado de similitud muy elevado\nentre \u201capricot\u201d y\u201cpineapple\u201d y entre \u201cdigital\u201d e\u201cinformation\u201d ,\ny adem\u00b4 as devuelva un valor de similitud muy bajo entre los pares\nde palabras que no tienen nada en com\u00b4 un.\narts\nboil\ndata\nfunction\nlarge\nsugar\nsummarized\napricot\n0\n1\n0\n0\n1\n1\n0\npineapple\n0\n1\n0\n0\n1\n1\n0\ndigital\n0\n0\n1\n1\n1\n0\n1\ninformation\n0\n0\n1\n1\n1\n0\n1\nTabla 5.6. Vectores de co-ocurrencia Brown Corpus\nComo conclusi\u00b4 on se extrae que para determinar el grado de\nsimilitud entre dos palabras es necesario:\n1.De\ufb01nir el tipo de caracter\u00b4 \u0131sticas utilizadas para crear los vec-\ntores.\n2.De\ufb01nir la ventana contextual de extracci\u00b4 on de informaci\u00b4 on.\n3.Determinar el valor que se le da a cada caracter\u00b4 \u0131stica del vector\n(binario, frecuencia, Informaci\u00b4 on Mutua...)\n118 5.1 WSD basado en conocimiento: DRelevant\n4.M\u00b4 etrica que establezca la distancia entre dos vectores (coseno,\ndistancia eucl\u00b4 \u0131dea...)\n5.1.5.1 WND y SUMO como caracter\u00b4 \u0131sticas.\nEn el ejemplo anterior se han utilizado como caracter\u00b4 \u0131sticas pa-\nra construir el vector de co-ocurrencia, las palabras que aparecen\nen un contexto de tama\u02dc no N. La aproximaci\u00b4 on que se propone\nen este trabajo es la utilizaci\u00b4 on de las categor\u00b4 \u0131as sem\u00b4 anticas de\nWND y SUMO como caracter\u00b4 \u0131sticas para construir los vectores de\nco-ocurrencia. De esta forma, se evita la creaci\u00b4 on de vectores con\nun elevado n\u00b4 umero de caracter\u00b4 \u0131sticas, muchas veces irrelevantes a\nla hora de establecer la similitud entre dos palabras.\nA continuaci\u00b4 on se muestra un ejemplo para WND:\nDada la frase:\n\u201cThere are a number of ways in which the chromosome struc-\nture can change, which will detrimentally change the genotype and\nphenotype of the organism\u201d\nLos pasos a seguir para obtener el vector de caracter\u00b4 \u0131sticas son:\nExtracci\u00b4 on de palabras del contexto. Se extraen aquellas\npalabras con contenido sem\u00b4 antico, omitiendo las stop words\n(art\u00b4 \u0131culos, preposiciones, ...). El resultado es una lista con:\nfnumber, way, chromosome structure change detrimentally ge-\nnotype phenotype organism g.\nAsignaci\u00b4 on de dominios relevantes. Para cada una de estas\npalabras se extraen sus dominios relevantes (calculados previa-\nmente con el Ratio de Asociaci\u00b4 on).\nPonderaci\u00b4 on de dominios. Se establecen cu\u00b4 ales son los domi-\nnios m\u00b4 as relevantes del contexto. Para ello, se ponderan aquellos\ndominios que aparecen en mayor n\u00b4 umero de palabras tal y como\nse muestra en la F\u00b4 ormula 5.5.\nPeso\nDom i=Dom\nwNX\nDom\nwiRADom i (5.5)\nLos pesos de aquellos dominios que aparecen en distintas pala-\nbras se van agregando de forma que, \ufb01nalmente se obtiene una\n5. M\u00b4 etodos 119\nlista de dominios no repetidos, de las palabras que intervienen\nen el contexto.\nLa Figura 5.6muestra el vector de caracter\u00b4 \u0131sticas obtenido\npara el ejemplo anterior.\n8\n>>>>>>>>>>><\n>>>>>>>>>>>:Biology 0.03102837\nEcology 0.00402855\nBotany 0.00003204\nZoology 0.00001779\nAnatomy 0.00001295\nPhysiology 0.000001002\nChemistry 0.00000100017\n...\nFigura 5.6. Vector de co-ocurrencia usando WND\nUna vez generado el vector de caracter\u00b4 \u0131sticas, es necesario me-\ndir la similitud entre diferentes vectores utilizando alguna m\u00b4 etrica\nespec\u00b4 \u0131\ufb01ca de comparaci\u00b4 on de vectores.\n5.1.6 M\u00b4 etricas sobre vectores\nGracias al vector de caracter\u00b4 \u0131sticas cuya obtenci\u00b4 on se ha co-\nmentado en la secci\u00b4 on anterior, es posible determinar el grado de\nsimilitud entre dos palabras o contextos.\nPara de\ufb01nir el grado de similitud entre dos palabras wyv, se\nnecesita una m\u00b4 etrica que tenga en cuenta los vectores asociados a\u00a1 !wy\u00a1 !vy obtenga un valor de similitud entre ambos. Las m\u00b4 etricas\nm\u00b4 as simples utilizadas para medir la distancia (o similitud) entre\nvectores son la Manhattan y la distancia Eucl\u00b4 \u0131dea. En la Figura\n5.7se muestra un gr\u00b4 a\ufb01co intuitivo de ambas m\u00b4 etricas aplicadas\nsobre dos vectores bidimensionales.\nLa distancia Manhattan tambi\u00b4 en conocida como la distancia\nde Levenshtein o norma L1 es:\nManhattan (\u00a1 !x ;\u00a1 !y) =NX\ni=1jxi\u00a1yij (5.6)\n120 5.1 WSD basado en conocimiento: DRelevant\n   \n \n \n \n \n \n \n b2 \na2 \na1 b1 ),(1),( Manhattan\u2192\u2192 \u2192\u2192\n== baLba\n),(2),(Euclidea\u2192\u2192 \u2192\u2192\n=baLba\u2192\nb\n\u2192\na\nFigura 5.7. Distancia Eucl\u00b4 \u0131dea y Manhattan\nLa distancia Eucl\u00b4 \u0131dea se de\ufb01ne como:\nEuclidea (\u00a1 !x ;\u00a1 !y) =vuut\nNX\ni=1(xi\u00a1yi)2 (5.7)\nA pesar de que estas dos m\u00b4 etricas proporcionan una medida\nde similitud muy intuitiva entre vectores, han sido muy poco uti-\nlizadas para medir similitud entre palabras. Esto es debido a que\nambas m\u00b4 etricas son muy sensibles a valores extremos.\nEn lugar de utilizar estas m\u00b4 etricas tan sencillas, la similitud\nentre palabras est\u00b4 a estrechamente relacionada con las m\u00b4 etricas\nutilizadas en Extracci\u00b4 on de Informaci\u00b4 on. Dado que los sistemas\nde extracci\u00b4 on de informaci\u00b4 on funcionan bastante bien a la hora\nde establecer la similitud entre palabras vamos a describir algunas\nde estas m\u00b4 etricas.\nUtilizando como ejemplo el vector de caracter\u00b4 \u0131sticas binarias\nmostrado en la Tabla 5.6, donde la similitud entre dos vectores\nera justamente el n\u00b4 umero de caracter\u00b4 \u0131sticas que ten\u00b4 \u0131an en com\u00b4 un,\npodemos asumir que tenemos un vector binario. De esta forma,\nse de\ufb01ne la m\u00b4 etrica de similitud utilizando el producto escalar,\ncomo sigue:\n5. M\u00b4 etodos 121\nProd\nescalar = (\u00a1 !v ;\u00a1 !w) =\u00a1 !v\u00a2\u00a1 !w=NX\ni=1vi\u00a3wi (5.8)\nEsta nueva m\u00b4 etrica asume que los vectores son binarios, pe-\nro ocurre como hemos visto en la secci\u00b4 on previa, que las carac-\nter\u00b4 \u0131sticas pueden almacenar valores de asociaci\u00b4 on entre palabras\nno binarios. Para este caso gen\u00b4 erico el vector de\ufb01nido para una\npalabra\u00a1 !wconNcaracter\u00b4 \u0131sticas f1:::fNes como sigue:\n\u00a1 !w= (asoc(w; f 1); asoc (w; f 2); :::asoc (w; f N)) (5.9)\nAhora se puede aplicar la m\u00b4 etrica del producto escalar sobre\nvectores que contienen valores de asociaci\u00b4 on, en lugar de valores\nbinarios. Pero el resultado proporcionado tiene un problema: favo-\nrece a los vectores m\u00b4 as largos. La longitud de un vector se de\ufb01ne\ncomo:\nj\u00a1 !vj=vuut\nNX\ni=1v2\ni (5.10)\nUn vector puede tener una longitud mayor debido a que tiene\nm\u00b4 as valores distintos de 0, o porque cada dimensi\u00b4 on tiene un valor\nm\u00b4 as elevado. Cualquiera de estos casos puede incrementar el re-\nsultado del producto escalar. Por tanto, si consideramos el vector\nasociado a una palabra muy frecuente, tendr\u00b4 a un mayor n\u00b4 umero\nde valores distintos de 0 y tendr\u00b4 a valores mayores en cada dimen-\nsi\u00b4 on (aunque se utilicen valores que controlen de alguna forma la\nfrecuencia). Por tanto, el producto escalar favorece a las palabras\nm\u00b4 as frecuentes.\nDebido a este problema, es necesario modi\ufb01car el producto es-\ncalar de forma que se normalicen los vectores y no se le d\u00b4 e m\u00b4 as\nimportancia a las palabras m\u00b4 as frecuentes. Este producto escalar\nnormalizado es el coseno del \u00b4 angulo formado por los dos vecto-\nres. Esta medida ha sido utilizada frecuentemente en sistemas de\nRecuperaci\u00b4 on de Informaci\u00b4 on ( Frakes y Baeza-Yates (1992 )) y ha\n122 5.1 WSD basado en conocimiento: DRelevant\nsido aplicada para calcular la similitud entre palabras a partir de\nsus relaciones gramaticales ( Ruge (1992 )).\nLa f\u00b4 ormula del coseno es la siguiente:\ncoseno (\u00a1 !x ;\u00a1 !y) =\u00a1 !x\u00a2\u00a1 !y\nj\u00a1 !xj \u00a3 j\u00a1 !yj=nX\ni=1xi\u00a3yi\ns\nnX\ni=1x2\ni\u00a3s\nnX\ni=1y2\ni(5.11)\nGracias a la normalizaci\u00b4 on de los vectores, la m\u00b4 etrica del co-\nseno no es sensible a valores extremos tal y como ocurr\u00b4 \u0131a con la\nManhattan y la Eucl\u00b4 \u0131dea. El coseno abarca desde 1 para vectores\nmuy pr\u00b4 oximos entre s\u00b4 \u0131 hasta 0 para vectores ortogonales que no\ntienen ninguna caracter\u00b4 \u0131stica en com\u00b4 un y \u00a11 para vectores apun-\ntando en direcciones opuestas (en la pr\u00b4 actica los valores tienden\na ser positivos).\nAdem\u00b4 as de la medida del coseno, existen otras medidas de\nsimilitud muy utilizadas en el campo de PLN. Entre las medidas\nm\u00b4 as representativas destacan: la medida de Kullback-Leibler (o\nentrop\u00b4 \u0131a relativa) ( Cover y Thomas (1991 )), la medida de Jensen-\nShannon (o radio de informaci\u00b4 on) ( Rao(1982 ),Lin(1991 )) y el\ncoe\ufb01ciente de Jaccard ( Jaccard (1901 )). A continuaci\u00b4 on se de\ufb01nen\ncada una de ellas.\nKL(\u00a1 !xjj\u00a1 !y) =nX\ni=1xilogxi\nyi(5.12)\nLa medida de Kullback-Leibler (KL) 5.12 determina la si-\nmilitud entre dos distribuciones x=fxigey=fyigy ha\nsido utilizada en ( Dagan et al. (1994 )) para medir la simili-\ntud entre palabras. Esta medida no es sim\u00b4 etrica, de forma que,\nKL(\u00a1 !xjj\u00a1 !y)6=KL(\u00a1 !yjj\u00a1 !x). Los valores que obtiene se encuentran\nentre 0 e in\ufb01nito y \u00b4 unicamente adopta el valor de 0 cuando las\ndos distribuciones son exactamente iguales.\n5. M\u00b4 etodos 123\nJS(\u00a1 !x ;\u00a1 !y) =1\n2[KL(\u00a1 !xjj\u00a1 !x+\u00a1 !y\n2) +KL(\u00a1 !yjj\u00a1 !x+\u00a1 !y\n2)] (5.13)\nLa medida de Jensen-Shannon (JS) 5.13, ha sido utilizada para\nmedir la similitud entre palabras en ( Dagan et al. (1997 ),Lee\n(1997 )). Esta medida es la media de la suma de los dos valores de\ndivergencia de KL entre las distribuciones xey, tomando valores\nentre 0 y 2 log 2.\nJaccard (\u00a1 !x ;\u00a1 !y) =jfi:xi>0^yi>0gj\njfi:xi>0_yi>0gj(5.14)\nEl coe\ufb01ciente de Jaccard 5.14mide la similitud entre dos dis-\ntribuciones de datos. Dados dos conjuntos xeyel resultado de\nesta medida es la cardinalidad de su intersecci\u00b4 on dividida por la\ncardinalidad de su uni\u00b4 on.\nAdem\u00b4 as de las mencionadas anteriormente existen otras pro-\npuestas de m\u00b4 etricas de similitud. Una comparaci\u00b4 on entre las di-\nferentes m\u00b4 etricas de similitud la encontramos en ( Dagan et al.\n(1999 )) y ( Lee(1999 )).\nPor su simplicidad y adaptaci\u00b4 on a diferentes tama\u02dc nos de los\ncontextos, en este trabajo se ha optado por utilizar la m\u00b4 etrica del\ncoseno para evaluar la similitud entre vectores de caracter\u00b4 \u0131sticas.\n5.1.7 Determinaci\u00b4 on del sentido correcto\nEl objetivo del m\u00b4 etodo DRelevant es determinar el sentido\ncorrecto de las palabras polis\u00b4 emicas que aparecen en un contexto\ndeterminado. Hasta ahora se han extra\u00b4 \u0131do los dominios relevantes\na partir de WND y SUMO, se han de\ufb01nido los vectores de ca-\nracter\u00b4 \u0131sticas que van a modelar el espacio sem\u00b4 antico de palabras,\nfrases, p\u00b4 arrafos, etc y por \u00b4 ultimo se ha establecido la m\u00b4 etrica de\nsimilitud entre vectores. El \u00b4 ultimo paso es la determinaci\u00b4 on del\nsentido correcto de cada palabra utilizando toda la informaci\u00b4 on\nobtenida a partir del contexto y de WND y SUMO.\nA continuaci\u00b4 on se va a explicar la mec\u00b4 anica del proceso me-\ndiante un ejemplo aplicado sobre WND.\n124 5.1 WSD basado en conocimiento: DRelevant\n5.1.7.1 Ejemplo ilustrativo sobre WND.\nSupongamos que queremos desambiguar la palabra \u201cimage\u201d\ndel siguiente texto extra\u00b4 \u0131do del British National Corpus (BNC):\n\u201cA successful description of a self-portrait may not be di\ufb03cult,\nbut an illuminating interpretation may call on many references,\nespecially other artists\u2019 pictures of themselves. What can be dedu-\nced from a self-portrait is often controversial; a critic is especially\nlikely to read into a self-portrait some opinion held about the ar-\ntist. When, as in the cases of Rembrandt and Van\nGogh, there is\na whole series of pictures to choose from, books can be written on\nthe self- images of one artist alone. This theme is a useful one\nfor assessing the quality of a critic\u2019s writing, since it tempts the\nrash into speculation, while an impoverished eye will miss rele-\nvant and useful comparisons. A theme where personal psychology\nis necessarily absent is the Christian subject of the Madonna and\nChild.\u201d\nEl primer paso, es construir el vector de contexto que modela\nsem\u00b4 anticamente el contenido del p\u00b4 arrafo donde aparece la palabra\nambigua. Se utiliza un POS-tagger para obtener los lemas de todas\nlas palabras y extraer sus correspondientes dominios relevantes.\nEl resultado es un vector de caracter\u00b4 \u0131sticas obtenido a partir de\nlos dominios relevantes de todas las palabras del contexto.\nEn la Figura 5.8se muestran los lemas obtenidos a partir del\ncontexto. Y en la Figura 5.9se muestra el vector de contexto\nobtenido a partir de los Dominios Relevantes.\nEl segundo paso, es obtener un segundo vector con el que es-\ntablecer el grado de similitud con el vector de contexto extra\u00b4 \u0131do\nanteriormente. Dado que se desea obtener el sentido correcto de\nla palabra \u201cimage\u201d , es necesario disponer de vectores de carac-\nter\u00b4 \u0131sticas que modelen cada uno de los posibles sentidos de esta\npalabra. Para ello, se utilizan las glosas de WordNet. Es decir,\npara cada uno de los sentidos de \u201cimage\u201d se extrae su glosa y se\nconstruye un vector de caracter\u00b4 \u0131sticas, denominado en este caso\nvector de sentido.\n5. M\u00b4 etodos 125\nNOMBRES\ndescription self portrait interpretation reference artist picture opi-\nnion case Van Gogh series book image theme one quality critic wri-\nting rash speculation eye comparison writing rash psychology subject\nMadonna Child\nVERBOS\nbe call deduce read hold choose write assess tempt miss\nADJETIVOS\nsuccessful di\ufb03cult illuminating many other controversial likely whole\nuseful impoverished relevant personal absent Christian\nFigura 5.8. Lemas del contexto\n8\n>>>>>>>>>>>>>>>><\n>>>>>>>>>>>>>>>>:doctrines 0.000264501\nart 0.000252649\nhistory 0.00016812\nheraldry 0.000243991\nlinguistics 0.000148377\ngrammar 0.000276004\nliterature 0.000195926\nphilology 0.00118873\nphilosophy 0.000871316\n...\nFigura 5.9. Vector de contexto\nEn la Tabla 5.7se muestran los 7 sentidos para \u201cimage\u201d con\nsus respectivas glosas.\nEn la Figura 5.10se muestran los vectores de sentido para los\n3 primeros sentidos de \u201cimage\u201d .\nEl tercer paso, una vez obtenidos los distintos vectores de senti-\ndo, es medir el grado de similitud entre cada uno de estos vectores\ny el vector de contexto. Aquel vector de sentido cuyo coseno con\nel vector de contexto obtenga el mayor valor, ser\u00b4 a el elegido como\nel sentido correcto de la palabra \u201cimage\u201d .\nEn este ejemplo, el sentido correcto para \u201cimage\u201d es el 2. Tal\ny como muestra la Figura 5.11, el resultado del coseno entre el\nvector de contexto y cada uno de los vectores de sentido demuestra\nque el sentido m\u00b4 as adecuado en este caso ser\u00b4 \u0131a el 2.\n126 5.1 WSD basado en conocimiento: DRelevant\nSynset\nDominio\nSentido\nGlosa\n04551473\nfactotum\nimage#1\nan iconic mental representation; \u201cher ima-\ngination forced images upon her too awful\nto contemplate\u201d\n03685960\npsychology\nimage#2\n(Jungian psychology) a personal facade\none presents to the world; \u201ca public image\nis as fragile...\n03118233\nfactotum\nimage#3\na visual representation of an object or sce-\nne or person produced on a surface; \u201cthey\nshowed us the...\n04559702\nfactotum\nimage#4\na standard or typical example; \u201che is the\nprototype of good breeding\u201d; \u201che provided\nAmerica with a...\n05317127\nliterature\nimage#5\nlanguage used in a \ufb01gurative or... nonlite-\nral sense\n07223613\nperson\nimage#6\nsomeone who closely resembles a famous\nperson (especially an actor); \u201che could be\nGingrich\u2019s double\u201d...\n02622723\nfactotum\nimage#7\na likeness of a person (especially in the\nform of sculpture); \u201cthe coin bears an ef-\n\ufb01gy of Lincoln...\nTabla 5.7. Glosas para \u201cimage\u201d\nimage#1 image#2 image#38\n>>>>>>>>>>>>>>>><\n>>>>>>>>>>>>>>>>:rowing 0.006974\ntable\ntennis 0.003351\nphotography 0.003125\npsychiatry 0.002593\nradiology 0.001896\ntv 0.001804\nstatistics 0.001599\nauto 0.001161\ntennis 0.001119\n...8\n>>>>>>>>>>>>>>>><\n>>>>>>>>>>>>>>>>:plastic\narts 0.003155\nwrestling 0.003151\ncycling 0.003146\nastrology 0.002747\nsurgery 0.002375\npost 0.002209\napplied\nscience 0.001851\nelectrotechnics 0.001670\nnumber 0.001574\n...8\n>>>>>>>>>>>>>>>><\n>>>>>>>>>>>>>>>>:plastic\narts 0.002746\napplied\nscience 0.001671\nastrology 0.001606\nelectrotechnics 0.001547\nradiology 0.001544\ncinema 0.001338\ntextiles 0.001331\ntv 0.001205\nsculpture 0.001091\n...\nFigura 5.10. Vectores de sentido para \u201cimage\u201d\nEn la Figura 5.12se muestra gr\u00b4 a\ufb01camente todo el proceso nece-\nsario para obtener el sentido de una palabra a partir del contexto\nque la rodea. Este proceso requiere el establecimiento en primer\nlugar de la cantidad de palabras que van a formar parte del con-\ntexto (ventana de Npalabras, p\u00b4 arrafo, oraci\u00b4 on...) y a partir de\nah\u00b4 \u0131 comienza la tarea de desambiguaci\u00b4 on.\n5. M\u00b4 etodos 127\n04551473\u2014factotum \u2014image#1\u2014 0.161629\n03685960\u2014psychology \u2014image#2\u2014 0.79989\n03118233\u2014factotum \u2014image#3\u2014 0.485136\n04559702\u2014factotum \u2014image#4\u2014 0.54842\n05317127\u2014literature \u2014image#5\u20140.111334\n07223613\u2014person \u2014image#6\u2014 0.690172\n02622723\u2014factotum \u2014image#7\u2014 0.149694\nFigura 5.11. Resultado del coseno entre VC y VS\u2019s\n  \nContexto \nDominios \nRelevantes POS \nTagger WordNet \nGlosas \nVector \nContexto Vector \nSentido#1 W \nVector \nSentido#2 Vector \nSentido#N \nCos(S#1) Cos(S#2) Cos(S#N) W W \nW W W W \nW W W \nFigura 5.12. Sistema DRelevant\n128 5.1 WSD basado en conocimiento: DRelevant\n5.1.8 Extended WordNet y Dominios Relevantes\nEn el proceso descrito anteriormente para la obtenci\u00b4 on de los\nDominios Relevantes a partir de las glosas de WordNet Domains,\nla hip\u00b4 otesis fundamental era que las palabras de la glosa que de\ufb01-\nnen un sentido de una palabra est\u00b4 an relacionadas sem\u00b4 anticamente,\ny por tanto, es muy probable que compartan el mismo dominio.\nComo resultado, usando la informaci\u00b4 on proporcionada por el do-\nminio asociado al sentido de la palabra, se etiquetaron las palabras\nde la glosa y se extrajeron los Dominios Relevantes para cada pa-\nlabra de WordNet. Sin embargo, este proceso podr\u00b4 \u0131a ser mejorado\nsi se tuvieran en cuenta los sentidos correctos de las palabras de\nlas glosas, ya que, de esta forma la anotaci\u00b4 on ser\u00b4 \u0131a mucho m\u00b4 as\nprecisa.\nDada la gran cantidad de aplicaciones actuales que utilizan\nWordNet como fuente de informaci\u00b4 on: sistemas de WSD, RI, QA,\netc, que requieren de informaci\u00b4 on l\u00b4 ogica y sem\u00b4 antica adicional\n(de la que WordNet carece), se ha planteado la mejora de este\nrecurso mediante la incorporaci\u00b4 on de informaci\u00b4 on sint\u00b4 actica, l\u00b4 ogi-\nca y sem\u00b4 antica, en el denominado Extended WordNet ( Harabagiu\net al. (1999 ),Mihalcea y Moldovan (2001 )). Este nuevo recurso\nha incorporado informaci\u00b4 on adicional a las glosas de WordNet, de\nforma que cada palabra de las glosas viene acompa\u02dc nada de infor-\nmaci\u00b4 on sint\u00b4 actica, lema, sentido, etc. Un ejemplo de esta nueva\nanotaci\u00b4 on se muestra en la Figura 5.13.\nSeg\u00b4 un muestra la Figura 5.13, hay tres fuentes de informaci\u00b4 on\na\u02dc nadidas a la glosa inicial:\nInformaci\u00b4 on sem\u00b4 antica. Comprendida entre las etiquetas\n<wsd> </wsd>. A cada palabra de la glosa se le asigna su\ncorrespondiente sentido, utilizando para ello un proceso semi-\nautom\u00b4 atico de desambiguaci\u00b4 on.\nInformaci\u00b4 on sint\u00b4 actica. Comprendida entre las etiquetas <parse >\n</parse >. Se extraen las categor\u00b4 \u0131as morfosint\u00b4 acticas de cada\nelemento que conforma la glosa.\nInformaci\u00b4 on l\u00b4 ogica. Comprendida entre las etiquetas <lft>\n</lft>. Se transforma cada glosa en su forma l\u00b4 ogica correspon-\ndiente.\n5. M\u00b4 etodos 129\n \n<gloss pos=\"NOUN\" synsetID=\"09786238\"> \n  <synonymSet>president</synonymSet>   \n <text> \n   the chief executive of a republic \n </text> \n  <wsd>  \n      <wf pos=\"DT\" >the</wf> \n      <wf pos=\"NN\" lemma=\"chief_executive\" quality=\"normal\" wnsn=\"2\" >  \n     chief_executive</wf> \n      <wf pos=\"IN\" >of</wf> \n      <wf pos=\"DT\" >a</wf>  \n      <wf pos=\"NN\" lemma=\"republic\" quality=\"normal\" wnsn=\"1\" >republic</wf> \n  </wsd> \n<parse quality=\"SILVER\"> \n(TOP (S (NP (NN president) ) \n        (VP (VBZ is)  \n            (NP (NP (DT the) (JJ chief) (NN executive) ) \n                (PP (IN of)  \n                    (NP (DT a) (NN republic) ) ) ) ) \n        (. .) ) )  \n</parse> \n <lft quality=\"GOLD\"> \n  president:NN(x1) -> chief_executive:NN(x1) of:IN(x1, x2) republic:NN(x2) \n </lft> \n</gloss> \nFigura 5.13. Extended WordNet para president#3\nEn nuestro caso, s\u00b4 olo vamos a utilizar la informaci\u00b4 on sem\u00b4 anti-\nca comprendida entre las etiquetas <wsd> </wsd>, para poder\nrealizar una anotaci\u00b4 on m\u00b4 as precisa de los dominios de las glosas de\nWordNet. As\u00b4 \u0131 pues, utilizando los sentidos de las palabras de las\nglosas, se extraen sus dominios asociados. De este modo, el recur-\nso l\u00b4 exico Dominios Relevantes mejorar\u00b4 a la calidad de anotaci\u00b4 on\nde las palabras de WordNet.\nUn ejemplo pr\u00b4 actico que demuestra la diferencia de anotaci\u00b4 on\nde WordNet Domains frente a Extended WordNet, es el mostrado\nen la Figura 5.14.\nEn este caso, se tiene la glosa asociada al sentido 3 de la palabra\n\u201cpresident\u201d , cuyos dominios asociados son Person yPolitics .\nEn la parte de la izquierda se muestra la anotaci\u00b4 on de dominios\n130 5.1 WSD basado en conocimiento: DRelevant\n \nSynset Dominios Palabra Glosa \n09786238 person politics president the chief executive of a republic \n \nWordNet  09786238   |  president \n \nthe chief_executive#2   of a   republic#1 \n person politics \nadministration \neconomy sociology \nExtWordNet 09786238 |  president \n \nthe chief_executive  of a republic \n person politics \nFigura 5.14. Extracci\u00b4 on de dominios con Extended WordNet\nmediante WordNet Domains, cuyo resultado es la asignaci\u00b4 on de\nlos dominios Person yPolitics a todas las palabras con con-\ntenido sem\u00b4 antico de la glosa. En la parte derecha se muestra el\nresultado de anotaci\u00b4 on tras utilizar Extended WordNet. En este\ncaso, al proporcionar el sentido correcto de las palabras de la glo-\nsa, se pueden extraer los dominos asociados a ellas, mejorando de\nesta forma la anotaci\u00b4 on.\nEn la Figura 5.15se muestra un ejemplo comparativo de ano-\ntaci\u00b4 on con respecto a la palabra \u201cpresident\u201d usando WordNet\nDomains y Extended WordNet.\nTal y como muestra la Figura 5.15, los Dominios Relevantes\npara \u201cpresident\u201d di\ufb01eren dependiendo de la fuente de informaci\u00b4 on\nutilizada. En ( V\u00b4 azquez et al. (2007 ))se compararon los resultados\nobtenidos por el m\u00b4 etodo de desambiguaci\u00b4 on DRelevant usando las\ndos alternativas. El an\u00b4 alisis posterior determin\u00b4 o que se obten\u00b4 \u0131an\nmejores resultados al utilizar los Dominios Relevantes enriqueci-\ndos con la informaci\u00b4 on de las glosas de Extended WordNet.\nLa evaluaci\u00b4 on del m\u00b4 etodo DRelevant se ha realizado sobre las\ntareas \u201cAll Words\u201d y\u201cLexical Sample\u201d deSenseval . Adem\u00b4 as, el\nrecurso l\u00b4 exico Dominios Relevantes ha sido empleado sobre otras\n5. M\u00b4 etodos 131\nDR WND DR ExtWN8\n>>>>>>>>>>>>>>>><\n>>>>>>>>>>>>>>>>:administration 0.001588\nbuilding\nindustry 0.000389\nart 0.000366\ncommerce 0.000420\neconomy 0.001077\nenterprise 0.000628\nfactotum 0.000385\ngeography 0.000321\nhistory 0.080090\n...8\n>>>>>>>>>>>>>>>><\n>>>>>>>>>>>>>>>>:politics 0.070828\nhistory 0.067804\nenterprise 0.002493\nmilitary 0.001694\neconomy 0.001420\nuniversity 0.001280\ntelecommunication 0.001030\nadministration 0.000949\nart 0.000795\n...\nFigura 5.15. Dominios Relevantes (DR) para \u201cpresident\u201d\ntareas de PLN como la resoluci\u00b4 on de la implicaci\u00b4 on textual. En el\nCap\u00b4 \u0131tulo de Evaluaci\u00b4 on se muestran los resultados obtenidos.\n5.2 WSD basado en conocimiento: DLSA\nEn el cap\u00b4 \u0131tulo anterior se hac\u00b4 \u0131a referencia a un modelo compu-\ntacional denominado LSA (An\u00b4 alisis de la Sem\u00b4 antica Latente). La\nidea de utilizar este modelo computacional para tratar el proble-\nma de la ambig\u00a8 uedad sem\u00b4 antica se debe a la capacidad que tiene\nLSA de adaptarse a cualquier idioma, contexto o circunstancia.\nEs decir, LSA es una t\u00b4 ecnica basada en modelos estoc\u00b4 asticos del\nsigni\ufb01cado o modelos sem\u00b4 anticos del lenguaje, la cual, no da im-\nportancia a las categor\u00b4 \u0131as l\u00b4 exicas, orden de las palabras, conjuga-\nciones verbales, etc.\nAunque inicialmente LSA fue concebida como una t\u00b4 ecnica pa-\nra Recuperaci\u00b4 on de Informaci\u00b4 on ( Deerwester et al. (1990 )), fue\nm\u00b4 as tarde en ( Landauer y Dumais (1997 )) cuando se propuso\nla utilizaci\u00b4 on de esta t\u00b4 ecnica para la adquisici\u00b4 on y representa-\nci\u00b4 on del conocimiento. A partir de entonces LSA ha sido aplicada\na diferentes \u00b4 areas: correcci\u00b4 on de textos en el \u00b4 ambito acad\u00b4 emico\n(Haley et al. (2005 )), cohesi\u00b4 on y coherencia de textos ( Graesser\net al. (2004 )), complemento de ontolog\u00b4 \u0131as ( Cederberg y Widdows\n(2003 )), categorizaci\u00b4 on de documentos ( Rosso et al. (2004 )), etc.\n132 5.2 WSD basado en conocimiento: DLSA\nEn cuanto a la tarea de WSD, LSA ya ha sido utilizada previa-\nmente, de forma que a partir de un algoritmo no supervisado se in-\nducen las similitudes entre palabras, bas\u00b4 andose en co-ocurrencias\nentre t\u00b4 erminos y contextos. Tal y como se describi\u00b4 o en el cap\u00b4 \u0131tulo\nanterior, la dimensi\u00b4 on del espacio vectorial inicial de la matriz se\nreduce utilizando la descomposici\u00b4 on en valores singulares. Final-\nmente, mediante la utilizaci\u00b4 on de t\u00b4 ecnicas de clustering, se iden-\nti\ufb01can los sentidos de las palabras ( Sch\u00a8 utze (1998 ),Widdows y\nPeters (2003 )).\nEn nuestro caso de estudio, LSA se utiliza para extraer in-\nformaci\u00b4 on sem\u00b4 antica a partir de la informaci\u00b4 on contextual y la\nco-ocurrencia de palabras. Posteriormente, la informaci\u00b4 on propor-\ncionada por LSA es utilizada como fuente de conocimiento para\nel nuevo m\u00b4 etodo de desambiguaci\u00b4 on autom\u00b4 atica DLSA.\n5.2.1 Base de datos l\u00b4 exica como fuente de conocimiento\nA medida que aumenta la cantidad de documentos que intervie-\nnen en la matriz original de LSA, tambi\u00b4 en aumenta la posibilidad\nde que un mismo t\u00b4 ermino aparezca en documentos distintos con el\nmismo signi\ufb01cado (palabras polis\u00b4 emicas). Esta circunstancia pro-\nduce como consecuencia la introducci\u00b4 on de ruido y confusi\u00b4 on en\nel espacio conceptual obtenido, ya que, cada documento se consi-\ndera independiente del resto. Una soluci\u00b4 on a este problema ser\u00b4 \u0131a\nla clasi\ufb01caci\u00b4 on inicial de los documentos a partir de diferentes\nt\u00b4 opicos, para as\u00b4 \u0131 mitigar los efectos de la distribuci\u00b4 on de palabras\nbajo el mismo sentido en diferentes documentos. Sin embargo,\nno existen actualmente sistemas lo su\ufb01cientemente precisos como\npara realizar esta clasi\ufb01caci\u00b4 on de forma autom\u00b4 atica, sin un costo\ncomputacional excesivo.\nAdem\u00b4 as del problema de la distribuci\u00b4 on de palabras polis\u00b4 emi-\ncas existe otro problema asociado a la utilizaci\u00b4 on de documentos\ncomo fuente de informaci\u00b4 on: el t\u00b4 opico tratado. Es decir, si para la\nobtenci\u00b4 on de datos se utilizan documentos relacionados, por ejem-\nplo, con medicina o biolog\u00b4 \u0131a, probablemente la palabra \u201cplanta\u201d\nestar\u00b4 a relacionada con palabras como: \u201cperenne\u201d, \u201cfotos\u00b4 \u0131ntesis\u201d,\n\u201cpolen\u201d, etc. Quedando relegados el resto de sentidos de la pala-\n5. M\u00b4 etodos 133\nbra \u201cplanta\u201d en favor del sentido asociado al t\u00b4 opico o registro de\nlos documentos. Por ello, para paliar los efectos de la utilizaci\u00b4 on\nde documentos como fuente de informaci\u00b4 on, es necesario utilizar\notro tipo de recurso que de alguna forma distribuya seg\u00b4 un crite-\nrios sem\u00b4 anticos las palabras polis\u00b4 emicas y sea independiente del\ndominio.\nPara solucionar los problemas derivados de la utilizaci\u00b4 on de\ndocumentos como fuente de informaci\u00b4 on, es necesario utilizar un\nrecurso que agrupe conceptos relacionados sem\u00b4 anticamente bajo\nuna serie de categor\u00b4 \u0131as gen\u00b4 ericas. Nuestra propuesta es la utiliza-\nci\u00b4 on de las categor\u00b4 \u0131as sem\u00b4 anticas de WND o SUMO, como fuente\nde conocimiento que agrupa palabras relacionadas sem\u00b4 anticamen-\nte y a partir de las cuales se puede construir una matriz concep-\ntual. De esta forma, se logra una matriz conceptual independiente\ndel dominio, ya que, se construye sobre una base de datos l\u00b4 exica\nque utiliza los conceptos de forma gen\u00b4 erica, donde cada aparici\u00b4 on\nde una palabra bajo una categor\u00b4 \u0131a sem\u00b4 antica (dominio) implica la\nasociaci\u00b4 on de un determinado sentido. Por tanto, se evita por una\nparte la dependencia del dominio que se daba en el caso de los\ndocumentos y adem\u00b4 as se soluciona el problema de la distribuci\u00b4 on\nde los mismos sentidos en diferentes documentos.\n5.2.2 LSA aplicado a WSD\nLa utilizaci\u00b4 on de categor\u00b4 \u0131as sem\u00b4 anticas como base para mode-\nlar los diferentes espacios contextuales de la matriz, proporcio-\nna informaci\u00b4 on muy \u00b4 util acerca de los sentidos de las palabras.\nAs\u00b4 \u0131 pues, a partir de los valores de similitud obtenidos tras apli-\ncar LSA sobre palabras, oraciones, o p\u00b4 arrafos, se puede establecer\na qu\u00b4 e dominio pertenece un determinado contexto. De esta forma,\nsi se intenta establecer el signi\ufb01cado de una palabra dentro de una\nfrase f1se realiza el c\u00b4 alculo sobre la matriz conceptual, obtenien-\ndo un listado con los dominios m\u00b4 as signi\ufb01cativos en relaci\u00b4 on a esa\nfrase (en lugar de los documentos m\u00b4 as similares). De este modo,\nes posible establecer el concepto sem\u00b4 antico sobre el que subyace\nun determinado contexto, y a partir de ah\u00b4 \u0131 se pueden determinar\nlos sentidos de las palabras que lo componen.\n134 5.2 WSD basado en conocimiento: DLSA\nEl m\u00b4 etodo que se propone en esta secci\u00b4 on utiliza como fuente\nde conocimiento la base de datos l\u00b4 exica WND y el recurso l\u00b4 exico\nDominios Relevantes. El proceso es el siguiente: a partir de la in-\nformaci\u00b4 on proporcionada por las glosas de WordNet Domains se\nconstruye la matriz conceptual, donde las columnas se correspon-\nden con los dominios de la jerarqu\u00b4 \u0131a de WND y las \ufb01las son las\npalabras de las glosas. Previamente a la obtenci\u00b4 on de la matriz\nse realiza la lematizaci\u00b4 on de todas las palabras, ya que, LSA con-\nsidera conceptos distintos, palabras en plural o en singular, o las\ndiferentes conjugaciones verbales. Los experimentos realizados en\n(V\u00b4 azquez et al. (2006 )), donde se utiliza la t\u00b4 ecnica de LSA para\ndeterminar la implicaci\u00b4 on textual, demuestran que tras la lema-\ntizaci\u00b4 on de las palabras que conforman la matriz conceptual los\nresultados mejoran.\nUna vez obtenida la matriz conceptual se realiza su descom-\nposici\u00b4 on en valores singulares reduciendo las dimensiones de la\nmatriz de 162 a 100. De esta forma, los dominios que est\u00b4 an den-\ntro de una subjerarqu\u00b4 \u0131a se agrupan y as\u00b4 \u0131 se consigue mantener\nuna mejor cohesi\u00b4 on sem\u00b4 antica en la matriz conceptual.\nTras la reducci\u00b4 on de dimensiones ya es posible determinar a\nqu\u00b4 e categor\u00b4 \u0131as sem\u00b4 anticas est\u00b4 a asociada una oraci\u00b4 on, un p\u00b4 arrafo,\netc. As\u00b4 \u0131 pues, se realiza la comparaci\u00b4 on entre el vector de palabras\npreviamente lematizadas del contexto de entrada con la matriz\nconceptual. El resultado es un listado con las categor\u00b4 \u0131as a las que\npertenece el contexto de entrada junto con su grado de similitud.\nA partir de las categor\u00b4 \u0131as (dominios) obtenidas como resultado\nde la aplicaci\u00b4 on de LSA, se han desarrollado una serie de heur\u00b4 \u0131sti-\ncas para determinar el sentido m\u00b4 as apropiado de las palabras del\ncontexto. Todas las heur\u00b4 \u0131sticas determinan el sentido de las pa-\nlabras del contexto inicial utilizando como fuente de informaci\u00b4 on\nlos dominios m\u00b4 as signi\ufb01cativos proporcionados por LSA.\n5.2.2.1 Heur\u00b4 \u0131stica 1: Ratio de Asociaci\u00b4 on.\nEsta heur\u00b4 \u0131stica utiliza los valores del Ratio de Asociaci\u00b4 on de\nlos Dominios Relevantes como base para determinar el sentido de\nlas palabras. En este caso, se extraen los 10 o 20 primeros domi-\n5. M\u00b4 etodos 135\nnios a partir de LSA. Estos dominios conforman un conjunto que\nse intersecciona con el conjunto de Dominios Relevantes de cada\nuno de los posibles sentidos de la palabra ambigua. De esta forma,\npara cada posible sentido, se seleccionan \u00b4 unicamente los dominios\ncompartidos con el resultado de LSA. El sentido seleccionado es\naquel con el valor m\u00b4 as elevado para los diferentes valores de RA\nobtenidos.\n5.2.2.2 Heur\u00b4 \u0131stica 2: Similitud LSA.\nEn esta heur\u00b4 \u0131stica \u00b4 unicamente se computan los valores de simi-\nlitud obtenidos por LSA. Cada dominio devuelto por LSA tiene\nasociado un valor de similitud. En este caso, si el dominio devuelto\npor LSA se encuentra entre los dominios relevantes de un deter-\nminado sentido de la palabra, se almacena su valor de similitud.\nEl resultado es el sumatorio de todos aquellos valores de simili-\ntud cuyos dominios se encuentran entre el listado de los dominios\nrelevantes de cada uno de los sentidos. El sentido elegido es aquel\ncuyo sumatorio es mayor.\n5.2.2.3 Heur\u00b4 \u0131stica 3: Similitud LSA \u00a3Ratio de Asocia-\nci\u00b4 on.\nEsta \u00b4 ultima heur\u00b4 \u0131stica determina el sentido de las palabras a\npartir del valor obtenido tras multiplicar el valor de similitud ob-\ntenido por LSA por el RA de los dominios de cada uno de los\nsentidos. En este caso, se le da preferencia a aquellos dominios\ncuyo valor de similitud obtenido por LSA es mayor. De esta for-\nma, se favorecen los dominios con mayor peso sem\u00b4 antico sobre la\nmatriz conceptual. Como en los casos anteriores el sentido selec-\ncionado es aquel con mayor valor.\n5.2.2.4 Ejemplo ilustrativo.\nSupongamos que tenemos el siguiente texto del que queremos\ndesambiguar el verbo \u201cadd\u201d:\n136 5.2 WSD basado en conocimiento: DLSA\n\u201cThe two Roman catholic priests, who were in all respects dedi-\ncated pastors and much liked by many in the local community, im-\nmediately opposed the idea, preaching against it at Sunday masses\nin the local convent and the school hall. The burden of the mes-\nsage was that good catholic parents sent their children to catholic\nschools. The curate added to this that those promoting the inte-\ngrated project were in fact promoting secularism. The fact that a\nprominent member of the current community council and an in-\ntegrated education supporter was a member of o\ufb03cial Sinn Fein,\nthe Workers\u2019 party, appeared to \ufb01gure in the reasoning, as this\nparty has always been suspected to be an anti - clerical and secu-\nlarist force. In residents\u2019 association meetings, the clergy\u2019s point\nof view received vocal support from one or two members of the\nolder village community which preceded the housing estate.\u201d\nEl primer paso es obtener los lemas de todas las palabras con\ncontenido sem\u00b4 antico (nombres, verbos adjetivos y adverbios). Una\nvez obtenidos los lemas se establece el grado de similitud entre el\nvector del contexto donde est\u00b4 a la palabra ambigua con respecto a\nla matriz conceptual de LSA (ver Figura 5.16).\nEn este caso, el resultado obtenido es:\n8\n>>>>>>>>>>>>>>>>>><\n>>>>>>>>>>>>>>>>>>:theatre 0.800681\nmusic 0.796623\nplay 0.795698\nskiing 0.786670\noptics 0.776752\nbadminton 0.775749\nbasketball 0.767051\nhockey 0.763763\ncard 0.762485\nsport 0.733817\n...\nFigura 5.16. Dominios Relevantes seg\u00b4 un LSA\nCon esta informaci\u00b4 on se procede a realizar la intersecci\u00b4 on con\ncada uno de los sentidos del verbo \u201cadd\u201d . Los tres primeros vec-\ntores de sentidos son los mostrados en la Figura 5.17.\n5. M\u00b4 etodos 137\nSentido 1 Sentido 2 Sentido 38\n>>>>>>>>>>>>>>>>>><\n>>>>>>>>>>>>>>>>>>:post 0.003351\ntable\ntennis 0.001158\nplastic\narts 0.000811\ntennis 0.000750\nbanking 0.000695\nartisanship 0.000641\nwrestling 0.000593\nphilately 0.000590\nschool 0.000504\nethnology 0.000483\n...8\n>>>>>>>>>>>>>>>>>><\n>>>>>>>>>>>>>>>>>>:oceanography 0.004109\nnumismatics 0.003551\nbasketball 0.003037\ntax 0.002671\noccultism 0.001521\nexchange 0.001425\narchery 0.000855\ndiving 0.000784\ngas 0.000708\npsychoanalysis 0.000699\n...8\n>>>>>>>>>>>>>>>>>><\n>>>>>>>>>>>>>>>>>>:badminton 0.003255\nwrestling 0.002423\nplastic\narts 0.002387\ncycling 0.002387\nsurgery 0.001844\nfootball 0.001549\napplied\nscience 0.001404\ncinema 0.001309\nuniversity 0.001072\nelectrotechnics 0.001055\n...\nFigura 5.17. Vectores de sentidos para \u201cadd\u201d\nTras la comparativa y extracci\u00b4 on de los dominios presentes en\nla intersecci\u00b4 on de cada vector de sentido con el vector de contexto\nobtenido a partir de LSA, el resultado utilizando la heur\u00b4 \u0131stica 2,\nes el mostrado en la Figura 5.18.\n8\n>>>>>>><\n>>>>>>>:add#1 - 9.644582\nadd#2 - 7.703261\nadd#3 - 6.741430\nadd#4 - 6.646582\nadd#5 - 6.737763\nadd#6 - 5.798008\nFigura 5.18. Selecci\u00b4 on del sentido correcto\nDe tal forma, que el sentido seleccionado \ufb01nalmente como el\napropiado para \u201cadd\u201d es el sentido 1.\n5.2.3 LSA aplicado a NED\nUn campo que actualmente est\u00b4 a teniendo una gran repercusi\u00b4 on\nes el relacionado con la detecci\u00b4 on y discriminaci\u00b4 on de entidades:\nnombres propios, lugares, organizaciones, etc.\nLa demanda de sistemas que por ejemplo, clasi\ufb01quen p\u00b4 aginas\nweb referentes a una determinada persona o una organizaci\u00b4 on,\n138 5.3 WSD basado en reglas ling\u00a8 u\u00b4 \u0131sticas sobre corpus\nes cada vez m\u00b4 as elevada. Esta necesidad surge debido a la gran\nproliferaci\u00b4 on de Internet en los \u00b4 ultimos a\u02dc nos, la aparici\u00b4 on de blogs,\np\u00b4 aginas personales, etc.\nAl igual que existen palabras polis\u00b4 emicas encontramos enti-\ndades nombradas que comparten la misma forma nominal pero\ndi\ufb01eren en signi\ufb01cado. Por ejemplo, las siglas ACM pertenecen\na: Association for Computing Machinery, Associaci\u00b4 o Catalana de\nMunicipis i Comarques, Actividades de Carpinter\u00b4 \u0131a de Madera,\nAsociaci\u00b4 on de Cel\u00b4 \u0131acos de Madrid, etc. En este caso, un sistema de\nclasi\ufb01caci\u00b4 on y discriminaci\u00b4 on deber\u00b4 \u0131a distinguir entre las distintas\nacepciones de ACM, bas\u00b4 andose primordialmente en los contextos\nde cada p\u00b4 agina. Es por ello, que hemos considerado la idea de\naprovechar las ventajas que proporciona LSA para determinar la\nsimilitud entre contextos y utilizarla para extraer aquellas p\u00b4 aginas\nweb o documentos que hagan referencia a una misma entidad.\nEn el apartado de Evaluaci\u00b4 on se muestran los resultados tras\nutilizar la t\u00b4 ecnica de LSA para desambiguaci\u00b4 on y discriminaci\u00b4 on\nde nombres propios.\n5.3 WSD basado en reglas ling\u00a8 u\u00b4 \u0131sticas sobre\ncorpus\nUno de los principales problemas en la resoluci\u00b4 on autom\u00b4 atica\nde la ambig\u00a8 uedad sem\u00b4 antica, radica en la falta de utilizaci\u00b4 on de co-\nnocimiento ling\u00a8 u\u00b4 \u0131stico ( Manning y Sch\u00a8 utze (1999 ),Calzolari et al.\n(2001 ), etc). En la actualidad, la gran mayor\u00b4 \u0131a de los sistemas se\ncentran en el desarrollo de complejos algoritmos estad\u00b4 \u0131sticos que\nmanejan muy poca cantidad de informaci\u00b4 on ling\u00a8 u\u00b4 \u0131stica. Conside-\nrando esta de\ufb01ciencia, se hace por tanto necesaria la incorporaci\u00b4 on\nde m\u00b4 as informaci\u00b4 on ling\u00a8 u\u00b4 \u0131stica que revele ciertas propiedades y re-\nlaciones en el lenguaje, no evidenciadas a trav\u00b4 es de estimaciones\nestad\u00b4 \u0131sticas.\nEl principal objetivo del m\u00b4 etodo desarrollado en esta secci\u00b4 on\nes demostrar que mediante la utilizaci\u00b4 on de informaci\u00b4 on ling\u00a8 u\u00b4 \u0131sti-\nca se obtiene un elevado porcentaje de aciertos en t\u00b4 erminos de\nprecisi\u00b4 on. Este incremento de la precisi\u00b4 on obtenida viene acom-\n5. M\u00b4 etodos 139\npa\u02dc nado de un decremento de la cobertura, debido en gran parte\na la escasez de recursos ling\u00a8 u\u00b4 \u0131sticos (en espa\u02dc nol, en nuestro caso),\nque impiden la obtenci\u00b4 on de informaci\u00b4 on ling\u00a8 u\u00b4 \u0131stica a gran escala.\nA continuaci\u00b4 on se exponen las caracter\u00b4 \u0131sticas de este m\u00b4 etodo\njunto con algunos ejemplos aplicados a WSD.\n5.3.1 Obtenci\u00b4 on de informaci\u00b4 on ling\u00a8 u\u00b4 \u0131stica\nLa decisi\u00b4 on de utilizar informaci\u00b4 on ling\u00a8 u\u00b4 \u0131stica para el desarro-\nllo de un m\u00b4 etodo de desambiguaci\u00b4 on autom\u00b4 atica, es debida a la\nnecesidad de evitar, en la medida de lo posible, el uso de par\u00b4 ame-\ntros estad\u00b4 \u0131sticos, frecuencias, medidas de similitud, etc, que llevan\nasociados un desv\u00b4 \u0131o y un margen de error, resultado de tratar los\ntextos desde el punto de vista matem\u00b4 atico.\nEl m\u00b4 etodo presentado en esta secci\u00b4 on utiliza informaci\u00b4 on im-\npl\u00b4 \u0131cita presente en textos no anotados sem\u00b4 anticamente como base\npara la adquisici\u00b4 on de conocimiento. De esta forma, no es necesa-\nria una anotaci\u00b4 on manual previa del corpus.\n5.3.1.1 Adquisici\u00b4 on de informaci\u00b4 on paradigm\u00b4 atica.\nActualmente, la obtenci\u00b4 on de informaci\u00b4 on sintagm\u00b4 atica rela-\ncionada con los sentidos de las palabras es dif\u00b4 \u0131cil de obtener y\nmuy costosa. El t\u00b4 ermino informaci\u00b4 on sintagm\u00b4 atica hace referen-\ncia a palabras que co-ocurren frecuentemente, incluyendo coloca-\nciones y restricciones de selecci\u00b4 on. Sin embargo, la informaci\u00b4 on\nparadigm\u00b4 atica, que hace referencia a palabras que aparecen en\ncontextos similares (hip\u00b4 onimos/hiper\u00b4 onimos, mer\u00b4 onimos/hol\u00b4 oni-\nmos, etc), es m\u00b4 as sencilla de obtener.\nEn esta secci\u00b4 on se va a describir c\u00b4 omo la obtenci\u00b4 on de infor-\nmaci\u00b4 on paradigm\u00b4 atica ayuda a la extracci\u00b4 on de informaci\u00b4 on sin-\ntagm\u00b4 atica. Esta idea est\u00b4 a basada en la hip\u00b4 otesis de que palabras\nsimilares sem\u00b4 anticamente (eje paradigm\u00b4 atico) pueden ser sustitui-\ndas en el mismo contexto (eje sintagm\u00b4 atico). Tal y como muestra\nla Figura 5.19:\nEn este caso, si se \ufb01ja la secuencia \u201cobra para \u00b4 organo\u201d , y se\ndeja libre la posici\u00b4 on ocupada por la palabra \u201cobra\u201d , se pueden\n140 5.3 WSD basado en reglas ling\u00a8 u\u00b4 \u0131sticas sobre corpus\n obra concierto pieza Relaciones \nparadigm\u00e1ticas \npara \u00f3rgano Relaciones \nsintagm\u00e1ticas \nFigura 5.19. Relaciones sintagm\u00b4 aticas y paradigm\u00b4 aticas\nextraer otras palabras similares sem\u00b4 anticamente que pueden sus-\ntituir a \u201cobra\u201d , como por ejemplo: \u201cconcierto\u201d ,\u201cpieza\u201d ,\u201ccompo-\nsici\u00b4 on\u201d , etc. Estas nuevas palabras pueden intercambiarse entre s\u00b4 \u0131,\nde forma que el contexto mantiene su signi\ufb01cado original: \u201ccom-\nposici\u00b4 on musical para un instrumento\u201d . Seg\u00b4 un el estudio realizado\nen (Miller y Charles (1991 )), se demuestra que un individuo deter-\nmina la similitud sem\u00b4 antica entre palabras, tomando como base\nlos contextos en los que se utilizan.\n5.3.1.2 Discriminadores de sentidos.\nA partir de la informaci\u00b4 on paradigm\u00b4 atica proporcionada, se\npuede establecer el sentido de la palabra ambigua. Es decir, a\npartir de todas las palabras que conforman el eje paradigm\u00b4 atico,\nque pueden ponerse en lugar de la palabra ambigua, y usando\nuna fuente de datos l\u00b4 exica que proporcione informaci\u00b4 on para cada\nuno de los posibles sentidos de la palabra, se puede establecer el\nsentido m\u00b4 as adecuado de la palabra ambigua.\nEn nuestro caso, la fuente de datos l\u00b4 exica elegida para la obten-\nci\u00b4 on de los diferentes sentidos de las palabras, ha sido EuroWord-\nNet1(Vossen (1998 )). EuroWordNet es una extensi\u00b4 on multiling\u00a8 ue\n1http://www.globalwordnet.org/\n5. M\u00b4 etodos 141\nde WordNet para 8 idiomas europeos (ingl\u00b4 es, espa\u02dc nol, alem\u00b4 an,\nholand\u00b4 es, italiano, franc\u00b4 es, estonio y checo). Cada synset de los\ndiferentes idiomas se encuentra conectado con el resto, a trav\u00b4 es\ndel llamado \u201cInter Lingual Index\u201d (ILI). En la Figura 5.20 se\nmuestra la interconexi\u00b4 on entre los diferentes idiomas.\n \nItaliano W \nItaliano W \nEspa\u00f1ol W \nEspa\u00f1ol W Alem\u00e1n W \nAlem\u00e1n W Ingl\u00e9s W \nIngl\u00e9s W \nRelaciones \nsem\u00e1nticas internas ILI \nMapeo entre ontolog\u00eda \nespec\u00edfica del lenguaje \ny ontolog\u00eda gen\u00e9rica Top concepts Merged Top \nOngology \nFigura 5.20. EuroWordNet\nDe esta forma, utilizando EuroWordNet y sus relaciones sem\u00b4 anti-\ncas, el m\u00b4 etodo desarrollado en esta secci\u00b4 on se va a aplicar sobre\nel idioma espa\u02dc nol. Para ello, se va a emplear el conjunto de \u201cva-\nriants\u201d2proporcionados para cada uno de los sentidos de una\npalabra. As\u00b4 \u0131 pues, para cada sentido Wide una palabra W, se\nextraen de EWN el conjunto de synsets con los que se relacio-\nna (hip\u00b4 onimos, hiper\u00b4 onimos, mer\u00b4 onimos, etc), junto con los \u201cva-\n2Los\u201cvariants\u201d son las palabras que forman un synset. Por ejemplo, los \u201cvariants\u201d\ndel synset n\u00b4 umero 00589353 de EWN son: tranquilidad, solaz, reposo, relax,\nrelajo, huelga...\n142 5.3 WSD basado en reglas ling\u00a8 u\u00b4 \u0131sticas sobre corpus\nriants\u201d que los identi\ufb01can. El resultado \ufb01nal es la asignaci\u00b4 on al\nsentido Witodos los \u201cvariants\u201d Viextra\u00b4 \u0131dos de las relaciones l\u00b4 exi-\nco sem\u00b4 anticas de EWN. Una vez obtenidos los conjuntos Vipara\ncada sentido i, el siguiente paso es eliminar aquellos \u201cvariants\u201d\nque se encuentren en m\u00b4 as de un sentido, obteniendo de esta forma\nuna serie de conjuntos disjuntos Dicon palabras relacionadas ex-\nclusivamente con el sentido Wide la palabra. El resultado \ufb01nal es\nuna serie de conjuntos Didenominados de aqu\u00b4 \u0131 en adelante como\nDiscriminadores de Sentidos.\nA continuaci\u00b4 on se muestra el proceso de extracci\u00b4 on de los Dis-\ncriminadores de Sentidos para la palabra \u201c\u00b4 organo\u201d que seg\u00b4 un Eu-\nroWordNet tiene cinco sentidos diferentes:\n\u00b4 organo#1: \u201cparte de una planta\u201d\n\u00b4 organo#2: \u201cagencia gubernamental, instrumento\u201d\n\u00b4 organo#3: \u201cparte funcional de un animal\u201d\n\u00b4 organo#4: \u201cinstrumento musical\u201d\n\u00b4 organo#5: \u201cperi\u00b4 odico\u201d\nPartiendo de \u00b4 organo#1 extraemos sus \u201cvariants\u201d a trav\u00b4 es de\nlas relaciones l\u00b4 exico sem\u00b4 anticas:\nSinonimia: \u00b4 organo vegetal.\nHiperonimia: objeto inanimado, objeto f\u00b4 \u0131sico, objeto, cosa, en-\ntidad.\nHiponimia: estructura reproductiva, l\u00b4 amina, ra\u00b4 \u0131z, tronco, tallo,\nrabillo, ped\u00b4 unculo, c\u00b4 alamo, ca\u02dc na, cabillo, hoja, follaje, ...\nHolonimia: \u00ae.\nMeronimia: \u00ae.\nCoordinados: talo, sombrero, sombrerito, sombrerillo, sombre-\nrete, p\u00b4 \u0131leo, carp\u00b4 oforo, volva, chalaza,...\nUna vez obtenidos todos los \u201cvariants\u201d se construye el conjun-\ntoV1=f\u00b4 organo vegetal, objeto inanimado, objeto f\u00b4 \u0131sico, objeto,\ncosa, entidad, estructura reproductiva, l\u00b4 amina, ra\u00b4 \u0131z, tronco, tallo,\nrabillo,... g. Y as\u00b4 \u0131 para cada uno de los sentidos de \u201c\u00b4 organo\u201d. Fi-\nnalmente, se extraen los Discriminadores de Sentidos, quedando\nel conjunto D1=f\u00b4 organo vegetal, l\u00b4 amina, ra\u00b4 \u0131z, tronco, tallo,... g.\nPara abarcar m\u00b4 as informaci\u00b4 on derivada de las relaciones de\nEuroWordNet, el conjunto de Discriminadores de Sentidos se ha\n5. M\u00b4 etodos 143\nampliado utilizando las relaciones heredadas de hiponimia, man-\nteniendo la caracter\u00b4 \u0131stica de conjuntos disjuntos. De esta forma,\na estos nuevos conjuntos ampliados se les denomina DE i(Discri-\nminadores de Sentidos Extendidos).\nLa obtenci\u00b4 on del sentido de una palabra viene determinado por\nel n\u00b4 umero de palabras del eje paradigm\u00b4 atico que tiene en com\u00b4 un\ncon cada uno de los conjuntos disjuntos de Discriminadores de\nSentidos. A mayor n\u00b4 umero de palabras en com\u00b4 un con el conjunto\nDE i, mayor probabilidad de que la palabra Wtenga asociado el\nsentido i.\n5.3.1.3 Identi\ufb01caci\u00b4 on de patrones sintagm\u00b4 aticos.\nPara la determinaci\u00b4 on de la informaci\u00b4 on paradigm\u00b4 atica es nece-\nsario el establecimiento, en primer lugar, de una serie de patrones\nsintagm\u00b4 aticos que identi\ufb01quen entidades con contenido sem\u00b4 anti-\nco susceptibles de ser intercambiadas con otras entidades en el\nmismo contexto (eje sintagm\u00b4 atico). De esta forma, cobra impor-\ntancia la determinaci\u00b4 on del contexto local para cada ocurrencia y\ncategor\u00b4 \u0131a sint\u00b4 actica.\nLa aparici\u00b4 on de una palabra en un contexto determinado pro-\nporciona informaci\u00b4 on muy \u00b4 util para su desambiguaci\u00b4 on ( Ravin\ny Leacock (2001 )). Asimismo, existe una interdependencia entre\nel signi\ufb01cado de una palabra y el signi\ufb01cado de las estructuras\nsint\u00b4 acticas superiores que la contienen: sintagma y oraci\u00b4 on. Un\nestudio realizado en ( Miller y Charles (1991 )) demuestra que una\nventana de pocas palabras alrededor de la ocurrencia ambigua, es\nsu\ufb01ciente para obtener su signi\ufb01cado. De esta forma, nuestra apro-\nximaci\u00b4 on parte de un contexto m\u00b4 \u0131nimo para identi\ufb01car el sentido\nde la ocurrencia ambigua, para posteriormente ampliarlo hasta\nobtener un \u00b4 unico sentido posible.\nSe parte por tanto, de una secuencia sintagm\u00b4 atica reducida que\ncontiene la ocurrencia ambigua, manteniendo \ufb01jos los dem\u00b4 as ele-\nmentos y se deja libre la posici\u00b4 on que ocupa la palabra ambigua.\nDe esta forma, se buscan en el corpus palabras que ocupen su lugar\nmanteniendo la misma informaci\u00b4 on sintagm\u00b4 atica original (Ver Fi-\ngura 5.19). A partir de aqu\u00b4 \u0131, se introduce un nuevo concepto, el de\n144 5.3 WSD basado en reglas ling\u00a8 u\u00b4 \u0131sticas sobre corpus\npatrones sintagm\u00b4 aticos, que son una tripleta formada por dos uni-\ndades ling\u00a8 u\u00b4 \u0131sticas L1 yL2 de contenido l\u00b4 exico (nombres, adjetivos,\nverbos o adverbios) y un patr\u00b4 on l\u00b4 exico-sint\u00b4 actico Rque expresa\nla relaci\u00b4 on (de dependencia, de coordinaci\u00b4 on, l\u00b4 exico-sem\u00b4 antica o\nde adyacencia) que comparten las dos unidades l\u00b4 exicas. La rela-\nci\u00b4 onRpuede contener valores nulos, por ejemplo, en el caso de\nrelaciones de adyacencia entre nombres y adjetivos:\npasaje -L1\u00ae-Rsubterr\u00b4 aneo -L2\nDe\ufb01nimos dos tipos de patrones sintagm\u00b4 aticos:\n1.Patrones sintagm\u00b4 aticos que corresponden a relaciones sint\u00b4 acti-\ncas (patrones sint\u00b4 acticos). Por ejemplo, corona de santo.\n2.Patrones sintagm\u00b4 aticos que corresponden a relaciones l\u00b4 exico-\nsem\u00b4 anticas (patrones l\u00b4 exico-sem\u00b4 anticos). Por ejemplo, los miem-\nbros del comit\u00b4 e (relaciones de meronimia).\nAmbos tipos de patrones son relevantes para la identi\ufb01caci\u00b4 on\ndel sentido de la palabra ambigua. En el caso de los patrones\nsint\u00b4 acticos, el elemento relacional Rse expresa mediante pala-\nbras funcionales, mientras que en los patrones l\u00b4 exico-sem\u00b4 anticos\nRsuele tener una forma m\u00b4 as compleja y puede contener tanto pa-\nlabras funcionales como de contenido l\u00b4 exico. En este trabajo, nos\nvamos a centrar en los patrones sint\u00b4 acticos, dejando como traba-\njo futuro la incorporaci\u00b4 on de patrones l\u00b4 exico-sem\u00b4 anticos. Adem\u00b4 as,\nvamos a centrar el proceso de desambiguaci\u00b4 on sobre los nombres,\npor ser esta categor\u00b4 \u0131a la m\u00b4 as rica en cuanto a relaciones sint\u00b4 acticas\nen sus proximidades.\nLas hip\u00b4 otesis para determinar el sentido de una palabra ambi-\ngua a partir de patrones sintagm\u00b4 aticos son las siguientes:\n1.Dos palabras que comparten un mismo patr\u00b4 on sintagm\u00b4 atico,\ntienen una alta probabilidad de estar relacionadas sem\u00b4 antica-\nmente.\n2.Dos ocurrencias de una palabra ambigua tienen una alta pro-\nbabilidad de pertenecer al mismo sentido si aparecen en un\nmismo patr\u00b4 on sintagm\u00b4 atico.\nPara la identi\ufb01caci\u00b4 on de patrones sint\u00b4 acticos se tienen en cuen-\nta dos criterios:\n5. M\u00b4 etodos 145\nEstructural (sint\u00b4 actico). Se tienen en cuenta determinadas com-\nbinaciones de categor\u00b4 \u0131as morfosint\u00b4 acticas mediante las que se\nestablecen relaciones sint\u00b4 acticas. En este caso, los patrones\nconsiderados son los siguientes:\nN1 (((ADV) ADV) ADJ/VPART), (PREP) (DET) (((ADV)\nADV) ADJ/VPART) N2\nN1 (((ADV) ADV) ADJ/VPART) CONJ* (DET) (((ADV)\nADV) ADJ/VPART) N2\nN ((ADV) ADV) ADJ/VPART (CONJ* ((ADV) ADV)\nADJ/VPART)\nN1 (((ADV) ADV) ADJ/VPART) PREP (DET) (((ADV)\nADV) ADJ/VPART) N2\nLas categor\u00b4 \u0131as entre par\u00b4 entesis hacen referencia a elementos\nque pueden estar o no presentes en el patr\u00b4 on. Y las categor\u00b4 \u0131as\nseparadas por una barra son alternativas para una misma po-\nsici\u00b4 on. Los patrones compuestos pueden descomponerse en pa-\ntrones simples mediante unas reglas de descomposici\u00b4 on prede-\n\ufb01nidas. Por ejemplo, el patr\u00b4 on [N ADJ1 CONJ ADJ2] se\ndescompone en [N ADJ1] y[N ADJ2] .\nFrecuencia. Aquellos patrones que cumplen el criterio estruc-\ntural se \ufb01ltran de acuerdo a su frecuencia de aparici\u00b4 on en el\ncorpus.\nMediante estos criterios se eliminan aquellas combinaciones in-\naceptables de categor\u00b4 \u0131as sint\u00b4 acticas y las combinaciones poco fre-\ncuentes.\nUna vez detectado el patr\u00b4 on sint\u00b4 actico en el que aparece la pa-\nlabra ambigua y las palabras relacionadas en el eje paradigm\u00b4 atico,\nse puede establecer el sentido de la palabra ambigua utilizando los\nDiscriminadores de Sentidos a partir de EWN.\n5.3.2 Prueba de conmutabilidad\nEl algoritmo utilizado para obtener el sentido correcto de una\nocurrencia ambigua es el denominado Prueba de Conmutabilidad.\nEste algoritmo utiliza la adaptaci\u00b4 on de EWN mediante Discrimi-\nnadores de Sentidos para determinar el sentido correcto de una\npalabra.\n146 5.3 WSD basado en reglas ling\u00a8 u\u00b4 \u0131sticas sobre corpus\nEste algoritmo est\u00b4 a basado en la hip\u00b4 otesis de que dos palabras\nque pueden conmutar en un contexto determinado est\u00b4 an relacio-\nnadas sem\u00b4 anticamente. En t\u00b4 erminos de los Discriminadores de\nSentidos de\ufb01nidos anteriormente, si una palabra ambigua puede\nsustituirse en sus patrones sint\u00b4 acticos por un Discriminador de\nSentido, entonces se le puede asignar el sentido correspondiente a\nese Discriminador.\nPara el ejemplo de la Figura 5.19,\u201cobra para \u00b4 organo\u201d , si se\nquiere desambiguar la palabra \u201c\u00b4 organo\u201d, se deben buscan ocurren-\ncias en el corpus del patr\u00b4 on [obra - para - X], donde X puede sus-\ntituirse por: viol\u00b4 \u0131n, guitarra, piano, etc. Los nombres que pueden\nsustituir a \u201c\u00b4 organo\u201d pertenecen al conjunto de Discriminadores de\nSentido de \u00b4 organo#4, y por tanto, \u201c\u00b4 organo\u201d podr\u00b4 \u0131a tener el senti-\ndo 4. La Figura 5.21muestra de forma gr\u00b4 a\ufb01ca el funcionamiento\ndel algoritmo de conmutabilidad.\n\u0001\n\u0001\n\u0001\u0001\n\u0001\n\u0001\n\u0001\u0002\u0001\u0003\u0001\u0004\u0001\u0005\u0001\u0006\u0001\u0002\u0001\u0003\u0001\u0004\u0001\u0005\u0001\u0007\u0007\u0001\u0002\u0001\u0003\u0001\u0004\u0001\u0005\u0001\u0006\b\u0001\u0006\b\u0001\t\n\u000b\u0001\n\t\n\f\u000b\u0001\n\t\r\u000b\u0001\u000e\u000f\u0010\u0001\n\u000e\u000f\n\f\u0001\n\u000e\u000f\r\u0001\u0002\u0001\u0003\u0001\u0004\u0001\u0005\u0001\u0006\u0007\n\f\u0001\n\u0002\u0001\u0003\u0001\u0004\u0001\u0005\u0001\u0006\u0007\u0011\u0001\u0012\u0013\u0014\u0015\u0016\u0017\u0001\n\u000e\u0018\u0001\n\u0019\u001a\u0001\nFigura 5.21. Prueba de conmutabilidad\nPara un patr\u00b4 on [Y - R - X] cualquiera, se deja libre la posici\u00b4 on\nque ocupa la palabra ambigua. Se buscan en el corpus ocurrencias\ndel patr\u00b4 on con palabras que conmutan en el lugar de la palabra\nambigua. Esas palabras conmutables se buscan en los Discrimi-\nnadores de Sentido para cada sentido de la palabra ambigua. El\nsentido elegido \ufb01nalmente es aquel que comparte mayor n\u00b4 umero\nde palabras conmutadas en su conjunto de Discriminadores de\nSentido.\n5. M\u00b4 etodos 147\nUna de las ventajas de este algoritmo es que no necesita cor-\npus anotados sem\u00b4 anticamente, ya que act\u00b4 ua directamente sobre\npalabras y no sobre sus sentidos.\nLa arquitectura del sistema de desambiguaci\u00b4 on autom\u00b4 atica es\nel mostrado en la Figura 5.22.\n\u0001\u0001\n\u0002\u0003\u0004\u0005\u0006\u0001\n\u0007\u0005\u0006\u0004\u0005\u0006\u0001\u0004\u0007\b\t\n\u000b\n\f\r\u000e\u000f\u0010\u0001\u0011\u0012\u0013\u0014\u0007\u0015\u0001\n\u0004\u0007\b\t\u0016\n\u0017\u0017\u000f\u0010\u0001\u0011\u0018\u0019\u001a\u0013\u001b\u0015\u0001\n\b\u001c\n\f\f\u001d\u001e\u0001\u001f\n\u0010\u000e\u000f\u0010\u0001\n\u0011\u0006\u0013\u0014\u0013\u0006\u0015\u0001\u0001\u0002\u0003\u0004\u0005\u0006\u0007\n\b\t\n\u0007\u0001\n\u0019 \u0003\u0001\n\u000b\f\r\u000e\u000b\u000f\u000b\u0010\u0011\u0003\u0006\u000e\u0012\f\u0007\n\u0003\u0012\u0007\f\u0012\u0010\u0013\u000b\u0003\u0006\f\u0007\u0014\u001d\u0010\u001f!\u000e\u0001\u0005\u0016\"\f\"#\n#\u000f\u000e\u0001$%#!\f\u001d\u0001 \b&\u0001\nFigura 5.22. Arquitectura sistema\nPreviamente a la obtenci\u00b4 on de los patrones sint\u00b4 acticos y a la\nb\u00b4 usqueda en el corpus de informaci\u00b4 on paradigm\u00b4 atica es necesa-\nrio un preproceso del texto. Se deben determinar los lemas de\nlas palabras y sus relaciones sint\u00b4 acticas. Para ello, se utiliza un\nanalizador morfosint\u00b4 actico para espa\u02dc nol ( Civit (2003 )) y un de-\nsambiguador morfol\u00b4 ogico ( Atserias et al. (1998 )).\n5.3.3 Heur\u00b4 \u0131sticas\nAdem\u00b4 as de utilizar la informaci\u00b4 on paradigm\u00b4 atica obtenida a\npartir de la sustituci\u00b4 on de la palabra ambigua en el patr\u00b4 on\nsint\u00b4 actico, se va a utilizar la informaci\u00b4 on proporcionada por la\noraci\u00b4 on donde aparece la palabra ambigua. Dado que el contexto\ndonde aparece la palabra ambigua (oraci\u00b4 on) ofrece informaci\u00b4 on\n148 5.3 WSD basado en reglas ling\u00a8 u\u00b4 \u0131sticas sobre corpus\nmuy valiosa, es interesante utilizar tambi\u00b4 en esta informaci\u00b4 on so-\nbre los conjuntos de Discriminadores de Sentidos.\nSe tendr\u00b4 an por tanto, dos fuentes de informaci\u00b4 on:\nC1:El conjunto de palabras correspondientes a la informaci\u00b4 on\nparadigm\u00b4 atica obtenida a partir del patr\u00b4 on sint\u00b4 actico donde\naparece la palabra ambigua.\nC2:El conjunto de todos los nombres de la oraci\u00b4 on donde apa-\nrece la palabra ambigua.\nSobre cada fuente de informaci\u00b4 on (C1 y C2) se aplica una\nheur\u00b4 \u0131stica:\nH1:Sobre la informaci\u00b4 on paradigm\u00b4 atica.\nH2:Sobre la informaci\u00b4 on proporcionada por la oraci\u00b4 on.\nCada heur\u00b4 \u0131stica intersecta el conjunto C1 o C2 con los con-\njuntos de Discriminadores de Sentidos de la palabra ambigua. De\nesta forma, aquella intersecci\u00b4 on que d\u00b4 e como resultado un conjun-\nto no vac\u00b4 \u0131o de elementos ser\u00b4 a el sentido elegido. Si cada heur\u00b4 \u0131stica\ndevuelve un sentido distinto, se conservan ambos. El objetivo de\neste m\u00b4 etodo es el de \ufb01ltrar los sentidos inadecuados, sin perder el\nsentido correcto al tratar de elegir una de las posibles opciones en\ncaso de desacuerdo.\n5.3.4 Ejemplo de aplicaci\u00b4 on\nSupongamos que tenemos el siguiente texto del cual queremos\nobtener el sentido de la palabra \u201c\u00b4 organo\u201d :\n\u201cLos enormes y continuados progresos cient\u00b4 \u0131\ufb01cos y t\u00b4 ecnicos de\nla Medicina actual han logrado hacer descender espectacularmente\nla mortalidad infantil, erradicar multitud de enfermedades hasta\nhace poco mortales, sustituir mediante trasplante o implantaci\u00b4 on\nde\u00b4 organos da\u02dc nados o partes del cuerpo inutilizadas y alargar las\nexpectativas de vida.\u201d\nEl primer paso es detectar el tipo de patr\u00b4 on sint\u00b4 actico en el que\nse encuentra la palabra a desambiguar. Para ello se utilizan los\npatrones sint\u00b4 acticos previamente adquiridos y en el caso de que sea\n5. M\u00b4 etodos 149\n NACN \nNA NCN \n\u00f3rgano da\u00f1ado \u00f3rgano o parte Esquema \nReglas de \ndescomposici\u00f3n \nResultado \nFigura 5.23. Extracci\u00b4 on de patrones\nun patr\u00b4 on compuesto se utilizan las reglas de descomposici\u00b4 on de\npatrones. La Figura 5.23muestra la extracci\u00b4 on de estos patrones.\nEl siguiente paso, una vez se han extra\u00b4 \u0131do los patrones sint\u00b4 acti-\ncos, es obtener informaci\u00b4 on paradigm\u00b4 atica presente tanto en cor-\npus como en el contexto que rodea a la palabra ambigua. La Fi-\ngura 5.24muestra el resultado de este proceso.\n Corpus Oraci\u00f3n \nmediador, terreno, ch\u00f3fer, \n\u00e1rbol, cabeza, planeta, parte, \nincremento, totalidad, \nguerrilla, programa, mitad, \npa\u00eds, temporada, art\u00edculo\u2026 progreso, cient\u00edfico, \nmortalidad, multitud, \nenfermedad, mortal, \ntrasplante, implantaci\u00f3n, \n\u00f3rgano, parte, cuerpo\u2026 \nexpectativa, vida \nFigura 5.24. Informaci\u00b4 on paradigm\u00b4 atica\nUna vez extra\u00b4 \u0131da la informaci\u00b4 on paradigm\u00b4 atica se compara con\nlos conjuntos de Discriminadores de Sentidos asociados a \u201c\u00b4 orga-\nno\u201d. Los cinco conjuntos asociados a cada sentido de \u201c\u00b4 organo\u201d se\nmuestran en la Tabla 5.8.\n150\n\u00b4 organo#1: \u00b4 organo vegetal, espora, \ufb02or, pera, manzana, bellota, hi-\nnojo, semilla, poro, p\u00b4 \u0131leo, carp\u00b4 oforo, ...\n\u00b4 organo#2: agencia, unidad administrativa, banco central, servicio\nsecreto, seguridad social, FBI, ...\n\u00b4 organo#3: parte del cuerpo, trozo, m\u00b4 usculo, ri\u02dc n\u00b4 on, oreja, ojo,\ngl\u00b4 andula, l\u00b4 obulo, t\u00b4 orax, dedo, articulaci\u00b4 on, rasgo, facci\u00b4 on, ...\n\u00b4 organo#4: instrumento de viento, instrumento musical, mecanismo,\naparato, teclado, pedal, corneta, ...\n\u00b4 organo#5: peri\u00b4 odico, publicaci\u00b4 on, medio de comunicaci\u00b4 on, m\u00b4 etodo,\nserie, serial, n\u00b4 umero, ejemplar, ...\nTabla 5.8. Discriminadores de Sentidos para \u201c\u00b4 organo\u201d\nTras comparar el conjunto de palabras del eje paradigm\u00b4 atico\ncon cada uno de los conjuntos de Discriminadores de Sentidos, se\naplican las dos heur\u00b4 \u0131sticas, tal y como muestra la Figura 5.25.\n \u0001\u0002\u0003\u0004\u0005\u0006\u0007\b\t\n\u000b\f\u000b\n\u0001\u0002\u0003\u2229\u0003\u0004\u0005\u0006\u0003\u0007\u0003\u2205\u0003\u0003\n\u0001\u0002\u0003\u2229\u0003\u0004\u0005\u0002\u0003\u0007\u0003\u2205\u0003\u0003\n\r\u000e\u000b\u2229\u2229\u2229\u2229\u000b\u000f\u0010\u0011\u000b\u2260\u2260\u2260\u2260\u000b\u2205\u2205\u2205\u2205\u0003\u0003\n\u0001\u0002\u0003\u2229\u0003\u0004\u0005\b\u0003\u0007\u0003\u2205\u0003\u0003\n\u0001\u0002\u0003\u2229\u0003\u0004\u0005\t\u0003\u0007\u0003\u2205\u0003\u0003\u0001\u0002\u0003\u0004\u0005\u0006\u0007\b\t\n\u000b\u000e\u000b\n\u0001\u0006\u0003\u2229\u0003\u0004\u0005\u0006\u0003\u0007\u0003\u2205\u0003\u0003\n\u0001\u0006\u0003\u2229\u0003\u0004\u0005\u0002\u0003\u0007\u0003\u2205\u0003\u0003\n\r\f\u000b\u2229\u2229\u2229\u2229\u000b\u000f\u0010\u0011\u000b\u2260\u2260\u2260\u2260\u000b\u2205\u2205\u2205\u2205\u000b\n\u0001\u0006\u0003\u2229\u0003\u0004\u0005\b\u0003\u0007\u0003\u2205\u0003\u0003\n\u0001\u0006\u0003\u2229\u0003\u0004\u0005\t\u0003\u0007\u0003\u2205\u0003\u0003\nFigura 5.25. Heur\u00b4 \u0131sticas\nFinalmente el sentido seleccionado es:\n\u00b4 organo#3: A fully di\ufb00erentiated structural and functional\nunit in an animal that is specialized for some particular function.\nCap\u0013\u0010tulo 6\nExperimentaci\u00b4 on y evaluaci\u00b4 on\nEn este cap\u00b4 \u0131tulo se describe todo el proceso de evaluaci\u00b4 on de\nlos sistemas de WSD implementados en este trabajo, as\u00b4 \u0131 como\nsu integraci\u00b4 on y aplicaci\u00b4 on en otras tareas de PLN. La primera\nparte del cap\u00b4 \u0131tulo se centra en el marco de trabajo para la eva-\nluaci\u00b4 on de sistemas de WSD, presentando las diferentes ediciones\nde la competici\u00b4 on Senseval1hasta la actualidad . En la segunda\nparte, se presenta la evaluaci\u00b4 on de nuestros sistemas comparando\nlos resultados obtenidos con otros sistemas participantes en Sen-\nseval . Finalmente, los sistemas de desambiguaci\u00b4 on se aplican a\notras tareas de PLN que requieren de un m\u00b4 odulo de desambigua-\nci\u00b4 on sem\u00b4 antica para mejorar sus resultados.\n6.1 Competiciones de evaluaci\u00b4 on\nA continuaci\u00b4 on se describen las tareas que se organizaron en\nlas distintas ediciones de Senseval y algunos de los sistemas que\nhan participado en esta competici\u00b4 on en sus diferentes ediciones.\n1http://www.senseval.org\n152 6.1 Competiciones de evaluaci\u00b4 on\n6.1.1 SENSEVAL: Evaluation Exercises for the\nSemantic Analysis of Text\nSenseval es una competici\u00b4 on de evaluaci\u00b4 on organizada en\nla l\u00b4 \u0131nea de otras competiciones como (D)ARPA ( HLT1 (1993 )),\nMUC ( MUC (1995 ),MUC (1998 )) y TREC ( D.(1995 ),D.(1996 )).\nLa primera competici\u00b4 on se realiz\u00b4 o en el a\u02dc no 1998 con veinticin-\nco sistemas participantes clasi\ufb01cados en dos categor\u00b4 \u0131as diferentes:\nsistemas supervisados y sistemas no supervisados. Los sistemas\nsupervisados que participaron requer\u00b4 \u0131an unos datos de entrena-\nmiento anotados sem\u00b4 anticamente. Mientras que para los sistemas\nno supervisados este tipo de informaci\u00b4 on no era necesaria. En es-\nta primera edici\u00b4 on se utiliz\u00b4 o un lexicon especial para los distintos\nconjuntos de sentidos: HECTOR ( Atkins (1992 )), que fue creado\npor la Universidad de Oxford. A los sistemas participantes se les\nproporcionaron los datos de entrenamiento, que eran textos ano-\ntados con el sentido correcto tomando como referencia HECTOR.\nLa evaluaci\u00b4 on se llev\u00b4 o a cabo poniendo a prueba los distintos siste-\nmas con una serie de ejemplos sin etiquetar, estos ejemplos deb\u00b4 \u0131an\nser anotados con el sentido correcto de cada palabra. Los idiomas\nutilizados en esta evaluaci\u00b4 on fueron: Ingl\u00b4 es (18 sistemas), Franc\u00b4 es\n(5 sistemas) e Italiano (2 sistemas).\nEn esta primera competici\u00b4 on los items a desambiguar se res-\ntringieron a un conjunto de 40 palabras (tarea \u201cLexical Sample\u201d).\nEste conjunto de palabras se estableci\u00b4 o de forma aleatoria, de ma-\nnera que fueron seleccionadas aquellas palabras con su\ufb01ciente con-\ntexto y ejemplos, utilizando la estrategia descrita por ( Kilgarri\ufb00\n(1998a )).\nEn (Kilgarri\ufb00 y Palmer (2000 )) se describe el \u00b4 ambito de es-\nta competici\u00b4 on as\u00b4 \u0131 como los problemas surgidos en la elecci\u00b4 on de\nlos corpus y el repositorio de sentidos. Con respecto a la tarea\n\u201cEnglish Lexical Sample\u201d en (Kilgarri\ufb00 y Rosenzweig (2000 )) se\nrealiza un estudio exhaustivo de todos los sistemas propuestos\nen esta competici\u00b4 on. Los sistemas que mejores resultados propor-\ncionaron fueron los sistemas supervisados de la Universidad de\nDurham ( Hawkins y Nettleton (2000 )) y de la Universidad de\nJohn Hopkins ( Yarowsky (2000b )).\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 153\nTras esta primera aproximaci\u00b4 on para evaluar los diferentes sis-\ntemas de WSD, se han realizado tres competiciones m\u00b4 as: Senseval-\n2ACL (2001 ),Senseval-3 ACL (2004 ) y la \u00b4 ultima de ellas Se-\nmeval ACL (2007 ).\n6.1.2 SENSEVAL-2: Second International Workshop on\nEvaluating Word Sense Disambiguation Systems\nEn esta edici\u00b4 on de Senseval doce idiomas fueron evaluados\ny se presentaron alrededor de noventa sistemas. Una de las prin-\ncipales diferencias con la edici\u00b4 on anterior fue la adici\u00b4 on de una\nnueva tarea: \u201cAll-Words\u201d , que requer\u00b4 \u0131a que los sistemas fueran\ncapaces de etiquetar con el sentido correcto todas las palabras\ncon contenido sem\u00b4 antico de los textos proporcionados.\nLas tareas propuestas fueron tres (entre par\u00b4 entesis se muestra\nel n\u00b4 umero de sistemas participantes en cada idioma):\nTarea All-words. Checo (1), holand\u00b4 es (datos no disponibles\npara evaluaci\u00b4 on), ingl\u00b4 es (21) y estonio (2).\nTarea Lexical Sample. Euskera (3), ingl\u00b4 es (27), italiano (2),\njapon\u00b4 es (7), coreano (2), espa\u02dc nol (12) y sueco (8).\nTarea Traducci\u00b4 on. Japon\u00b4 es (9).\nLa tarea \u201cLexical Sample\u201d tiene como objetivo la obtenci\u00b4 on del\nsentido correcto de una \u00b4 unica palabra por frase, mientras que en\nla tarea \u201cAll words\u201d , los sistemas deben desambiguar sem\u00b4 antica-\nmente todas las palabras, a excepci\u00b4 on de las funcionales (conjun-\nciones, preposiciones, art\u00b4 \u0131culos, etc.), que aparecen en las frases\nde los corpus proporcionados. La tarea de traducci\u00b4 on, en la que\ns\u00b4 olo se particip\u00b4 o con la lengua japonesa, es un subtipo de \u201cLexical\nSample\u201d porque s\u00b4 olo hay que desambiguar una \u00b4 unica palabra. La\ndiferencia es que el sentido de la palabra se de\ufb01ne de acuerdo a\nsu traducci\u00b4 on.\nEl repositorio utilizado para establecer los sentidos de las pala-\nbras fue WordNet 1.7 para el idioma ingl\u00b4 es y EuroWordNet para\nel resto de idiomas.\n154 6.1 Competiciones de evaluaci\u00b4 on\n6.1.3 SENSEVAL-3: Evaluation exercises for Word\nSense Disambiguation\nLa tercera competici\u00b4 on de Senseval tuvo lugar en Julio de\n2004 Barcelona (Espa\u02dc na). En esta edici\u00b4 on se organizaron catorce\ntareas:\nTarea 1. English all words. (64 sistemas)( Snyder y Palmer\n(2004 )) Tal y como se hizo en el Senseval2, en esta nueva edici\u00b4 on\nse etiquetaron aproximadamente 5000 palabras extra\u00b4 \u0131das del\ncorpus de Penn Treebank, tomando como referencia WordNet\n1.7.1. Se etiquetaron nombres, adjetivos y adverbios haci\u00b4 endose\ndos revisiones para formalizar criterios.\nTarea 2. Italian all words. (7 sistemas) ( Ulivieri et al. (2004 ))\nEn esta edici\u00b4 on adem\u00b4 as de proponer una tarea de \u201clexical sam-\nple\u201d para italiano tambi\u00b4 en se propuso la tarea de \u201call words\u201d. A\ncada participante se le proporcion\u00b4 o un peque\u02dc no conjunto de tex-\ntos de aproximadamente 5000 palabras extra\u00b4 \u0131dos del corpus Ita-\nlian Treebank. Las palabras etiquetadas fueron nombres, verbos,\nadjetivos, adverbios y nombres propios, todas ellas atendiendo\na la anotaci\u00b4 on de ItalWordNet ( Corazzari y Alonge (2001 )).\nTarea 3. Basque lexical sample. (8 sistemas) ( Agirre et al.\n(2004 )) En esta tarea se evaluaron sistemas supervisados y semi-\nsupervisados para WSD. Cada participante fue provisto de un\npeque\u02dc no conjunto de ejemplos etiquetados y un conjunto m\u00b4 as\namplio de ejemplos no etiquetados para unas 40 palabras. To-\ndas las palabras fueron etiquetadas con la versi\u00b4 on de WordNet\n1.6 (aunque se puede obtener f\u00b4 acilmente su equivalente en la\nversi\u00b4 on de WordNet 1.7). Esta tarea fue coordinada junto con\notras tareas de lexical sample (Catal\u00b4 an, Ingl\u00b4 es, Italiano, Ruma-\nno, Espa\u02dc nol) para tener en com\u00b4 un al menos 10 de las palabras\nutilizadas en la evaluaci\u00b4 on.\nTarea 4. Catalan lexical sample. (8 sistemas) ( M` arquez et al.\n(2004b )) Al igual que en caso del Euskera tambi\u00b4 en se hizo una\ntarea de lexical sample para Catal\u00b4 an. Compartiendo la etique-\ntaci\u00b4 on con WordNet 1.6 y su adaptaci\u00b4 on a WordNet 1.7. Tam-\nbi\u00b4 en se proporcionaron textos de entrenamiento etiquetados y\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 155\ntextos no etiquetados para los sistemas supervisados y semi-\nsupervisados que participaron.\nTarea 5. Chinese lexical sample. (16 sistemas) En esta tarea se\nutilizaron tres tipos de datos: diccionario, datos de entrenamien-\nto y datos de evaluaci\u00b4 on. El diccionario conten\u00b4 \u0131a entradas para\n20 palabras distintas. Para cada palabra hab\u00b4 \u0131an de\ufb01nidos varios\nsentidos basados en el recurso HowNet ( Gan y Wong (2000 )).\nPara cada sentido, la entrada del diccionario listaba: un iden-\nti\ufb01cador para el sentido, la categor\u00b4 \u0131a sint\u00b4 actica de la palabra,\nuna de\ufb01nici\u00b4 on y una traducci\u00b4 on al ingl\u00b4 es, as\u00b4 \u0131 como alguna in-\nformaci\u00b4 on adicional. Los datos de entrenamiento consist\u00b4 \u0131an en\n20-100 ejemplos por palabra, con m\u00b4 as ejemplos para aquellas\npalabras con un n\u00b4 umero m\u00b4 as elevado de sentidos. Dos conjun-\ntos de entrenamiento fueron distribuidos: uno con etiquetaci\u00b4 on\nsint\u00b4 actica y otro sin esa informaci\u00b4 on.\nTarea 6. English lexical sample. (65 sistemas) ( Mihalcea et al.\n(2004a ))\nLos datos en esta tarea fueron obtenidos a partir de la interfaz\ndel Open Mind Word Expert (OMWE) ( Chklovski y Mihalcea\n(2002 )). Para asegurar la \ufb01abilidad se extrajeron dos etique-\ntas por item y se realizaron diversos tests con la \ufb01nalidad de\nllegar a un acuerdo entre las distintas anotaciones de los eti-\nquetadores. La elecci\u00b4 on de OMWE como interfaz para obtener\nlos datos de la tarea fue debida a su probada calidad en otras\nevaluaciones. Se extrajeron alrededor de 60 palabras ambiguas\nentre nombres, adjetivos y verbos. Parte del test de evaluaci\u00b4 on\nfue creado por el Departamento de Ling\u00a8 u\u00b4 \u0131stica de la Universi-\ndad del Norte de Texas (UNT). Otra parte del test de evalua-\nci\u00b4 on fue extra\u00b4 \u0131do a partir de corpus etiquetado de la web. Se\nutiliz\u00b4 o la versi\u00b4 on de WordNet 1.7.1 para nombres y adjetivos\ny Wordsmyth2para verbos. Adem\u00b4 as tambi\u00b4 en se distribuyeron\nlos agrupamientos de sentidos que posibilitaban una evaluaci\u00b4 on\nmenos restrictiva (coarse) frente a una evaluaci\u00b4 on m\u00b4 as estricta\n(\ufb01ne). Adem\u00b4 as tambi\u00b4 en se distribuy\u00b4 o el mapeo entre la anota-\nci\u00b4 on de Wordsmyth y WordNet.\n2http://www.wordsmyth.net/\n156 6.1 Competiciones de evaluaci\u00b4 on\nTarea 7. Italian lexical sample. (11 sistemas) ( Magnini et al.\n(2004 )) En esta tarea sigue los mismos principios que las tareas\nde lexical sample para Euskera y Catal\u00b4 an mencionadas anterior-\nmente. Se utiliz\u00b4 o para la anotaci\u00b4 on de sentidos el MultiWordNet\nItaliano ( Pianta et al. (2002 )), que fue especialmente desarro-\nllado para la tarea.\nTarea 8. Romanian lexical sample. (8 sistemas) ( Mihalcea et al.\n(2004b ))\nEn esta tarea se seleccionaron 50 palabras, cubriendo nom-\nbres, adjetivos, verbos y adverbios, con distintos grados de am-\nbig\u00a8 uedad. Para cada palabra se extrajeron un conjunto de ejem-\nplos a partir de un extenso corpus en Rumano. Los sentidos y\nlas expresiones de palabras m\u00b4 ultiples fueron extra\u00b4 \u0131dos del Word-\nNet Rumano o de DEX3un reconocido diccionario del Rumano.\nLos datos fueron extra\u00b4 \u0131dos a partir de la interfaz del OMWE,\nedici\u00b4 on en rumano.\nTarea 9. Spanish lexical sample. (18 sistemas) ( M` arquez et al.\n(2004a ))\nAl igual que para Catal\u00b4 an, Euskera, Ingl\u00b4 es e Italiano tambi\u00b4 en\nse organiz\u00b4 o la tarea lexical sample para Espa\u02dc nol. El repertorio\nde sentidos fue obtenido a partir de WordNet 1.6 con su res-\npectivo mapeo a WordNet 1.7. Esta tarea se coordin\u00b4 o con las\ndem\u00b4 as tareas de lexical sample para compartir al menos 10 de\nlas palabras propuestas para desambiguar.\nTarea 10. Automatic subcategorization acquisition. (35 siste-\nmas) ( Preiss y Korhonen (2004 ))\nEn esta tarea se evaluaron diversos sistemas de WSD en el con-\ntexto de subcategorizaci\u00b4 on autom\u00b4 atica. La tarea se restringi\u00b4 o a\n30 verbos, de elevada frecuencia de aparici\u00b4 on y con m\u00b4 ultiples\nsentidos. En este caso se publicaron los 30 verbos de la tarea\npero no se proporcion\u00b4 o ning\u00b4 un corpus de entrenamiento. El cor-\npus de evaluaci\u00b4 on consisti\u00b4 o en alrededor de 1000 instancias pa-\nra cada verbo, que se deb\u00b4 \u0131an anotar con el sentido correcto, de\nacuerdo a la versi\u00b4 on de WordNet 1.7.1.\n3http://dexonline.ro/\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 157\nTarea 11. Multilingual lexical sample. (23 sistemas) ( Chklovski\net al. (2004 ))\nEl objetivo de esta tarea era crear un marco de referencia pa-\nra la evaluaci\u00b4 on de sistemas de Traducci\u00b4 on Autom\u00b4 atica, cen-\ntr\u00b4 andose en la traducci\u00b4 on de palabras ambiguas. Esta tarea era\nmuy similar a la tarea lexical sample, excepto que en lugar de\nutilizar el inventario de sentidos de un diccionario se utiliz\u00b4 o la\npropuesta de Resnik y Yarowsky usando las traducciones de las\npalabras en otra lengua como \u201cinventario\u201d. Los textos originales\neran en Ingl\u00b4 es y la anotaci\u00b4 on para las palabras se deb\u00b4 \u0131a hacer la\ntraducci\u00b4 on en otro idioma. La tarea se restringi\u00b4 o a textos Ingl\u00b4 es-\nFranc\u00b4 es e Ingl\u00b4 es-Hindi con alrededor de 50 palabras ambiguas\npor pareja de idiomas.\nTarea 12. WSD of WordNet glosses. (36 sistemas)( Litkowski\n(2004b )) Relacionado con WordNet se desarroll\u00b4 o eXtended Word-\nNet ( Harabagiu et al. (1999 )), un recurso que enriquece la ver-\nsi\u00b4 on inicial de WordNet a\u02dc nadiendo la contenido morfol\u00b4 ogico y\nsem\u00b4 antico, a los t\u00b4 erminos de las glosas de WordNet. El proceso\npara obtener una buena anotaci\u00b4 on es costoso y en muchos casos\nse realiza de forma manual. El objetivo de esta tarea era desarro-\nllar un m\u00b4 etodo de anotaci\u00b4 on autom\u00b4 atica tomando como corpus\nde evaluaci\u00b4 on las glosas previamente etiquetadas en eXtended\nWordNet. En el marco de la tarea \u201call-words\u201d , se deb\u00b4 \u0131an eti-\nquetar nombres, verbos, adverbios y adjetivos, con la salvedad\nde que ning\u00b4 un contexto era proporcionado. Los sistemas parti-\ncipantes pod\u00b4 \u0131an utilizar cualquier informaci\u00b4 on adicional como\nsynsets, la jerarqu\u00b4 \u0131a de WordNet y otro tipo de relaciones en\nWordNet.\nTarea 13. Semantic Roles. (36 sistemas) ( Litkowski (2004a ))\nUtilizando como base una porci\u00b4 on del corpus anotado de Frame-\nNet, los sistemas deb\u00b4 \u0131an realizar la anotaci\u00b4 on de roles sem\u00b4 anti-\ncos siguiendo las m\u00b4 etricas del estudio de Gildea y Jurafsky ( Gil-\ndea y Jurafsky (2002 )).\nTarea 14. Logic Forms. (26 sistemas) ( Rus(2004 )) El objetivo\nde esta tarea era transformar oraciones formuladas en ingl\u00b4 es en\nsu correspondiente notaci\u00b4 on de l\u00b4 ogica de primer orden. Cada\n158 6.1 Competiciones de evaluaci\u00b4 on\npalabra con contenido sem\u00b4 antico se correspond\u00b4 \u0131a con un predi-\ncado.\n6.1.4 SENSEVAL-4/SEMEVAL-1: 4th International\nWorkshop on Semantic Evaluations\nLa \u00b4 ultima edici\u00b4 on Senseval4tuvo lugar en Junio de 2007 en\nPraga (Rep\u00b4 ublica Checa). En esta edici\u00b4 on se organizaron diecio-\ncho tareas (la tarea 3 se cancel\u00b4 o):\nTarea 1. Evaluating WSD on Cross-Language Information Re-\ntrieval. (2 sistemas) ( Agirre et al. (2007 ))\nTarea 2. Evaluating Word Sense Induction and Discrimination\nSystems. (6 sistemas) ( Agirre y Soroa (2007 ))\nTarea 4. Classi\ufb01cation of Semantic Relations between Nomi-\nnals. (15 sistemas) ( Girju et al. (2007 ))\nTarea 5. Multilingual Chinese-English Lexical Sample. (6 sis-\ntemas) ( Jin et al. (2007 ))\nTarea 6. Word Sense Disambiguation of Prepositions. (5 siste-\nmas) ( Litkowski y Hargraves (2007 ))\nTarea 7. Coarse Grained English All Words Task. (12 sistemas)\n(Navigli et al. (2007 ))\nTarea 8. Metonymy Resolution at SemEval 2007. (5 sistemas)\n(Markert y Nissim (2007 ))\nTarea 9. Multilevel Semantic Annotation of Catalan and Spa-\nnish. (2 sistemas) ( M` arquez et al. (2007 ))\nTarea 10. English Lexical Substitution Task. ( McCarthy y Na-\nvigli (2007 ))\nTarea 11. English Lexical Sample Task via English-Chinese\nParallel Text. ( Ng y Chan (2007 ))\nTarea 12. Turkish Lexical Sample Task. ( Orhan et al. (2007 ))\nTarea 13. Web People Search. ( Artiles et al. (2007 ))\nTarea 14. A\ufb00ective Text. ( Strapparava y Mihalcea (2007 ))\nTarea 15. TempEval Temporal Relation Identi\ufb01cation. ( Ver-\nhagen et al. (2007 ))\n4http://nlp.cs.swarthmore.edu/semeval/\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 159\nTarea 16. Evaluation of Wide Coverage Knowledge Resources.\n(Cuadros y Rigau (2007 ))\nTarea 17. English Lexical Sample, SRL and All Words. ( Prad-\nhan et al. (2007 ))\nTarea 18. Arabic Semantic Labeling. ( Diab et al. (2007 ))\nTarea 19. Frame Semantic Structure Extraction. ( Baker et al.\n(2007 ))\n6.2 Participaci\u00b4 on en Senseval\nPara la evaluaci\u00b4 on de los diferentes sistemas de WSD, es ne-\ncesario determinar un inventario de sentidos con el que anotar\nlas palabras polis\u00b4 emicas de los textos. Adem\u00b4 as, se debe de\ufb01nir un\nconjunto de corpus sobre los que realizar la anotaci\u00b4 on y posterior\nevaluaci\u00b4 on de los resultados. Junto con el establecimiento de un\nrepositorio de sentidos, se plantean otro tipo de problemas, como\npor ejemplo, el c\u00b4 omo decidir el grado de distinci\u00b4 on entre un sen-\ntido u otro. Este problema se denomina nivel de granularidad de\nsentidos ( Edmonds y Kilgarri\ufb00 (1998 )), donde se pueden distin-\nguir dos tipos: granularidad \ufb01na ( \u201c\ufb01ne-grained\u201d ) y granularidad\ngruesa ( \u201ccoarse-grained\u201d ). Los repositorios de sentidos con granu-\nlaridad \ufb01na tienen como caracter\u00b4 \u0131stica poseer una divisi\u00b4 on muy\ndetallada de los sentidos pero con un alto nivel de ambig\u00a8 uedad.\nSin embargo, los repositorios de sentidos con granularidad grue-\nsa proporcionan una divisi\u00b4 on muy general de los sentidos con un\nnivel muy bajo de ambig\u00a8 uedad.\nPara las diferentes evaluaciones dentro de la competici\u00b4 on Sen-\nseval , se ha utilizado como repositorio de sentidos WordNet,\ncaracterizado por tener una granularidad \ufb01na, donde existe una\ndivisi\u00b4 on de los sentidos muy detallada. Todos los sistemas partici-\npantes deben anotar una serie de palabras polis\u00b4 emicas de acuerdo\na los diferentes sentidos de WordNet. Finalmente, la evaluaci\u00b4 on de\nla efectividad de cada sistema se realiza estableciendo una com-\nparaci\u00b4 on con respecto a una anotaci\u00b4 on manual de los corpus de\nevaluaci\u00b4 on.\n160 6.2 Participaci\u00b4 on en Senseval\nLas medidas utilizadas para la evaluaci\u00b4 on de los sistemas de\nWSD son las siguientes:\nPrecision =Instancias correctas contestadas\nInstancias contestadas(6.1)\nCobertura =Instancias correctas contestadas\nTotal instancias(6.2)\nA continuaci\u00b4 on se describen las tareas en las que nuestros siste-\nmas de WSD han participado, junto con los resultados obtenidos\ny su clasi\ufb01caci\u00b4 on respecto a otros sistemas participantes.\n6.2.1 DRelevant: All Words\nLa evaluaci\u00b4 on del m\u00b4 etodo de desambiguaci\u00b4 on DRelevant pre-\nsentado en este trabajo, se ha realizado sobre los textos de la\ntarea \u201cEnglish all-words\u201d deSenseval-2 . Esta tarea consiste en\ndesambiguar todas las palabras con contenido sem\u00b4 antico (nom-\nbres, verbos, adjetivos y adverbios), que aparecen en los textos\nproporcionados, para su posterior evaluaci\u00b4 on. El n\u00b4 umero total de\npalabras a desambiguar (nombres, verbos, adjetivos y adverbios)\nsupone un total de 2473 instancias.\nPara evaluar la e\ufb01ciencia del m\u00b4 etodo, se han adoptado diferen-\ntes criterios atendiendo al tama\u02dc no del contexto seleccionado y al\nn\u00b4 umero de dominios empleado para realizar el proceso de desam-\nbiguaci\u00b4 on. En las siguientes secciones se detallan cada una de los\nexperimentos realizados.\n6.2.1.1 Experimento 1: Oraci\u00b4 on como contexto.\nEn este primer experimento, el contexto seleccionado para rea-\nlizar el proceso de desambiguaci\u00b4 on es la oraci\u00b4 on. Es decir, a partir\ndel corpus proporcionado se extraen todas las oraciones, se anali-\nzan morfol\u00b4 ogicamente mediante el \u201cTree-tagger\u201d y se guardan los\nnombres, verbos, adjetivos y adverbios de cada oraci\u00b4 on en dife-\nrentes \ufb01cheros, que ser\u00b4 an la entrada para el sistema DRelevant.\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 161\nEn la Tabla 6.1, se muestra la e\ufb01ciencia del m\u00b4 etodo con el\ncriterio de utilizar como contexto la oraci\u00b4 on.\nContexto: Oraci\u00b4 on\nPrecisi\u00b4 on\nCobertura\nCobertura Absoluta\n44 %\n32 %\n73 %\nTabla 6.1. Medida de la e\ufb01ciencia utilizando como contexto la oraci\u00b4 on\nTras el proceso de desambiguaci\u00b4 on, el n\u00b4 umero de palabras\ncorrectamente desambiguadas no super\u00b4 o el 50 % del n\u00b4 umero total\nde instancias. Estos resultados son debidos en gran medida a la\nescasa informaci\u00b4 on que aporta el contexto de la oraci\u00b4 on, ya que, el\nn\u00b4 umero de palabras proporcionadas por la oraci\u00b4 on no es su\ufb01cien-\nte para obtener una buena informaci\u00b4 on contextual y determinar\ncorrectamente los sentidos.\n6.2.1.2 Experimento 2: Ventana de 100 palabras como\ncontexto.\nEn esta segunda prueba, se establece como contexto una venta-\nna de 100 palabras alrededor de cada palabra ambigua. Es decir,\npara cada una de las palabras a desambiguar se extraen las 100 pa-\nlabras con contenido sem\u00b4 antico que la rodean (50 palabras previas\ny 50 palabras posteriores). Por ejemplo, si quisi\u00b4 eramos desambi-\nguar la palabra \u2019sound\u2019 , el contexto extra\u00b4 \u0131do ser\u00b4 \u0131a el siguiente:\n\u201c(50 palabras previas)... Then, at a signal, the ringers begin\nvarying the order in which the bells sound without altering the\nsteady rhythm of the striking...(50 palabras posteriores)\u201d\nEn caso de que no se pudieran extraer las 50 palabras anterio-\nres a la palabra a desambiguar, porque se ha llegado al comienzo\ndel texto, el contexto de 100 palabras se completar\u00b4 \u0131a con la in-\nformaci\u00b4 on de las palabras posteriores a la palabra ambigua. Del\nmismo modo, en caso de que no se pudieran extraer las 50 pala-\nbras posteriores a la palabra a desambiguar porque se ha llegado\n162 6.2 Participaci\u00b4 on en Senseval\nal \ufb01nal del texto, el resto, se extraer\u00b4 \u0131a a partir de las palabras\nanteriores a la palabra ambigua.\nEn la Tabla 6.2se muestra la e\ufb01ciencia del m\u00b4 etodo al utilizar\ncomo contexto una ventana de 100 palabras. En este caso tanto\nla precisi\u00b4 on, como la cobertura y la cobertura absoluta sufren\nun incremento, llegando a alcanzar el 47 %, el 38 % y el 81 %\nrespectivamente.\nContexto: Ventana de 100 palabras\nPrecisi\u00b4 on\nCobertura\nCobertura Absoluta\n47 %\n38 %\n81 %\nTabla 6.2. Medida de la e\ufb01ciencia utilizando como contexto una ventana de 100\npalabras\nA la vista de los resultados obtenidos, es evidente la necesidad\nde disponer de un contexto lo su\ufb01cientemente amplio, para esta-\nblecer correctamente los sentidos de las palabras.\n6.2.1.3 Experimento 3: Reducci\u00b4 on y agrupaci\u00b4 on de los do-\nminios.\nEn este experimento, se intenta minimizar el nivel de especiali-\nzaci\u00b4 on de los dominios. Este proceso se ha realizado partiendo de\nla estructuraci\u00b4 on jer\u00b4 arquica de los dominios en WordNet Domains.\nEn este caso, se agrupan dentro de un dominio que se encuentra\nen un nivel superior de la jerarqu\u00b4 \u0131a, aquellos subdominios que de-\npenden de \u00b4 el. Es decir, se agrupan dentro de un mismo dominio\nel conjunto de dominios que pertenecen a su misma jerarqu\u00b4 \u0131a pe-\nro que est\u00b4 an en los niveles inferiores. Por ejemplo, en el caso de\nla jerarqu\u00b4 \u0131a del dominio Medicine , se encuentran por debajo de\n\u00b4 el los dominios: Dentistry ,Pharmacy ,Psychiatry ,Radio-\nlogy ySurgery . Estos dominios se engloban dentro del dominio\nMedicine , y as\u00b4 \u0131 se reduce el espacio de b\u00b4 usqueda y el grado de\nespecializaci\u00b4 on. Obteniendo \ufb01nalmente 43 dominios, sobre los 165\ndominios iniciales.\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 163\nLa reducci\u00b4 on del nivel de especializaci\u00b4 on de los dominios requie-\nre una nueva anotaci\u00b4 on de los sentidos de las palabras de WordNet\ny por tanto, una nueva obtenci\u00b4 on de los dominios relevantes jun-\nto con su correspondiente ratio de asociaci\u00b4 on. Esta tarea se ha\nrealizado previamente a la aplicaci\u00b4 on del sistema DRelevant.\nDado que los resultados a partir de una ventana contextual\nde 100 palabras han demostrado obtener mejores resultados en\nel proceso de anotaci\u00b4 on de sentidos, este experimento, se rea-\nliz\u00b4 o manteniendo la ventana de 100 palabras y utilizando la re-\nducci\u00b4 on del nivel de especializaci\u00b4 on de los dominios.\nEn este caso, tras analizar los resultados obtenidos, se vuelve a\nincrementar el n\u00b4 umero de palabras correctamente desambiguadas,\ny por consiguiente, la precisi\u00b4 on tambi\u00b4 en sufre un incremento, tal\ny como se muestra en la Tabla 6.3.\nReducci\u00b4 on del n\u00b4 umero de dominios\nPrecisi\u00b4 on\nCobertura\nCobertura Absoluta\n48 %\n41 %\n85 %\nTabla 6.3. Medida de la e\ufb01ciencia reduciendo el nivel de especializaci\u00b4 on de los\ndominios\nSe hace patente, por tanto, que la reducci\u00b4 on del nivel de espe-\ncializaci\u00b4 on de los dominios, in\ufb02uye positivamente en el proceso de\ndesambiguaci\u00b4 on.\n6.2.1.4 Experimento 4: Desambiguaci\u00b4 on a nivel de domi-\nnio.\nEl \u00b4 ultimo experimento realizado, se basa en la necesidad de\nreducir el n\u00b4 umero de sentidos de una misma palabra proporcio-\nnados por WordNet. Es decir, en WordNet, la distinci\u00b4 on entre los\ndistintos sentidos de una palabra es en algunos casos muy dif\u00b4 \u0131cil\nde establecer, es lo que se denomina granularidad \ufb01na, como se\ncomentaba al principio de esta secci\u00b4 on. Para intentar reducir es-\nta granularidad se agrupan aquellos sentidos etiquetados con el\n164 6.2 Participaci\u00b4 on en Senseval\nmismo dominio. De esta forma, el resultado de la desambiguaci\u00b4 on\npara una palabra, no ser\u00b4 \u0131a un \u00b4 unico sentido, sino todos aquellos\nsentidos de la palabra que tengan asociado el mismo dominio que\nse obtenga tras el proceso de desambiguaci\u00b4 on. Por ejemplo, su-\npongamos que tras el proceso de desambiguaci\u00b4 on de la palabra\n\u201cbank\u201d , se obtiene el dominio Economy , entonces dar\u00b4 \u0131amos co-\nmo resultado los tres sentidos asociados a este dominio: bank#1 ,\nbank#3 ybank#6 .\nLa reducci\u00b4 on de la granularidad de WordNet se realiz\u00b4 o utili-\nzando los 165 dominios de la jerarqu\u00b4 \u0131a de WordNet Domains. La\nopci\u00b4 on de reducir la granularidad a partir de reducir el nivel de\nespecializaci\u00b4 on de dominios no se ha planteado, porque se reducen\ndram\u00b4 aticamente el n\u00b4 umero de sentidos de las palabras.\nEn este caso, los resultados obtenidos reportan una precisi\u00b4 on\ndel 54 %, tal y como se muestra en la Tabla 6.4.\nDesambiguaci\u00b4 on a nivel de dominio\nPrecisi\u00b4 on\nCobertura\nCobertura Absoluta\n54 %\n43 %\n80 %\nTabla 6.4. Medida de la e\ufb01ciencia desambiguando a nivel de dominio\nAs\u00b4 \u0131 pues, la agrupaci\u00b4 on de sentidos como cab\u00b4 \u0131a esperar obtiene\nmejores resultados. En muchos casos, la distinci\u00b4 on de sentidos es\ndemasiado \ufb01na, y es muy dif\u00b4 \u0131cil establecer la l\u00b4 \u0131nea que diferencia\nun sentido de otro, por tanto, la agrupaci\u00b4 on resuelve este dilema.\n6.2.1.5 Comparativa con otros sistemas.\nLa evaluaci\u00b4 on del sistema DRelevant aqu\u00b4 \u0131 presentado sobre la\ntarea \u201cEnglish all-words\u201d deSenseval-2 , tiene como \ufb01nalidad\nel poder establecer una comparativa con el resto de sistemas no\nsupervisados, que participaron en esta edici\u00b4 on. Esta comparaci\u00b4 on\nse realiza atendiendo a las medidas de precisi\u00b4 on y cobertura.\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 165\nEn la Tabla 6.5se muestran los resultados obtenidos por los\ndistintos sistemas que participaron en la tarea \u201cEnglish all-words\u201d\ndeSenseval-2 .\nSistema\nPrecision\nCobertura\n1\nSMWaw-\n0.69\n0.690\n2\nAve-Antwerp\n0.636\n0.636\n3\nLIA-Sinequa-AllWords\n0.618\n0.618\n4\nDavid-fa-UNED-AW-T\n0.575\n0.569\n5\nDavid-fa-UNED-AW-U\n0.556\n0.550\n6\nGchao2-\n0.475\n0.454\n7\nGchao3-\n0.474\n0.453\n8\nKen-Litkowski-clr-aw\n0.451\n0.451\n9\nGchao-\n0.500\n0.449\nExp4\nDRelevant-4\n0.54\n0.43\nExp3\nDRelevant-3\n0.48\n0.41\nExp2\nDRelevant-2\n0.47\n0.38\n10\ncm.guo-usm-english-tagger2\n0.360\n0.360\n11\nMagnini2-irst-eng-all\n0.748\n0.357\n12\nCmguo-usm-english-tagger\n0.345\n0.338\n13\nc.guo-usm-english-tagger3\n0.336\n0.336\nExp1\nDRelevant-1\n0.44\n0.32\n14\nAgirre2-ehu-dlist-all\n0.572\n0.291\n15\nJudita-\n0.440\n0.200\n16\nDianam-system3ospdana\n0.545\n0.169\n17\nDianam-system2ospd\n0.566\n0.169\n18\nDianam-system1\n0.598\n0.140\n19\nWoody-IIT2\n0.328\n0.038\n20\nWoody-IIT3\n0.294\n0.034\n21\nWoody-IIT1\n0.287\n0.033\nTabla 6.5. Comparaci\u00b4 on de los resultados de los distintos sistemas participantes\nen la tarea \u201cEnglish all-words\u201d deSenseval-2 .\nA continuaci\u00b4 on vamos a evaluar la posici\u00b4 on alcanzada por nues-\ntro sistema en cada uno de los experimentos realizados:\nExperimento 1. Este experimento trata de evaluar la e\ufb01cien-\ncia del m\u00b4 etodo de desambiguaci\u00b4 on propuesto, utilizando como\ncontexto las palabras de la oraci\u00b4 on donde aparece la instan-\ncia a desambiguar. En este caso, la precisi\u00b4 on obtenida es de\n166 6.2 Participaci\u00b4 on en Senseval\nun 44 % y la cobertura es de un 32 %. Con estos resultados\nnuestro sistema se situar\u00b4 \u0131a en la posici\u00b4 on 14 por delante del\nsistema de Agirre2-ehu-dlist-all.\nExperimento 2. En este experimento el contexto utilizado se\nampl\u00b4 \u0131a mediante la utilizaci\u00b4 on de una ventana de 100 pala-\nbras alrededor de la instancia a desambiguar. En este caso, la\nprecisi\u00b4 on obtenida es de un 47 % y la cobertura es de un 38 %.\nCon los resultados obtenidos en este experimento nuestro sis-\ntema se situar\u00b4 \u0131a en la posici\u00b4 on 10 por delante del m\u00b4 etodo de\nMagnini2-irst-eng-all. Este dato supone que nuestro m\u00b4 etodo\nmejora los resultados obtenidos por el m\u00b4 etodo de Magnini, e\nindica que la utilizaci\u00b4 on de las glosas de WordNet Domains pa-\nra extraer el recurso l\u00b4 exico Dominios Relevantes y su posterior\nutilizaci\u00b4 on en un m\u00b4 etodo de WSD ofrece buenos resultados.\nExperimento 3. En este experimento se reduce el nivel de es-\npecializaci\u00b4 on de los dominios y se utiliza una ventana de 100\npalabras alrededor de la instancia a desambiguar. Se obtiene\nun 48 % de precisi\u00b4 on y un 41 % de cobertura. Los resultados\nobtenidos en este experimento mejoran la precisi\u00b4 on y la co-\nbertura del experimento anterior, pero no suponen un cambio\nen la posici\u00b4 on alcanzada por nuestro sistema con respecto a\nlos otros participantes de Senseval-2\nExperimento 4. En este experimento se trata de reducir el\nproblema de la granularidad \ufb01na de WordNet agrupando\naquellos sentidos de una misma palabra, que comparten un\nmismo dominio. En este caso, la precisi\u00b4 on obtenida es de un\n54 % y la cobertura es de un 43 %. Aqu\u00b4 \u0131 ocurre lo mismo que\nen experimento anterior, los valores de precisi\u00b4 on y cobertura\nsufren una mejora, pero no lo su\ufb01ciente como para mejorar la\nposici\u00b4 on de nuestro sistema.\nEn de\ufb01nitiva, la utilizaci\u00b4 on del recurso l\u00b4 exico Dominios Rele-\nvantes y su aplicaci\u00b4 on en un m\u00b4 etodo de WSD, ofrece unos resul-\ntados prometedores con respecto a los actuales sistemas de de-\nsambiguaci\u00b4 on autom\u00b4 atica del sentido de las palabras. Adem\u00b4 as, el\nrecurso Dominios Relevantes, ofrece informaci\u00b4 on muy \u00b4 util para re-\nlacionar sem\u00b4 anticamente diferentes palabras, y puede ser utilizado\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 167\ncomo recurso para otras tareas de PLN, tal y como se demues-\ntra en las siguientes secciones: reconocimiento de la implicaci\u00b4 on\ntextual, discriminaci\u00b4 on de nombres, etc.\n6.2.2 DRelevant mejorado con Extended WordNet\nEl recurso l\u00b4 exico Dominios Relevantes, utilizado como base de\nconocimiento del m\u00b4 etodo de desambiguaci\u00b4 on DRelevant, puede ser\nmejorado si se utiliza para su construcci\u00b4 on Extended WordNet en\nlugar de WordNet Domains. Como ya se coment\u00b4 o en el cap\u00b4 \u0131tulo\nanterior, Extended WordNet proporciona informaci\u00b4 on adicional\nacerca de los sentidos de las palabras de las glosas. Esta informa-\nci\u00b4 on ha sido utilizada para obtener de nuevo el recurso Dominios\nRelevantes mejorado.\nUtilizando esta nueva versi\u00b4 on de DR se han realizado los mis-\nmos experimentos para la tarea all-words obteniendo los resulta-\ndos mostrados en la Tabla 6.6.\nOpci\u00b4 on\nPrecisi\u00b4 on\nRecall\nContexto oraci\u00b4 on\n0.56\n0.46\nVentana de 100 palabras\n0.61\n0.47\nReducci\u00b4 on del num. de dominios\n0.62\n0.50\nDesamb. a nivel de dominio\n0.63\n0.56\nTabla 6.6. Evaluaci\u00b4 on de WSD DRelevant usando Extended WordNet\nA la vista de los resultados, se aprecia una mejora sobre los\nanteriores experimentos. Se produce un aumento del 12 % a nivel\nde precisi\u00b4 on en el experimento que toma como contexto la oraci\u00b4 on.\nUn 4 % de mejora con respecto al experimento que utiliza una\nventana de 100 palabras y el experimento que reduce el n\u00b4 umero de\ndominios, agrupando aquellos que descienden del mismo concepto.\nLo mismo ocurre con el \u00b4 ultimo experimento, que trata de evitar la\ngranularidad \ufb01na de WordNet, desambiguando a nivel de dominio\nen lugar de a nivel de sentido.\nPodemos concluir que la elecci\u00b4 on de los contextos y la infor-\nmaci\u00b4 on proporcionada por \u00b4 estos, son fundamentales para la ob-\n168 6.2 Participaci\u00b4 on en Senseval\ntenci\u00b4 on del recurso Dominios Relevantes. Adem\u00b4 as, una buena ca-\nlidad de los DR supone una mejora de los resultados del sistema\nWSD Relevant. De esta forma, con los nuevos resultados nuestro\nsistema escala cinco posiciones con respecto al resto de sistemas\nparticipantes en la tarea \u201call-words\u201d .\n6.2.3 R2D2: English All Words y English Lexical Sample\nDentro del marco del proyecto R2D2 (Recuperaci\u00b4 on de Res-\npuestas en Documentos Digitalizados)5se particip\u00b4 o en la tercera\nedici\u00b4 on de Senseval . El objetivo de esta participaci\u00b4 on fue eva-\nluar el resultado de la combinaci\u00b4 on de diferentes sistemas de WSD\ndentro de las tareas English All-Words y English Lexical Sample.\nPara llevar a cabo el experimento se combinaron tanto siste-\nmas supervisados como sistemas no supervisados. De forma que\nse intent\u00b4 o paliar la falta en muchos casos de ejemplos de entre-\nnamiento para los sistemas supervisados que imped\u00b4 \u0131a la correcta\ndetecci\u00b4 on de los sentidos, incorporando m\u00b4 etodos no supervisados\nque no necesitaban ejemplos de entrenamiento.\nLos sistemas participantes para la tarea English All-words fue-\nron cuatro: Maximum Entropy, UPV-SHMM-AW, DRelevant y\nCIAOSENSO. En la tarea English Lexical Sample participaron\ntambi\u00b4 en cuatro sistemas: DRelevant, CIAOSENSO, LVQ-JAEN-\nELS y Maximum Entropy. La Tabla 6.7muestra las caracter\u00b4 \u0131sticas\nde cada uno de los sistemas participantes.\n6.2.3.1 R2D2: English All Words.\nEn la Tabla 6.8se presentan los resultados obtenidos para los\ndiferentes sistemas participantes, tanto supervisados como no su-\npervisados. En este caso, se han tomado como v\u00b4 alidas aquellas\nrespuestas anotadas como desconocidas por todos los sistemas.\nDe esta forma, tanto precisi\u00b4 on como cobertura coinciden debido\na que siempre se contesta el 100 % de las instancias. El sistema\nR2D2 resultado de la combinaci\u00b4 on de sistemas WSD supervisados\n5Proyecto \ufb01nanciado por el Ministerio de Ciencia y Tecnolog\u00b4 \u0131a. TIC2003-07158-\nC04-01\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 169\nSistemas\nDescripci\u00b4 on\nMaximum entropy\nSistema supervisado basado en los modelos de pro-\nbabilidad de M\u00b4 axima entrop\u00b4 \u0131a. Este sistema uti-\nliza un conjunto de caracter\u00b4 \u0131sticas y un conjunto\nde ejemplos de entrenamiento extra\u00b4 \u0131dos del cor-\npus Semcor para resolver la ambig\u00a8 uedad ( Su\u00b4 arez\ny Palomar (2002 )).\nUPV-SHMM-AW\nSistema supervisado basado en modelos especiali-\nzados ocultos de Markov (Specialized Hidden Mar-\nkov Models) ( Molina et al. (2002 )).\nDRelevant\nSistema no supervisado basado en la adquisici\u00b4 on\nde conocimiento a trav\u00b4 es de WordNet Domains\n(Montoyo et al. (2003 )).\nCIAOSENSO\nSistema no supervisado basado en densidad con-\nceptual, frecuencia de sentidos de WordNet y\nWordNet Domains ( Rosso et al. (2003 )).\nLVQ-Jaen-ELS\nSistema supervisado basado en redes neurona-\nles utilizando LVQ, integrando Semcor y varias\nrelaciones sem\u00b4 anticas de WordNet ( Vega et al.\n(2003 )).\nTabla 6.7. Sistemas participantes en el equipo R2D2\ny no supervisados, se coloca en cuarto lugar respecto al resto de\nsistemas participantes.\nEl sistema de votaci\u00b4 on utilizado en esta tarea combina los re-\nsultados de los diferentes sistemas de WSD seg\u00b4 un se muestra en\nla Figura 6.1.\n \nMAX. ENT. \nUPV-SHMM \nDRELEVANT \nCIAOSENSO X \nX \n-- \n-- X \n-- \nX \n-- X \n-- \n-- \nX -- \nX \n-- \nX -- \nX \nX \n-- -- \n-- \nX \nX X \n-- \n-- \n-- -- \nX \n-- \n-- -- \n-- \nX \n-- -- \n-- \n-- \nX 1 2 3 4 5 6 7 8 9 10 \nFigura 6.1. Sistema de votaci\u00b4 on R2D2 All Words\n170 6.2 Participaci\u00b4 on en Senseval\nInicialmente se le da preferencia a aquellos sentidos dados como\nrespuesta por la mayor\u00b4 \u0131a de sistemas. Pero en caso de no existir\nacuerdo, se decide el sentido correcto en un m\u00b4 aximo de 10 pasos.\nTal y como muestra la Figura 6.1el primer paso da preferencia\na los sistemas supervisados, si no existe acuerdo, el segundo paso\ncomprueba el acuerdo entre Max. Ent. y DRelevant... El sistema\nde votaci\u00b4 on contin\u00b4 ua hasta que en alg\u00b4 un paso exista acuerdo, si no\nes as\u00b4 \u0131, los sentidos que han permanecido sin anotar se deciden en\n\u00b4 ultima instancia por un solo sistema, dando siempre preferencia\na los sistemas supervisados.\nSystem\nPrecision/Recall\nGAMBL-AW-S\n0.652\nSenseLearner-S\n0.646\nKoc University-S\n0.641\nR2D2: English-all-words\n0.626\nMeaning-allwords-S\n0.624\nMeaning-simple-S\n0.610\nupv-shmm-eaw-S\n0.609\nLCCaw\n0.607\nUJAEN-S\n0.590\nIRST-DDD-00-U\n0.583\nUniversity of Sussex-Prob5\n0.572\nUniversity of Sussex-Prob4\n0.554\nUniversity of Sussex-Prob3\n0.551\nDFA-Unsup-AW-U\n0.548\nIRST-DDD-LSI-U\n0.501\nKUNLP-Eng-All-U\n0.500\nupv-unige-CIAOSENSO-eaw-U\n0.481\nmerl.system3\n0.458\nupv-unige-CIAOSENSO2-eaw-U\n0.452\nmerl.system1\n0.450\nIRST-DDD-09-U\n0.446\nautoPS-U\n0.436\nclr04-aw\n0.434\nmerl.system2\n0.359\nautoPSNVs-U\n0.359\nTabla 6.8. Resultados para AllWords con validaci\u00b4 on de respuestas no anotadas\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 171\nEn la Tabla 6.9se muestran los resultados obtenidos, ignoran-\ndo las respuestas no anotadas. De esta forma, ya no existe un\n100 % en el n\u00b4 umero de respuestas anotadas, sino que \u00b4 este se redu-\nce al no tenerse en cuenta instancias no anotadas con un sentido\ndeterminado. De esta forma, la precisi\u00b4 on y cobertura di\ufb01eren en\nsu valor. En este caso, respecto al sistema R2D2, los resultados\nno di\ufb01eren en absoluto de los anteriores, debido a que siempre\nse responden el 100 % de las instancias, utilizando un m\u00b4 etodo de\nvotaci\u00b4 on entre los diferentes sistemas.\nSystem\nPrecision\nRecall\nGAMBL-AW-S\n0.651\n0.651\nSenseLearner-S\n0.651\n0.642\nKoc University-S\n0.648\n0.639\nR2D2: English-all-words\n0.626\n0.626\nMeaning-allwords-S\n0.625\n0.623\nMeaning-simple-S\n0.611\n0.610\nLCCaw\n0.614\n0.606\nupv-shmm-eaw-S\n0.616\n0.605\nUJAEN-S\n0.601\n0.588\nIRST-DDD-00-U\n0.583\n0.582\nUniversity of Sussex-Prob5\n0.585\n0.568\nUniversity of Sussex-Prob4\n0.575\n0.550\nUniversity of Sussex-Prob3\n0.573\n0.547\nDFA-Unsup-AW-U\n0.557\n0.546\nKUNLP-Eng-All-U\n0.510\n0.496\nIRST-DDD-LSI-U\n0.661\n0.496\nupv-unige-CIAOSENSO-eaw-U\n0.581\n0.480\nmerl.system3\n0.467\n0.456\nupv-unige-CIAOSENSO2-eaw-U\n0.608\n0.451\nmerl.system1\n0.459\n0.447\nIRST-DDD-09-U\n0.729\n0.441\nautoPS-U\n0.490\n0.433\nclr04-aw\n0.506\n0.431\nautoPSNVs-U\n0.563\n0.354\nmerl. system2\n0.480\n0.352\nTabla 6.9. Resultados para AllWords sin validaci\u00b4 on de respuestas no anotadas\n172 6.2 Participaci\u00b4 on en Senseval\n6.2.3.2 R2D2: English Lexical Sample.\nEn la tarea English Lexical Sample el objetivo es desambiguar\nuna serie de palabras etiquetadas dentro de un corpus: nombres,\nverbos y adjetivos. El m\u00b4 etodo utilizado para seleccionar el sentido\n\ufb01nal de cada palabra, es un sistema de votaci\u00b4 on, donde el sentido\nm\u00b4 as votado por todos los sistemas es el seleccionado. En caso\nde no existir acuerdo entre varios sentidos se le da prioridad a\nlos sistemas supervisados debido a que demuestran una mejor\nprecisi\u00b4 on en esta tarea (sistema similar al presentado en la Figura\n6.1). La Tabla 6.2.3.2 muestra los resultados obtenidos en esta\ntarea.\nTabla 6.10: Sistemas participantes en la tarea English Lexical Sample de\nSenseval-3\nFine\nCoarse\nSystem/Team\nDescription\nP\nR\nP\nR\nhtsa3\nU.Bucharest\n(Grozea)\nA Naive Bayes system, with correc-\ntion of the a-priori frequencies, by di-\nviding the output con\ufb01dence of the\nsenses by frequency\u00ae(\u00ae= 0.2)\n72.9\n72.9\n79.3\n79.3\nIRST-\nKernels\nITC-IRST\n(Strappara-\nva)\nKernel methods for pattern abstrac-\ntion, paradigmatic and syntagmatic\ninfo.and unsupervised term proximity\n(LSA) on BNC, in an SVM classi\ufb01er.\n72.6\n72.6\n79.5\n79.5\nnusels\nNat.U. Singa-\npore (Lee)\nA combination of knowledge sour-\nces (part-of-speech of neighbouring\nwords, words in context, local colloca-\ntions, syntactic relations), in an SVM\nclassi\ufb01er.\n72.4\n72.4\n78.8\n78.8\nhtsa4\nSimilar to htsa3, with di\ufb00erent correc-\ntion function of a-priori frequencies.\n72.4\n72.4\n78.8\n78.8\nBCU comb\nBasque\nCountry U.\n(Agirre &\nMartinez)\nAn ensemble of decision lists, SVM,\nand vectorial similarity, improved\nwith a variety of smoothing techni-\nques. The features consist of local\ncollocations, syntactic dependencies,\nbag-of-words, domain features.\n72.3\n72.3\n78.9\n78.9\nhtsa1\nSimilar to htsa3, but with smaller\nnumber of features.\n72.2\n72.2\n78.7\n78.7\n(contin\u00b4 ua . . . )\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 173\nTabla 6.10: Sistemas participantes en la tarea English Lexical Sample de\nSenseval-3 (continuaci\u00b4 on)\nFine\nCoarse\nSystem/Team\nDescription\nP\nR\nP\nR\nrlsc-comb\nU.Bucharest\n(Popescu)\nA regularized least-square classi\ufb01ca-\ntion (RLSC), using local and topical\nfeatures, with a term weighting sche-\nme.\n72.2\n72.2\n78.4\n78.4\nhtsa2\nSimilar to htsa4, but with smaller\nnumber of features.\n72.1\n72.1\n78.6\n78.6\nBCU english\nSimilar to BCU comb, but with a vec-\ntorial space model learning.\n72.0\n72.0\n79.1\n79.1\nrlsc-lin\nSimilar to rlsc-comb, with a linear\nkernel, and a binary weighting sche-\nme.\n71.8\n71.8\n78.4\n78.4\nHLTC\nHKUST\nall\nHKUST\n(Carpuat)\nA voted classi\ufb01er combining a new\nkernel PCA method, a Maximum En-\ntropy model, and a boosting-based\nmodel, using syntactic and collocatio-\nnal features\n71.4\n71.4\n78.6\n78.6\nTALP\nU.P.Catalunya\n(Escudero et\nal.)\nA system with per-word feature se-\nlection, using a rich feature set. For\nlearning, it uses SVM, and combines\ntwo binarization procedures: one vs.\nall, and constraint learning.\n71.3\n71.3\n78.2\n78.2\nMC-WSD\nBrown U.\n(Ciaramita &\nJohnson)\nA multiclass averaged perceptron\nclassi\ufb01er with two components: one\ntrained on the data provided, the\nother trained on this data, and on\nWordNet glosses. Features consist of\nlocal and syntactic features.\n71.1\n71.1\n78.1\n78.1\nHLTC\nHKUST\nall2\nSimilar to HLTC HKUST all, also\nadds a Naive Bayes classi\ufb01er.\n70.9\n70.9\n78.1\n78.1\nNRC-Fine\nNRC (Tur-\nney)\nSyntactic and semantic features,\nusing POS tags and pointwise mutual\ninformation on a terabyte corpus. Fi-\nve basic classi\ufb01ers are combined with\nvoting.\n69.4\n69.4\n75.9\n75.9\nHLTC\nHKUST\nme\nSimilar to HLTC HKUST all, only\nwith a maximum entropy classi\ufb01er.\n69.3\n69.3\n76.4\n76.4\nNRC-Fine2\nSimilar to NRC-Fine, with a di\ufb00erent\nthreshold for dropping features\n69.1\n69.1\n75.6\n75.6\n(contin\u00b4 ua . . . )\n174 6.2 Participaci\u00b4 on en Senseval\nTabla 6.10: Sistemas participantes en la tarea English Lexical Sample de\nSenseval-3 (continuaci\u00b4 on)\nFine\nCoarse\nSystem/Team\nDescription\nP\nR\nP\nR\nGAMBL\nU. Antwerp\n(Decadt)\nA cascaded memory-based classi\ufb01er,\nusing two classi\ufb01ers based on global\nand local features, with a genetic al-\ngorithm for parameter optimization.\n67.4\n67.4\n74.0\n74.0\nSinequaLex\nSinequa Labs\n(Crestan)\nSemantic classi\ufb01cation trees, built on\nshort contexts and document seman-\ntics, plus a decision system based on\ninformation retrieval techniques.\n67.2\n67.2\n74.2\n74.2\nCLaC1\nConcordia U.\n(Lamjiri)\nA Naive Bayes approach using a con-\ntext window around the target word,\nwhich is dynamically adjusted\n67.2\n67.2\n75.1\n75.1\nSinequaLex2\nA cumulative method based on scores\nof surrounding words.\n66.8\n66.8\n73.6\n73.6\nUMD SST4\nU. Maryland\n(Cabezas)\nSupervised learning using Support\nVector Machines, using local and wide\ncontext features, and also grammati-\ncal and expanded contexts.\n66.0\n66.0\n73.7\n73.7\nProb1\nCambridge\nU. (Preiss)\nA probabilistic modular WSD sys-\ntem, with individual modules ba-\nsed on separate known approaches to\nWSD (26 di\ufb00erent modules)\n65.1\n65.1\n71.6\n71.6\nSyntaLex-3\nU.Toronto\n(Moham-\nmad)\nA supervised system that uses local\npart of speech features and bigrams,\nin an ensemble classi\ufb01er using bagged\ndecision trees.\n64.6\n64.6\n72.0\n72.0\nUNED\nUNED (Arti-\nles)\nA similarity-based system, relying on\nthe co-occurrence of nouns and adjec-\ntives in the test and training exam-\nples.\n64.1\n64.1\n72.0\n72.0\nSyntaLex-4\nSimilar to SyntaLex-3, but with uni-\n\ufb01ed decision trees.\n63.3\n63.3\n71.1\n71.1\nCLaC2\nSyntactic and semantic (WordNet hy-\npernyms) information of neighboring\nwords, fed to a Maximum Entropy\nlearner. See also CLaC1\n63.1\n63.1\n70.3\n70.3\nSyntaLex-1\nBagged decision trees using local POS\nfeatures. See also SyntaLex-3.\n62.4\n62.4\n69.1\n69.1\nSyntaLex-2\nSimilar to SyntaLex-1, but using\nbroad context part of speech features.\n61.8\n61.8\n68.4\n68.4\nProb2\nSimilar to Prob1, but invokes only 12\nmodules.\n61.9\n61.9\n69.3\n69.3\n(contin\u00b4 ua . . . )\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 175\nTabla 6.10: Sistemas participantes en la tarea English Lexical Sample de\nSenseval-3 (continuaci\u00b4 on)\nFine\nCoarse\nSystem/Team\nDescription\nP\nR\nP\nR\nDuluth-ELSS\nU.Minnesota\n(Pedersen)\nAn ensemble approach, based on th-\nree bagged decision trees, using uni-\ngrams, bigrams, and co-occurrence\nfeatures\n61.8\n61.8\n70.1\n70.1\nUJAEN\nU.Ja\u00b4 en\n(Garc\u00b4 \u0131a-\nVega)\nA Neural Network supervised system,\nusing features based on semantic re-\nlations from WordNet extracted from\nthe training data\n61.3\n61.3\n69.5\n69.5\nR2D2\nU. Alicante\n(Vazquez)\nA combination of supervised (Maxi-\nmum Entropy, HMM Models, Vector\nQuantization, and unsupervised (do-\nmains and conceptual density) sys-\ntems.\n63.4\n52.1\n69.7\n57.3\nIRST-Ties\nITC-IRST\n(Strappara-\nva)\nA generalized pattern abstraction\nsystem, based on boosted wrapper in-\nduction, using only few syntagmatic\nfeatures.\n70.6\n50.5\n76.7\n54.8\nNRC-Coarse\nSimilar to NRC-Fine; maximizes the\ncoarse score, by training on coarse\nsenses.\n48.5\n48.5\n75.8\n75.8\nNRC-\nCoarse2\nSimilar to NRC-Coarse, with a di\ufb00e-\nrent threshold for dropping features.\n48.4\n48.4\n75.7\n75.7\nU.Alicante\n(Vazquez)\nA maximum entropy method and\na bootstrapping algorithm (\u201cre-\ntraining\u201d) with, iterative feeding\nof training cycles with new high-\ncon\ufb01dence examples.\n78.2\n31.0\n82.8\n32.9\n6.2.4 DLSA: English Lexical Sample\nEl nuevo m\u00b4 etodo de WSD basado en LSA, presentado en el\ncap\u00b4 \u0131tulo anterior ha sido evaluado sobre la tarea \u201cEnglish Lexi-\ncal Sample\u201d deSenseval-3 . En l\u00b4 \u0131neas generales, este m\u00b4 etodo\nutiliza como base para representar el conocimiento, una matriz\n[dominios - t\u00b4 erminos], donde cada columna se corresponde con\nuna categor\u00b4 \u0131a sem\u00b4 antica de los dominios de WND, y cada \ufb01la se\ncorresponde con un t\u00b4 ermino (lema). Para la obtenci\u00b4 on de la ma-\ntriz conceptual se utiliza como fuente de informaci\u00b4 on las glosas de\nWND, ya que, est\u00b4 an anotadas con sus correspondientes categor\u00b4 \u0131as\n176 6.2 Participaci\u00b4 on en Senseval\nsem\u00b4 anticas (dominio). Finalmente, tras la obtenci\u00b4 on de la matriz,\nel espacio conceptual se reduce a una matriz de 100 dimensiones.\nEn el proceso de desambiguaci\u00b4 on se ha utilizado el m\u00b4 etodo DL-\nSA con dos aproximaciones diferentes: una primera aproximaci\u00b4 on\nutilizando como matriz conceptual todo el conjunto de palabras\ncon contenido sem\u00b4 antico (nombres, verbos, adjetivos y adverbios)\ny una segunda aproximaci\u00b4 on restringiendo el tipo de categor\u00b4 \u0131as\nsem\u00b4 anticas en la matriz (s\u00b4 olo nombres, s\u00b4 olo verbos o s\u00b4 olo adje-\ntivos). El objetivo de estas dos aproximaciones es determinar si\nexiste alguna interferencia motivada por el uso de contextos m\u00b4 as\no menos restringidos.\n6.2.4.1 Matriz conceptual NVAR.\nEn esta secci\u00b4 on se presentan los resultados obtenidos por el\nm\u00b4 etodo DLSA utilizando como fuente de informaci\u00b4 on una ma-\ntriz conceptual construida a partir de todos los nombres, verbos,\nadjetivos y adverbios de las glosas de WordNet. Para realizar la\ncodi\ufb01caci\u00b4 on de la matriz se han obtenido previamente los lemas\nde las palabras de las glosas de WordNet. Esto se debe a que LSA\ntoma como datos diferentes un nombre en plural y el mismo nom-\nbre en singular. Nuestra hip\u00b4 otesis es que ni el tiempo verbal, ni\nlos plurales alteran el contenido sem\u00b4 antico de las palabras de un\ncontexto. Una vez obtenida la matriz inicial con 162 dimensio-\nnes, cada una de ellas correspondiendo a un dominio de WND, se\nprocede a la reducci\u00b4 on de la matriz a \u00b4 unicamente 100 dimensio-\nnes. A partir de aqu\u00b4 \u0131 se han utilizado diferentes heur\u00b4 \u0131sticas para\ndeterminar el sentido correcto de cada palabra:\n20 dominios m\u00b4 as relevantes: Sobre los 20 primeros dominios\nobtenidos por el algoritmo de LSA.\n10 dominios m\u00b4 as relevantes: Sobre los 10 primeros dominios\nobtenidos por el algoritmo de LSA.\nPasos para la obtenci\u00b4 on del sentido correcto DLSA\nWSD:\n1.Aplicar LSA sobre el contexto de la palabra ambigua.\nDevuelve los dominios con el grado de similitud m\u00b4 as elevado\nrespecto al contexto.\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 177\n2.Comparar los dominios obtenidos con LSA con los do-\nminios relevantes de cada sentido de la palabra ambi-\ngua. Para cada sentido de la palabra ambigua, se seleccionan\naquellos dominios que coinciden con los Dominios Relevantes\nde ese sentido.\n3.Selecci\u00b4 on de heur\u00b4 \u0131stica (para cada posible sentido):\n3.1. Se suman los valores del Ratio de Asociaci\u00b4 on (RA) para\ncada uno de los dominios seleccionados.\n3.2. Se suman los valores de similitud obtenidos con LSA\npara los dominios seleccionados (esta heur\u00b4 \u0131stica es la que pro-\nporciona mejores resultados).\n3.3 En este tercera heur\u00b4 \u0131stica, los dominios obtenidos por\nLSA tienen asociado un valor de similitud, que ser\u00b4 a m\u00b4 as eleva-\ndo cuanto mayor sea la similitud del contexto con el dominio.\nPara dar mayor peso a los dominios con mayor valor de simi-\nlitud se ha optado por realizar el producto de los valores de\nsimilitud de LSA por el RA. De esta forma se le da prioridad\na los dominios con mayor valor de similitud.\nEn la Tabla 6.11 se muestran los resultados obtenidos para\ncada heur\u00b4 \u0131stica.\n10 dominios\n20 dominos\nFine\nCoarse\nFine\nCoarse\nNombres\nHeur\u00b4 \u0131stica 1\n21.3\n33.5\n21.5\n36.2\nHeur\u00b4 \u0131stica 2\n44.9\n52\n41.4\n48.4\nHeur\u00b4 \u0131stica 3\n21.2\n33.4\n21.5\n36.2\nVerbos\nHeur\u00b4 \u0131stica 1\n35.4\n41.9\n34.8\n42.5\nHeur\u00b4 \u0131stica 2\n51.3\n55\n49\n53.7\nHeur\u00b4 \u0131stica 3\n35.4\n41.9\n34.8\n42.5\nAdjetivos\nHeur\u00b4 \u0131stica 1\n11.1\n18.3\n9.8\n18.3\nHeur\u00b4 \u0131stica 2\n41.8\n50.03\n37.3\n44.4\nHeur\u00b4 \u0131stica 3\n11.1\n18.3\n9.8\n18.3\nTabla 6.11. DLSA aplicado sobre todas las categor\u00b4 \u0131as NVAR\nSeg\u00b4 un la Tabla 6.11, la Heur\u00b4 \u0131stica 2 proporciona los mejores\nresultados. En este caso, aplicando LSA sobre una matriz concep-\n178 6.2 Participaci\u00b4 on en Senseval\ntual con todas las categor\u00b4 \u0131as sem\u00b4 anticas (nombres, verbos, adje-\ntivos y adverbios), se alcanza una precisi\u00b4 on de alrededor de 45 %\nen el caso de evaluar el sistema con granularidad \ufb01na y de un\n55 % en el caso de evaluar el sistema con granularidad gruesa. Los\nvalores obtenidos tambi\u00b4 en demuestran que la utilizaci\u00b4 on de los 10\nprimeros dominios como fuente de informaci\u00b4 on sem\u00b4 antica es su\ufb01-\nciente para alcanzar buenos resultados. En cambio, la utilizaci\u00b4 on\nde los 20 primeros dominios empeora los resultados gradualmente.\n6.2.4.2 Matriz conceptual N-V-A.\nLos resultados obtenidos tras la evaluaci\u00b4 on de los nombres\n(aproximaci\u00b4 on matriz con s\u00b4 olo nombres) se re\ufb02ejan en la Tabla\n6.12, donde se muestra el grado de precisi\u00b4 on/recall obtenidos para\ncada palabra en concreto. En todos nuestros experimentos, siem-\npre se han contestado todas las instancias, por tanto, precisi\u00b4 on y\nrecall alcanzan el mismo resultado.\nPara los verbos y los adjetivos, los resultados individuales ob-\ntenidos (aproximaci\u00b4 on matriz s\u00b4 olo verbos y s\u00b4 olo adjetivos) son los\nmostrados en las Tablas 6.13y6.14.\nEn la Tabla 6.15 se muestran los resultados obtenidos para\ncada heur\u00b4 \u0131stica.\nAl igual que suced\u00b4 \u0131a en el experimento anterior, los mejores\nresultados seg\u00b4 un la Tabla 6.15son los de la Heur\u00b4 \u0131stica 2. En este\ncaso se han realizado tres matrices conceptuales distintas, una por\ncada categor\u00b4 \u0131a (N, V, A o R). En este caso, los resultados obteni-\ndos en este \u00b4 ultimo experimento, mejoran los anteriores. Es decir,\nespecializando las matrices conceptuales y restringiendo el uso de\ncategor\u00b4 \u0131as l\u00b4 exicas, se pueden mejorar los resultados en el proceso\nde desambiguaci\u00b4 on. De esta forma, si se trata de desambiguar un\nnombre, la informaci\u00b4 on contextual perteneciente a los nombres\nque lo rodean proporciona un mejor indicativo de sus relaciones\nsem\u00b4 anticas, que todas las dem\u00b4 as palabras que lo rodean.\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 179\nPalabra\nPrecisi\u00b4 on/Recall\nargument\n53.27\narm\n67.74\natmosphere\n57.79\naudience\n51.51\nbank\n32.5\ndegree\n61.41\ndi\ufb00erence\n40.35\ndi\ufb03culty\n18.18\ndisc\n27\nimage\n37.68\ninterest\n23.65\njudgment\n15.62\norganization\n39.28\npaper\n4.28\nparty\n18.91\nperformance\n26.74\nplan\n82.14\nshelter\n32.98\nsort\n82.89\nsource\n68.96\nTabla 6.12. Resultados ELS sobre nombres\n6.2.4.3 Comparativa con otros sistemas.\nEn la tarea \u201cEnglish Lexical Sample\u201d , participaron tanto sis-\ntemas supervisados como sistemas no supervisados. Los prime-\nros obtuvieron mejores resultados alcanzando el mejor sistema un\n72.9 % de precisi\u00b4 on y cobertura ( Grozea (2004 )). Con respecto a\nlos sistemas no supervisados, el mejor sistema obtuvo un 66.1 %\nde precisi\u00b4 on ( Ramakrishnan et al. (2004 )). Dado que DLSA es un\nsistema no supervisado, realizaremos la comparativa de los resul-\ntados obtenidos con estos \u00b4 ultimos. En la Tabla 6.16se muestran\nlos resultados obtenidos para cada uno de los sistemas participan-\ntes junto con una breve descripci\u00b4 on de cada uno de ellos.\nLa heur\u00b4 \u0131stica que mejores resultados proporciona para nuestro\nm\u00b4 etodo DLSA es la heur\u00b4 \u0131stica 2, la cual, selecciona el sentido m\u00b4 as\nadecuado a partir de la intersecci\u00b4 on de los dominios obtenidos por\n180 6.2 Participaci\u00b4 on en Senseval\nPalabra\nPrecisi\u00b4 on/Recall\nactivate\n8.84\nadd\n48.85\nappear\n45.03\nask\n29.35\nbegin\n60.52\nclimb\n78.12\ndecide\n51.61\neat\n97.70\nencounter\n53.12\nexpect\n74.35\nexpress\n88.88\nhear\n40.62\nlose\n81.81\nmean\n30\nmiss\n21.53\nnote\n95.52\noperate\n16.66\nplay\n17.64\nproduce\n89.24\nprovide\n72.46\nreceive\n44.44\nremain\n37.14\nrule\n50\nsmell\n41.17\nsuspend\n13.17\ntalk\n89.39\ntreat\n47.36\nuse\n100\nwash\n16.45\nwatch\n98.03\nwin\n50\nwrite\n19.09\nTabla 6.13. Resultados ELS sobre verbos\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 181\nPalabra\nPrecisi\u00b4 on/Recall\ndi\ufb00erent\n53.19\nhot\n80.95\nimportant\n21.05\nsimple\n27.77\nsolid\n17.03\nTabla 6.14. Resultados ELS sobre adjetivos\n10 dominios\n20 dominios\nFine\nCoarse\nFine\nCoarse\nNombres\nHeur\u00b4 \u0131stica 1\n23.8\n38\n26.2\n42\nHeur\u00b4 \u0131stica 2\n45.8\n53.3\n44\n50.4\nHeur\u00b4 \u0131stica 3\n23.8\n38.1\n26.1\n41.8\nVerbos\nHeur\u00b4 \u0131stica 1\n36.2\n41.8\n37.6\n43.1\nHeur\u00b4 \u0131stica 2\n53.2\n58\n52.7\n57.6\nHeur\u00b4 \u0131stica 3\n36.4\n41.8\n38\n43.4\nAdjetivos\nHeur\u00b4 \u0131stica 1\n11.1\n19\n10.5\n17.6\nHeur\u00b4 \u0131stica 2\n45.1\n54.9\n41.8\n49.7\nHeur\u00b4 \u0131stica 3\n10.5\n18.3\n11.1\n19\nTabla 6.15. DLSA aplicado sobre cada categor\u00b4 \u0131a por separado\nLSA y los dominios relevantes del vector de sentidos, utilizando\n\u00b4 unicamente los valores de similitud obtenidos por LSA.\nEl resultado global tras la evaluaci\u00b4 on sobre el corpus de test\ndeSenseval-3 , posiciona nuestro sistema en cuarto lugar con\nrespecto al resto de sistemas no supervisados participantes en la\ntarea English Lexical Sample.\n6.2.5 SenseDiscrim: Spanish Lexical Sample\nEl sistema SenseDiscrim basado en reglas ling\u00a8 u\u00b4 \u0131sticas aplicadas\nsobre corpus y en la obtenci\u00b4 on de conjuntos de discriminadores\nde sentidos sobre WordNet, se ha evaluado sobre el corpus de test\ndeSenseval-3 en la tarea Spanish Lexical Sample.\nDado que este sistema actualmente se ha desarrollado para la\ndesambiguaci\u00b4 on de nombres, es necesaria la combinaci\u00b4 on con otro\n182 6.2 Participaci\u00b4 on en Senseval\nFine\nCoarse\nSistema\nDescripci\u00b4 on\nP\nR\nP\nR\nwsdiit\nIIT Bombay\n(Ramakrish-\nnan et al.)\nUtiliza la medida de similitud de Lesk\nentre los contextos de palabras ambi-\nguas y de\ufb01niciones de diccionarios.\n66.1\n65.7\n73.9\n74.1\nCymfony\n(Niu)\nUtiliza un modelo de m\u00b4 axima en-\ntrop\u00b4 \u0131a para clustering no supervisado,\nutilizando palabras vecinas y estruc-\nturas sint\u00b4 acticas como caracter\u00b4 \u0131sticas.\n56.3\n56.3\n66.4\n66.4\nProb0\nCambridge\nU. (Preiss)\nCombina dos m\u00b4 odulos no supervisa-\ndos, utilizando informaci\u00b4 on b\u00b4 asica de\nPOS-tagging e informaci\u00b4 on de fre-\ncuencia.\n54.7\n54.7\n63.6\n63.6\nDLSA H2\nUniversity\nof Alicante\n(svazquez)\nUtiliza LSA combinada con Dominios\nRelevantes. Heur\u00b4 \u0131stica 2.\n48.9\n48.9\n54.2\n54.2\nclr04-ls\nCL\nResearch\n(Litkowski)\nUtiliza una serie de propiedades\n(sint\u00b4 acticas, sem\u00b4 anticas, patrones de\nsubcategorizaci\u00b4 on, otra informaci\u00b4 on\nl\u00b4 exica).\n45.0\n45.0\n55.5\n55.5\nCIAOSENSO\nU. Genova\n(Buscaldi)\nCombina la densidad conceptual con\nla frecuencia de palabras y la infor-\nmaci\u00b4 on proporcionada por dominios.\n50.1\n41.7\n59.1\n49.3\nKUNLP\nKorea\nU. (Seo)\nSelecciona el sentido de las palabras\nutilizando sustitutos a trav\u00b4 es de la je-\nrarqu\u00b4 \u0131a de WordNet (ant\u00b4 onimos, hi-\nper\u00b4 onimos, etc). La selecci\u00b4 on se hace\na partir de la co-ocurrencia de pala-\nbras en un corpus.\n40.4\n40.4\n52.8\n52.8\nDuluth-\nSenseRelate\nU.Minnesota\n(Pedersen)\nAsigna el sentido mejor relacionado\ncon los posibles sentidos de las pala-\nbras vecinas. Se utilizan las glosas de\nWordNet para medir la similitud en-\ntre sentidos.\n40.3\n38.5\n51.0\n48.7\nDFA-LS-\nUnsup\nUNED\n(Fernandez)\nCombina tres heur\u00b4 \u0131sticas: similitud\nentre sin\u00b4 onimos y el contexto, de\nacuerdo a la medida de la informa-\nci\u00b4 on mutua; patrones l\u00b4 exico-sint\u00b4 acti-\ncos a partir de las glosas de WordNet\ny la heur\u00b4 \u0131stica del primer sentido.\n23.4\n23.4\n27.4\n27.4\nTabla 6.16. Sistemas no supervisados en la tarea ELS de Senseval-3\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 183\nsistema para responder a las instancias referentes a verbos y adje-\ntivos. En nuestro caso, se ha optado por la utilizaci\u00b4 on del sistema\nsupervisado de M\u00b4 axima Entrop\u00b4 \u0131a ( Su\u00b4 arez (2004 )) que ha demos-\ntrado obtener una alta precisi\u00b4 on en el proceso de desambiguaci\u00b4 on.\nEn la tarea Spanish Lexical Sample se deb\u00b4 \u0131an desambiguar\n21 nombres: arte, autoridad, banda, canal, circuito, columna, co-\nraz\u00b4 on, corona, gracia, grano, hermano, letra, masa, mina, natu-\nraleza, operaci\u00b4 on, \u00b4 organo, partido, pasaje, programa y tabla. De\nestos 21 nombres s\u00b4 olo se realiz\u00b4 o un an\u00b4 alisis parcial de los 13 nom-\nbres mostrados en la Tabla 6.17.\nEl objetivo principal de la evaluaci\u00b4 on del sistema SenseDiscrim,\nes demostrar que mediante la elecci\u00b4 on de un determinado n\u00b4 umero\nde patrones de los que se puede extraer informaci\u00b4 on paradigm\u00b4 atica\ny de un conjunto de discriminadores de sentidos, se puede obtener\nuna alta precisi\u00b4 on que supera a la mayor\u00b4 \u0131a de sistemas actuales.\nPara la adquisici\u00b4 on de informaci\u00b4 on paradigm\u00b4 atica a partir de\npatrones sintagm\u00b4 aticos se ha utilizado el corpus EFE sobre no-\nticias en espa\u02dc nol, junto con un umbral= 5 de frecuencia m\u00b4 \u0131nima\npara la extracci\u00b4 on de informaci\u00b4 on.\nEl procedimiento seguido para la desambiguaci\u00b4 on de nombres\nes el siguiente:\n1.Se identi\ufb01can los patrones sint\u00b4 acticos con un \ufb01ltro de frecuen-\ncia m\u00b4 \u0131nimo de 5.\n2.Se adquiere la informaci\u00b4 on paradigm\u00b4 atica de los patrones iden-\nti\ufb01cados utilizando el corpus EFE como corpus de b\u00b4 usqueda.\n3.Se utiliza el algoritmo de Prueba de Conmutabilidad estable-\nciendo un sentido para cada patr\u00b4 on identi\ufb01cado en el paso\nprevio.\n4.Para cada patr\u00b4 on: se interseccionan las propuestas de sentidos\na partir de la informaci\u00b4 on sintagm\u00b4 atica y de la informaci\u00b4 on\nparadigm\u00b4 atica. El sentido propuesto por la mayor\u00b4 \u0131a de los pa-\ntrones es seleccionado. En caso, de no existir acuerdo, se da\npreferencia al sentido m\u00b4 as frecuente en WordNet.\nEl an\u00b4 alisis posterior de los resultados demuestra que para la\nmitad de los nombres de la tarea de \u201cSpanish Lexical Sample\u201d ,\nno existe informaci\u00b4 on su\ufb01ciente en el corpus EFE que permita\n184 6.2 Participaci\u00b4 on en Senseval\nPalabra\nOcurrencias\nContestadas\nCorrectas\nCobertura\nPrecisi\u00b4 on\nautoridad\n132\n38\n35\n28.79 %\n92.11 %\ncanal\n131\n21\n21\n16.03 %\n100 %\ncircuito\n132\n3\n1\n1.52 %\n50 %\ncorona\n64\n0\n0\n0 %\n0 %\ngracia\n38\n0\n0\n0 %\n0 %\ngrano\n61\n2\n0\n3.28 %\n0 %\nhermano\n66\n0\n0\n0 %\n0 %\nmasa\n85\n0\n0\n0 %\n0 %\nnaturaleza\n128\n0\n0\n0 %\n0 %\npartido\n66\n17\n14\n25.76 %\n82.35 %\npasaje\n111\n0\n0\n0 %\n0 %\nprograma\n133\n26\n23\n19.55 %\n88.46 %\ntabla\n64\n0\n0\n0 %\n0 %\nTabla 6.17. Resultados del sistema SenseDiscrim para los nombres de la tarea\nSpanish Lexical Sample de Senseval-3\nidenti\ufb01car patrones con un grado de \ufb01abilidad elevado. En cam-\nbio, para el resto de nombres identi\ufb01cados, la precisi\u00b4 on obtenida\nes muy elevada, tal y como se pretend\u00b4 \u0131a demostrar. En nuestro\ncaso, mediante la utilizaci\u00b4 on de patrones y la combinaci\u00b4 on de la\ninformaci\u00b4 on paradigm\u00b4 atica y el conjunto de discriminadores de\nsentidos de WordNet, es posible realizar una desambiguaci\u00b4 on con\nuna alta e\ufb01cacia.\n6.2.5.1 Evaluaci\u00b4 on de los resultados.\nLos resultados obtenidos tras la evaluaci\u00b4 on fueron de un 84 %\nde precisi\u00b4 on y un 47 % de cobertura. Cabe destacar que los resul-\ntados en cuanto a precisi\u00b4 on son excelentes en detrimento de una\nbaja cobertura. Esto es debido en gran parte, a la escasez de cor-\npus en espa\u02dc nol, lo que supone un impedimento para la extracci\u00b4 on\nde informaci\u00b4 on paradigm\u00b4 atica.\nLa Tabla 6.18 muestra los resultados obtenidos por los siste-\nmas que participaron en la tarea \u201cSpanish Lexical Sample\u201d de\nSenseval-3 .\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 185\nSistema\nPrec.\nRecall\nCover.\nF\u00af=1\nIRST\n84.20 %\n84.20 %\n100.0 %\n84.20\nUA-SRT\n84.00 %\n84.00 %\n100.0 %\n84.00\nUMD\n82.48 %\n82.48 %\n100.0 %\n82.48\nUNED\n81.76 %\n81.76 %\n100.0 %\n81.76\nSWAT\n79.45 %\n79.45 %\n100.0 %\n79.45\nD-SLSS\n74.29 %\n75.02 %\n100.0 %\n74.65\nCSUSMCS\n67.84 %\n67.82 %\n99.9 %\n67.83\nUA-NSM\n61.93 %\n61.93 %\n100.0 %\n61.93\nUA-NP\n84.31 %\n47.27 %\n56.1 %\n60.58\nMFC\n67.72 %\n67.72 %\n100.0 %\n67.72\nCOMB\n85.98 %\n85.98 %\n100.0 %\n85.98\nTabla 6.18. Resultados de los sistemas participantes en la tarea Spanish Lexical\nSample Senseval-3\nLos resultados mostrados en la Tabla 6.18se encuentran orde-\nnados seg\u00b4 un la medida F\u00af=1. Nuestro sistema alcanza la mayor\nprecisi\u00b4 on, sin embargo, obtiene una cobertura muy baja debido\na la escasez de corpus de los que extraer patrones e informaci\u00b4 on\nparadigm\u00b4 atica.\nEl mejor sistema en esta tarea fue IRST ( Strapparava et al.\n(2004 )) que utilizaba SVM como algoritmo de aprendizaje. Este\nsistema obtuvo los mejores resultados para las palabras con menos\nejemplos por sentido.\nLos dos \u00b4 ultimos sistemas mostrados en la tabla corresponden\na un sistema utilizado como baseline MFC (Most Frequent Sen-\nse Clasi\ufb01er) y un sistema de votaci\u00b4 on COMB que combina las\nrespuestas de los mejores sistemas en la tarea.\n6.2.6 Web People Search\nEn la cuarta edici\u00b4 on de Senseval se present\u00b4 o una nueva tarea\ndenominada \u201cWeb People Search\u201d (WePS), esta tarea tiene co-\nmo objetivo la detecci\u00b4 on y clasi\ufb01caci\u00b4 on de distintos documentos\n(p\u00b4 aginas web) a partir de los nombres propios que aparecen en\nellos. La di\ufb01cultad de esta tarea viene determinada por la exis-\ntencia de nombres propios ambiguos que aparecen en diferentes\n186 6.2 Participaci\u00b4 on en Senseval\ncontextos. Es por tanto necesario distinguir entre los distintos\ncontextos de los documentos y establecer para cada contexto los\nnombres propios relacionados con ellos.\nDebido a la necesidad de utilizar la informaci\u00b4 on contextual co-\nmo base para la detecci\u00b4 on y distinci\u00b4 on de diferentes entidades,\nse ha considerado viable la utilizaci\u00b4 on de la t\u00b4 ecnica de LSA para\nesta tarea. En concreto, se ha utilizado LSA para la agrupaci\u00b4 on\nde contextos similares a partir de la informaci\u00b4 on sem\u00b4 antica conte-\nnida. Tras la obtenci\u00b4 on de los contextos similares se ha utilizado\nuna t\u00b4 ecnica de clustering para la creaci\u00b4 on de conjuntos disjuntos\nde documentos.\nEl sistema presentado en esta tarea consta de varios m\u00b4 odulos.\nA continuaci\u00b4 on se describen cada uno de ellos:\nM\u00b4 odulo de preproceso. El primer m\u00b4 odulo se encarga de rea-\nlizar el preproceso de los documentos de entrada. Dado que\ntodos los documentos son p\u00b4 aginas web, existen etiquetas es-\npec\u00b4 \u0131\ufb01cas del lenguaje HTML y c\u00b4 odigo Javascript que no deben\ntenerse en cuenta. Por tanto, mediante un proceso de detec-\nci\u00b4 on y eliminaci\u00b4 on de elementos propios del lenguaje HTML se\nobtiene \u00b4 unicamente el texto comprendido entre las etiquetas\n<title> </title >y las etiquetas <body > </body >.\nM\u00b4 odulo de extracci\u00b4 on de informaci\u00b4 on contextual. En es-\nte m\u00b4 odulo se utilizan los resultados obtenidos en el m\u00b4 odulo\nde preproceso para la extracci\u00b4 on de informaci\u00b4 on relevante que\nayude a identi\ufb01car correctamente los diferentes contextos. Es-\nte m\u00b4 odulo se divide en cuatro sub-procesos:\n\u00b2Detecci\u00b4 on de nombres. Todos los nombres propios del\ncontexto (personas, organizaciones, lugares, etc), son detec-\ntados y extra\u00b4 \u0131dos. Para esta tarea se ha utilizado la arqui-\ntectura GATE6(Cunningham (2002 ),Cunningham (2005 ))\nque integra un m\u00b4 odulo de detecci\u00b4 on de entidades. El objeti-\nvo de este sub-m\u00b4 odulo es obtener los nombres propios de las\ndiferentes categor\u00b4 \u0131as y detectar sus ocurrencias en el resto\nde documentos. De esta forma, documentos que compartan\nlas mismas entidades pueden hacer referencia al mismo in-\n6http://gate.ac.uk/\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 187\ndividuo. Este sub-m\u00b4 odulo retorna como salida una matriz\nde valores binarios, donde 1 signi\ufb01ca que los documentos\ncomparados comparten m\u00b4 as de la mitad de sus entidades y\n0 cualquier otro caso.\n\u00b2Identi\ufb01caci\u00b4 on de enlaces web. Para cada documento se\nhan extra\u00b4 \u0131do los enlaces comprendidos entre las etiquetas\n<a href > </a>. Dado que los enlaces detectados son muy\nespec\u00b4 \u0131\ufb01cos se ha empleado una funci\u00b4 on que extrae la ra\u00b4 \u0131z\ngeneral de cada uno de los enlaces. Por ejemplo, la direc-\nci\u00b4 ond1http://www.cs.ualberta.ca/~lindek/index.htm\nse transformar\u00b4 a en http://www.cs.ualberta.ca/~lindek .\nDe esta forma si dos direcciones cualquiera d1yd2, compar-\nten la misma ra\u00b4 \u0131z d1Td2se consideran la misma direcci\u00b4 on.\nEl nivel de profundidad seleccionado de cada enlace es 3\nniveles como m\u00b4 aximo y 2 niveles como m\u00b4 \u0131nimo. La salida\nde este sub-m\u00b4 odulo es una matriz de valores binarios con 1\nsi el par de documentos comparten m\u00b4 as de 3 enlaces y 0 en\notro caso.\n\u00b2Detecci\u00b4 on de t\u00b4 \u0131tulos. Para cada documento se han ex-\ntra\u00b4 \u0131do los t\u00b4 \u0131tulos comprendidos entre las etiquetas <title>\n</title >.\u00b4Estos se han introducido en una matriz de uni-\ngramas utilizada como entrada para un sistema autom\u00b4 atico\nde clustering SenseClusters7. Mediante un criterio de cluste-\nring con parada autom\u00b4 atica se han agrupado los diferentes\ndocumentos de acuerdo al contexto de los t\u00b4 \u0131tulos. Del resul-\ntado obtenido se ha generado una nueva matriz de valores\nbinarios con 1 para los pares de documentos situados en el\nmismo cluster y 0 en otro caso.\n\u00b2Tratamiento del cuerpo de la p\u00b4 agina web. La parte de\ntexto comprendida entre las etiquetas <body > </body >ha\nsido tratada para extraer las categor\u00b4 \u0131as sint\u00b4 acticas de las pa-\nlabras usando Tree Tagger8. El resultado de este sub-m\u00b4 odulo\nes la anotaci\u00b4 on del texto con la informaci\u00b4 on sint\u00b4 actica de ca-\nda palabra: \u201cwater#v the#det \ufb02owers#n and#conj pass#v\nme#pron the#det glass#n of#prep water#n\u201d. El objetivo\n7http://www.d.umn.edu/~tpederse/senseclusters.html\n8http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/\n188 6.2 Participaci\u00b4 on en Senseval\nde esta transformaci\u00b4 on es servir de entrada al m\u00b4 odulo de\nLSA para poner tener en cuenta las categor\u00b4 \u0131as sint\u00b4 acticas\nde las palabras y poder construir as\u00b4 \u0131 una matriz conceptual\nm\u00b4 as precisa, ya que, no es lo mismo encontrar una palabra\nactuando como nombre (\u201cwater#n\u201d), que actuando como\nverbo (\u201cwater#v\u201d).\nM\u00b4 odulo de clustering. El \u00b4 ultimo m\u00b4 odulo es el m\u00b4 odulo de cla-\nsi\ufb01caci\u00b4 on de documentos en sus correspondientes clusters. En\neste m\u00b4 odulo se realizan tres sub-tareas.\n\u00b2LSA. Utilizando LSA, a partir de la codi\ufb01caci\u00b4 on obtenida\nen el sub-m\u00b4 odulo de tratamiento del cuerpo de los docu-\nmentos, se construye la matriz conceptual. En esta matriz\nlas \ufb01las representan palabras de la colecci\u00b4 on de documentos\ny las columnas representan los documentos (p\u00b4 aginas web)\ny las celdas contienen le frecuencia de ocurrencia de cada\npalabra en cada documento. A continuaci\u00b4 on se ha reducido\nla matriz a 300 dimensiones para evitar el ruido causado por\ninformaci\u00b4 on irrelevante. Finalmente, la salida de este sub-\nm\u00b4 odulo es una matriz que representa el grado de similitud\nentre los diferentes documentos.\n\u00b2Combinaci\u00b4 on de informaci\u00b4 on contextual. En este sub-\nm\u00b4 odulo se han combinado los resultados de la extracci\u00b4 on de\ninformaci\u00b4 on referente a entidades, t\u00b4 \u0131tulos, enlaces y cuer-\npo de los documentos. Esta informaci\u00b4 on se ha introducido\nen una nueva matriz de 100x400 dimensiones. Las \ufb01las se\ncorresponden con el n\u00b4 umero de documentos y las columnas\nrepresentan los valores obtenidos para las entidades, t\u00b4 \u0131tu-\nlos, enlaces y cuerpo de los documentos. Esta matriz es la\nentrada a un algoritmo de clustering denominado K-means9\nque determina el clustering de documentos a partir de esa\ninformaci\u00b4 on.\n\u00b2K-means. Para realizar el clustering de Np\u00b4 aginas web\nenKconjuntos disjuntos Sjque contienen Njpuntos de\ndatos, se utiliza la minimizaci\u00b4 on del cuadrado de sumas\n9http://www.cs.waikato.ac.nz/ml/weka/\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 189\nJ=KX\nj=1X\nn2Sjjxn\u00a1mujj2, donde xnes un vector que repre-\nsenta el navopunto de dato y mujes el centroide geom\u00b4 etri-\nco de los puntos de datos en Sj. La matriz a partir de la\ncual se realiza el clustering incluye la informaci\u00b4 on del t\u00b4 \u0131tu-\nlo, enlaces, entidades y cuerpo de las p\u00b4 aginas web. En la\nimplementaci\u00b4 on de K-means no existe un criterio de parada\nautom\u00b4 atico ( Witten y Frank (1999 )) por lo que se estable-\nci\u00b4 o manualmente.\nLa arquitectura del sistema WePS se muestra en la Figura 6.2.\n6.2.6.1 Evaluaci\u00b4 on de los sistemas de la tarea WePS.\nLos datos utilizados para la evaluaci\u00b4 on de los sistemas en la\ntarea WePS fueron extra\u00b4 \u0131dos de Wikipedia, de las personas que\nparticiparon en ACL06 y del corpus Web03 ( Mann (2006 )) que\ncontiene 32 nombres aleatorios extra\u00b4 \u0131dos del US Census. En la\nTabla 6.19se muestra la relaci\u00b4 on de los diferentes nombres propios\ncon su nivel de ambig\u00a8 uedad.\nLas medidas utilizadas para la evaluaci\u00b4 on de los distintos sis-\ntemas fueron \u201cPurity\u201d e \u201cInverse Purity\u201d. La medida de \u201cPurity\u201d\nest\u00b4 a relacionada con la medida de Precisi\u00b4 on, muy utilizada en Re-\ncuperaci\u00b4 on de Informaci\u00b4 on. Esta medida se centra en la frecuencia\nde las categor\u00b4 \u0131as m\u00b4 as comunes en cada cluster y da mayor pun-\ntuaci\u00b4 on a los sistemas cuya clasi\ufb01caci\u00b4 on introduce menos ruido en\nlos clusters. Siendo Cel conjunto de clusters a ser evaluados, L\nel conjunto de categor\u00b4 \u0131as (anotadas manualmente) y nel n\u00b4 umero\nde elementos clasi\ufb01cados, la medida \u201cPurity\u201d se obtiene seg\u00b4 un la\nF\u00b4 ormula 6.3.\nPurity =X\nijCij\nnm\u00b4 axPrecision (Ci; Lj) (6.3)\n190 6.2 Participaci\u00b4 on en Senseval\nNombre\nEntidades\nDocumentos\nDescartados\nWikipedia names\nArthur Morgan\n19\n100\n52\nJames Morehead\n48\n100\n11\nJames Davidson\n59\n98\n16\nPatrick Killen\n25\n96\n4\nWilliam Dickson\n91\n100\n8\nGeorge Foster\n42\n99\n11\nJames Hamilton\n81\n100\n15\nJohn Nelson\n55\n100\n25\nThomas Fraser\n73\n100\n13\nThomas Kirk\n72\n100\n20\nAverage\n56.50\n99.30\n17,50\nACL06 Names\nDekang Lin\n1\n99\n0\nChris Brockett\n19\n98\n5\nJames Curran\n63\n99\n9\nMark Johnson\n70\n99\n7\nJerry Hobbs\n15\n99\n7\nFrank Keller\n28\n100\n20\nLeon Barrett\n33\n98\n9\nRobert Moore\n38\n98\n28\nSharon Goldwater\n2\n97\n4\nStephen Clark\n41\n97\n39\nAverage\n31.00\n98.40\n12,80\nUS Census Names\nAlvin Cooper\n43\n99\n9\nHarry Hughes\n39\n98\n9\nJonathan Brooks\n83\n97\n8\nJude Brown\n32\n100\n39\nKaren Peterson\n64\n100\n16\nMarcy Jackson\n51\n100\n5\nMartha Edwards\n82\n100\n9\nNeil Clark\n21\n99\n7\nStephan Johnson\n36\n100\n20\nViolet Howard\n52\n98\n27\nAverage\n50.30\n99.10\n14.90\nGlobal average\n45.93\n98.93\n15.07\nTabla 6.19. Nombres ambiguos en WePS\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 191\n\u0001B\u00fasqueda Web  HTML/XML \ncleaning \nDocumentos Preproceso \nTitle Body \nLinks \nTexto Nombres \npropios \nMatriz a partir \ndel contexto \nK-means \nCluster analysis \nWEKA LSA transformaci\u00f3n \nmatricial Informaci\u00f3n contextual  \nClustering \nClusters \nFigura 6.2. Arquitectura sistema WePS\nDonde la precisi\u00b4 on de un cluster Cipara una categor\u00b4 \u0131a deter-\nminada Ljse de\ufb01ne como:\nPrecision = (Ci; Lj) =jCiTLjj\njCij(6.4)\nLa medida \u201cInverse Purity\u201d se centra en el cluster con m\u00b4 axi-\nmo \u201crecall\u201d para cada categor\u00b4 \u0131a, dando mayor puntuaci\u00b4 on a los\nresultados que proporcionan mayor n\u00b4 umero de elementos para ca-\n192 6.2 Participaci\u00b4 on en Senseval\nda categor\u00b4 \u0131a en su correspondiente cluster. Esta medida se de\ufb01ne\nseg\u00b4 un la F\u00b4 ormula 6.5:\nInversePurity =X\nijLij\nnm\u00b4 axPrecision (Li; Cj) (6.5)\nPara la clasi\ufb01caci\u00b4 on \ufb01nal de los sistemas, se utiliz\u00b4 o la medida\narm\u00b4 onica F\u00ae=0;5. Esta medida se de\ufb01ne seg\u00b4 un la F\u00b4 ormula 6.6:\nF=1\n\u00ae1\nPurity+ (1\u00a1\u00ae)1\nInversePurity(6.6)\nAdem\u00b4 as se a\u02dc nadi\u00b4 o otro valor a \u00aepara dar mayor importancia\na la \u201cInverse Purity\u201d, \u00ae= 0;2. La idea es que para un busca-\ndor web, deber\u00b4 \u0131a ser m\u00b4 as f\u00b4 acil desechar unas pocas p\u00b4 aginas web\nincorrectas en un cluster que contenga toda la informaci\u00b4 on nece-\nsaria, que tener que obtener la informaci\u00b4 on a partir de diversos\nclusters. Por lo tanto, el alcanzar un valor elevado en la \u201cInverse\nPurity\u201d deber\u00b4 \u0131a tenerse tambi\u00b4 en en cuenta a la hora de evaluar\nlos diferentes sistemas.\nLa Tabla 6.20muestra los resultados obtenidos tras la evalua-\nci\u00b4 on de nuestro sistema.\nComo se observa en la Tabla 6.20, la media de efectividad de\nnuestro sistema est\u00b4 a alrededor del 56 %. Con respecto a los otros\nparticipantes de la tarea WePS nuestro sistema se sit\u00b4 ua en la\nd\u00b4 ecima posici\u00b4 on de entre diecis\u00b4 eis participantes (Ver Tabla 6.21).\nTras el an\u00b4 alisis de los resultados obtenidos se detectaron algu-\nnas limitaciones a la hora de asignar correctamente los clusters.\nPor ejemplo, exist\u00b4 \u0131an muchas p\u00b4 aginas web que no conten\u00b4 \u0131an ape-\nnas informaci\u00b4 on entre las etiquetas <body > </body >, lo que\ndi\ufb01cultaba el correcto funcionamiento de LSA, ya que, el resulta-\ndo de calcular la similitud de un documento sin informaci\u00b4 on en el\ncuerpo de la p\u00b4 agina web respecto a otros, daba como resultado 0.\nOtra limitaci\u00b4 on viene dada por la diferencia de tama\u02dc no de los\ncontextos de las distintas p\u00b4 aginas web. Una consecuencia de esta\nvariedad es que LSA obtiene peores resultados si los contextos no\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 193\nName\nPurity\nInverse Purity\nF\u00ae=0.5\nF\u00ae=0.2\nMark Johnson\n0,55\n0,74\n0,63\n0,69\nSharon Goldwater\n0,96\n0,23\n0,37\n0,27\nRobert Moore\n0,36\n0,67\n0,47\n0,57\nLeon Barrett\n0,62\n0,51\n0,56\n0,52\nDekang Lin\n0,99\n0,43\n0,60\n0,49\nStephen Clark\n0,52\n0,75\n0,62\n0,69\nFrank Keller\n0,38\n0,67\n0,48\n0,58\nJerry Hobbs\n0,54\n0,63\n0,58\n0,61\nJames Curran\n0,53\n0,61\n0,57\n0,59\nChris Brockett\n0,73\n0,40\n0,51\n0,44\nThomas Fraser\n0,66\n0,57\n0,61\n0,58\nJohn Nelson\n0,68\n0,76\n0,72\n0,74\nJames Hamilton\n0,56\n0,60\n0,58\n0,59\nWilliam Dickson\n0,59\n0,78\n0,67\n0,73\nJames Morehead\n0,36\n0,64\n0,46\n0,56\nPatrick Killen\n0,56\n0,69\n0,62\n0,66\nGeorge Foster\n0,46\n0,70\n0,56\n0,64\nJames Davidson\n0,58\n0,71\n0,64\n0,68\nArthur Morgan\n0,77\n0,47\n0,59\n0,51\nThomas Kirk\n0,26\n0,90\n0,41\n0,60\nPatrick Killen\n0,56\n0,69\n0,62\n0,66\nHarry Hughes\n0,66\n0,54\n0,59\n0,56\nJude Brown\n0,64\n0,63\n0,64\n0,63\nStephan Johnson\n0,56\n0,80\n0,66\n0,73\nMarcy Jackson\n0,40\n0,73\n0,52\n0,63\nKaren Peterson\n0,56\n0,72\n0,63\n0,68\nNeil Clark\n0,68\n0,36\n0,47\n0,40\nJonathan Brooks\n0,53\n0,76\n0,63\n0,70\nViolet Howard\n0,58\n0,75\n0,65\n0,71\nGlobal average\n0,58\n0,64\n0,58\n0,60\nTabla 6.20. Resultados evaluaci\u00b4 on WePS\nson de un tama\u02dc no semejante. En un futuro se pretende trabajar\ncon una ventana de tama\u02dc no espec\u00b4 \u0131\ufb01co para cada contexto.\nAdem\u00b4 as, en WePS el n\u00b4 umero de individuos que comparten el\nmismo nombre es desconocido. Por tanto, el establecimiento del\nn\u00b4 umero de clusters es muy complicado y en el caso de K-means\nque no dispone de un criterio de parada, se debe hacer de forma\n194 6.2 Participaci\u00b4 on en Senseval\nmanual. En nuestro experimento, el establecimiento del n\u00b4 umero\nde clusters se hizo evaluando los resultados obtenidos para dife-\nrentes rangos sobre el corpus de entrenamiento. Los resultados\ndemostraron que el n\u00b4 umero de clusters id\u00b4 oneo para un correcto\nfuncionamiento se establec\u00b4 \u0131a entre 25 y 50.\nEn la Tabla 6.21se pueden consultar los resultados obtenidos\npor el resto de participantes en la tarea.\nMacro-averaged Scores\nF-measures\nrank\nteam-id\n\u00ae= 0;5\n\u00ae= 0;2\nPur\nInv\nPur\n1\nCU COMSEM\n0.78\n0.83\n0.72\n0.88\n2\nIRST-BP\n0.75\n0.77\n0.75\n0.80\n3\nPSNUS\n0.75\n0.78\n0.73\n0.82\n4\nUVA\n0.67\n0.62\n0.81\n0.60\n5\nSHEF\n0.66\n0.73\n0.60\n0.82\n6\nFICO\n0.64\n0.76\n0.53\n0.90\n7\nUNN\n0.62\n0.67\n0.60\n0.73\n8\nONE-IN-ONE\n0.61\n0.52\n1.00\n0.47\n9\nAUG\n0.60\n0.73\n0.50\n0.88\n10\nSWAT-IV\n0.58\n0.64\n0.55\n0.71\n11\nUA-ZSA\n0.58\n0.60\n0.58\n0.64\n12\nTITPI\n0.57\n0.71\n0.45\n0.89\n13\nJHU1-13\n0.53\n0.65\n0.45\n0.82\n14\nDFKI2\n0.50\n0.63\n0.39\n0.83\n15\nWIT\n0.49\n0.66\n0.36\n0.93\n16\nUC3M 13\n0.48\n0.66\n0.35\n0.95\n17\nUBC-AS\n0.40\n0.55\n0.30\n0.91\n18\nALL-IN-ONE\n0.40\n0.58\n0.29\n1.00\nTabla 6.21. Resultados evaluaci\u00b4 on sistemas WePS\nLos resultados presentados en la Tabla 6.21 responden a la\nmedida del macro-promedio10en lugar de a la medida del micro-\npromedio11. Se opt\u00b4 o por estas medidas porque el macro-promedio\n10El macro-promedio viene determinado por calcular el valor de Fpara cada per-\nsona y despu\u00b4 es calcular la media entre los resultados obtenidos\n11El micro-promedio viene determinado por las medidas de Purity e Inverse Purity\nsobre todas las instancias, para luego calcular el valor de Fsobre esos resultados\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 195\ntiene una interpretaci\u00b4 on m\u00b4 as clara: si la medida de evaluaci\u00b4 on es\nF, entonces se deber\u00b4 \u0131a calcular Fpara cada nombre de persona\ny entonces calcular la media de todos los valores de Fobtenidos.\n6.3 Participaci\u00b4 on en iCLEF\nDentro del marco de la competici\u00b4 on CLEF (Cross-Language\nEvaluation Forum) para la evaluaci\u00b4 on de sistemas en espacios\nmultiling\u00a8 ues, se particip\u00b4 o en la tarea espec\u00b4 \u0131\ufb01ca iCLEF ( Gonzalo\ny Oard (2004 )). En esta tarea (cross-language search system), el\nobjetivo era determinar la forma de proporcionar la mejor asis-\ntencia a distintos usuarios que formulaban preguntas en su lengua\nmaterna y obten\u00b4 \u0131an respuestas en otra lengua distinta.\nEl conjunto de preguntas proporcionadas para esta tarea fue-\nron extra\u00b4 \u0131das de la tarea de Question Answering del CLEF 2004,\ncon el \ufb01n de comparar los resultados obtenidos por sistemas\nautom\u00b4 aticos y los obtenidos con los experimentos interactivos.\nEn nuestro caso ( Navarro et al. (2004 )), el sistema proporcio-\nnaba varias respuestas (50 p\u00b4 arrafos) para una misma pregunta,\njunto con una serie de indicadores que establec\u00b4 \u0131an grados de simi-\nlitud entre cada par (pregunta-respuesta). Las preguntas estaban\nformuladas en espa\u02dc nol y las respuestas en ingl\u00b4 es.\nPara lograr el objetivo de asistir a los usuarios a localizar la\nrespuesta correcta, nos centramos en dos ideas:\n1.El tipo de informaci\u00b4 on mostrada al usuario. Debe ser\nsu\ufb01ciente para la localizaci\u00b4 on de la respuesta correcta, dado\nque el usuario no conoce de antemano la respuesta a cada\npregunta. Es el usuario el que debe decidir si la respuesta se\nencuentra en el p\u00b4 arrafo mostrado o no. Por tanto, no s\u00b4 olo se\ndebe mostrar la respuesta de forma expl\u00b4 \u0131cita, sino el su\ufb01ciente\ncontexto para poder extraer la respuesta correcta.\n2.C\u00b4 omo se muestra la informaci\u00b4 on al usuario. Concreta-\nmente en qu\u00b4 e lengua se le muestra la informaci\u00b4 on al usuario. Si\nlos usuarios no conocen la lengua de los p\u00b4 arrafos que muestran\nlas respuestas, se les debe proporcionar alguna informaci\u00b4 on ex-\ntra para localizar la respuesta correcta.\n196 6.3 Participaci\u00b4 on en iCLEF\nA partir de estas premisas, usuarios con poco conocimiento del\ningl\u00b4 es podr\u00b4 \u0131an establecer la respuesta correcta a partir de resul-\ntados obtenidos en ingl\u00b4 es y no en su lengua materna. Adem\u00b4 as,\nmediante el uso de este tipo de sistemas, se podr\u00b4 \u0131a evitar la tra-\nducci\u00b4 on de grandes vol\u00b4 umenes de datos a diferentes idiomas para\nsatisfacer la demanda de informaci\u00b4 on a partir de otras lenguas.\n6.3.1 Desarrollo de los experimentos\nCon el objetivo de asistir a los usuarios en su b\u00b4 usqueda de\ninformaci\u00b4 on, se han seguido tres pasos para realizar los experi-\nmentos.\n1.Formulaci\u00b4 on de la pregunta y traducci\u00b4 on autom\u00b4 atica.\nSe extrajeron preguntas en espa\u02dc nol de la colecci\u00b4 on del CLEF\n2004 y fueron traducidas con un sistema autom\u00b4 atico de tra-\nducci\u00b4 on a Ingl\u00b4 es12.\n2.Extracci\u00b4 on de pasajes relevantes. Para localizar los pa-\nsajes relevantes de la colecci\u00b4 on de documentos en ingl\u00b4 es se\nutiliz\u00b4 o un sistema de recuperaci\u00b4 on de informaci\u00b4 on autom\u00b4 atico\n(Llopis (2003 )). Este sistema extrae pasajes relacionados con\nla pregunta y los ordena de mayor relevancia a menor relevan-\ncia. Concretamente, el tama\u02dc no de cada pasaje extra\u00b4 \u0131do fue de\n5 frases, tama\u02dc no m\u00b4 as que su\ufb01ciente para localizar una posible\nrespuesta.\n3.Interacci\u00b4 on con el usuario y localizaci\u00b4 on de la respues-\nta.Las preguntas en espa\u02dc nol y los pasajes en ingl\u00b4 es se mos-\ntraron a los usuarios a trav\u00b4 es de una p\u00b4 agina web. Los usuarios\ndeb\u00b4 \u0131an de localizar la respuesta correcta entre los diferentes\npasajes mostrados. Entonces deb\u00b4 \u0131an seleccionar la respuesta\n(cadena de caracteres) y el pasaje donde aparec\u00b4 \u0131a.\nEl problema de esta tarea, tal y como se ha mencionado an-\nteriormente, es la falta de conocimiento por parte del usuario de\nla lengua en la que se muestran los pasajes. Es por tanto necesa-\nria la incorporaci\u00b4 on de cierta informaci\u00b4 on que ayude al usuario a\ndeterminar el pasaje y la respuesta correcta para cada pregunta.\n12http://babelfish.yahoo.com/\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 197\nPara ello, se desarrollaron dos m\u00b4 etodos: uno basado en etiquetas\nsem\u00b4 anticas y otro basado en patrones sint\u00b4 actico-sem\u00b4 anticos (SSP).\n6.3.1.1 M\u00b4 etodo interactivo I: Dominios Relevantes.\nEste primer m\u00b4 etodo utiliza el recurso l\u00b4 exico Dominios Relevan-\ntes para ayudar a la localizaci\u00b4 on de las respuestas por parte de\nlos usuarios. Como ya se explic\u00b4 o en el cap\u00b4 \u0131tulo anterior los Do-\nminios Relevantes (extra\u00b4 \u0131dos a partir de WordNet Domains), son\naquellos dominios o etiquetas sem\u00b4 anticas m\u00b4 as representativas de\nun palabra. En este caso, nuestra hip\u00b4 otesis es que si sabemos los\ndominios relevantes de la pregunta y los dominios relevantes de las\nrespuestas, podemos reducir la colecci\u00b4 on de pasajes a aquellos que\ncompartan ciertos dominios. De esta forma, la respuesta correcta\nser\u00b4 a localizada con mayor facilidad y con una alta probabilidad\nen aquellos pasajes que compartan la mayor cantidad de dominios\nrelevantes respecto a la pregunta en cuesti\u00b4 on.\nUn ejemplo de la informaci\u00b4 on proporcionada a los usuarios,\nse muestra en la Figura 6.3. En esta captura de la p\u00b4 agina web\nmostrada a cada usuario se aprecian: la pregunta en cuesti\u00b4 on, el\npasaje seleccionado, los dominios relevantes de la pregunta y los\ndominios relevantes del pasaje.\nPara la pregunta \u201c\u00bfQui\u00b4 en es el director gerente de FIAT?\u201d, los\ndominios asociados son: Administration ,Economy yTrans-\nport . Y de entre los dominios mostrados para el pasaje encon-\ntramos Economy yTransport entre los cinco primeros. Por\ntanto, este pasaje podr\u00b4 \u0131a ser candidato de contener la respuesta\ncorrecta.\nAdem\u00b4 as de proporcionar informaci\u00b4 on \u00b4 util acerca de los domi-\nnios involucrados en cada consulta, el orden de los pasajes obte-\nnido por el sistema de recuperaci\u00b4 on fue alterado. De forma que\naquellos pasajes con mayor similitud respecto a la pregunta, fue-\nron mostrados previamente a aquellos cuya similitud era menor.\n198 6.3 Participaci\u00b4 on en iCLEF\n \nFigura 6.3. P\u00b4 agina web interactiva para dominios relevantes\n6.3.1.2 M\u00b4 etodo interactivo II: Patrones sint\u00b4 actico-sem\u00b4 anti-\ncos.\nEl segundo m\u00b4 etodo est\u00b4 a basado en patrones sint\u00b4 actico-sem\u00b4 anti-\ncos. Con este m\u00b4 etodo se muestra al usuario una serie de patrones\n(SSP) junto con los pasajes en ingl\u00b4 es, donde cada patr\u00b4 on est\u00b4 a for-\nmado por los verbos y los nombres principales. La hip\u00b4 otesis en\neste caso es determinar si esta informaci\u00b4 on permite al usuario de-\ncidir si el pasaje mostrado contiene la respuesta a la pregunta\nformulada. Intuitivamente cuando un usuario busca la respuesta\na una determinada pregunta en una porci\u00b4 on de texto, \u00b4 este presta\nm\u00b4 as atenci\u00b4 on a los nombres y verbos, intentando localizar ver-\nbos o nombres similares a los de la pregunta. Con los patrones,\nlos verbos y nombres principales son extra\u00b4 \u0131dos autom\u00b4 aticamente,\nfacilitando esta tarea a los usuarios.\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 199\nDesde el punto de vista te\u00b4 orico un patr\u00b4 on sint\u00b4 actico-sem\u00b4 antico\nest\u00b4 a formado por tres componentes:\n1.Un verbo con su sentido o sentidos.\n2.El marco de subcategorizaci\u00b4 on de ese sentido.\n3.Las preferencias de selecci\u00b4 on de cada argumento.\nDado que obtener de forma autom\u00b4 atica esta informaci\u00b4 on es un\nproceso muy costoso, el sistema utiliza una versi\u00b4 on de SSP\u2019s me-\nnos compleja. En este nuevo modelo, el verbo se representa por la\npalabra y su sentido o sentidos, el marco de subcategorizaci\u00b4 on se\nrepresenta por el nombre principal de cada argumento (si el argu-\nmento es una cl\u00b4 ausula, en lugar del nombre se utilizar\u00b4 a el verbo) y\nlas preferencias de selecci\u00b4 on de cada argumento se representar\u00b4 an\npor el sentido o los sentidos de los nombres principales.\nEn la Figura 6.4se muestra una captura de la p\u00b4 agina web\nmostrada al usuario. En esta captura se aprecia por una parte la\npregunta, el pasaje y los SSP\u2019s asociados al pasaje.\n \nFigura 6.4. P\u00b4 agina web interactiva para patrones SSP\n200 6.3 Participaci\u00b4 on en iCLEF\nUtilizando los SSP\u2019s, s\u00b4 olo la informaci\u00b4 on m\u00b4 as importante de\ncada frase es mostrada al usuario: los verbos y los nombres prin-\ncipales y las relaciones sint\u00b4 actico-sem\u00b4 anticas existentes entre ellos.\n6.3.2 Resultados\nEn la Figura 6.5se muestran los resultados obtenidos por los\nusuarios con cada m\u00b4 etodo interactivo. Como se puede observar\nlos usuarios obtuvieron resultados similares con ambos m\u00b4 etodos.\n\u00b4Unicamente se aprecia una peque\u02dc na mejora de 0.015 obtenida por\nel m\u00b4 etodo de patrones.\n 0,375 0,5 \n0,453123 0,5625 \n0 0,1 0,2 0,3 0,4 0,5 0,6 \nMedia por sistema (estricta) Media por sistema (tolerante) Dominios Relevantes SSP's \nFigura 6.5. Media gen\u00b4 erica\nLas medidas de efectividad de los sistemas son las mismas uti-\nlizadas en la tarea de CL-QA (Cross Language Question Answe-\nring). La media estricta son las respuestas correctas obtenidas a\npartir de pasajes que contienen la respuesta. Y la media tolerante,\nson las respuestas correctas obtenidas por los usuarios indepen-\ndientemente de encontrarse en el pasaje correcto.\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 201\n6.3.2.1 Media por usuario.\nLas Figuras 6.6y6.7representan la media obtenida por ca-\nda usuario. La Figura 6.6muestra las respuestas correctas en-\ncontradas por el usuario en un pasaje que realmente contiene la\nrespuesta (estricta).\n 0,125 0,625 \n0,375 0,625 \n0 0,25 0,375 0,625 \n0,375 0,5 \n0,375 0,625 \n0,375 0,625 \n0 0,75 \n0 0,1 0,2 0,3 0,4 0,5 0,6 0,7 0,8 \n1 2 3 4 5 6 7 8 \nUsuarios Dominios RelevantesSSP's \nFigura 6.6. Media estricta por usuario\nLa Figura 6.7muestra las respuestas correctas obtenidas por\ncada usuario, independientemente de seleccionar el pasaje correc-\nto (tolerante).\n6.3.3 Interpretaci\u00b4 on de resultados y trabajo futuro\nA partir de los resultados obtenidos pueden desprenderse las\nsiguientes conclusiones:\nLos resultados son bajos quiz\u00b4 as porque no se ha utilizado nin-\nguna traducci\u00b4 on como ayuda. Podr\u00b4 \u0131a incorporarse una pseudo\ntraducci\u00b4 on que realmente ayude a la localizaci\u00b4 on de la respuesta\ncorrecta.\nEn el caso de los Dominios Relevantes, este m\u00b4 etodo ayuda a en-\ncontrar la respuesta correcta pero existen algunos errores debido\nal escaso contexto de las preguntas. Para subsanar esta escasez\n202 6.4 Participaci\u00b4 on en Textual Entailment Recognition\n 0,75 \n0,625\n0,375 0,625\n0,250,375 0,3750,625 0,6250,75 \n0,625 0,625\n0,5 0,625\n0 0,75 \n0 0,1 0,2 0,3 0,4 0,5 0,6 0,7 0,8 \n1 2 3 4 5 6 7 8 \nUsuarios Dominios Relevantes SSP's \nFigura 6.7. Media tolerante por usuario\nde informaci\u00b4 on, se podr\u00b4 \u0131an a\u02dc nadir m\u00b4 as palabras utilizando rela-\nciones de hiperonimia, homonimia, etc.\nEn el caso de los SSP\u2019s ser\u00b4 \u0131a necesario mejorar la codi\ufb01caci\u00b4 on\nde los patrones, ya que, actualmente su interpretaci\u00b4 on resulta\ncomplicada, seg\u00b4 un las encuestas realizadas posteriormente a los\nusuarios.\nComo trabajos futuros se pretende traducir los patrones obte-\nnidos a partir de un m\u00b4 etodo basado en alineamiento de verbos.\nAdem\u00b4 as, se pretende mejorar la extracci\u00b4 on de pasajes del sistema\nde recuperaci\u00b4 on de informaci\u00b4 on mediante la inclusi\u00b4 on de informa-\nci\u00b4 on relativa a los Dominios Relevantes.\n6.4 Participaci\u00b4 on en Textual Entailment\nRecognition\nEntre las diferentes tareas de PLN, surge la necesidad de iden-\nti\ufb01car similitudes sem\u00b4 anticas entre diferentes fragmentos de texto.\nEsta tarea recibe el nombre de detecci\u00b4 on de la implicaci\u00b4 on textual\no Recognising Textual Entailment (RTE).\nNuestra hip\u00b4 otesis es que la utilizaci\u00b4 on de informaci\u00b4 on sem\u00b4 anti-\nca, podr\u00b4 \u0131a ser muy \u00b4 util para resolver el problema de la implicaci\u00b4 on\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 203\ntextual. Por ello, se ha desarrollado un sistema de detecci\u00b4 on de\nla implicaci\u00b4 on textual participando en las competiciones RTE2 y\nAVE. Adem\u00b4 as, directamente relacionada con la detecci\u00b4 on de la\nimplicaci\u00b4 on textual se encuentra la detecci\u00b4 on de la par\u00b4 afrasis, por\nello, tambi\u00b4 en se han realizado varios experimentos que determinan\nla efectividad de nuestro sistema.\n6.4.1 RTE2 PASCAL\nLa detecci\u00b4 on de la implicaci\u00b4 on textual ( Dagan et al. (2005 ))\nes una tarea que consiste en determinar dados dos fragmentos\nde texto, si \u00b4 estos proporcionan el mismo contenido sem\u00b4 antico. Es\ndecir, si a partir de textos diferentes se transmite la misma infor-\nmaci\u00b4 on. Por ejemplo, dados los textos \u201cMuri\u00b4 o debido a la p\u00b4 erdida\nde sangre\u201d y \u201cSe desangr\u00b4 o hasta morir\u201d, ambos denotan la mis-\nma informaci\u00b4 on, y se podr\u00b4 \u0131a inferir que el primer texto implica\nel segundo. Para resolver este problema se han realizado diferen-\ntes aproximaciones ( Akhmatova (2005 ),Andreevska et al. (2005 ),\nHerrera et al. (2005 )), todas ellas evaluadas dentro del marco de\nPASCAL (Pattern Analysis, Statistical Modelling and Computa-\ntional Learning) y m\u00b4 as concretamente en la tarea de Recognising\nTextual Entailment Challenge (RTE13).\nEn este tipo de problema, es necesario disponer de cierto co-\nnocimiento sem\u00b4 antico acerca de los dos contextos implicados. Por\nello, nuestro estudio se ha centrado en la determinaci\u00b4 on de la\nin\ufb02uencia de la informaci\u00b4 on sem\u00b4 antica para la detecci\u00b4 on de la im-\nplicaci\u00b4 on textual.\nLa evaluaci\u00b4 on de las diferentes aproximaciones se ha realizado\nutilizando el corpus del RTE2 donde los ejemplos proporcionados\nest\u00b4 an balanceados (50 % son verdaderos y 50 % son falsos). Todos\nlos ejemplos han sido extra\u00b4 \u0131dos de aplicaciones reales de Extrac-\nci\u00b4 on de Informaci\u00b4 on, Recuperaci\u00b4 on de Informaci\u00b4 on, Recuperaci\u00b4 on\nde Respuestas y Res\u00b4 umenes autom\u00b4 aticos. En total se proporciona-\nron 1600 ejemplos, de los cuales, 800 se distribuyeron como corpus\nde preparaci\u00b4 on (development data) y los 800 restantes como cor-\n13http://pascallin.ecs.soton.ac.uk/Challenges/RTE2/\n204 6.4 Participaci\u00b4 on en Textual Entailment Recognition\npus de evaluaci\u00b4 on (test data).\n6.4.1.1 Utilizaci\u00b4 on de diferentes corpus para LSA.\nLos diferentes experimentos que se han realizado han tenido co-\nmo objetivo determinar la in\ufb02uencia de la elecci\u00b4 on de un corpus\ndeterminado para establecer la correspondencia sem\u00b4 antica entre\ndos frases. Para ello se han obtenido diferentes espacios sem\u00b4 anticos\nutilizando la t\u00b4 ecnica de LSA, los cuales se describen a continua-\nci\u00b4 on:\nBNC corpus (LSA\nBNC\nNoTag) . Resultados utilizando infor-\nmaci\u00b4 on del corpus BNC con palabras lematizadas.\nH sentences (LSA\nLemaH, LSA\nNoLemaH) . Resultados utili-\nzando como corpus las frases H (hip\u00b4 otesis) y construyendo dos\nmatrices diferentes: una con las palabras lematizadas y la otra\ncon las palabras no lematizadas.\nT sentences (LSA\nLemaT, LSA\nNoLemaT) . Resultados utili-\nzando como corpus las frases T (test) y construyendo dos ma-\ntrices diferentes: una con las palabras lematizadas y la otra con\nlas palabras no lematizadas.\nRelevant Domains (LSA\nRD). Resultados utilizando el re-\ncurso Dominios Relevantes de cada frase T y de cada frase H.\nLa medida de evaluaci\u00b4 on utilizada ha sido la \u201cAccuracy\u201d seg\u00b4 un\nla F\u00b4 ormula 6.7:\naccuracy =Ejemplos correctos\nTotal ejemplos(6.7)\nEn la Tabla 6.22 se muestran los resultados obtenidos para\ncada uno de los diferentes experimentos realizados.\nPara cada experimento se han evaluado los resultados de forma\nindependiente para cada tipo de datos de entrada: IE (Extracci\u00b4 on\nde Informaci\u00b4 on), IR (Recuperaci\u00b4 on de Informaci\u00b4 on), QA (B\u00b4 usque-\nda de respuestas) y SUM (Resumen autom\u00b4 atico). Como se puede\nobservar, los mejores resultados se han obtenido utilizando las fra-\nses de Text (LSA\nLemaT) y los Dominios Relevantes (LSA\nRD).\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 205\nDatos\nAcc.\nIE\nIR\nQA\nSUM\ndevLSA\nBNC\nNoTag\n49.90\n49.87\n49.15\n50.15\n50.43\ndevLSA\nLemaH\n53.25\n52.00\n48.00\n54.00\n59.00\ndevLSA\nNoLemaH\n50.17\n50.15\n50.03\n50.22\n50.28\ndevLSA\nLemaT\n56.87\n51.50\n58.00\n56.50\n61.50\ndevLSA\nNoLemaT\n52.88\n50.50\n53.00\n48.00\n60.00\ndevLSA\nRD\n56.98\n52.25\n58.60\n56.83\n60.25\ntestLSA\nBNC\nNoTag\n49.67\n49.43\n49.00\n50.02\n50.24\ntestLSA\nLemaH\n49.38\n52.50\n48.50\n49.00\n47.50\ntestLSA\nNoLemaH\n53.37\n50.50\n54.00\n49.00\n60.00\ntestLSA\nLemaT\n54.25\n50.50\n48.00\n57.00\n61.50\ntestLSA\nNoLemaT\n53.63\n52.50\n50.00\n50.00\n62.00\ntestLSA\nRD\n54.51\n50.55\n48.53\n56.73\n62.25\nTabla 6.22. Resultados usando diferentes corpus y LSA\nLa primera aproximaci\u00b4 on utiliza como corpus todas las frases de\nText y las frases de Hip\u00b4 otesis como entrada al m\u00b4 odulo LSA. En es-\nte caso, los resultados son 56 ;87 % para los datos de preparaci\u00b4 on y\n52;25 % par los datos de evaluaci\u00b4 on. Estos resultados son mejores\nque los obtenidos en el experimento LSA\nLemaH porque las frases\nde Text proporcionan mayor informaci\u00b4 on sem\u00b4 antica. Por lo tanto,\npara inferir que dos frases tienen el mismo signi\ufb01cado sem\u00b4 antico\nse necesita una aproximaci\u00b4 on con una base contextual apropiada.\nLa segunda aproximaci\u00b4 on utiliza como corpus el recurso Dominios\nRelevantes. En este caso, la matriz contextual inicial se ha obteni-\ndo a partir de la informaci\u00b4 on de WordNet Domains. Este espacio\nsem\u00b4 antico se ha utilizado para extraer la similitud entre cada par\nde frases H-T. Como resultado, se ha obtenido un 56 ;98 % para los\ndatos de preparaci\u00b4 on y un 54 ;51 % para los datos de evaluaci\u00b4 on.\nEn este caso, los resultados obtenidos han sido bastante buenos\ndebido a que las palabras sem\u00b4 anticamente relacionadas compar-\nten las mismas categor\u00b4 \u0131as sem\u00b4 anticas de WordNet Domains y esta\ninformaci\u00b4 on es muy \u00b4 util a la hora de relacionar textos relativos a\nlas tares de QA y SUM. En cuanto al resto de experimentos, se\ndemuestra que no se dispone de su\ufb01ciente informaci\u00b4 on contextual\npara detectar correctamente la implicaci\u00b4 on textual.\n206 6.4 Participaci\u00b4 on en Textual Entailment Recognition\n6.4.1.2 Utilizaci\u00b4 on de la medida del coseno.\nOtra serie de experimentos se ha realizado utilizando la medida\nde similitud del coseno. En este caso, se ha utilizado la medida\ntradicional de similitud entre documentos y la adaptaci\u00b4 on de esta\nmedida a los Dominios Relevantes. Los resultados se muestran en\nla Tabla 6.23.\nDatos\nAcc.\nIE\nIR\nQA\nSUM\ndevCoseno\nDF\n52.60\n48.63\n47.32\n55.13\n59.32\ndevCoseno\nRD\n54.25\n50.50\n48.00\n57.00\n61.50\ntestCoseno\nDF\n52.18\n46.13\n49.43\n55.34\n57.83\ntestCoseno\nRD\n54.00\n46.50\n56.50\n56.00\n57.00\nTabla 6.23. Results for the cosine measure\nA la vista de los resultados queda patente el mejor funcio-\nnamiento de la medida del coseno combinada con los Dominios\nRelevantes. En este caso se alcanza un 54 % tanto para los textos\nde evaluaci\u00b4 on como de preparaci\u00b4 on. Pero estos resultados demues-\ntran que la informaci\u00b4 on contextual dada por las frases no es muy\nrepresentativa y no proporciona su\ufb01ciente conocimiento. Por lo\ntanto, la medida del coseno podr\u00b4 \u0131a utilizarse combinada con otras\nfuentes de informaci\u00b4 on.\n6.4.1.3 Combinaci\u00b4 on de LSA y coseno con un sistema de\naprendizaje.\nPara poder utilizar la informaci\u00b4 on proporcionada por la medida\nde similitud del coseno y de LSA, \u00b4 estas se introdujeron como\nnuevas caracter\u00b4 \u0131sticas en un sistema de aprendizaje autom\u00b4 atico.\nMLEnt with previous features (MLEnt\nLex, MLEnt\nSem) .\nResultados del sistema previo MLEnt con caracter\u00b4 \u0131sticas l\u00b4 exicas\ny sem\u00b4 anticas.\nMLEnt with LSA (MLEnt\nLex\nLSA\nLemaT, MLEnt\nSem\nLSA\nLemaT) . Resultados del sistema previo MLEnt con LSA. En es-\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 207\nte caso, se utiliz\u00b4 o como corpus para la matriz de LSA las frases\nde Text con las palabras lematizadas.\nMLEnt with cosine (MLEnt\nLex\ncosine,MLEnt\nSem\ncosine) .\nResultados del sistema previo MLEnt combinado con la medi-\nda del coseno. En este caso, el coseno se obtiene utilizando el\nrecurso Dominios Relevantes.\nMLEnt with LSA and cosine (MLEnt\nLex\nLSA\nLemaT\ncosine,\nMLEnt\nSem\nLSA\nLemaT\ncosine) . Resultados del sistema pre-\nvio MLEnt combinando LSA y la medida de similitud del co-\nseno. En este caso, se utiliz\u00b4 o LSA con las frases de Text y la\nmedida del coseno con los Dominios Relevantes.\nLos resultados obtenidos se muestran en la Tabla 6.24.\nSets\nAcc.\nIE\nIR\nQA\nSUM\ndevMLEnt\nLex\n56.87\n49.50\n55.50\n51.00\n71.50\ndevMLEnt\nSem\n60.12\n54.00\n61.00\n59.00\n66.50\ndevMLEnt\nLex\nLSA\nLemaT\n62.03\n56.13\n62.53\n60.32\n69.15\ndevMLEnt\nLex\ncosine\n56.91\n49.45\n55.62\n52.13\n70.43\ndevMLEnt\nLex\nLSA\nLemaT\ncosine\n57.13\n49.50\n55.50\n52.50\n71.00\ndevMLEnt\nSem\nLSA\nLemaT\n62.56\n57.13\n62.83\n60.54\n69.75\ndevMLEnt\nSem\ncosine\n60.21\n54.13\n61.06\n59.14\n66.54\ndevMLEnt\nSem\nLSA\nLemaT\ncos\n61.75\n56.00\n59.50\n62.50\n69.00\ntestMLEnt\nLex\n51.75\n52.00\n53.50\n55.50\n46.00\ntestMLEnt\nSem\n54.25\n50.00\n55.50\n47.50\n64.00\ntestMLEnt\nLex\nLSA\nLemaT\n55.01\n51.23\n55.83\n47.96\n65.03\ntestMLEnt\nLex\ncosine\n52.57\n49.50\n44.95\n53.73\n62.13\ntestMLEnt\nLex\nLSA\nLemaT\ncosine\n54.87\n46.50\n53.00\n56.00\n64.00\ntestMLEnt\nSem\nLSA\nLemaT\n56.18\n52.03\n56.53\n50.14\n66.03\ntestMLEnt\nSem\ncosine\n54.42\n50.22\n55.62\n47.61\n64.25\ntestMLEnt\nSem\nLSA\nLemaT\ncos\n56.50\n53.00\n58.00\n57.50\n57.50\nTabla 6.24. Resultados para la combinaci\u00b4 on de MLEnt con LSA y el coseno\nComo muestra la Tabla 6.24, los experimentos que se han lle-\nvado a cabo combinando los valores de LSA y el coseno como\nnuevas caracter\u00b4 \u0131sticas, mejoran los resultados previos del siste-\nma MLEnt. Por tanto, podemos concluir que a\u02dc nadir informaci\u00b4 on\nsem\u00b4 antica a un sistema de aprendizaje autom\u00b4 atico proporciona\nmayor efectividad. De hecho, el mejor resultado obtenido es de\n208 6.4 Participaci\u00b4 on en Textual Entailment Recognition\nun 62 % para el conjunto de datos de preparaci\u00b4 on y de un 57 %\npara el conjunto de datos de evaluaci\u00b4 on. Estos resultados se han\nobtenido a partir del experimento realizado tras la combinaci\u00b4 on\nde LSA con el coseno y el sistema MLEnt.\n6.4.1.4 Comparativa con otros sistemas participantes.\nEn la competici\u00b4 on para la detecci\u00b4 on de la implicaci\u00b4 on textual\nRTE2, participaron 23 equipos. Cada equipo pod\u00b4 \u0131a enviar hasta\ndos ejecuciones para evaluar sus resultados. La Tabla 6.25presen-\nta los resultados obtenidos en t\u00b4 erminos de la medida de \u201cAccu-\nracy\u201d .\nDesde el punto de vista sem\u00b4 antico, los resultados obtenidos\nofrecen una mejora con respecto al sistema inicial MLEnt. De esta\nforma, se puede a\ufb01rmar que la combinaci\u00b4 on del sistema de apren-\ndizaje MLEnt con recursos sem\u00b4 anticos tales como, los dominios\nrelevantes y la sem\u00b4 antica latente pone de mani\ufb01esto la utilidad de\na\u02dc nadir informaci\u00b4 on sem\u00b4 antica para la detecci\u00b4 on de la implicaci\u00b4 on\ntextual.\nAdem\u00b4 as, analizando los resultados obtenidos con respecto al\nresto de participantes, la media obtenida ronda el 58 %, por lo\nque nuestro sistema obtiene resultados signi\ufb01cativos.\n6.4.2 AVE CLEF2006\nEn esta competici\u00b4 on se particip\u00b4 o en la tarea Answer Validation\nExercise (AVE) ( Pe\u02dc nas et al. (2006a )), con el sistema basado en\naprendizaje MLEnt desarrollado en ( Kozareva y Montoyo (2006 ),\nKozareva et al. (2006 )). Este sistema fue utilizado para la tarea\nRTE y fue posteriormente adaptado para la tarea AVE.\nEn la competici\u00b4 on AVE el objetivo es determinar si a partir de\nunsnippet proporcionado por un sistema de b\u00b4 usqueda de respues-\ntas (T-Texto) se puede extraer la informaci\u00b4 on proporcionada en\nun texto (H-Hip\u00b4 otesis). De esta forma, se podr\u00b4 \u0131a evaluar de forma\nautom\u00b4 atica el funcionamiento de sistemas de Question Answering.\nEn la edici\u00b4 on de 2006 AVE se plante\u00b4 o como tarea multiling\u00a8 ue\npara detectar la correcci\u00b4 on de las respuestas dadas por un siste-\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 209\nSistema\nAcc\nAdams (Dallas)\n0.6262\nBos (Rome & Leeds)\n0.6162\n0.6062\nBurchardt (Saarland)\n0.5900\n0.5775\nClarke (Sussex)\n0.5275\n0.5475\nDe Marne\ufb00e (Stanford)\n0.5763\n0.6050\nDelmonte (Venice)\n0.5475\nFerr\u00b4 andez (Alicante)\n0.5563\n0.5475\nHerrera (UNED)\n0.5975\n0.5887\nHickl (LCC)\n0.7538\nInkpen (Ottawa)\n0.5800\n0.5825\nKatrenko (Amsterdam)\n0.5900\n0.5713\nKouylekov (ITC-irst & Trento)\n0.5725\n0.6050\nCombinaci\u00b4 on MLEnt \u2013 Lex \u2013 LSA\n0.5501\nCombinaci\u00b4 on MLEnt \u2013 Sem - LSA\n0.5618\nCombinaci\u00b4 on MLEnt \u2013 Sem - LSA \u2013 coseno\n0.5650\nKozareva (Alicante)\n0.5487\n0.5500\nLitkowski (CL Research)\n0.5813\n0.5663\nMarsi (Tilburg & Twente)\n0.6050\nNewman (Dublin)\n0.5250\n0.5437\nNicholson (Melbourne)\n0.5288\n0.5088\nNielsen (Colorado)\n0.5962\n0.5875\nRus (Memphis)\n0.5900\n0.5837\nSchilder (THomson & MInnesota)\n0.5437\n0.5550\nTatu (LCC)\n0.7375\nVanderwende (Microsoft Research & Stanford)\n0.6025\n0.5850\nZanzotto (MIllan & Rome)\n0.6388\n0.6250\nTabla 6.25. Evaluaci\u00b4 on de sistemas en RTE2\n210 6.4 Participaci\u00b4 on en Textual Entailment Recognition\nma de QA en diferentes idiomas: espa\u02dc nol, ingl\u00b4 es, alem\u00b4 an, franc\u00b4 es,\nitaliano, holand\u00b4 es y portugu\u00b4 es.\n6.4.2.1 M\u00b4 odulo de solapamiento de palabras: Sistema\nMLEnt.\nEl sistema MLEnt est\u00b4 a compuesto de dos m\u00b4 odulos: m\u00b4 odulo\nde palabras superpuestas y m\u00b4 odulo de similitud sem\u00b4 antica. Dado\nque la tarea AVE es una tarea multiling\u00a8 ue, el m\u00b4 odulo de similitud\nsem\u00b4 antica no se ha utilizado debido a que \u00b4 este utiliza la informa-\nci\u00b4 on proporcionada por WordNet y es muy costoso adaptar este\nm\u00b4 odulo para diferentes idiomas.\nLos atributos utilizados por el m\u00b4 odulo de palabras superpues-\ntas son los siguientes:\nn-gramas. Busca posiciones comunes de unigramas entre el\nTexto y la Hip\u00b4 otesis. De acuerdo a este atributo el par Texto-\nHip\u00b4 otesis ser\u00b4 a correcto si ambos comparten las mismas palabras.\nDe la misma forma, este atributo determina que un par no es\ncorrecto si no contienen ninguna palabra en com\u00b4 un. Este atri-\nbuto no considera informaci\u00b4 on de similitud sem\u00b4 antica, as\u00b4 \u0131 por\nejemplo si \u201cveh\u00b4 \u0131culo\u201d y \u201ccoche\u201d aparecen respectivamente en T\ny H son consideradas palabras sin ning\u00b4 un tipo de relaci\u00b4 on y por\ntanto, totalmente distintas. Otro punto d\u00b4 ebil de este atributo\nes que no tiene en cuenta el orden de las palabras y la estruc-\ntura de las frases. En este caso, frases del tipo \u201cMary calls the\npolice\u201d y \u201d The police calls Mary\u201d, contienen las mismas pala-\nbras, pero con este atributo el resultado ser\u00b4 \u0131a que no in\ufb01eren el\nmismo signi\ufb01cado. Para solventar este problema se han creado\nlos siguientes atributos LongCS y skip-gramas.\nLongCS (Longest Common Subsequence). Obtiene se-\ncuencias de palabras no consecutivas de cualquier longitud, en-\ntre el Texto y la Hip\u00b4 otesis. Un valor elevado de LongCS signi\ufb01ca\nsentencias similares. El valor de LongCS entre cada par T(m)-\nH(n), donde m es la longitud del Texto y n es la longitud de la\nhip\u00b4 otesis, se determina comoLongCS (T;H)\nn.\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 211\nskip-gramas. Representa cualquier par de palabras en una ora-\nci\u00b4 on con un n\u00b4 umero indeterminado de palabras entre ellas. Una\nvez determinados todos los pares de palabras del Texto y la\nHip\u00b4 otesis, se realiza el conteo de los skip-gramas de la siguiente\nformaskip\ngramas (T;H)\nC(n;numero\nskip\u00a1gramas ). Donde skip\u00a1gramas (T; H) ha-\nce referencia al n\u00b4 umero de skip-gramas comunes entre T y H,\nC(n; numero\nskip\u00a1gramas ) es una funci\u00b4 on combinatoria, don-\ndenes el n\u00b4 umero de palabras en H y numero\nskip-gramas se\ncorresponde con el n\u00b4 umero de n-gramas comunes entre T y H.\nDe acuerdo a este atributo el par T-H ser\u00b4 a correcto cuantos m\u00b4 as\nskip-gramas tengan en com\u00b4 un. Por ejemplo, para las siguientes\noraciones:\nS1: \u201cMary calls the police\u201d\nS2: \u201cMary called the police\u201d\nS3: \u201cThe police called Mary\u201d\nMediante el atributo skip-gramas se deduce que las frases S1 y\nS2 tienen una relaci\u00b4 on de similitud m\u00b4 as fuerte que S1 y S3 o S2\ny S3. Sin embargo, los atributos n-gramas y LongCS no son tan\nefectivos y no pueden determinar la similitud correctamente.\nmapeo\nnum\u00b4 erico. Se identi\ufb01can los n\u00b4 umeros presentes en T\ny H y se veri\ufb01can. Para frases donde no existen n\u00b4 umeros, este\natributo asigna en valor NO para el par. De acuerdo a este\natributo, el par T-H ser\u00b4 a correcto cuanto los n\u00b4 umeros de T y H\ncoincidan.\nEl conjunto de atributos descrito ha sido evaluado \u00b4 unicamente\nsobre ingl\u00b4 es y espa\u02dc nol, debido a que s\u00b4 olo se proporcion\u00b4 o corpus\nde entrenamiento para estos dos idiomas. Para la fase de entre-\nnamiento se utilizaron los clasi\ufb01cadores SVM y kNN, junto con\nla observaci\u00b4 on de la medida IG (Information Gain), para los dos\nidiomas y diferentes tama\u02dc nos de corpus de entrenamiento. IG es\nuna medida que indica a partir de un conjunto de caracter\u00b4 \u0131sticas\ncu\u00b4 ales son las m\u00b4 as importantes. De acuerdo a IG, los dos atributos\nque proporcionan mejores resultados son LongCS y skip-gramas.\nPara la caracter\u00b4 \u0131stica de solapamiento de palabras, el sistema ge-\nnera dos salidas, una obtenida a partir del atributo LongCS y otra\nobtenida por el atributo de skip-gramas.\n212 6.4 Participaci\u00b4 on en Textual Entailment Recognition\nPara el resto de idiomas a los que no se proporcion\u00b4 o corpus de\nentrenamiento se tuvo que ajustar los atributos LongCS y skip-\ngramas. Dado que los atributos utilizados dependen de la longi-\ntud del solapamiento de palabras normalizado por el n\u00b4 umero total\nde palabras presentes en H, fue posible adaptar estos atributos.\nAs\u00b4 \u0131, utilizando las medidas de desviaci\u00b4 on est\u00b4 andar obtenidas para\nLongCS y skip-gramas en espa\u02dc nol e ingl\u00b4 es, se adaptaron al resto\nde idiomas.\n6.4.2.2 M\u00b4 odulo de similitud sem\u00b4 antica: LSA.\nUna de las caracter\u00b4 \u0131sticas de LSA es la de detectar similitu-\ndes sem\u00b4 anticas entre textos que aun no compartiendo las mismas\npalabras, puedan estar relacionados. Esta capacidad ya fue co-\nmentada en el cap\u00b4 \u0131tulo anterior con m\u00b4 as detalle.\nEn nuestro caso, para poder aplicar LSA sobre la tarea AVE se\nutiliz\u00b4 o como corpus para construir la matriz conceptual las frases\ndel Texto. Esta decisi\u00b4 on fue tomada debido al estudio realizado\nen (V\u00b4 azquez et al. (2006 )), donde al utilizar las frases de T como\ncorpus, la evaluaci\u00b4 on sobre la tarea de RTE obten\u00b4 \u0131a mejores resul-\ntados. Por tanto, para cada uno de los distintos idiomas - ingl\u00b4 es,\nespa\u02dc nol, italiano, alem\u00b4 an, holand\u00b4 es, portugu\u00b4 es y franc\u00b4 es - se cons-\ntruyeron diferentes matrices conceptuales utilizando las oraciones\ndel Texto del corpus proporcionado por AVE.\nA partir de las matrices conceptuales obtenidas en cada caso,\nse pueden establecer relaciones de similitud entre t\u00b4 erminos, frases\no documentos. En nuestros experimentos, dado que el objetivo\n\ufb01nal era determinar si dos frases T-H ten\u00b4 \u0131an relaci\u00b4 on sem\u00b4 antica,\nse utiliz\u00b4 o la similitud entre frases. El resultado tras aplicar cada\nfrase de H sobre la matriz conceptual, es un listado ordenado de\nmayor a menor similitud con las diferentes frases de T.\nEn los siguientes ejemplos se muestran los datos de entrada.\nPara cada pregunta Qse proporcionaba un pasaje de texto Tdel\ncual se deb\u00b4 \u0131a inferir H. Los ejemplos muestran una instancia para\nla que se debe devolver FALSO (ejemplo 1) y otra para la que se\ndebe devolver VERDADERO (ejemplo2).\nEjemplo 1:\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 213\n<pairid=\u201c4525\u201d value=\u201cNO\u201d task=\u201cQA\u201d >\n<qlang=\u201cEN\u201d src=\u201cclef2006\u201d type=\u201cOBJECT\u201d >What is\nAtlantis </q>\n<tdoc=\u201c096222\u201d >TO ATLANTIS\u2019 CREW. From As-\nsociated Press NASA brie\ufb02y lost contact with the space\nshuttle Atlantis and its six astronauts Sunday because of\ncrossed radio signals. The problem occurred as Atlantis\nswitched from one Tracking and Data Relay Satellite to\nanother, a routine procedure during Atlantis nor its crew\nwas in any danger, and no science data was lost, said Mis-\nsion Control with Atlantis was restored after eight minu-\ntes, but it was an hour before engineers realized crossed\nsignals, </t>\n<h>Atlantis is ATLANTIS THE LOST EMPIRE. </h>\n</pair >\nEste es un par T-H extra\u00b4 \u0131do de la colecci\u00b4 on de test de AVE,\npara la cual el sistema debe devolver \u201cNO\u201d como respuesta. En\neste caso, a partir del resultado obtenido por un sistema de QA\npara la pregunta \u201cWhat is Atlantis?\u201d , se trata de establecer si a\npartir del texto T se puede inferir la respuesta H. El resultado\ntras aplicar el M\u00b4 odulo LSA es el valor 0 ;402886, se considera por\ntanto, que no existe implicaci\u00b4 on entre ambos pares.\nEjemplo 2:\n<pairid=\u201c7818\u201d value=\u201cYES\u201d task=\u201cQA\u201d >\n<qlang=\u201cEN\u201d src=\u201cclef2006\u201d type=\u201cOBJECT\u201d >What is\nAtlantis </q>\n<tdoc=\u201cLA110794-0104\u201d >NASA brie\ufb02y lost contact\nwith the space shuttle Atlantis and its six astronauts Sun-\nday because of crossed radio signals. </t>\n<h>Atlantis is the space shuttle. </h>\n</pair >\nEn este ejemplo, el resultado debe ser \u201cYES\u201d. Para la pregun-\nta\u201cWhat is Atlantis?\u201d , y con el par T-H, s\u00b4 \u0131 se puede inferir el\ncontenido de H a partir de T. En este caso, el m\u00b4 odulo LSA ob-\ntiene el valor 0 ;905481, por lo que s\u00b4 \u0131 existe implicaci\u00b4 on para el par.\n214 6.4 Participaci\u00b4 on en Textual Entailment Recognition\n6.4.2.3 M\u00b4 odulo combinatorio.\nEl \u00b4 ultimo paso para la obtenci\u00b4 on del sistema \ufb01nal presentado\nen AVE es realizar la combinaci\u00b4 on del resultado de los m\u00b4 odulos\nde las secciones anteriores: m\u00b4 odulo de solapamiento de palabras\ny m\u00b4 odulo de LSA. La combinaci\u00b4 on de ambos m\u00b4 odulos se realiza\nmediante una estrategia de votaci\u00b4 on.\nPara garantizar una buena elecci\u00b4 on en la votaci\u00b4 on se realiza-\nron diferentes pruebas para comprobar la compatibilidad de los\ndistintos m\u00b4 odulos. La medida utilizada fue el coe\ufb01ciente Kappa\n(Cohen (1960 ),Pedersen (2002 )), que permite establecer el grado\nde acuerdo entre los distintos clasi\ufb01cadores seg\u00b4 un la F\u00b4 ormula 6.8.\nKappa =P0\u00a1Pe\n1\u00a1Pe(6.8)\nSiendo P0=num acuerdos\nnum acuerdos +num desacuerdosyPe=nX\ni=1(Pi1\u00a3Pi2)\nDonde:\nn= n\u00b4 umero de categor\u00b4 \u0131as\ni= n\u00b4 umero de la categor\u00b4 \u0131a (de 1 hasta n)\nPi1= proporci\u00b4 on de ocurrencia de la categor\u00b4 \u0131a i para el obser-\nvador 1.\nPi2= proporci\u00b4 on de ocurrencia de la categor\u00b4 \u0131a i para el obser-\nvador 2.\nUn valor de Kappa elevado indica un alto grado de acuerdo\nentre los clasi\ufb01cadores por lo que no existe una mejora aparente\ntras aplicar la votaci\u00b4 on. En cambio, un valor de Kappa bajo in-\ndica un grado de acuerdo muy bajo por lo que se podr\u00b4 a apreciar\nuna mejora tras la combinaci\u00b4 on de los resultados. Landis y Koch\n(Landis y Koch (1977 )) propusieron unos m\u00b4 argenes para valorar\nel grado de acuerdo en funci\u00b4 on del \u00b4 \u0131ndice Kappa Tabla 6.26.\nPara cada par T-H de AVE, se obtuvieron diferentes resultados\nusando LongCS, skip-gramas y LSA. La medida Kappa se uti-\nliz\u00b4 o evaluando los tres resultados juntos y tambi\u00b4 en se evalu\u00b4 o por\npares de resultados. Los experimentos desarrollados para ingl\u00b4 es\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 215\nKappa\nGrado de acuerdo\n<0\nSin acuerdo\n0\u00a10;2\nInsigni\ufb01cante\n0;2\u00a10;4\nBajo\n0;4\u00a10;6\nModerado\n0;6\u00a10;8\nBueno\n0;8\u00a11\nMuy bueno\nTabla 6.26. Grado de acuerdo Kappa\ny espa\u02dc nol (de los \u00b4 unicos idiomas de los que se dispon\u00b4 \u0131a de cor-\npus de entrenamiento), demostraron que la mejor combinaci\u00b4 on\nera LongCS con skip-gramas y LongCS, skip-gramas y LSA. Por\ntanto, se presentaron dos ejecuciones distintas.\nUna vez la medida Kappa determin\u00b4 o las salidas que deb\u00b4 \u0131an ser\ncombinadas, se aplic\u00b4 o la t\u00b4 ecnica de votaci\u00b4 on. Mediante esta t\u00b4 ecni-\nca, se combinaron las distintas salidas en una \u00b4 unica predicci\u00b4 on.\nLas salidas generadas para LongCS, skip-gramas y LSA fueron\nevaluadas y se escogi\u00b4 o la respuesta con mayor n\u00b4 umero de votos.\nPara LongCS y skip-gramas, no se pudo aplicar votaci\u00b4 on dado que\ns\u00b4 olo hay dos clasi\ufb01cadores. En este caso, se tom\u00b4 o como estrategia\nque si no hab\u00b4 \u0131a acuerdo entre los dos clasi\ufb01cadores se respondie-\nra \u201cNO\u201d, y si hab\u00b4 \u0131a consenso se respondiera lo que indicaran los\nclasi\ufb01cadores.\n6.4.2.4 Evaluaci\u00b4 on de resultados.\nLa evaluaci\u00b4 on de los resultados obtenidos se realiz\u00b4 o sobre los di-\nferentes idiomas de la tarea AVE: ingl\u00b4 es, espa\u02dc nol, alem\u00b4 an, franc\u00b4 es,\nitaliano, holand\u00b4 es y portugu\u00b4 es. En la Tabla 6.27se muestran los\nresultados para las distintas ejecuciones individuales del m\u00b4 odu-\nlo de solapamiento de palabras y LSA, as\u00b4 \u0131 como los resultados\nobtenidos para las dos combinaciones LongCS y skip-gramas y\nLongCS, skip-gramas y LSA.\nPara la evaluaci\u00b4 on de los resultados obtenidos se han utilizado\nlas siguientes medidas de evaluaci\u00b4 on:\n216 6.4 Participaci\u00b4 on en Textual Entailment Recognition\nprecision =#contestados correctamente como Y ES\n#total contestados como Y ES(6.9)\nrecall =#contestados correctamente como Y ES\n#total pares Y ES(6.10)\nF-score =2\u00a4recall \u00a4precision\nrecall +precision(6.11)\nEstas medidas fueron proporcionadas por los organizadores de\nla tarea AVE. De acuerdo a un estudio realizado en ( Pe\u02dc nas et al.\n(2006b )), el 25 % de los pares son ciertos y el 75 % son falsos.\nPor tanto, el funcionamiento de los sistemas presentados deber\u00b4 \u0131a\nevaluarse teniendo en cuenta los pares etiquetados como \u201cYES\u201d.\nPara los diferentes idiomas desarrollamos a continuaci\u00b4 on una\npeque\u02dc na descripci\u00b4 on de las tareas realizadas:\nIngl\u00b4 es. Para este idioma, se dispuso de una fase de entrenamien-\nto utilizando los datos del corpus ENGARTE14proporcionado.\nLos resultados obtenidos en este experimento se utilizaron como\nindicadores para seleccionar los mejores atributos del conjunto\ninicial. El mejor atributo del m\u00b4 odulo de solapamiento de pa-\nlabras fue LongCS tanto para el test como para el corpus de\nentrenamiento. Esto demuestra que un tercio de de los pares\ndel AVE pueden ser resueltos correctamente, simplemente con-\nsiderando las secuencias solapadas entre dos textos.\nLos atributos skip-gramas y LSA obtienen alrededor de un 27 %\nde precisi\u00b4 on. La combinaci\u00b4 on de ambos no supuso ninguna me-\njora en el corpus de test pero s\u00b4 \u0131 se increment\u00b4 o en un 2 % en el\ncorpus de entrenamiento. El mejor resultado para este idioma\nse obtuvo mediante la combinaci\u00b4 on de LongCS, skip-gramas y\nLSA. Esto demuestra que el atributo LSA detecta correctamen-\nte pares que los otros dos atributos no son capaces de clasi\ufb01car.\nDe acuerdo con la medida estad\u00b4 \u0131stica z0con un nivel de con-\n\ufb01anza de 0.975 el incremento es signi\ufb01cativo.\n14http://nlp.uned.es/QA/ave\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 217\nIdioma\nPrecision\nRecall\nF-score\nIngl\u00b4 es\nLongCS\n15;22\n80;93\n28;57\nIngl\u00b4 es\nSkip\n16;91\n69;30\n27;18\nIngl\u00b4 es\nLSA\n23;29\n30;23\n26;31\nIngl\u00b4 es\nLongCS&Skip\n18;33\n64;65\n28;56\nIngl\u00b4 es\nLongCS&Skip&LSA\n24;92\n69;77\n36.72\nEspa\u02dc nol\nLongCS\n44;21\n66;62\n53.15\nEspa\u02dc nol\nSkip\n37;24\n43;07\n39;94\nEspa\u02dc nol\nLSA\n34;15\n14;45\n20;31\nEspa\u02dc nol\nLongCS&Skip\n47;48\n39;34\n43;03\nEspa\u02dc nol\nLongCS&Skip&LSA\n40;65\n76;15\n53.01\nAlem\u00b4 an\nLongCS\n38;90\n60;56\n47.37\nAlem\u00b4 an\nSkip\n34;37\n43;91\n38;55\nAlem\u00b4 an\nLSA\n11;43\n1;13\n2;06\nAlem\u00b4 an\nLongCS&Skip\n41;30\n37;68\n39;41\nAlem\u00b4 an\nLongCS&Skip&LSA\n36;34\n67;42\n47.22\nFranc\u00b4 es\nLongCS\n33;96\n67;09\n45.09\nFranc\u00b4 es\nSkip\n30;48\n46;38\n36;78\nFranc\u00b4 es\nLSA\n32;36\n15;88\n21;31\nFranc\u00b4 es\nLongCS&Skip\n38;36\n43;69\n40;85\nFranc\u00b4 es\nLongCS&Skip&LSA\n34;44\n73;62\n46.93\nItaliano\nLongCS\n25;78\n70;59\n37.77\nItaliano\nSkip\n21;96\n86;10\n34;99\nItaliano\nLSA\n29;16\n22;45\n25;37\nItaliano\nLongCS&Skip\n21;64\n88;77\n34;80\nItaliano\nLongCS&Skip&LSA\n28;30\n72;19\n40.66\nHoland\u00b4 es\nLongCS\n14;26\n90;12\n24;62\nHoland\u00b4 es\nSkip\n15;80\n67;901\n25.64\nHoland\u00b4 es\nLSA\n13;88\n12;34\n13;07\nHoland\u00b4 es\nLongCS&Skip\n18;90\n67;90\n29.57\nHoland\u00b4 es\nLongCS&Skip&LSA\n14;84\n90;12\n25;48\nPortugu\u00b4 es\nLongCS\n12;50\n3;90\n5;94\nPortugu\u00b4 es\nSkip\n8;00\n21;00\n11;58\nPortugu\u00b4 es\nLSA\n11;26\n12;76\n11;96\nPortugu\u00b4 es\nLongCS&Skip\n19;04\n12;77\n15.29\nPortugu\u00b4 es\nLongCS&Skip&LSA\n19;15\n14;76\n16.67\nTabla 6.27. Resultados para la evaluaci\u00b4 on de AVE\n218 6.4 Participaci\u00b4 on en Textual Entailment Recognition\nEspa\u02dc nol. Para espa\u02dc nol se desarroll\u00b4 o otra fase de entrenamiento\nutilizando como corpus SPARTE. Para el corpus del test los me-\njores resultados se obtuvieron con el atributo LongCS llegando\na un valor aproximado de 53 %. El resultado tras la aplicaci\u00b4 on\nde la votaci\u00b4 on sobre la combinaci\u00b4 on de los tres atributos obtuvo\nel mismo valor que el atributo LongCS por separado. Esto es\ndebido en gran parte a la baja cobertura de LSA, que depende\ndel n\u00b4 umero y tipo de palabras de las frases de Texto.\nAlem\u00b4 an, franc\u00b4 es e italiano. Para estos tres idiomas los mejo-\nres resultados se obtuvieron con el atributo LongCS y la combi-\nnaci\u00b4 on de los tres atributos. El rango de valores proporcionados\npor la medida F-score se sit\u00b4 ua entre 40 % a 47 %. Como se pue-\nde observar, los resultados de LSA son m\u00b4 as bajos respecto a los\nobtenidos con los atributos del m\u00b4 odulo de solapamiento. Esto\nes debido a que el grado de similitud de 0.8 sobre el que se pro-\npuso determinar si un par T-H era correcto, depende del tipo\nde palabras contenidas en T y debe ser estudiado con detalle\npara cada idioma.\nHoland\u00b4 es y portugu\u00b4 es. Para estos dos idiomas se obtuvieron\nlos peores resultados. Cabe destacar que en el caso del holand\u00b4 es\nel atributo skip-gramas obtiene mejores resultados que LongCS.\nEste hecho puede estar relacionado con el origen de este idioma\ny el orden existente entre las palabras, ya que, los skip-gramas\nbuscan posiciones independientes unas de otras a diferencia de\nlos n-gramas que buscan posiciones contiguas. Para portugu\u00b4 es,\nLSA obtiene mejores resultados que cualquiera de los atributos\ndel m\u00b4 odulo de solapamiento de palabras. El resultado tras la\nvotaci\u00b4 on para portugu\u00b4 es obtuvo un 4 % de mejora frente a los\nclasi\ufb01cadores individuales.\nA la vista de los resultados obtenidos tras la evaluaci\u00b4 on de los\ndistintos atributos o clasi\ufb01cadores por separado o mediante vo-\ntaci\u00b4 on, podemos concluir que \u00b4 estos funcionan correctamente in-\ndependientemente del idioma utilizado. Adem\u00b4 as, la estrategia de\nvotaci\u00b4 on mejora en la mayor\u00b4 \u0131a de los casos los resultados obteni-\ndos por los clasi\ufb01cadores de forma individual.\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 219\n6.4.2.5 Comparativa con otros sistemas participantes.\nEn la competici\u00b4 on AVE participaron 11 equipos diferentes, los\ncuales, realizaron la evaluaci\u00b4 on de sus sistemas en diferentes idio-\nmas. En nuestro caso, nuestro sistema se ha adaptado de tal forma\nque es capaz de trabajar sobre diferentes idiomas, tal y como se\nha mostrado en las secciones previas. Sin embargo, debido a las\ncaracter\u00b4 \u0131sticas espec\u00b4 \u0131\ufb01cas de cada idioma y a la forma estable-\ncer conexiones entre palabras, la efectividad del sistema se ve en\nalgunos casos truncada.\nLa Tabla 6.28 muestra los resultados obtenidos por los dife-\nrentes sistemas, junto con la posici\u00b4 on alcanzada por el sistema\nde\ufb01nido en las secciones anteriores.\nA la vista de los resultados obtenidos, podemos concluir que\nel sistema propuesto, resultado de la combinaci\u00b4 on de recursos de\n\u00b4 \u0131ndole sem\u00b4 antica con un sistema de aprendizaje autom\u00b4 atico, ob-\ntiene buenos resultados. Cabe destacar que este sistema se ha\naplicado a todos los idiomas de la tarea, adaptando en cada ca-\nso \u00b4 unicamente el m\u00b4 odulo de LSA. Esta adaptaci\u00b4 on simplemente\nrequiere que la codi\ufb01caci\u00b4 on de la matriz conceptual se realice a\npartir de la informaci\u00b4 on de los textos de cada idioma respectiva-\nmente.\n6.4.3 Detecci\u00b4 on de par\u00b4 afrasis\nEstrechamente relacionada con el concepto de Implicaci\u00b4 on Tex-\ntual se encuentra la par\u00b4 afrasis. Mediante la par\u00b4 afrasis se puede\nreescribir un texto utilizando sin\u00b4 onimos (par\u00b4 afrasis mec\u00b4 anica) o\ncambiando la estructura, el contenido . . . (par\u00b4 afrasis constructi-\nva), pero siempre conservando el signi\ufb01cado original. Por ejemplo,\n\u201cveh\u00b4 \u0131culo\u201d y \u201ccoche\u201d, \u201cX est\u00b4 a casado con Y\u201d y \u201cX es el marido\nde Y\u201d, etc.\nExisten diferentes aproximaciones que tratan de identi\ufb01car la\npar\u00b4 afrasis entre textos. Muchas de ellas se centran en la extrac-\nci\u00b4 on de reglas que detectan la par\u00b4 afrasis ( Lin y Pantel (2001 ),\nBarzilay y McKeown (2001 ),Barzilay y McKeown (2003 )). Otras\nidenti\ufb01can la par\u00b4 afrasis entre textos a partir del solapamiento de\n220 6.4 Participaci\u00b4 on en Textual Entailment Recognition\nSistema\nPrec\nRec\nF\nIngl\u00b4 es\nCOGEX\n0.3261\n0.7576\n0.4559\nZNZ -TV 2\n0.2838\n0.7424\n0.4106\nitc-irst\n0.3090\n0.5354\n0.3919\nZNZ -TV 1\n0.2707\n0.6263\n0.3780\nUA\ncomb\n0.2492\n0.6977\n0.3672\nuaofe 2\n0.2040\n0.7172\n0.3177\nuaofe 1\n0.2144\n0.5404\n0.3070\nutwente.ta\n0.3313\n0.2778\n0.3022\nutwente.lcs\n0.2692\n0.2828\n0.2759\nebisbal\n0.2143\n0.0455\n0.075\nEspa\u02dc nol\nCOGEX\n0.527\n0.7139\n0.6063\nUNED 1\n0.467\n0.7168\n0.5655\nUNED 2\n0.4652\n0.7079\n0.5615\nNED\n0.4364\n0.6796\n0.5315\nUA\ncomb\n0.4065\n0.7615\n0.5301\nR2D2\n0.4387\n0.5648\n0.4938\nutwente.ta\n0.4811\n0.4560\n0.4682\nutwente.lcs\n0.5507\n0.3562\n0.4326\nAlem\u00b4 an\nFUH 1\n0.5839\n0.5058\n0.5420\nFUH 2\n0.7293\n0.3837\n0.5029\nUA\ncomb\n0.3634\n0.6742\n0.4722\nutwente.lcs\n0.4\n0.0872\n0.1432\nFranc\u00b4 es\nUA\ncomb\n0.3444\n0.7362\n0.46.93\nLIRAVE\n0.4327\n0.0638\n0.1112\nutwente.lcs\n0.4625\n0.0525\n0.0943\nItaliano\nUA\ncomb\n0.2830\n0.7219\n0.4066\nutwente.lcs\n0.3281\n0.1123\n0.1673\nHoland\u00b4 es\nutwente.ta\n0.2874\n0.5926\n0.3871\nUA\ncomb\n0.1890\n0.6790\n0.2957\nutwente.lcs\n0.2\n0.2469\n0.2201\nPortugu\u00b4 es\nutwente.lcs\n0.5783\n0.2553\n0.3542\nUA\ncomb\n0.1915\n0.1476\n0.1667\nTabla 6.28. Evaluaci\u00b4 on sistemas participantes en AVE\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 221\npalabras o de la similitud entre palabras. El problema de estas\naproximaciones es que representan de forma global los conceptos\ny por tanto, no re\ufb02ejan realmente el signi\ufb01cado de los contextos.\nNuestra propuesta para detectar la par\u00b4 afrasis utiliza como\nfuente de informaci\u00b4 on el recurso l\u00b4 exico Dominios Relevantes. De\nesta forma, se pueden establecer las diferentes relaciones sem\u00b4 anti-\ncas entre diferente segmentos de texto. La hip\u00b4 otesis en la que se\nbasa esta aproximaci\u00b4 on es que las etiquetas sem\u00b4 anticas o dominios\ndeterminan la coherencia de los textos, ya que, palabras relaciona-\ndas sem\u00b4 anticamente comparten dominios similares y maximizan\nla similitud entre textos. Para establecer las similitudes entre los\ndiferentes segmentos de texto se utiliza la t\u00b4 ecnica de LSA, cuya\nmatriz se obtiene tomando como contextos las palabras de las glo-\nsas de WordNet asociadas a cada uno de los diferentes dominios.\n6.4.3.1 Utilizaci\u00b4 on de WordNet Domains y SUMO.\nAdem\u00b4 as de WND existe otra ontolog\u00b4 \u0131a m\u00b4 as general construida\nsobre las de\ufb01niciones de WordNet, estamos hablando de la onto-\nlog\u00b4 \u0131a SUMO. Esta ontolog\u00b4 \u0131a al igual que ocurr\u00b4 \u0131a con WND extien-\nde las relaciones entre palabras utilizando categor\u00b4 \u0131as sem\u00b4 anticas\no dominios. El objetivo de este estudio es determinar la in\ufb02uen-\ncia ejercida por el tipo de ontolog\u00b4 \u0131a utilizada para establecer las\nrelaciones sem\u00b4 anticas entre diferentes contextos.\nEn la Figura 6.8se muestra una parte de cada una de las jerar-\nqu\u00b4 \u0131as de WND y SUMO. Como se puede apreciar los conceptos\nrepresentados en la jerarqu\u00b4 \u0131a de SUMO son mucho m\u00b4 as gen\u00b4 ericos\nque los representados en WND.\nLa evaluaci\u00b4 on de este m\u00b4 etodo se ha realizado a partir de la\nobtenci\u00b4 on de dos matrices conceptuales distintas: una matriz ob-\ntenida a partir de WND y otra obtenida a partir de SUMO.\nEl proceso de obtenci\u00b4 on de las matrices es b\u00b4 asicamente el mis-\nmo. El primer paso es obtener los Dominios Relevantes de cada\npalabra utilizando la jerarqu\u00b4 \u0131a de WND y la jerarqu\u00b4 \u0131a de SUMO.\nLa obtenci\u00b4 on de los dominios relevantes se realiza a partir de la\nf\u00b4 ormula del Ratio de Asociaci\u00b4 on, que determina la relevancia de\nun dominio con respecto a una palabra. Con esta informaci\u00b4 on se\n222 6.4 Participaci\u00b4 on en Textual Entailment Recognition\n Entity \n   Physical \n      Object \n          SelfConnectedObject \nRegion \nSubstance \nCorpuscularObject \n          Collection \n      Process \n   Abstract \n      Class \nSet \n      Relation \n      Proposition \n      Quantity \nNumber doctrines \n   archaeology \n   astrology \n   history \n      heraldry \n   linguistics \n      grammar \n   literature \n      philology \n   philosophy \n   psychology \n      psychoanalysis \n   art \n      dance \n      drawing \n         painting \nExtracto de la jerarqu\u00eda  de SUMO Extracto de la jerarqu\u00eda  de WND \nFigura 6.8. Comparaci\u00b4 on de las jerarqu\u00b4 \u0131as SUMO y WND\nconstruye la matriz conceptual, utilizando en lugar de documen-\ntos como columnas, las etiquetas sem\u00b4 anticas de los dominios y\ncomo valor en cada celda, el valor del Ratio de asociaci\u00b4 on de cada\npalabra con respecto a cada dominio.\nUna vez obtenidas las matrices conceptuales se realiza su des-\ncomposici\u00b4 on en valores singulares, reduciendo ambas matrices a\n100 dimensiones.\n6.4.3.2 Ejemplo ilustrativo.\nPara ilustrar la aplicaci\u00b4 on de los Dominios Relevantes y LSA\nse muestra a continuaci\u00b4 on un ejemplo de resoluci\u00b4 on de par\u00b4 afrasis.\nEn este caso, dados dos fragmentos de texto, se van a extraer sus\ncorrespondientes espacios conceptuales y se va a determinar un\nvalor de similitud entre ambos. El valor a partir del cual dos tex-\ntos son considerados como par\u00b4 afrasis uno del otro se ha obtenido\nemp\u00b4 \u0131ricamente a partir de una serie de experimentos previos sobre\nun corpus de entrenamiento.\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 223\nEl primer paso, es obtener los lemas de las palabras de los\ntextos implicados (Figura 6.9). Para ello se ha utilizado el ana-\nlizar sint\u00b4 actico Tree-Tagger. Se ha optado por extraer los lemas\ndebido a que la matriz conceptual de LSA se ha construido a\npartir de las palabras lematizadas de WordNet. En este ejem-\nplo, se han extra\u00b4 \u0131do los dominios relevantes de nombres, verbos,\nadjetivos y adverbios, para ambos segmentos. Las palabras que\naparecen subrayadas en la Figura 6.9, son aquellas para las que\nse han considerado sus dominios relevantes.\nText Segment 1: Women\nwho eat\npotatoes\nand other tuberous\nvegetables\nduring\npregnancy\nmay be at risk\nof triggering\ntype\n1 diabetes\nin their children\n, Melbourne\nresearchers\nbelieve\n.\nText Segment 2: Australian researchers\nbelieve\nthey have found\na trigger\nof type\n1 diabetes\nin children\n- their mothers\neating\npotatoes\nand other tuberous\nvegetables\nduring pregnancy\n.\nFigura 6.9. Textos n\u00b4 umero 1634 del corpus\nLa Figura 6.10 muestra los dominios relevantes de cada una\nde las palabras de los segmentos seg\u00b4 un la medida del Ratio de\nAsociaci\u00b4 on.\nUna vez determinados los dominios relevantes de los dos seg-\nmentos de texto, es necesario determinar el grado de similitud\nentre ambos. Para ello, se utiliza la t\u00b4 ecnica de LSA que obtiene\nlos dominios que tienen en com\u00b4 un ambos segmentos de texto (ver\nFigura 6.29). Con esta informaci\u00b4 on se seleccionan los dominos\ncon la probabilidad m\u00b4 as elevada que coincidan con los dominios\nrelevantes extra\u00b4 \u0131dos anteriormente.\nFinalmente, se obtiene el valor del dominio m\u00b4 as apropriado de\nacuerdo a los valores de similitud obtenidos. En este caso, el do-\nminio seleccionado es Applied\nScience .\n6.4.3.3 Evaluaci\u00b4 on.\n224 6.4 Participaci\u00b4 on en Textual Entailment Recognition\nText Segment 1:\nwoman =fsexuality 0.236904, fashion 0.074808, person 0.072525, athletics 0.048517, jewe-\nllery 0.042176 g\neat=fgastronomy 0.168685, ecology 0.034430, folklore 0.026185, physiology 0.017776,\nanthropology 0.012501 g\npotato =fagriculture 0.056402, gastronomy 0.009348, entomology 0.004056, racing\n0.003743, medicine 0.002409 g\ntuberous =fagriculture 0.000782, biology 0.000284, botany 0.003115, botany 0.003115,\ngastronomy 0.002218 g\nvegetable =fgastronomy 0.040430, zootechnics 0.023290, agriculture 0.022609, earth\n0.009891, body\ncare 0.009335 g\npregnancy =fsurgery 0.027848, physiology 0.025092, medicine 0.005344, anatomy\n0.002291, color 0.001075 g\nrisk= finsurance 0.049295, exchange 0.015876, enterprise 0.013756, industry 0.001393,\ncommerce 0.001289 g\ntrigger =fcommerce 0.002437, computer\nscience 0.001999, factotum 0.000088 g\ntype =fzoology 0.052495, philology 0.048450, bowling 0.043687, publishing 0.023217, bio-\nlogy 0.018311 g\ndiabetes =fpharmacy 0.006108, medicine 0.005782, alimentation 0.000724, time\nperiod\n0.000290, factotum 0.000020... g\nchild =fethnology 0.008168, acoustics 0.006704, color 0.002306, body\ncare 0.001732, eco-\nnomy 0.001036 g\nresearcher =fperson 0.000636, factotum 0.000010 g\nbelieve =fdoctrines 0.195175, theology 0.155574, pure\nscience 0.137293, folklore 0.079765,\nreligion 0.067227 g\nText Segment 2:\nresearcher =fperson 0.000636, factotum 0.000010 g\nbelieve =fdoctrines 0.195175, theology 0.155574, pure\nscience 0.137293, folklore 0.079765,\nreligion 0.067227 g\n\ufb01nd=fzoology 0.102364, chemistry 0.072100, statistics 0.045846, geology 0.043141, astro-\nlogy 0.042836 g\ntrigger =fcommerce 0.002437, computer\nscience 0.001999, factotum 0.000088 g\ntype =fzoology 0.052495, philology 0.048450, bowling 0.043687, publishing 0.023217, bio-\nlogy 0.018311 g\ndiabetes =fpharmacy 0.006108, medicine 0.005782, alimentation 0.000724, time\nperiod\n0.000290, factotum 0.000020 g\nchild =fethnology 0.008168, acoustics 0.006704, color 0.002306, body\ncare 0.001732, eco-\nnomy 0.001036 g\nmother =farchaeology 0.014541, anthropology 0.003027, computer\nscience 0.000241, ad-\nministration 0.000241, biology 0.000239 g\neat=fgastronomy 0.168685, ecology 0.034430, folklore 0.026185, physiology 0.017776,\nanthropology 0.012501 g\npotato =fagriculture 0.056402, gastronomy 0.009348, entomology 0.004056, racing\n0.003743, medicine 0.002409 g\ntuberous =fagriculture 0.000782, biology 0.000284, botany 0.003115, botany 0.003115,\ngastronomy 0.002218 g\nvegetable =fgastronomy 0.040430, zootechnics 0.023290, agriculture 0.022609, earth\n0.009891, body\ncare 0.009335 g\npregnancy =fsurgery 0.027848, physiology 0.025092, medicine 0.005344, anatomy\n0.002291, color 0.001075 g\nFigura 6.10. Los cinco primeros dominios relevantes de cada palabra\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 225\nLSA dominios en segmento 1\nLSA dominios en segmento 2\nDominio\nSimilitud\nDominio\nSimilitud\napplied\nscience\n0.770537\napplied\nscience\n0.793825\npharmacy\n0.740445\npharmacy\n0.777943\nphilology\n0.717400\necology\n0.713885\npublishing\n0.716576\ntransport\n0.709478\ntheology\n0.714463\nbiology\n0.705481\npedagogy\n0.705165\nbotany\n0.701570\ntelecommunication\n0.700763\nuniversity\n0.694129\nuniversity\n0.698827\npublishing\n0.693940\npsychoanalysis\n0.697876\nchemistry\n0.693747\nTabla 6.29. LSA listado con los nuevo dominios relevantes para cada texto\nPara evaluar la correcci\u00b4 on de los resultados se han realizado\ndiversos experimentos sobre un corpus de par\u00b4 afrasis15. El proce-\nso de evaluaci\u00b4 on consiste en determinar dados dos segmentos de\ntexto si existe par\u00b4 afrasis entre ambos.\nEl corpus utilizado ( Dolan et al. (2004 )) ha sido extra\u00b4 \u0131do de\nla web. El n\u00b4 umero de instancias de entrenamiento es de 4076 y el\nn\u00b4 umero de instancias de test es de 1725.\nUn ejemplo de segmentos de texto es: \u201cInhibited children tend\nto be timid with new people, objects, and situations, while uninhi-\nbited children spontaneously approach them.\u201d y\u201cSimply put, shy\nindividuals tend to be more timid with new people and situations.\u201d\nLas medidas de evaluaci\u00b4 on utilizadas han sido: precisi\u00b4 on, recall,\naccuracy y f-measure.\nSe han desarrollado dos tipos de experimentos. El primero,\nestudia c\u00b4 omo representar el concepto subyacente a dos segmentos\nde texto, utilizando WND y SUMO. En el segundo, se estudia si el\nuso de ontolog\u00b4 \u0131as m\u00b4 as gen\u00b4 ericas, produce mejores resultados. Los\nresultados obtenidos se muestran en la Tabla 6.30. En esta tabla se\nmuestran los resultados obtenidos en el corpus de entrenamiento\ny en el corpus de test. As\u00b4 \u0131 como tambi\u00b4 en una serie de umbrales\nutilizados, con los que se concluye que un umbral de 0.4 es el m\u00b4 as\nadecuado.\n15http://research.microsoft.com/en-us/projects/paraphrase/default.aspx\n226 6.4 Participaci\u00b4 on en Textual Entailment Recognition\nDatos\nUmb\nAcc\nPrec\nRec\nF\nWordNet Domains\nTrain\n0.8\n80.29\n72.97\n70.83\n71.89\n0.6\n97.35\n68.91\n96.07\n80.26\n0.4\n98.52\n68.36\n97.82\n80.48\nTest\n0.8\n80.34\n72.08\n70.44\n71.25\n0.6\n97.10\n67.50\n95.64\n79.14\n0.4\n98.26\n66.84\n97.38\n79.27\nSUMO\nTrain\n0.8\n38.59\n81.69\n09.08\n16.34\n0.6\n94.28\n69.44\n91.53\n78.97\n0.4\n96.27\n68.93\n94.47\n79.71\nTest\n0.8\n40.05\n81.29\n09.85\n17.57\n0.6\n93.50\n68.67\n90.23\n77.99\n0.4\n95.18\n68.11\n92.76\n78.55\nText similarity ap-\nproach\nTest\n\u2013\n68.80\n74.10\n81.70\n77.70\nTabla 6.30. Representaci\u00b4 on conceptual para identi\ufb01car la par\u00b4 afrasis\nPara la resoluci\u00b4 on de la par\u00b4 afrasis esta aproximaci\u00b4 on propor-\nciona no s\u00b4 olo el signi\ufb01cado del texto sino tambi\u00b4 en su concepto\nsem\u00b4 antico global. Durante el proceso de entrenamiento y de test\nWND y SUMO obtienen resultados similares. Sin embargo, WND\nproporciona resultados m\u00b4 as precisos. Las diferencias m\u00b4 as notables\nentre los dos experimentos se muestran con umbrales de valores\nelevados. Mientras que WND var\u00b4 \u0131a alrededor de un 10 % entre los\ndiferentes umbrales, SUMO var\u00b4 \u0131a del 16 al 79 %. Esto debido en\ngran parte a la jerarqu\u00b4 \u0131a utilizada en ambas ontolog\u00b4 \u0131as. En WND\nlos dominios se pueden solapar con una alta probabilidad mien-\ntras que en la jerarqu\u00b4 \u0131a gen\u00b4 erica de SUMO este solapamiento es\nmenos evidente.\nEn la Tabla 6.30 tambi\u00b4 en se muestra una comparativa con\nlos resultados obtenidos por la aproximaci\u00b4 on mediante similitudes\n(Corley y Mihalcea (2005 )). Se puede apreciar que nuestra aproxi-\nmaci\u00b4 on obtiene mejores resultados. Ya que, el establecimiento de\nsimilitudes palabra \u00a1palabra o texto \u00a1texto, no determinan exac-\ntamente el signi\ufb01cado del texto. En nuestro caso, se determina\nla similitud entre palabras pertenecientes a distintas categor\u00b4 \u0131as\nsint\u00b4 acticas en base al concepto sem\u00b4 antico subyacente.\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 227\nAlgunas limitaciones con respecto a la representaci\u00b4 on concep-\ntual de los segmentos de texto son debidas a la inclusi\u00b4 on del do-\nminio Factotum , cuando no se puede clasi\ufb01car alguna palabra.\nCon respecto a la ontolog\u00b4 \u0131a SUMO se hace patente la necesidad\nde incorporar m\u00b4 as de 20 dominios representativos, para determi-\nnar el concepto sem\u00b4 antico de cada segmento de texto ( Kozareva\net al. (2007 )).\n6.5 Integraci\u00b4 on de DRelevant en un sistema\nbasado en aprendizaje\nEl sistema DRelevant ha sido utilizado para enriquecer el con-\njunto de caracter\u00b4 \u0131sticas de un sistema de aprendizaje autom\u00b4 atico.\nEl objetivo de este experimento es comprobar si la integraci\u00b4 on de\nla informaci\u00b4 on proporcionada por el sistema DRelevant in\ufb02uye de\nforma positiva en el proceso de desambiguaci\u00b4 on. Para realizar el\nexperimento, se han utilizado los datos de la tarea English lexical\nsample de Senseval-2 .\n6.5.1 Sistema de aprendizaje inicial\nEl sistema de aprendizaje inicial para el desarrollo de nues-\ntro experimento es el descrito en ( Su\u00b4 arez (2004 )). Este sistema\nde aprendizaje supervisado (WSD\nMAX\nENT), est\u00b4 a basado en el\nmodelo probabil\u00b4 \u0131stico de m\u00b4 axima entrop\u00b4 \u0131a ( Ratnaparkhi (1998 )),\ndonde a partir del modelado de una serie de caracter\u00b4 \u0131sticas o atri-\nbutos y del aprendizaje a partir de corpus anotados sem\u00b4 antica-\nmente trata de resolver el problema de la ambig\u00a8 uedad sem\u00b4 antica.\nEl conjunto de atributos utilizado por el sistema WSD\nMAX\nENT\nse muestra en la Tabla 6.31.\nEstos atributos se basan, principalmente, en el conocimiento\nling\u00a8 u\u00b4 \u0131stico del contexto cercano a la palabra ambigua: palabras y\ncomposiciones de palabras que la acompa\u02dc nan, categor\u00b4 \u0131as grama-\nticales, rol gramatical, dependencias, etc.\nLa de\ufb01nici\u00b4 on de atributos no tiene por qu\u00b4 e ser exclusivamente\nautom\u00b4 atica y a partir del corpus de aprendizaje. Tambi\u00b4 en se po-\ndr\u00b4 \u0131a incorporar informaci\u00b4 on externa al corpus si fuera necesaria.\n2286.5 Integraci\u00b4 on de DRelevant en un sistema\nbasado en aprendizaje\nNo relajados\n0: la palabra ambigua\nl: lemas (de palabras llenas) en \u00a71,\u00a72,\u00a73\ns: palabras en posiciones \u00a71,\u00a72,\u00a73\nb: lemas de pares de palabras en (-2, -1), (-1, +1), (+1, +2)\nc: pares de palabras en (-2, -1), (-1, +1), (+1, +2)\np: categor\u00b4 \u0131as gramaticales de palabras en \u00a71,\u00a72,\u00a73\nkm: lemas de nombres que aparecen en al menos el m % de contextos de un\nsentido\nr: rol gramatical de la palabra ambigua\nd: la palabra de la que depende la ambigua\nm: palabra compuesta a la que pertenece la ambigua\nRelajados\nL: lemas (de palabras llenas) en \u00a71,\u00a72,\u00a73\nW: palabras llenas en \u00a71,\u00a72,\u00a73\nS: palabras en \u00a71,\u00a72,\u00a73\nB: lemas de pares de palabras en (-2, -1), (-1, +1), (+1, +2)\nC: pares de palabras en (-2, -1), (-1, +1), (+1, +2)\nP: categor\u00b4 \u0131as gramaticales en \u00a71,\u00a72,\u00a73\nD: la palabra de la que depende la ambigua\nM: palabra compuesta a la que pertenece la ambigua\nTabla 6.31. Conjunto de atributos de WSD\nMAX\nENT\nY es en este punto donde a\u02dc nadimos la informaci\u00b4 on proporcionada\npor el sistema DRelevant.\n6.5.2 Nuevas caracter\u00b4 \u0131sticas usando DRelevant\nPara la incorporaci\u00b4 on de la informaci\u00b4 on del sistema DRelevant\nen el sistema supervisado WSD\nMAX\nENT se van a utilizar las\netiquetas de WordNet Domains del contexto m\u00b4 as cercano a la pa-\nlabra a desambiguar. Concretamente se utilizar\u00b4 an las etiquetas de\ndominio de las dos palabras situadas a la derecha y a la izquierda\nde la palabra objetivo. V\u00b4 ease la Figura 6.11.\nEn este caso, la palabra objetivo es \u201ccar\u201d y se utiliza el sis-\ntema DRelevant para anotar las cuatro palabras m\u00b4 as cercanas a\n\u201ccar\u201d con contenido sem\u00b4 antico (nombres, verbos, adjetivos o ad-\nverbios) con sus respectivos dominios. Una vez acabado el proceso\nde desambiguaci\u00b4 on con DRelevant y anotadas las cuatro palabras\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 229\n \n \n \n \nYou have to drive   fast your              to  win the  race \nFactotum \u00bfsentido? Transport Sport Sport car \n \nFigura 6.11. Anotaci\u00b4 on con DRelevant\ncon sus respectivos dominios, el segundo paso es integrar esta in-\nformaci\u00b4 on en el corpus de entrenamiento del sistema, como una\nnueva caracter\u00b4 \u0131stica m\u00b4 as para el aprendizaje. El tercer paso es\nentrenar el sistema supervisado con esta nueva informaci\u00b4 on. Para\n\ufb01nalmente evaluar los resultados obtenidos con el corpus de test.\nCabe destacar que en el proceso de integraci\u00b4 on de los dominios\ncomo nuevos atributos del sistema, no se realiz\u00b4 o ninguna codi\ufb01-\ncaci\u00b4 on especial, sino que se utilizaron tal cual fueron anotados, lo\nque puede haber signi\ufb01cado alguna merma en el acierto \ufb01nal.\n6.5.3 Resultados\nLos resultados tras el enriquecimiento con DRelevant se mues-\ntran en la Tabla 6.32. Los experimentos se realizaron sobre la\ntarea English Lexical Sample de Senseval-2 sobre una muestra\nde 29 nombres. En esta tabla se pueden comparar los resultados\nobtenidos antes y despu\u00b4 es de a\u02dc nadir los nuevos atributos.\nComo se puede apreciar, de los 29 nombres escogidos s\u00b4 olo 4\nempeoraron en el proceso de desambiguaci\u00b4 on tras usar los nuevos\natributos. Los dem\u00b4 as nombres o mantuvieron los mismos resulta-\ndos o sufrieron una mejora tras el proceso de desambiguaci\u00b4 on.\nLa raz\u00b4 on de que la mejora total sea de s\u00b4 olo un 2 % se debe\nprincipalmente a que gran parte de los nombres no incrementan\nsu acierto. Adem\u00b4 as cabe destacar que el proceso de anotaci\u00b4 on del\nsistema DRelevant no es correcto al 100 %. Tampoco se se ha te-\nnido en cuenta si el dominio \u201cfactotum\u201d (etiqueta de WordNet\nDomains que indica que cierto nombre resulta inclasi\ufb01cable) debe\neliminarse para mejorar el proceso de anotaci\u00b4 on. Incluso se po-\ndr\u00b4 \u0131a probar una ventana de palabras mayor en torno al nombre\n2306.5 Integraci\u00b4 on de DRelevant en un sistema\nbasado en aprendizaje\nNombres\nSinDRelevant\nConDRelevant\nMejora\nart\n68,3\n68,3\n0\nauthority\n53,8\n56,3\n2,5\nbar\n51,9\n51\n-0,9\nbum\n86,5\n91,9\n5,4\nchair\n89,8\n89,8\n0\nchannel\n12,5\n18,8\n6,3\nchild\n61\n62,7\n1,7\nchurch\n60\n60\n0\ncircuit\n24,5\n38,8\n14,3\nday\n64\n64,7\n0,7\ndetention\n90,9\n86,4\n-4,5\ndyke\n80\n80\n0\nfacility\n71,4\n64,3\n-7,1\nfatigue\n86,8\n86,8\n0\nfeeling\n60,4\n66,7\n6,3\ngrip\n15,8\n15,8\n0\nhearth\n79,3\n79,3\n0\nholiday\n100\n100\n0\nlady\n87,5\n90\n2,5\nmaterial\n36,2\n51,7\n15,5\nmouth\n56,9\n58,8\n1,9\nnation\n72\n72\n0\nnature\n43,2\n46\n2,8\npost\n51,2\n51,2\n0\nrestraint\n48,4\n51,6\n3,2\nsense\n43,2\n48,7\n5,5\nspade\n82,4\n88,2\n5,8\nstress\n46\n40,5\n-5,5\nyew\n79,2\n79,2\n0\nTotal\n62\n64\n2\nTabla 6.32. Enriquecimiento de un sistema basado en aprendizaje con DRelevant\nobjetivo. Adem\u00b4 as, tambi\u00b4 en ser\u00b4 \u0131a interesante aplicar estos atribu-\ntos sobre verbos y adjetivos. Todas estas posibles mejoras quedan\npendientes como trabajo futuro.\n6. Experimentaci\u00b4 on y evaluaci\u00b4 on 231\n6.5.4 Test de McNemar\nTras la inclusi\u00b4 on de los dominios como una nueva caracter\u00b4 \u0131stica\nen el sistema supervisado WSD\nMAX\nENT, es necesario determi-\nnar la signi\ufb01cancia de los cambios producidos. Para ello, se va a\nutilizar el test de McNemar ( Everitt (1977 )) que determina si los\nresultados obtenidos antes y despu\u00b4 es de la inclusi\u00b4 on de los domi-\nnios como nueva caracter\u00b4 \u0131stica producen cambios signi\ufb01cativos.\nLa Tabla 6.33muestra la informaci\u00b4 on utilizada para construir\nla tabla de contingencia:\nEjemplos clasi\ufb01cados err\u00b4 oneamente\nEjemplos clasi\ufb01cados err\u00b4 oneamente por\npor ambos algoritmos\nWSD\nSinDOm pero\nno por WSD\nConDom\nEjemplos clasi\ufb01cados err\u00b4 oneamente\nEjemplos clasi\ufb01cados correctamente por\npor WSD\nConDom pero\nambos algoritmos\nno por WSD\nSinDOm\nTabla 6.33. Tabla de contingencia para el test de McNemar\nPara abreviar, se utilizar\u00b4 a la notaci\u00b4 on de la Tabla 6.34. As\u00b4 \u0131 se\npuede identi\ufb01car cada caso mediante las variables: n00; n01; n10; n11.\nn00\nn01\nn10\nn11\nTabla 6.34. Notaci\u00b4 on abreviada Tabla de contingencia del test de McNemar\nLa Tabla 6.35 muestra los valores asociados a cada variable\ntras aplicar ambos algoritmos a las instancias de test de English\nLexical Sample Senseval .\nLa suma de todas las variables es el n\u00b4 umero total de ejemplos\nen el conjunto de instancias de test. En nuestro caso: 447 + 96 +\n68 + 685 = 1296.\nEl test de McNemar se utiliza para comparar los resultados de\nuna hip\u00b4 otesis nula o te\u00b4 orica H0, con los resultados de la hip\u00b4 otesis\npara los valores reales observados H1. La hip\u00b4 otesis nula tiene como\n232\n447\n96\n68\n685\nTabla 6.35. Valores observados antes y despu\u00b4 es de la inclusi\u00b4 on de los dominios\npremisa que ambos algoritmos comparten los mismos errores, por\ntanto, n01=n10. Supongamos que el nivel de signi\ufb01cancia es\n\u00ae= 0;05 con 1 grado de libertad, por tanto, \u00c22\n1\u00a10;95= 3;841459.\nRegla de decisi\u00b4 on:\nSi\u00c22> \u00c22\n1\u00a1\u00aerechazamos H0y existe asociaci\u00b4 on signi\ufb01cativa\n(p-value < \u00ae).\nSi\u00c22\u00b7\u00c22\n1\u00a1\u00aeasumimos H0y no existe asociaci\u00b4 on signi\ufb01cativa\n(p-value \u00b8\u00ae).\nEn nuestro caso en particular:\n\u00c22=(jn01\u00a1n10j\u00a11)2\nn01+n10=(j96\u00a168j\u00a11)2\n96+68= 4;45\nComo el valor de \u00c22= 4;45> \u00c22\n1\u00a10;95= 3;84 entones p <0;05,\nconcluyendo que la utilizaci\u00b4 on de dominios es signi\ufb01cativa para la\nmejora del sistema WSD\nMAX\nENT.\nCap\u0013\u0010tulo 7\nConclusiones y trabajos futuros\nEn este cap\u00b4 \u0131tulo \ufb01nal y como consecuci\u00b4 on de esta Tesis docto-\nral, se presenta una s\u00b4 \u0131ntesis sobre el trabajo desarrollado, un an\u00b4 ali-\nsis de los bene\ufb01cios aportados por la desambiguaci\u00b4 on autom\u00b4 atica\na otras de tareas de PLN, una serie de propuestas con vistas al\nfuturo, as\u00b4 \u0131 como el conjunto de publicaciones relevantes derivadas\nde este trabajo.\n7.1 Aportaciones\nEn esta Tesis se ha presentado la de\ufb01nici\u00b4 on y evaluaci\u00b4 on de\nvarios m\u00b4 etodos de resoluci\u00b4 on de la ambig\u00a8 uedad sem\u00b4 antica: DRe-\nlevant, DLSA y SenseDiscrim. Todos los m\u00b4 etodos presentados se\nclasi\ufb01can dentro de la categor\u00b4 \u0131a de m\u00b4 etodos no supervisados, ba-\nsados en conocimiento. Estos m\u00b4 etodos han sido evaluados seg\u00b4 un\nlas especi\ufb01caciones de la competici\u00b4 on Senseval mostrando una\ncomparativa respecto a otros sistemas. Adem\u00b4 as, se han integrado\nuna serie de recursos sem\u00b4 anticos (Dominios Relevantes, SUMO)\nsobre diferentes t\u00b4 ecnicas (LSA, Machine Learning) con el objeti-\nvo de resolver problemas que afectan a otras tareas de PLN, tales\ncomo: reconocimiento de la variabilidad sem\u00b4 antica o detecci\u00b4 on y\nclasi\ufb01caci\u00b4 on de nombres propios. Adem\u00b4 as, como consecuci\u00b4 on del\nestudio de la distribuci\u00b4 on y relaciones entre los sentidos en bases\nde datos l\u00b4 exicas como WordNet se ha creado un nuevo recurso\n234 7.1 Aportaciones\nl\u00b4 exico: Dominios Relevantes. Este recurso es susceptible de inte-\ngrarse en otros sistemas de WSD o servir de referencia sem\u00b4 antica\npara otras tareas de PLN.\nLas principales aportaciones siguiendo la estructura de esta\nTesis han sido:\n7.1.1 Estudio del estado del arte\nEstudio de la evoluci\u00b4 on de los sistemas de resoluci\u00b4 on autom\u00b4 ati-\nca de la ambig\u00a8 uedad desde los comienzos del PLN hasta la fecha\nactual. Se ha realizado una clasi\ufb01caci\u00b4 on de dichos sistemas dentro\nde distintas categor\u00b4 \u0131as, distinguiendo entre sistemas supervisados\ny sistemas no supervisados.\nA la vista de los resultados obtenidos en las distintas com-\npeticiones para evaluaci\u00b4 on de sistemas que resuelven de forma\nautom\u00b4 atica la ambig\u00a8 uedad en el lenguaje, los sistemas supervi-\nsados han demostrado ser m\u00b4 as e\ufb01cientes que los sistemas no su-\npervisados. Sin embargo, el principal problema de los sistemas\nsupervisados reside en la escasez de corpus anotados para su en-\ntrenamiento.\n7.1.2 Estudio de los sistemas de evaluaci\u00b4 on en WSD\nSe ha realizado un estudio de la evoluci\u00b4 on de los m\u00b4 etodos\nde evaluaci\u00b4 on de sistemas de WSD. Originalmente exist\u00b4 \u0131a una\nimposibilidad de realizar estudios comparativos entre diferentes\nsistemas debido a la utilizaci\u00b4 on de distintos tipos de anotaci\u00b4 on\nsem\u00b4 antica o de corpus utilizados para la evaluaci\u00b4 on. Ante este\nproblema, desde 1998 hasta la actualidad, la evaluaci\u00b4 on de sis-\ntemas de WSD se realiza bajo un marco com\u00b4 un de evaluaci\u00b4 on:\nla competici\u00b4 on Senseval . Esta competici\u00b4 on uni\ufb01ca criterios de\nevaluaci\u00b4 on permitiendo de esta forma evaluar distintos sistemas y\ncomparar los resultados obtenidos.\n7.1.3 Descripci\u00b4 on de los recursos l\u00b4 exicos utilizados\nSe han descrito los distintos recursos l\u00b4 exicos utilizados para el\ndesarrollo de los m\u00b4 etodos de WSD presentados en este trabajo.\n7. Conclusiones y trabajos futuros 235\nEn nuestro caso, la base de conocimiento principal sobre la que\nsubyacen todos los m\u00b4 etodos desarrollados es WordNet: una base\nde datos l\u00b4 exica que sigue una serie de criterios psicoling\u00a8 u\u00b4 \u0131sticos,\nampliamente utilizada en PLN. A partir de esta base de datos\nl\u00b4 exica se han utilizado otras ontolog\u00b4 \u0131as como SUMO o WordNet\nDomains que enriquecen las inter-relaciones de palabras presen-\ntes en WordNet. Adem\u00b4 as, mediante la utilizaci\u00b4 on de una versi\u00b4 on\nextendida de WordNet, Extended WordNet, se ha mejorado la\nobtenci\u00b4 on del nuevo recurso l\u00b4 exico Dominios Relevantes. Este re-\ncurso l\u00b4 exico proporciona informaci\u00b4 on relevante acerca de las pala-\nbras polis\u00b4 emicas junto con las categor\u00b4 \u0131as sem\u00b4 anticas con las que\nse relacionan.\nAdem\u00b4 as, se ha presentado y descrito detalladamente la t\u00b4 ecnica\nde LSA, que permite extraer relaciones existentes entre palabras a\ntrav\u00b4 es de sus ocurrencias en diferentes contextos. Esta t\u00b4 ecnica ha\nsido adaptada a nuestras necesidades, transformando el concepto\nde contextos (documentos) en categor\u00b4 \u0131as sem\u00b4 anticas (dominios).\n7.1.4 De\ufb01nici\u00b4 on de los m\u00b4 etodos evaluados\nSe han descrito los distintos m\u00b4 etodos de WSD, los cuales, uti-\nlizan la informaci\u00b4 on de WordNet, SUMO y la t\u00b4 ecnica de LSA.\nEstos m\u00b4 etodos pueden aplicarse a diferentes lenguas utilizando el\nenlace ILI de EuroWordNet. \u00b4Unicamente se requiere un prepro-\nceso inicial de los textos para obtener los lemas de las palabras\ndel contexto ambiguo. Asimismo, mediante la utilizaci\u00b4 on de la in-\nformaci\u00b4 on de Extended WordNet se han mejorado los resultados\nobtenidos en el proceso de desambiguaci\u00b4 on.\nTodos los m\u00b4 etodos de\ufb01nidos han sido evaluados sobre los cor-\npus de Senseval y comparados con el resto de sistemas partici-\npantes en las diferentes tareas.\n7.1.5 Evaluaci\u00b4 on y aplicaci\u00b4 on de los sistemas de WSD a\ntareas de PLN\nSe ha presentado el marco de evaluaci\u00b4 on de sistemas de WSD\nSenseval , en sus diferentes ediciones. En cada edici\u00b4 on se han\n236 7.2 Trabajos Futuros\nmantenido una serie de tareas relacionadas con WSD ( All Words\nyLexical Sample en diferentes idiomas) y adem\u00b4 as se han ido\na\u02dc nadiendo progresivamente otro tipo de tareas en las que el pro-\nceso de desambiguaci\u00b4 on autom\u00b4 atica es bene\ufb01cioso (Web People\nSearch, desambiguaci\u00b4 on de preposiciones, detecci\u00b4 on de sentimien-\ntos, etc).\nTodos los m\u00b4 etodos de\ufb01nidos han sido evaluados siguiendo los\ncriterios de Senseval . Adem\u00b4 as, se ha evaluado la integraci\u00b4 on\nde estos sistemas no supervisados con otros sistemas de WSD,\nobteniendo buenos resultados.\nDado que la tarea de WSD, no est\u00b4 a considerada como una\ntarea \ufb01nal, as\u00b4 \u0131 como, traducci\u00b4 on autom\u00b4 atica o clasi\ufb01caci\u00b4 on de do-\ncumentos, se han realizado una serie de experimentos aplicando\nlos sistemas de WSD sobre otras tareas de PLN. En nuestro caso,\nse han aplicado para resolver la implicaci\u00b4 on textual, la detecci\u00b4 on\nde par\u00b4 afrasis o la clasi\ufb01caci\u00b4 on de nombres propios comunes per-\ntenecientes a distintas personas.\n7.2 Trabajos Futuros\nComo trabajos futuros queda pendiente la elaboraci\u00b4 on de un\nsistema de WSD que combine los recursos obtenidos en esta Tesis\npara crear un sistema de WSD supervisado. El objetivo es deter-\nminar si el modelado de caracter\u00b4 \u0131sticas utilizando un sistema de\nWSD no supervisado basado en conocimiento, ayuda a un sistema\nde WSD supervisado. En ( V\u00b4 azquez et al. (2007 )) se describe la\npropuesta de este sistema.\nTambi\u00b4 en queda pendiente mejorar el recurso Relevant Domains\nincluyendo informaci\u00b4 on relativa a las relaciones existentes entre\nlos dominios y la jerarqu\u00b4 \u0131a de relaciones de WordNet: hiponimi-\nna, meronimia, hiperonimia... As\u00b4 \u0131 como mejorar la obtenci\u00b4 on de\nla matriz conceptual utilizada por LSA, incorporando informa-\nci\u00b4 on relativa a las relaciones existentes entre palabras: verbos con\nobjetos directos, sintagmas nominales, etc. Adem\u00b4 as, el sistema\nSenseDiscrim puede ser enriquecido mediante la obtenci\u00b4 on de nue-\n7. Conclusiones y trabajos futuros 237\nvos patrones que incorporen informaci\u00b4 on relacionada con verbos\ny adjetivos.\nPor \u00b4 ultimo, se est\u00b4 a desarrollando la adaptaci\u00b4 on de los m\u00b4 eto-\ndos descritos en esta Tesis para su aplicaci\u00b4 on a la resoluci\u00b4 on de\nlos tests de TOEFL que tienen como objetivo la detecci\u00b4 on de si-\nmilitudes entre pares de palabras. El objetivo de este estudio es\ndeterminar si ante la falta de contexto proporcionado, se pueden\nadaptar los recursos existentes para seleccionar pares de palabras\nfuertemente relacionadas sem\u00b4 anticamente.\n7.3 Producci\u00b4 on cient\u00b4 \u0131\ufb01ca\nA continuaci\u00b4 on se muestran las publicaciones realizadas como\nconsecuci\u00b4 on de esta Tesis. Todas ellas en orden cronol\u00b4 ogico desde\n2002 hasta 2008.\n2008\nZornitsa Kozareva, Sonia V\u00b4 azquez, Andr\u00b4 es Montoyo. Domain\nInformation for Fine-Grained Person Name Catego-\nrization. CICLing 2008. Haifa (Israel). pp: 311-321. Lecture\nNotes in Computer Science. Vol: 4919/2008. ISSN: 0302-9743.\n2007\nZornitsa Kozareva, Sonia V\u00b4 azquez, Andr\u00b4 es Montoyo. The in-\n\ufb02uence of context during the categorization and dis-\ncrimination of Spanish and Portuguese person names.\nSEPLN 2007. Sevilla (Espa\u02dc na). pp: 81-88. Procesamiento del\nLenguaje Natural. Vol: 39. ISSN: 1135-5948.\nZornitsa Kozareva, Sonia V\u00b4 azquez, Andr\u00b4 es Montoyo. The\nUsefulness of Conceptual Representation for the Iden-\nti\ufb01cation of Semantic Variability Expressions. CICLing\n2007. Mexico city (Mexico). pp: 325-336. Lecture Notes in\nComputer Science. Vol: 4394/2007. ISSN: 0302-9743.\n238 7.3 Producci\u00b4 on cient\u00b4 \u0131\ufb01ca\nSonia V\u00b4 azquez, Andr\u00b4 es Montoyo, Zornitsa Kozareva. Word\nSense Disambiguation Using Extended Relevant Do-\nmains Resource. IC-AI 2007. Las Vegas (Nevada, USA). pp:\n823-828. CSREA Press. ISBN: 1-60132-024-8.\nSonia V\u00b4 azquez, Zornitsa Kozareva, Andr\u00b4 es Montoyo. How\nContext and Semantic Information Can Help a Ma-\nchine Learning System? MICAI 2007. Aguascalientes (Me-\nxico). pp: 996-1003. Lecture Notes in Computer Science. Vol:\n4827/2007 ISSN: 0302-9743.\nZornitsa Kozareva, Sonia V\u00b4 azquez, Andr\u00b4 es Montoyo. Multi-\nlingual Name Disambiguation with Semantic Informa-\ntion. TSD 2007. Pilsen (Rep\u00b4 ublica Checa). pp: 23-30. Lecture\nNotes in Computer Science. Vol: 4629/2007. ISSN: 0302-9743.\nZornitsa Kozareva, Sonia V\u00b4 azquez, Andr\u00b4 es Montoyo. Disco-\nvering the Underlying Meanings and Categories of\na Name through Semantic and Domain Information.\nRecent Advances in Natural Language Processing (RANLP\n2007). Borovets (Bulgaria).\nZornitsa Kozareva, Sonia V\u00b4 azquez, Andr\u00b4 es Montoyo. A Lan-\nguage Independent Approach for Name Categoriza-\ntion and Discrimination. ACL-PASCAL Workshop on Tex-\ntual Entailment and Paraphrasing. 45th Annual Meeting of\nthe Association for Computational Linguistics. Praga (Rep\u00b4 ubli-\nca Checa).\nZornitsa Kozareva, Borja Navarro, Sonia V\u00b4 azquez, Andr\u00b4 es\nMontoyo. UA-ZBSA: A Headline Emotion Classi\ufb01ca-\ntion through Web Information. International Workshop\non Semantic Evaluations SEMEVAL. 4th Interntional SemEval-\nACL 2007. Praga (Rep\u00b4 ublica Checa).\nZornitsa Kozareva, Sonia V\u00b4 azquez, Andr\u00b4 es Montoyo. UA-\nZSA: Web Page Clustering on the basis of Name Di-\n7. Conclusiones y trabajos futuros 239\nsambiguation. International Workshop on Semantic Evalua-\ntions SEMEVAL. 4th Interntional SemEval- ACL 2007. Praga\n(Rep\u00b4 ublica Checa).\n2006\nSonia V\u00b4 azquez, Zornitsa Kozareva, Andr\u00b4 es Montoyo. Contri-\nbuci\u00b4 on de la informaci\u00b4 on sem\u00b4 antica en un sistema de\naprendizaje autom\u00b4 atico para resolver la implicaci\u00b4 on\ntextual. SEPLN 2006. Zaragoza (Espa\u02dc na). pp: 189-196. Pro-\ncesamiento del Lenguaje Natural. Vol: 37. ISSN: 1135-5948.\nZornitsa Kozareva, Sonia V\u00b4 azquez, Andr\u00b4 es Montoyo. Univer-\nsity of Alicante at QA@CLEF2006: Answer Validation\nExercise. CLEF 2006. Alicante (Espa\u02dc na). pp: 522-525. Lec-\nture Notes in Computer Science. Vol: 4730/2007. ISSN: 0302-\n9743.\nSonia V\u00b4 azquez, Zornitsa Kozareva, Andr\u00b4 es Montoyo. Textual\nEntailment Beyond Semantic Similarity Information.\nMICAI 2006. Apizaco (Mexico). pp: 900-910. Lecture Notes in\nComputer Science. Vol: 4293/2006. ISSN: 0302-9743.\nZornitsa Kozareva, Sonia V\u00b4 azquez, Andr\u00b4 es Montoyo. The Ef-\nfect of Semantic Knowledge Expansion to Textual En-\ntailment Recognition. TSD 2006. Brno (Rep\u00b4 ublica Che-\nca). pp: 143-150. Lecture Notes in Computer Science. Vol:\n4188/2006. ISSN: 0302-9743.\n2005\nBorja Navarro, Lorenza Moreno-Monteagudo, Elisa Nogue-\nra, Sonia V\u00b4 azquez, Fernando Llopis, Andr\u00b4 es Montoyo. \u201dHow\nMuch Context Do You Need?\u201d: An Experiment About\nthe Context Size in Interactive Cross-Language Ques-\ntion Answering. CLEF 2005. Viena (Austria). pp: 273-282.\nLecture Notes in Computer Science. Vol: 4022/2006. ISSN:\n240 7.3 Producci\u00b4 on cient\u00b4 \u0131\ufb01ca\n0302-9743.\n2004\nIulia Nica, Maria Ant` onia Mart\u00b4 \u0131, Andr\u00b4 es Montoyo, Sonia\nV\u00b4 azquez. Combining EWN and Sense-Untagged Cor-\npus for WSD. CICLing 2004. Se\u00b4 ul (Korea). pp: 188-200.\nLecture Notes in Computer Science. Vol: 2945/2004. ISSN:\n0302-9743.\nSonia V\u00b4 azquez, Estela Saquete, Andr\u00b4 es Montoyo, Patricio\nMart\u00b4 \u0131nez-Barco, Rafael Mu\u02dc noz. The Role of Temporal Ex-\npressions in Word Sense Disambiguation. CICLing 2004.\nSe\u00b4 ul (Korea). pp: 209-212. Lecture Notes in Computer Scien-\nce.Vol: 2945/2004. ISSN: 0302-9743.\nBorja Navarro, Lorenza Moreno, Sonia V\u00b4 azquez, Fernando\nLlopis, Andr\u00b4 es Montoyo, Miguel Angel Var\u00b4 o. Improving In-\nteraction with the User in Cross-Language Question\nAnswering Through Relevant Domains and Syntactic\nSemantic Patterns. CLEF 2004. Bath (Reino Unido). pp:\n334-342. Lecture Notes in Computer Science. Vol: 3491/2005.\nISSN: 0302-9743.\nSonia V\u00b4 azquez, Andr\u00b4 es Montoyo, German Rigau. Using Re-\nlevant Domains Resource for Word Sense Disambigua-\ntion. IC-AI 2004. Las Vegas (Nevada, USA). pp: 784-789. CS-\nREA Press. ISBN: 1-932415-32-7.\nIulia Nica, Andr\u00b4 es Montoyo, Sonia V\u00b4 azquez, Maria Ant` onia\nMart\u00b4 \u0131. An Unsupervised WSD Algorithm for a NLP\nSystem. NLDB 2004. Manchester (Reino Unido). pp: 288-\n298. Lecture Notes in Computer Science. Vol: 3136/2004.\nISSN: 0302-9743.\nIulia Nica, Maria Antonia Mart\u00b4 \u0131, Andr\u00b4 es Montoyo, Sonia\nV\u00b4 azquez. Intensive Use of Lexicon and Corpus for\nWSD. SEPLN 2004. Barcelona (Espa\u02dc na). pp: 147-154. Pro-\n7. Conclusiones y trabajos futuros 241\ncesamiento del Lenguaje Natural. Vol: 32. ISSN: 1135-5948.\nSonia V\u00b4 azquez, Andr\u00b4 es Montoyo. Multilingual Extended\nWordNet. Biennial Iberoamerican Conference on Arti\ufb01cial\nIntelligence (IBERAMIA). Puebla (Mexico).\nSonia V\u00b4 azquez, Andr\u00b4 es Montoyo. Utilizaci\u00b4 on del recurso\nDominios Relevantes en WSD. III Jornadas en Tecno-\nlog\u00b4 \u0131a del Habla. Valencia (Espa\u02dc na).\nSonia V\u00b4 azquez, Rafael Romero, Armando Su\u00b4 arez, Andr\u00b4 es\nMontoyo, Manuel Garc\u00b4 \u0131a, Maria Teresa Mart\u00b4 \u0131n, Miguel \u00b4Angel\nGarc\u00b4 \u0131a, Alfonso Ure\u02dc na, Davide Buscaldi, Paolo Rosso, Antonio\nMolina, Ferran Pl\u00b4 a, Encarna Segarra. The R2D2 Team at\nSENSEVAL-3. International Workshop on Evaluating Word\nSense Disambiguation Systems (SENSEVAL) in conjunction\nwith the Annual Meeting of Association for Computational\nLinguistics. Barcelona (Espa\u02dc na).\nSonia V\u00b4 azquez, Rafael Romero, Armando Su\u00b4 arez, Andr\u00b4 es\nMontoyo, Iulia Nica, Maria Antonia Mart\u00b4 \u0131. The Univer-\nsity of Alicante systems at SENSEVAL-3. International\nWorkshop on Evaluating Word Sense Disambiguation Systems\n(SENSEVAL) in conjunction with the Annual Meeting of As-\nsociation for Computational Linguistics. Barcelona (Espa\u02dc na).\nIulia Nica, Maria Antonia Mart\u00b4 \u0131, Andr\u00b4 es Montoyo, Sonia\nV\u00b4 azquez. Enriching EWN with syntagmatic informa-\ntion by means of WSD. International Conference on Lan-\nguage Resources and Evaluation (LREC). Lisboa (Portugal).\nIulia Nica, Maria Antonia Mart\u00b4 \u0131, Andr\u00b4 es Montoyo, Sonia\nV\u00b4 azquez. Towards \ufb01lling the gap between lexicon and\ncorpus. International Conference on Language Resources and\nEvaluation (LREC). Lisboa (Portugal).\n242\n2003\nSonia V\u00b4 azquez, Andr\u00b4 es Montoyo, German Rigau. M\u00b4 etodo de\ndesambiguaci\u00b4 on l\u00b4 exica basada en el recurso l\u00b4 exico Do-\nminios Relevantes. SEPLN 2003. Alcal\u00b4 a de Henares (Es-\npa\u02dc na). pp: 141-148. Procesamiento del Lenguaje Natural. Vol:\n31. ISSN: 1135-5948.\n2002\nSonia V\u00b4 azquez, Ma Carmen Calle, Susana Soler, Andr\u00b4 es Mon-\ntoyo. Speci\ufb01cation Marks Method: Design and Imple-\nmentation. CICLing 2002. Mexico city (Mexico). pp: 439-\n442. Lecture Notes in Computer Science. Vol: 2276/2002.\nISSN: 0302-9743.\nAndr\u00b4 es Montoyo, Rafael Romero, Sonia V\u00b4 azquez, MaCar-\nmen Calle, Susana Soler. The Role of WSD for Multi-\nlingual Natural Language Applications. TSD 2002. Br-\nno (Rep\u00b4 ublica Checa). pp: 41-48. Lecture Notes in Computer\nScience. Vol: 2448/2002. ISSN: 0302-9743 .\nAp\u0013endice A\nAcr\u00b4 onimos\nACL . Association of Computational Linguistics.\nACM . Association for Computing Machinery.\nAR. Association Ratio.\nAVE . Answer Validation Exercise.\nBNC . British National Corpus.\nCBC . Clustering by Committee.\nCICLING . Conference on Intelligent Text Processing and Com-\nputational Linguistics.\nCLEF . Cross Language Evaluation Forum.\nCOLING . International Conference on Computational Linguis-\ntics.\nDARPA . Defense Advanced Research Project Agency.\nEI. Extracci\u00b4 on de Informaci\u00b4 on.\nEWN . EuroWordNet.\nGATE . General Architecture for Text Engineering.\nGPLSI . Grupo de Procesamiento del Lenguaje Natural.\nICAI . International Conference on Arti\ufb01cial Intelligence.\niCLEF . Interactive track of CLEF\nILI. Inter Lingual Index\nIM. Informaci\u00b4 on Mutua.\nKIF. Knowledge Interchange Format.\nLCS . Lowest Common Subsumer.\nLongCS . Longest Common Subsequence.\n244\nLDOCE . Longman Dictionary of Contemporary English.\nLREC . International Conference on Language Resources and\nEvaluation.\nLSA . Latent Semantic Analysis o An\u00b4 alisis de la Sem\u00b4 antica La-\ntente.\nLSI. Latent Semantic Indexing.\nLVQ . Learning Vector Quanti\ufb01cation.\nMI. Mutual Information.\nMICAI . Mexican International Conference on Arti\ufb01cial Intelli-\ngence.\nMUC . Message Understanding Conferences.\nMRD . Machine Readable Dictionary.\nNBC . Na\u00a8 \u0131ve Bayes Classi\ufb01er.\nNLDB . International Conference on Applications of Natural Lan-\nguage to Information Systems.\nPASCAL . Pattern Analysis, Statistical Modelling and Compu-\ntational Learning.\nPLN . Procesamiento del Lenguaje Natural.\nPMI . Pointwise Mutual Information.\nQA. Question Answering.\nRA. Ratio de asociaci\u00b4 on.\nRAE . Real Academia Espa\u02dc nola.\nRANLP . Recent Advances in Natural Language Processing.\nRI. Recuperaci\u00b4 on de Informaci\u00b4 on.\nRNA . Red Neuronal Arti\ufb01cial.\nRTE . Recognising Textual Entailment.\nSemCor (SEMantic COncoRdance)\nSenseval/Semeval . Evaluation Exercises for the Semantic Analy-\nsis of Text.\nSEPLN . Sociedad Espa\u02dc nola para el Procesamiento del Lenguaje\nNatural.\nSFC . Subject Field Codes.\nSIGIR . Special Interest Group on Information Retrieval.\nSIGLEX . Special Interest Group on the Lexicon of the Associa-\ntion for Computational Linguistics.\nSUMO . Suggested Upper Merged Ontology.\nSVD . Singular Value Decomposition.\nA. Acr\u00b4 onimos 245\nSVM . Support Vector Machines.\nTA. Traducci\u00b4 on autom\u00b4 atica.\nTOEFL . Test of English as a Foreign Language.\nTREC . Text Retrieval Conference.\nWDD . Word Domain Disambiguation.\nWePS . Web People Search.\nWND . WordNet Domains.\nWSD . Word Sense Disambiguation.\nWSD\nMAX\nENT . Sistema de desambiguaci\u00b4 on autom\u00b4 atica ba-\nsado en modelos de probabilidad de m\u00b4 axima entrop\u00b4 \u0131a.\nBibliograf\u00b4 \u0131a\nAbney, Steven P. (2002). ( (Bootstrapping ) ), en ACL, p\u00b4 ags.\n360\u2013367.\nAbney, Steven P. (2004). ( (Understanding the yarowsky algo-\nrithm) ),Computational Linguistics ,30(3), 365\u2013395.\nACL , editor (2001). Proceedings of the SENSEVAL-2: Second\nInternational Workshop on Evaluating Word Sense Disambigua-\ntion Systems .\nACL , editor (2004). Proceedings of the SENSEVAL-3: Third In-\nternational Workshop on the Evaluation of Systems for the Se-\nmantic Analysis of Text .\nACL , editor (2007). Proceedings of the SEMEVAL-2007: Fourth\nInternatinal Workshop on Semantic Evaluations .\nAgirre, E. yD. Mart \u0013\u0010nez (2000). ( (Exploring automatic word\nsense disambiguation with decision lists and the Web ) ), enPro-\nceedings of the Semantic Annotation And Intelligent Annotation\nworkshop organized by COLING , Luxembourg.\nAgirre, Eneko ,Itziar Aldabe ,Mikel Lersundi ,David\nMart \u0013\u0010nez,Eli Pociello yLarraitz Uria (2004). ( (The bas-\nque lexical-sample task ) ), en Rada Mihalcea y Phil Edmonds,\neditores, Senseval-3: Third International Workshop on the Eva-\nluation of Systems for the Semantic Analysis of Text , p\u00b4 ags. 1\u20134,\nAssociation for Computational Linguistics, Barcelona, Spain.\n248 BIBLIOGRAF \u00b4IA\nAgirre, Eneko ,Bernardo Magnini ,Oier Lopez de La-\ncalle ,Arantxa Otegi ,German Rigau yPiek Vossen\n(2007). ( (Semeval-2007 task 01: Evaluating wsd on cross-language\ninformation retrieval ) ), enProceedings of the Fourth Internatio-\nnal Workshop on Semantic Evaluations (SemEval-2007) , p\u00b4 ags.\n1\u20136, Association for Computational Linguistics, Prague, Czech\nRepublic.\nAgirre, Eneko yDavid Martinez (2001). ( (Learning class-\nto-class selectional preferences ) ), en Proceedings of the Works-\nhop C \u00b8omputational Natural Language Learning\u201d(CoNLL-2001).\nIn conjunction with ACL\u20192001/EACL\u20192001 , Toulouse, France.\nAgirre, Eneko yGerman Rigau (1996). ( (Word Sense Di-\nsambiguation using Conceptual Density ) ), en Proceedings of\nthe 16th International Conference on Computational Linguistic\n(COLING\u00b496) , Copenhagen, Denmark.\nAgirre, Eneko yAitor Soroa (2007). ( (Semeval-2007 task\n02: Evaluating word sense induction and discrimination sys-\ntems) ), enProceedings of the Fourth International Workshop on\nSemantic Evaluations (SemEval-2007) , p\u00b4 ags. 7\u201312, Association\nfor Computational Linguistics, Prague, Czech Republic.\nAkhmatova, E. (2005). ( (Textual entailment resolution via ato-\nmic propositions ) ), en Proceedings of the PASCAL Challenges\nWorkshop on Recognising Textual Entailment, 2005. , p\u00b4 ags. 61\u2013\n64.\nAllen, James F. (1984). ( (Towards a general theory of action\nand time ) ),Artif. Intell. ,23(2), 123\u2013154.\nAndreevska, A. ,Z. Li yS. Bergler (2005). ( (Can shallow\npredicate argument structure determine entailment? ) ), en Pro-\nceedings of the PASCAL Challenges Workshop on Recognising\nTextual Entailment, 2005. , p\u00b4 ags. 45\u201348.\nArtiles, Javier ,Julio Gonzalo ySatoshi Sekine (2007).\n( (The semeval-2007 weps evaluation: Establishing a benchmark\nfor the web people search task ) ), enProceedings of the Fourth In-\nternational Workshop on Semantic Evaluations (SemEval-2007) ,\np\u00b4 ags. 64\u201369, Association for Computational Linguistics, Prague,\nCzech Republic.\nBIBLIOGRAF \u00b4IA 249\nAtkins, Sue (1992). ( (Tools for computer-aided corpus lexico-\ngraphy: the hector project ) ), p\u00b4 ags. 1\u201360.\nAtserias, J. ,J. Carmona ,I. Castell \u0013on,S. Cerve-\nll,M. Civit ,L. M \u0012arquez ,M.A. Mart \u0013\u0010,L. Padr \u0013o,\nR. Placer ,H. Rodr \u0013\u0010guez ,M. Taul \u0013eyJ. Turmo (1998).\n( (Morphosyntactic Analysis and Parsing of Unrestricted Spanish\nText) ), enProceedings of First International Conference on Lan-\nguage Resources and Evaluation (LREC\u201998) , Granada, Spain.\nBaker, Collin ,Michael Ellsworth yKatrin Erk\n(2007). ( (Semeval-2007 task 19: Frame semantic structure extrac-\ntion) ), enProceedings of the Fourth International Workshop on\nSemantic Evaluations (SemEval-2007) , p\u00b4 ags. 99\u2013104, Associa-\ntion for Computational Linguistics, Prague, Czech Republic.\nBanerjee, Satanjeev yTed Pedersen (2002). ( (An adapted\nlesk algorithm for word sense disambiguation using wordnet. ) ), en\nCICLing , p\u00b4 ags. 136\u2013145.\nBarzilay, Regina yKathleen McKeown (2001).\n( (Extracting paraphrases from a parallel corpus ) ), en ACL,\np\u00b4 ags. 50\u201357.\nBarzilay, Regina yKathleen McKeown (2003).\n( (Learning to paraphrase: An unsupervised approach using\nmultiple-sequence alignment ) ), enHTLT-NAACL , p\u00b4 ags. 16\u201323.\nBloehdorn, Stephan yAndreas Hotho (2004). ( (Text clas-\nsi\ufb01cation by boosting weak learners based on terms and con-\ncepts.) ), enICDM , p\u00b4 ags. 331\u2013334.\nBlum, Avrim yTom M. Mitchell (1998). ( (Combining labe-\nled and unlabeled sata with co-training ) ), enCOLT , p\u00b4 ags. 92\u2013100.\nBoguraev, B. yT. Briscoe (1989). Computational lexico-\ngraphy for Natural Language Processing , Longman, London and\nNew York.\nBrill, E. (1995). ( (Transformation-based error-driven learning\nand natural language processing: A case study in part of speech\ntagging ) ),Computational Linguistics ,21(4), 543\u2013565.\nBrockmann, Carsten yMirella Lapata (2003).\n( (Evaluating and combining approaches to selectional pre-\nference acquisition ) ), enEACL , p\u00b4 ags. 27\u201334.\n250 BIBLIOGRAF \u00b4IA\nBrown, Peter F. ,Stephen A. Della Pietra yVincent\nJ. Della Pietra (1991). ( (Word sense Disambiguation using\nstatistical methods ) ), enProceedings of 29th Annual Meeting of\nthe Association for Computational Linguistics , p\u00b4 ags. 264\u2013270.\nCalzolari, Nicoletta ,Ornella Corazzari yAntonio\nZampolli (2001). ( (Lexical-semantic tagging of an italian cor-\npus) ), enCICLing , p\u00b4 ags. 291\u2013304.\nCederberg, Scott yDominic Widdows (2003). ( (Using lsa\nand noun coordination information to improve the precision and\nrecall of automatic hyponymy extraction ) ), enIn Proceedings of\nCoNLL , p\u00b4 ags. 111\u2013118.\nChklovski, Timothy yRada Mihalcea (2002). ( (Building a\nsense tagged corpus with open mind word expert ) ), enProceedings\nof the ACL-02 workshop on Word sense disambiguation , p\u00b4 ags.\n116\u2013122, Association for Computational Linguistics, Morristown,\nNJ, USA.\nChklovski, Timothy ,Rada Mihalcea ,Ted Pedersen\nyAmruta Purandare (2004). ( (The senseval-3 multilingual\nenglishhindi lexical sample task ) ), en Rada Mihalcea y Phil Ed-\nmonds, editores, Senseval-3: Third International Workshop on\nthe Evaluation of Systems for the Semantic Analysis of Text ,\np\u00b4 ags. 5\u20138, Association for Computational Linguistics, Barcelo-\nna, Spain.\nChurch, Kenneth ,William Gale ,Patrick Hanks yDo-\nnald Hindle (1991). ( (Using statistics in lexical analysis ) ), en\nUri Zernik, editor, Lexical acquisition , p\u00b4 ags. 115\u2013164, Erlbaum.\nChurch, Kenneth Ward yPatrick Hanks (1990). ( (Word\nassociation norms, mutual information, and lexicography ) ),Com-\nputational Linguistics ,16(1), 22\u201329.\nCiaramita, Massimiliano yMark Johnson (2000).\n( (Explaining away ambiguity: Learning verb selectional preferen-\nce with bayesian networks ) ), enCOLING , p\u00b4 ags. 187\u2013193.\nCivit, Montse (2003). ( (Criterios de etiquetaci\u00b4 on y desambi-\nguaci\u00b4 on morfosint\u00b4 actica de corpus en espa\u02dc nol ) ), Tesis Doctoral.\nUniversidad de Barcelona.\nClough, Paul yMark Stevenson (2004). ( (Cross-language\ninformation retrieval using eurowordnet and word sense disam-\nBIBLIOGRAF \u00b4IA 251\nbiguation. ) ), enECIR , p\u00b4 ags. 327\u2013337.\nCohen, Jacob (1960). ( (A coe\ufb03cient of agreement for nominal\nscales) ),Educational and Psychological Measurement ,20(1), 37\u2013\n46.\nConnine, Cynthia (1990). ( (E\ufb00ects of sentence context and\nlexical knowledge in speech processing ) ), p\u00b4 ags. 281\u2013294.\nCorazzari, Ornella yAntonietta Alonge (2001).\n( (Italwordnet: extending and exploiting an existing resource for\ncomputational tasks ) ), .\nCorley, Courtney yRada Mihalcea (2005). ( (Measures of\ntext semantic similarity ) ), enACL workshop on Empirical Mode-\nling of Semantic Equivalence .\nCover, Thomas M. yJoy A. Thomas (1991). Elements of\ninformation theory , Wiley-Interscience, New York, NY, USA.\nCowie, Jim ,Joe Guthrie yLouise Guthrie (1992).\n( (Lexical disambiguation using simulated annealing ) ), enProcee-\ndings of the 14th International Conference on Computational\nLinguistic, COLING\u00b492 , p\u00b4 ags. 359\u2013365, Nantes, France.\nCuadros, Montse yGerman Rigau (2007). ( (Semeval-2007\ntask 16: Evaluation of wide coverage knowledge resources ) ), en\nProceedings of the Fourth International Workshop on Semantic\nEvaluations (SemEval-2007) , p\u00b4 ags. 81\u201386, Association for Com-\nputational Linguistics, Prague, Czech Republic.\nCunningham, H. (2002). ( (GATE, a General Architecture for\nText Engineering ) ),Computers and the Humanities ,36, 223\u2013254.\nCunningham, H. (2005). ( (Information Extraction, Automa-\ntic) ),Encyclopedia of Language and Linguistics, 2nd Edition .\nD., Harman (1995). ( (Overview of the 3rd text retrieval confe-\nrence (trec-3) ) ), National Institute of Standards and Technology\n(NIST) Special Publication 500-225, US.\nD., Harman (1996). ( (Overview of the 3rd text retrieval confe-\nrence (trec-4) ) ), National Institute of Standards and Technology\n(NIST) Special Publication 500-236, US.\nDagan, I. ,A. Itai yU. Schwall (1991). ( (Two languages are\nmore informative than one ) ),Proceedings of the Annual Meeting\nof the Association for Computational Linguistics , p\u00b4 ags. 130\u2013137.\n252 BIBLIOGRAF \u00b4IA\nDagan, Ido ,Oren Glickman yBernardo Magnini (2005).\n( (The pascal recognising textual entailment challenge. ) ), enPro-\nceedings of the PASCAL Challenges Workshop on Recognising\nTextual Entailment .\nDagan, Ido ,Lillian Lee yFernando C. ~N. Pereira\n(1997). ( (Similarity-based methods for word sense disambigua-\ntion) ),CoRR ,cmp-lg/9708010 .\nDagan, Ido ,Lillian Lee yFernando C. ~N. Pereira\n(1999). ( (Similarity-based models of word cooccurrence proba-\nbilities ) ),Machine Learning ,34(1-3), 43\u201369.\nDagan, Ido ,Shaul Marcus yShaul Markovitch (1993).\n( (Contextual word similarity and estimation from sparse data ) ),\nenIn Proceedings of the 31st Annual Meeting of the Association\nfor Computational Linguistics , p\u00b4 ags. 164\u2013171.\nDagan, Ido ,Fernando C. ~N. Pereira yLillian Lee\n(1994). ( (Similarity-based estimation of word cooccurrence pro-\nbabilities ) ), enACL, p\u00b4 ags. 272\u2013278.\nDeerwester, Scott C. ,Susan T. Dumais ,Thomas K.\nLandauer ,George W. Furnas yRichard A. Harshman\n(1990). ( (Indexing by latent semantic analysis ) ),JASIS ,41(6),\n391\u2013407.\nDiab, Mona ,Musa Alkhalifa ,Sabry ElKateb ,Chris-\ntiane Fellbaum ,Aous Mansouri yMartha Palmer\n(2007). ( (Semeval-2007 task 18: Arabic semantic labeling ) ), en\nProceedings of the Fourth International Workshop on Semantic\nEvaluations (SemEval-2007) , p\u00b4 ags. 93\u201398, Association for Com-\nputational Linguistics, Prague, Czech Republic.\nDill, Stephen ,Nadav Eiron ,David Gibson ,Daniel\nGruhl ,Ramanathan V. Guha ,Anant Jhingran ,Ta-\npas Kanungo ,Sridhar Rajagopalan ,Andrew Tomkins ,\nJohn A. Tomlin yJason Y. Zien (2003). ( (Semtag and seeker:\nbootstrapping the semantic web via automated semantic anno-\ntation. ) ), enWWW , p\u00b4 ags. 178\u2013186.\nDolan, Bill ,Chris Quirk yChris Brockett (2004).\n( (Unsupervised construction of large paraphrase corpora: Exploi-\nting massively parallel news sources ) ), enProceedings of the 20th\nBIBLIOGRAF \u00b4IA 253\nInternational Conference on Computational Linguistics , Geneva,\nSwitzerland.\nDuda, Richard ,Peter Hart yDavid Stork (2001).\n( (Pattern classi\ufb01cation ) ), Segunda Edici\u00b4 on. Nueva York: John Wi-\nley & Sons.\nEdmonds, Philip yAdam Kilgarriff (1998). ( (Introduction\nto the special issue on evaluating word sense disambiguation sys-\ntems.) ), enJournal of Natural Language Engineering .\nEscudero, G. ,L. M\u0013arquez yG. Rigau (2000). ( (Naive Bayes\nand Exemplar-Based approaches to Word Sense Disambiguation\nRevisited ) ), enProceedings of the 14th European Conference on\nArti\ufb01cial Intelligence, ECAI-2000 , Berlin, Germany.\nEveritt, B. S. (1977). The analysis of contingency tables ,\nChapman and Hall.\nFellbaum, Christiane (1998). WordNet: An Electronic Lexi-\ncal Database , The MIT Press.\nFirth, J. R. (1957). ( (A synopsis of linguistic theory. studies\nin linguistic analysis ) ), en Special Volume, Philological Society ,\np\u00b4 ags. 1\u201332.\nFrakes, William B. yRicardo A. Baeza-Yates , edito-\nres (1992). Information Retrieval: Data Structures & Algorithms ,\nPrentice-Hall.\nFramis, Francesc Ribas (1994). ( (An experiment on learning\nappropriate selectional restrictions from a parsed corpus ) ), en\nCOLING , p\u00b4 ags. 769\u2013774.\nFrancis, W. ~N.yH. Kucera (1979). ( (Brown corpus manual ) ),\ninf. t\u00b4 ec. , Department of Linguistics, Brown University, Providen-\nce, Rhode Island, US.\nFurnas, George W. ,Scott C. Deerwester ,Susan T.\nDumais ,Thomas K. Landauer ,Richard A. Harsh-\nman,Lynn A. Streeter yKaren E. Lochbaum (1988).\n( (Information retrieval using a singular value decomposition mo-\ndel of latent semantic structure ) ), enSIGIR , p\u00b4 ags. 465\u2013480.\nG. Miller, T. Randee, C. Leacock yR. Bunker (1993).\n( (A Semantic Concordance ) ), en Proceeding of 3rd DARPA\nWorkshop on Human Language Tecnology , p\u00b4 ags. 303\u2013308, Plains-\nboro, New Jersey.\n254 BIBLIOGRAF \u00b4IA\nGale, W. ,K. Church yD. Yarowsky (1992a). ( (Estimating\nupper and lower bounds on the performance or word-sense disam-\nbiguation programs ) ), enProceedings of the 30th Annual Meeting\nof the Association for Computational Linguistic .\nGale, William ,Kenneth Church yDavid Yarowsky\n(1992b). ( (A method for disambiguating word senses in a large\ncorpus ) ),Computers and the Humanities ,26, 415\u2013439.\nGan, Kok Wee yPing Wai Wong (2000). ( (Annotating infor-\nmation structures in chinese texts using hownet ) ), enProceedings\nof the second workshop on Chinese language processing , p\u00b4 ags.\n85\u201392, Association for Computational Linguistics, Morristown,\nNJ, USA.\nGarc \u0013\u0010a, Manuel (2006). ( (Resoluci\u00b4 on de la ambig\u00a8 uedad l\u00b4 exica\nmediante aprendizaje por cuanti\ufb01caci\u00b4 on vectorial ) ), Tesis Docto-\nral. Departamento de Inform\u00b4 atica. Universidad de Ja\u00b4 en.\nGenesereth, Michael R. (1991). ( (Knowledge interchange\nformat ) ), enKR, p\u00b4 ags. 599\u2013600.\nGildea, Daniel yDaniel Jurafsky (2002). ( (Automatic la-\nbeling of semantic roles ) ),Computational Linguistics ,28(3), 245\u2013\n288.\nGirju, Roxana ,Preslav Nakov ,Vivi Nastase ,Stan Sz-\npakowicz ,Peter Turney yDeniz Yuret (2007). ( (Semeval-\n2007 task 04: Classi\ufb01cation of semantic relations between nomi-\nnals) ), enProceedings of the Fourth International Workshop on\nSemantic Evaluations (SemEval-2007) , p\u00b4 ags. 13\u201318, Association\nfor Computational Linguistics, Prague, Czech Republic.\nGolding, A. R. (1995). ( (A bayesian-hybrid method for\ncontext-sensitive spelling correction ) ), In Proceedings of the 3rd\nWorkshop on Very Large Corpora, ACL.\nGonzalo, Julio yDouglas W. Oard (2004). ( (iclef 2004\ntrack overview: Pilot experiments in interactive cross-language\nquestion answering ) ), enCLEF , p\u00b4 ags. 310\u2013322.\nGraesser, Arthur ,Danielle McNamara ,Max Louwer-\nseyZhiqiang Cai (2004). ( (Coh-metrix: Analysis of text on\ncohesion and language. ) ),36(2), 193\u2013202.\nGroup, CORPORATE PDP Research (1986). Parallel dis-\ntributed processing: explorations in the microstructure of cogni-\nBIBLIOGRAF \u00b4IA 255\ntion, vol. 2: psychological and biological models , MIT Press, Cam-\nbridge, MA, USA.\nGrozea, Cristian (2004). ( (Finding optimal parameter set-\ntings for high performance word sense disambiguation ) ), en Rada\nMihalcea y Phil Edmonds, editores, Senseval-3: Third Interna-\ntional Workshop on the Evaluation of Systems for the Semantic\nAnalysis of Text , p\u00b4 ags. 125\u2013128, Association for Computational\nLinguistics, Barcelona, Spain.\nHaley, Debra Trusso ,Pete Thomas ,Anne De Roeck y\nMarian Petre (2005). ( (A research taxonomy for latent seman-\ntic analysis-based educational applications ) ), en In Proceedings\nof the International Conference on Recent Advances in Natural\nLanguage Processing , p\u00b4 ags. 21\u201323.\nHalliday, Michael yRuqaiya Hasan (1976). ( (Cohesion in\nEnglish ) ),London:Longman .\nHarabagiu, Sanda M. ,George A. Miller yDan I. Mol-\ndovan (1999). ( (Wordnet 2 - a morphologically and semantically\nenhanced resource ) ), enSIGLEX .\nHarris, Zellig (1968). ( (Mathematical structures of language ) ),\nenNew York: Interscience Publishers John Wiley & Sons .\nHawkins, Paul yDavid Nettleton (2000). ( (Large scale wsd\nusing learning applied to senseval ) ), enComputers and the Hu-\nmanities , vol. 34, p\u00b4 ags. 135\u2013140.\nHerrera, J. ,A. Pe ~nasyF. Verdejo. (2005). ( (Textual en-\ntailment recognition based on dependency analysis and word-\nnet.) ), enProceedings of the PASCAL Challenges Workshop on\nRecognising Textual Entailment,2005.\nHirst, Graeme yDavid St-Onge (1998). ( (Lexical chains\nas representations of context in the detection and correction of\nmalaproprisms ) ),In WordNet: An electronic lexical database, ed.\nby Christiane Fellbaum , p\u00b4 ags. 305\u2013332.\nHLT1 (1993). ( (Proceedings of the arpa workshop on human lan-\nguage technology ) ), Morgan Kaufmann, San Mateo, CA.\nJaccard, P. (1901). ( (\u00b4Etude comparative de la distribution \ufb02o-\nrale dans une portion des alpes et des jura ) ),Bull Soc Vaudoise\nSci Nat ,37, 547\u2013579.\n256 BIBLIOGRAF \u00b4IA\nJiang, Jay J. yDavid W. Conrath (1997). ( (Semantic simi-\nlarity based on corpus statistics and lexical taxonomy ) ),CoRR ,\ncmp-lg/9709008 .\nJin, Peng ,Yunfang Wu yShiwen Yu (2007). ( (Semeval-\n2007 task 05: Multilingual chinese-english lexical sample ) ), en\nProceedings of the Fourth International Workshop on Semantic\nEvaluations (SemEval-2007) , p\u00b4 ags. 19\u201323, Association for Com-\nputational Linguistics, Prague, Czech Republic.\nJing, Hongyan yEvelyne Tzoukermann (1999).\n( (Information retrieval based on context distance and morp-\nhology ) ), en SIGIR \u201999: Proceedings of the 22nd annual\ninternational ACM SIGIR conference on Research and develop-\nment in information retrieval , p\u00b4 ags. 90\u201396, ACM Press, New\nYork, NY, USA.\nKilgariff, A. (2001). ( (English lexical sample task descrip-\ntion) ),Proceedings of Senseval-2: Second International Workshop\non Evaluating Word Sense Disambiguaion Systems. , p\u00b4 ags. 17\u201320.\nKilgarriff, A. (1998a). ( (Gold standard for evaluating word\nsense disambiguation programs ) ),Computer Speech and Langua-\nge, Special Issue on evaluation ,12(3).\nKilgarriff, A. (1998b). ( (Senseval: An exercise in evaluating\nword sense disambiguation programs ) ), enLREC, Granada, May\n1998, p\u00b4 ags. 581\u2013588.\nKilgarriff, A. yM. Palmer (2000). ( (Introduction to the\nSpecial Issue on SENSEVAL ) ),Computers and the Humanities ,\n34(1/2) (1-13).\nKilgarriff, A. yJ Rosenzweig (2000). ( (Framework and re-\nsults for english Senseval ) ),Computers and the Humanities ,\n34(1-2).\nKohonen, T. (1989). Self-organization and associative memory:\n3rd edition , Springer-Verlag New York, Inc., New York, NY,\nUSA.\nKozareva, Zornitsa yAndr \u0013es Montoyo (2006). ( (Mlent:\nThe machine learning entailment system of the university of ali-\ncante) ), enIn Proceedings of the PASCAL Challenges Workshop\non Recognising Textual Entailment .\nBIBLIOGRAF \u00b4IA 257\nKozareva, Zornitsa ,Sonia V \u0013azquez yAndr \u0013es Monto-\nyo(2006). ( (Adaptation of a machine learning textual entailment\nsystem to a multilingual answer validation exercise ) ), enIn Wor-\nking Notes of CLEF 2006 .\nKozareva, Zornitsa ,Sonia V \u0013azquez yAndr \u0013es Monto-\nyo(2007). ( (The usefulness of conceptual representation for the\nidenti\ufb01cation of semantic variability expressions ) ), enCICLing ,\np\u00b4 ags. 325\u2013336.\nKrovets, R. (1997). ( (Homonymy and polysemy in information\nretrival ) ), enProceedings of the 35th Annual Meeting of the Asso-\nciation for Computational Linguistic and 8th Conference of the\nEuropean Chapter of the Association for Computational Linguis-\ntic, p\u00b4 ags. 72\u201379, Madrid, Spain.\nKrovets, R. yW. Bruce Croft (1992). ( (Lexical ambiguity\nand information retrieval ) ),ACM ,10(2), 115\u2013141.\nKrovetz, Robert (1998). ( (More than one sense per discour-\nse) ), enProceedings of SENSEVAL Workshop .\nLandauer, Thomas K. ySusan T. Dumais (1997). ( (A so-\nlution to plato\u2019s problem: The latent semantic analysis theory\nof acquisition, induction and representation of knowledge ) ), en\nPsychological Review , p\u00b4 ags. 211\u2013240.\nLandis, J. R. yG. G. Koch (1977). ( (The measurement of ob-\nserver agreement for categorical data. ) ),Biometrics ,33(1), 159\u2013\n174.\nLeacock, Claudia ,Martin Chodorow yGeorge A. Mi-\nller (1998). ( (Using Corpus Statistics and WordNet Relations\nfor Sense Identi\ufb01cation ) ),Computational Linguistics ,24(1), 147\u2013\n165.\nLee, Lillian (1997). ( (Similarity-based approaches to natural\nlanguage processing ) ),CoRR ,cmp-lg/9708011 .\nLee, Lillian (1999). ( (Measures of distributional similarity ) ), en\nACL.\nLesk, Michael (1986). ( (Automated sense disambiguation\nusing machine-readable dictionaries: How to tell a pine cone\nfrom an ice cream cone ) ), enProceedings of the 1986 SIGDOC\nConference, Association for Computing Machinery , p\u00b4 ags. 24\u201326,\nToronto, Canada.\n258 BIBLIOGRAF \u00b4IA\nLewis, D. yM. Ringuette (1994). ( (A comparison of two lear-\nning algorithms for text categorization ) ), In Proceedings of the\n3rd Annual Symposium on Document Analysis and Information\nRetrieval.\nLin, Dekang (1997). ( (Using syntactic dependency as local con-\ntext to resolve word sense ambiguity ) ), enProceedings of the 35th\nAnnual Meeting of the Association for Computational Linguistic\nand the 8th Conference of the European Chapter of the Associa-\ntion for Computational Linguistics , p\u00b4 ags. 64\u201371.\nLin, Dekang (1998a). ( (Automatic retrieval and clustering of\nsimilar words ) ), enCOLING-ACL , p\u00b4 ags. 768\u2013774.\nLin, Dekang (1998b). ( (An information-theoretic de\ufb01nition of\nsimilarity. ) ), enICML , p\u00b4 ags. 296\u2013304.\nLin, Dekang yPatrick Pantel (2001). ( (Discovery of inferen-\nce rules for question answering ) ),Natural Language Engineering ,\n7, 343\u2013360.\nLin, Jianhua (1991). ( (Divergence measures based on the shan-\nnon entropy ) ),IEEE Transactions on Information Theory ,37(1),\n145\u2013.\nLitkowski, Ken (2004a). ( (Senseval-3 task: Automatic labeling\nof semantic roles ) ), en Rada Mihalcea y Phil Edmonds, editores,\nSenseval-3: Third International Workshop on the Evaluation of\nSystems for the Semantic Analysis of Text , p\u00b4 ags. 9\u201312, Associa-\ntion for Computational Linguistics, Barcelona, Spain.\nLitkowski, Ken (2004b). ( (Senseval-3 task: Word sense disam-\nbiguation of wordnet glosses ) ), en Rada Mihalcea y Phil Ed-\nmonds, editores, Senseval-3: Third International Workshop on\nthe Evaluation of Systems for the Semantic Analysis of Text ,\np\u00b4 ags. 13\u201316, Association for Computational Linguistics, Barce-\nlona, Spain.\nLitkowski, Kenneth C. yOrin Hargraves (2007).\n( (Semeval-2007 task 06: Word-sense disambiguation of preposi-\ntions) ), enProceedings of the Fourth International Workshop on\nSemantic Evaluations (SemEval-2007) , p\u00b4 ags. 24\u201329, Association\nfor Computational Linguistics, Prague, Czech Republic.\nLlopis, Fernando (2003). ( (Ir-n: Un sistema de recuperaci\u00b4 on\nde informaci\u00b4 on basado en pasajes ) ), Tesis Doctoral. Departamen-\nBIBLIOGRAF \u00b4IA 259\nto de Lenguajes y Sistemas Inform\u00b4 aticos, Universidad de Alican-\nte.\nLuk, A. (1995). ( (Statistical sense disambiguation with relatively\nsmall corpora using dictionary de\ufb01nitions ) ),Proceedings of the\n33rd Meetings of the Association for Computational Linguistics\n(ACL-95). Cambridge, M.A., 1995 , p\u00b4 ags. 181\u2013188.\nMagnini, B. yG. Cavaglia (2000). ( (Integrating subject \ufb01eld\ncodes into WordNet ) ), enProceedings of Third International Con-\nference on Language Resources and Evaluation (LREC-2000) .\nMagnini, Bernardo ,Danilo Giampiccolo yAlessandro\nVallin (2004). ( (The italian lexical sample task at senseval-3 ) ),\nen Rada Mihalcea y Phil Edmonds, editores, Senseval-3: Third\nInternational Workshop on the Evaluation of Systems for the\nSemantic Analysis of Text , p\u00b4 ags. 17\u201320, Association for Compu-\ntational Linguistics, Barcelona, Spain.\nMagnini, Bernardo yC. Strapparava (2000).\n( (Experiments in Word Domain Disambiguation for Para-\nllel Texts ) ), en Proceedings of the ACL Workshop on Word\nSenses and Multilinguality , Hong Kong, China.\nMann, Gideon S. (2006). ( (Multi-document statistical fact ex-\ntraction and fusion ) ), Ph.D. Thesis.\nManning, C. D. yH. Sch \u007futze (1999). Foundations of Statis-\ntical Natural Language Processing , The MIT Press, Cambridge,\nMassachusetts.\nMarkert, Katja yMalvina Nissim (2007). ( (Semeval-2007\ntask 08: Metonymy resolution at semeval-2007 ) ), enProceedings\nof the Fourth International Workshop on Semantic Evaluations\n(SemEval-2007) , p\u00b4 ags. 36\u201341, Association for Computational\nLinguistics, Prague, Czech Republic.\nMarkov, A. (1971). ( (Extension of the limit theorems of pro-\nbability theory to a sum of variables connected in a chain ) ), en\nDynamic Probabilistic Systems, volume 1: Markov Chains.\nM\u0012arquez, Lluis ,Mariona Taul \u0013e,Antonia Mart \u0013\u0010,N\u0013uria\nArtigas ,Mar Garc \u0013\u0010a,Francis Real yDani Ferr \u0013es\n(2004a). ( (Senseval-3: The spanish lexical sample task ) ), en Rada\nMihalcea y Phil Edmonds, editores, Senseval-3: Third Interna-\ntional Workshop on the Evaluation of Systems for the Semantic\n260 BIBLIOGRAF \u00b4IA\nAnalysis of Text , p\u00b4 ags. 21\u201324, Association for Computational\nLinguistics, Barcelona, Spain.\nM\u0012arquez, Lluis ,Mariona Taul \u0013e,Antonia Mart \u0013\u0010,Mar\nGarc \u0013\u0010a,Francis Real yDani Ferr \u0013es(2004b). ( (Senseval-3:\nThe catalan lexical sample task ) ), en Rada Mihalcea y Phil Ed-\nmonds, editores, Senseval-3: Third International Workshop on\nthe Evaluation of Systems for the Semantic Analysis of Text ,\np\u00b4 ags. 147\u2013150, Association for Computational Linguistics, Bar-\ncelona, Spain.\nM\u0012arquez, Llu \u0013\u0010s,Lluis Villarejo ,M. A. Mart \u0013\u0010yMa-\nriona Taul \u0013e(2007). ( (Semeval-2007 task 09: Multilevel se-\nmantic annotation of catalan and spanish ) ), en Proceedings of\nthe Fourth International Workshop on Semantic Evaluations\n(SemEval-2007) , p\u00b4 ags. 42\u201347, Association for Computational\nLinguistics, Prague, Czech Republic.\nMart \u0013\u0010nez, David ,Eneko Agirre yLlu\u0013\u0010s M\u0012arquez (2002).\n( (Syntactic features for high precision word sense disambigua-\ntion) ), enCOLING .\nMart \u0013\u0010nez, D. yE. Agirre (2000). ( (One sense per collocation\nand genre/topic variations ) ), enProceedings of the Joint SIGDAT\nConference on Empirical Methods in Natural Language Proces-\nsing and Very Large Corpora , Hong Kong.\nMart \u0013\u0010nez, David (2004). ( (Supervised word sense disambigua-\ntion: facing current challenges ) ), Tesis Doctoral. Departamento\nde Lenguajes y Sisteams Inform\u00b4 aticos. Universidad del Pa\u00b4 \u0131s Vas-\nco.\nMcCarthy, Diana ,Rob Koeling ,Julie Weeds yJohn A.\nCarroll (2004). ( (Finding predominant word senses in untag-\nged text. ) ), enACL, p\u00b4 ags. 279\u2013286.\nMcCarthy, Diana yRoberto Navigli (2007). ( (Semeval-\n2007 task 10: English lexical substitution task ) ), enProceedings\nof the Fourth International Workshop on Semantic Evaluations\n(SemEval-2007) , p\u00b4 ags. 48\u201353, Association for Computational\nLinguistics, Prague, Czech Republic.\nMcRoy, Susan (1992). ( (Using multiple knowledge sources for\nword sense discrimination ) ),Computational Linguistics ,18(1),\n1\u201330.\nBIBLIOGRAF \u00b4IA 261\nMelamed, I. Dan yPhilip Resnik (2000). ( (Tagger evaluation\ngiven hierarchical tag sets ) ),CoRR ,cs.CL/0008007 .\nMihalcea, Rada ,Timothy Chklovski yAdam Kil-\ngarriff (2004a). ( (The senseval-3 english lexical sample task ) ),\nen Rada Mihalcea y Phil Edmonds, editores, Senseval-3: Third\nInternational Workshop on the Evaluation of Systems for the\nSemantic Analysis of Text , p\u00b4 ags. 25\u201328, Association for Compu-\ntational Linguistics, Barcelona, Spain.\nMihalcea, Rada yDan Moldovan (1999). ( (A Method for\nword sense disambiguation of unrestricted text ) ), enProceedings\nof the 37th Annual Meeting of the Association for Computational\nLinguistic , p\u00b4 ags. 152\u2013158, Maryland, Usa.\nMihalcea, Rada yDan I. Moldovan (2001). ( (extended\nwordnet: Progress report ) ), enin Proceedings of NAACL Works-\nhop on WordNet and Other Lexical Resources , p\u00b4 ags. 95\u2013100.\nMihalcea, Rada ,Vivi N \u0015astase ,Timothy Chklovski ,\nDoina T \u0015atar ,Dan Tufis \u0018 yFlorentina Hristea (2004b).\n( (An evaluation exercise for romanian word sense disambigua-\ntion) ), en Rada Mihalcea y Phil Edmonds, editores, Senseval-3:\nThird International Workshop on the Evaluation of Systems for\nthe Semantic Analysis of Text , p\u00b4 ags. 29\u201332, Association for Com-\nputational Linguistics, Barcelona, Spain.\nMiller, George yWalter Charles (1991). ( (Contextual\ncorrelates of semantic similarity ) ), en Language and Cognitive\nProcesses , p\u00b4 ags. 1\u201328.\nMiller, George A. (1995). ( (Wordnet: A lexical database for\nenglish. ) ),Commun. ACM ,38(11), 39\u201341.\nMitchell, Tom M. (1997a). ( (Machine learning ) ), enMcGraw\nHill.\nMitchell, Tom M. (1997b). ( (Machine learning meets natural\nlanguage ) ), enEPIA , p\u00b4 ag. 391.\nMolina, Antonio ,Ferran Pla yEncarna Segarra\n(2002). ( (A hidden markov model approach to word sense di-\nsambiguation ) ), enIBERAMIA , p\u00b4 ags. 655\u2013663.\nMontoyo, Andr \u0013es(2002). ( (Desambiguaci\u00b4 on l\u00b4 exica mediante\nmarcas de especi\ufb01cidad ) ), Tesis Doctoral. Departamento de Len-\nguajes y Sistemas Inform\u00b4 aticos. Universidad de Alicante.\n262 BIBLIOGRAF \u00b4IA\nMontoyo, Andr \u0013es,Sonia V \u0013azquez yGerman Rigau\n(2003). ( (M\u00b4 etodo de desambiguaci\u00b4 on l\u00b4 exica basada en el recurso\nl\u00b4 exico Dominios Relevantes ) ),Procesamiento del Lenguaje Natu-\nral,31, 141\u2013148.\nMooney, Raymond (1996). ( (Comparative experiments on di-\nsambiguating word sense: An illustration of the role of bias in\nmachine learning ) ), enProceedings of the 1st Conference on Em-\npirical Methods in Natural Language Processing , p\u00b4 ags. 82\u201391.\nMUC (1995). ( (Proceedings of the 6th message understanding\nconference (muc-6) ) ), Morgan Kaufmann, San Mateo, CA.\nMUC (1998). ( (Proceedings of the 7th message understanding\nconference (muc-7) ) ), Morgan Kaufmann, San Mateo, CA.\nNavarro, Borja ,Lorenza Moreno ,Sonia V \u0013azquez ,\nFernando Llopis ,Andr \u0013es Montoyo yMiguel Angel\nVar\u0013o(2004). ( (Improving interaction with the user in cross-\nlanguage question answering through relevant domains and syn-\ntactic semantic patterns ) ), enCLEF , p\u00b4 ags. 334\u2013342.\nNavigli, Roberto ,Kenneth C. Litkowski yOrin Har-\ngraves (2007). ( (Semeval-2007 task 07: Coarse-grained english\nall-words task ) ), en Proceedings of the Fourth International\nWorkshop on Semantic Evaluations (SemEval-2007) , p\u00b4 ags. 30\u2013\n35, Association for Computational Linguistics, Prague, Czech\nRepublic.\nNg, Hwee Tou yYee Seng Chan (2007). ( (Semeval-2007\ntask 11: English lexical sample task via english-chinese parallel\ntext) ), enProceedings of the Fourth International Workshop on\nSemantic Evaluations (SemEval-2007) , p\u00b4 ags. 54\u201358, Association\nfor Computational Linguistics, Prague, Czech Republic.\nNigam, Kamal yRayid Ghani (2000). ( (Analyzing the e\ufb00ec-\ntiveness and applicability of co-training ) ), enCIKM , p\u00b4 ags. 86\u201393.\nNiles, Ian yAdam Pease (2001). ( (Towards a standard upper\nontology ) ), enFOIS , p\u00b4 ags. 2\u20139.\nNiles, Ian yAdam Pease (2003). ( (Linking lexicons and on-\ntologies: Mapping wordnet to the suggested upper merged onto-\nlogy) ), enIKE, p\u00b4 ags. 412\u2013416.\nOrhan, Zeynep ,Emine C \u0018elik yDemirg \u007fuc \u0018 Neslihan\n(2007). ( (Semeval-2007 task 12: Turkish lexical sample task ) ), en\nBIBLIOGRAF \u00b4IA 263\nProceedings of the Fourth International Workshop on Semantic\nEvaluations (SemEval-2007) , p\u00b4 ags. 59\u201363, Association for Com-\nputational Linguistics, Prague, Czech Republic.\nPantel, Patrick yDekang Lin (2002). ( (Document cluste-\nring with committees ) ), enSIGIR , p\u00b4 ags. 199\u2013206.\nPatwardhan, Siddharth ,Satanjeev Banerjee yTed Pe-\ndersen (2003). ( (Using measures of semantic relatedness for\nword sense disambiguation. ) ), enCICLing , p\u00b4 ags. 241\u2013257.\nPedersen, Ted (1997). ( (Naive mixes for word sense disambi-\nguation ) ), enAAAI/IAAI , p\u00b4 ag. 841.\nPedersen, Ted (2002). ( (Assessing system agreement and ins-\ntance di\ufb03culty in the lexical sample tasks of senseval-2 ) ),CoRR ,\ncs.CL/0205068 .\nPedersen, Ted yRebecca Bruce (1997). ( (Distinguishing\nword senses in untagged text ) ), enProceedings of the 2th Con-\nference on Empirical Methods in Natural Language Processing ,\np\u00b4 ags. 197\u2013207.\nPekar, V. yM. Krkoska (2003). ( (Weighting distributional\nfeatures for automatic semantic classi\ufb01cation of words ) ), enPro-\nceedings of the International Conference on Recent Advances in\nNatural Language Processing (RANLP-03) , p\u00b4 ags. 369\u2013373.\nPekar, Viktor ,Ruslan Mitkov ,Dimitar Blagoev yAn-\ndrea Mulloni (2006). ( (Finding translations for low-frequency\nwords in comparable corpora ) ),Machine Translation ,20(4), 247\u2013\n266.\nPe~nas, Anselmo ,\u0013Alvaro Rodrigo ,Valent \u0013\u0010n Sama yFe-\nlisa Verdejo (2006a). ( (Overview of the answer validation exer-\ncise 2006 ) ), enCLEF , p\u00b4 ags. 257\u2013264.\nPe~nas, Anselmo ,\u0013Alvaro Rodrigo yFelisa Verdejo\n(2006b). ( (Sparte, a test suite for recognising textual entailment\nin spanish ) ), enCICLing , p\u00b4 ags. 275\u2013286.\nPianta, Emanuele ,Luisa Bentivogli yChristian Gi-\nrardi (2002). ( (Multiwordnet: developing an aligned multilin-\ngual database ) ), enIn Proceedings of the First International Con-\nference on Global WordNet , Mysore (India).\nPradhan, Sameer ,Edward Loper ,Dmitriy Dligach y\nMartha Palmer (2007). ( (Semeval-2007 task-17: English lexi-\n264 BIBLIOGRAF \u00b4IA\ncal sample, srl and all words ) ), enProceedings of the Fourth In-\nternational Workshop on Semantic Evaluations (SemEval-2007) ,\np\u00b4 ags. 87\u201392, Association for Computational Linguistics, Prague,\nCzech Republic.\nPreiss, Judita yAnna Korhonen (2004). ( (Wsd for subca-\ntegorization acquisition task description ) ), en Rada Mihalcea y\nPhil Edmonds, editores, Senseval-3: Third International Works-\nhop on the Evaluation of Systems for the Semantic Analysis of\nText, p\u00b4 ags. 33\u201336, Association for Computational Linguistics,\nBarcelona, Spain.\nPustejovsky, James (1991). ( (The generative lexicon ) ),Com-\nputational Linguistics ,17(4), 409\u2013441.\nQuillian (1986). ( (Induction of decision trees. ) ), en Machine\nLearning , p\u00b4 ags. 81\u2013106.\nQuillian (1993). ( (C4.5. programs for machine learning ) ), en\nMorgan Kaufmann, editor, Machine Learning .\nQuinlan, Ross (1993). C4.5: Programs for Machine Learning ,\nMorgan Kaufmann.\nRada, R. ,H. Mili ,E. Bicknell yM. Blettner (1989).\n( (Development an Application of a Metric on Semantic Nets ) ),\nIEEE Transactions on Systems, Man and Cybernetics ,19(1),\n17\u201330.\nRamakrishnan, Ganesh ,B. Prithviraj yPushpak Bhat-\ntacharya (2004). ( (A gloss-centered algorithm for disambigua-\ntion) ), en Rada Mihalcea y Phil Edmonds, editores, Senseval-3:\nThird International Workshop on the Evaluation of Systems for\nthe Semantic Analysis of Text , p\u00b4 ags. 217\u2013221, Association for\nComputational Linguistics, Barcelona, Spain.\nRao, C. R. (1982). ( (Diversity: Its measurement, decomposition,\napportionment and analysis ) ), enSankya: The Indian Journal of\nStatistics , p\u00b4 ags. 1\u201322.\nRatnaparkhi, Adwait (1998). ( (Maximum entropy models for\nnatural language ambiguity resolution ) ), Tesis Doctoral. Univer-\nsidad de Pensilvania.\nRavin, Yael yClaudia Leacock (2001). ( (Polysemy theoreti-\ncal and computational approaches ) ), enOxford University Press .\nBIBLIOGRAF \u00b4IA 265\nRayson, P. yR. Garside (2000). ( (Comparing corpora using\nfrequency pro\ufb01ling. ) ), enIn proceedings of the workshop on Com-\nparing Corpora, held in conjunction with the 38th annual meeting\nof the Association for Computational Linguistics (ACL 2000) ,\np\u00b4 ags. 1\u20136.\nResnik, Philip (1993). Selection and Information: A Class-\nbased Approach to Lexical Relationships , Tesis Doctoral, Univer-\nsity of Pennsylvania.\nResnik, Philip (1995b). ( (Using information content to evaluate\nsemantic similarity in a taxonomy ) ), enProceedings of the 14th\nInternational Joint Conference on Arti\ufb01cial Intelligence , p\u00b4 ags.\n448\u2013453.\nRigau, German (1998). ( (Automatic acquisition of lexical\nknowledge from mrds ) ), Tesis Doctoral. Departamento de Len-\nguajes y Sistemas Inform\u00b4 aticos, Universidad Polit\u00b4 ecnica de Ca-\ntalu\u02dc na.\nRivest, Ronald (1987). ( (Learning decision lists ) ),Machine\nLearning ,2, 229\u2013246.\nRosso, Paolo ,Francesco Masulli ,Davide Buscaldi ,\nFerran Pla yAntonio Molina (2003). ( (Automatic noun\nsense disambiguation ) ), enCICLing , p\u00b4 ags. 273\u2013276.\nRosso, Paolo ,Antonio Molina ,Ferran Pla ,Daniel\nJim\u0013enez yVicente Vidal (2004). ( (Information retrieval and\ntext categorization with semantic indexing ) ), enCICLing , p\u00b4 ags.\n596\u2013600.\nRuge, Gerda (1992). ( (Experiments on linguistically-based\nterm associations ) ),Inf. Process. Manage. ,28(3), 317\u2013332.\nRus, Vasile (2004). ( (A \ufb01rst evaluation of logic form identi\ufb01-\ncation systems ) ), en Rada Mihalcea y Phil Edmonds, editores,\nSenseval-3: Third International Workshop on the Evaluation of\nSystems for the Semantic Analysis of Text , p\u00b4 ags. 37\u201340, Asso-\nciation for Computational Linguistics, Barcelona, Spain.\nRussell, Stuart J. yPeter Norvig (1995). ( (A modern,\nagent-oriented approach to introductory arti\ufb01cial intelligence ) ),\nSIGART Bulletin ,6(2), 24\u201326.\nS., Small (1980). ( (Word expert parsing: A theory of distributed\nword-based natural language understanding ) ), .\n266 BIBLIOGRAF \u00b4IA\nSanderson, M. (1994). ( (Word sense disambiguation and infor-\nmation retrieval ) ), enProceedings of the 17th Annual Internatio-\nnal ACM SIGIR Conference on Research and Development in\nInformation Retrieval , p\u00b4 ags. 142\u2013151.\nSch\u007futze, H. (1998). ( (Automatic word sense discrimination ) ),\nComputational Linguistics ,24(1), 97\u2013123.\nSch\u007futze, H. yJ. Pedersen (1995). ( (Information retrieval ba-\nsed on word senses ) ), enProceedings of 4th Annual Symposium on\nDocument Analysis and Information Retrieval , p\u00b4 ags. 161\u2013175.\nSmall, Steven yCharles Rieger (1982). Parsing and com-\nprehending with word experts (a theory and its realization) , p\u00b4 ags.\n89\u2013147, Lawrence Erlbaum and associates, Hillsdale, NJ, Wendy\nLenhert and Martin Ringle ed.\nSnyder, Benjamin yMartha Palmer (2004). ( (The english\nall-words task ) ), en Rada Mihalcea y Phil Edmonds, editores,\nSenseval-3: Third International Workshop on the Evaluation of\nSystems for the Semantic Analysis of Text , p\u00b4 ags. 41\u201343, Asso-\nciation for Computational Linguistics, Barcelona, Spain.\nStetina, J. ,S. Kurohashi yM.~Nagao (1998). ( (General\nword sense disambiguation method based on full sentencial con-\ntext) ), enProceedings of Usage of WordNet in Natural Language\nProcessing. COLING-ACL Workshop , Montreal, Canada.\nStevenson, Mark yYorick Wilks (2001). ( (The interaction\nof knowledge sources in word sense disambiguation. ) ),Computa-\ntional Linguistics ,27(3), 321\u2013349.\nStrapparava, Carlo ,Massimiliano Gliozzo yClaudio\nGiuliano (2004). ( (Pattern abstraction and term similarity for\nword sense disambiguation: Irst at senseval-3 ) ), en Senseval-3:\nThird International Workshop on the Evaluation of Systems for\nthe Semantic Analysis of Text , p\u00b4 ags. 229\u2013234, Association for\nComputational Linguistics.\nStrapparava, Carlo yRada Mihalcea (2007). ( (Semeval-\n2007 task 14: A\ufb00ective text ) ), enProceedings of the Fourth In-\nternational Workshop on Semantic Evaluations (SemEval-2007) ,\np\u00b4 ags. 70\u201374, Association for Computational Linguistics, Prague,\nCzech Republic.\nBIBLIOGRAF \u00b4IA 267\nSu\u0013arez, Armando yManuel Palomar (2002). ( (A maxi-\nmum entropy-based word sense disambiguation system ) ), enCO-\nLING .\nSu\u0013arez, Armando (2004). ( (Resoluci\u00b4 on de la ambig\u00a8 uedad\nsem\u00b4 antica de las palabras mediante modelos de probabilidad de\nm\u00b4 axima entrop\u00b4 \u0131a ) ), Tesis Doctoral. Departamento de Lenguajes\ny Sistemas Inform\u00b4 aticos, Universidad de Alicante.\nTowell, Geoffrey G. yEllen M. Voorhees (1998).\n( (Disambiguating highly ambiguous words ) ),Computational Lin-\nguistics ,24(1), 125\u2013145.\nTurney, Peter D. (2001). ( (Mining the web for synonyms:\nPmi-ir versus lsa on toe\ufb02 ) ), enECML , p\u00b4 ags. 491\u2013502.\nTurney, Peter D. (2004). ( (Human-level performance on\nword analogy questions by latent relational analysis ) ),CoRR ,\nabs/cs/0412024 .\nUlivieri, Marisa ,Elisabetta Guazzini ,Francesca Ber-\ntagna yNicoletta Calzolari (2004). ( (Senseval-3: The ita-\nlian all-words task ) ), en Rada Mihalcea y Phil Edmonds, editores,\nSenseval-3: Third International Workshop on the Evaluation of\nSystems for the Semantic Analysis of Text , Association for Com-\nputational Linguistics, Barcelona, Spain.\nValdivia, M. T. Mart \u0013\u0010n,Alfonso Ure ~na L \u0013opez yMa-\nnuel Garc \u0013\u0010a Vega (2002). ( (Resoluci\u00b4 on de la ambig\u00a8 uedad me-\ndiante redes neuronales ) ),Procesamiento del Lenguaje Natural ,\n29, 39\u201345.\nVapnik, Vladimir (1998). ( (Statistical learning theory ) ), enNew\nYork USA: John Wiley .\nVasilescu, Florentina ,Philippe Langlais yGuy Lapal-\nme(2004). ( (Evaluating variants of the Lesk approach for disam-\nbiguating words ) ),Proceedings of the Conference on language Re-\nsources and Evaluation (LREC) , p\u00b4 ags. 633\u2013636.\nV\u0013azquez, Sonia ,Zornitsa Kozareva yAndr \u0013es Montoyo\n(2006). ( (Textual entailment beyond semantic similarity informa-\ntion) ), enMICAI , p\u00b4 ags. 900\u2013910.\nV\u0013azquez, Sonia ,Andr \u0013es Montoyo yZornitsa Kozare-\nva(2007). ( (Word sense disambiguation using extended relevant\ndomains resource ) ), enIC-AI , p\u00b4 ags. 823\u2013828.\n268 BIBLIOGRAF \u00b4IA\nVega, Manuel Garc \u0013\u0010a,Mar\u0013\u0010a Teresa Mart \u0013\u0010n-Valdivia\nyLuis Alfonso Ure ~na(2003). ( (Aprendizaje competitivo LVQ\npara la desambiguaci\u00b4 on l\u00b4 exica ) ),Procesamiento del Lenguaje Na-\ntural,31, 125\u2013132.\nVerhagen, Marc ,Robert Gaizauskas ,Frank Schil-\nder,Mark Hepple ,Graham Katz yJames Pustejovsky\n(2007). ( (Semeval-2007 task 15: Tempeval temporal relation iden-\nti\ufb01cation ) ), enProceedings of the Fourth International Workshop\non Semantic Evaluations (SemEval-2007) , p\u00b4 ags. 75\u201380, Associa-\ntion for Computational Linguistics, Prague, Czech Republic.\nVeronis, Jean yNancy Ide (1990). ( (Word Sense Disambi-\nguation with very large neural networks extracted from machine\nreadable dictionaries ) ), enProceedings of the 13th International\nConference on Computational Linguistics, COLING\u00b490,volume\n2, p\u00b4 ags. 389\u2013394, Helsinki, Finland.\nVossen, P. (1998). ( (The Restructured Core WordNets in Eu-\ntoWordNet: Subset1. ) ), enDeliverable D014, D015, WP3, WP4 ,\nEuroWordNet LE2-4003.\nVossen, Piek ,German Rigau ,I~naki Alegr \u0013\u0010a,Ene-\nko Agirre ,David Farwell yManuel Fuentes (2006).\n( (Meaningful results for information retrieval in the MEANING\nproject ) ),Proceedings of the 3rd Global WordNet Conference .\nV\u0013azquez, Sonia ,Zornitsa Kozareva yAndr \u0013es Monto-\nyo(2007). ( (How context and semantic information can help a\nmachine learning system ) ), enMexican International Conferen-\nce on Arti\ufb01cial Intelligence , Lecture Notes in Computer Science,\np\u00b4 ags. 996\u20131003, Aguascalientes (Mexico).\nWiddows, Dominic yStanley Peters (2003). ( (Word vec-\ntors and quantum logic experiments with negation and disjunc-\ntion) ), en Proceedings of Mathematics of Language , p\u00b4 ags. 141\u2013\n154.\nWilks, Yorick (1972). ( (Grammar, meaning and the machine\nanalysis of language. ) ), enLondon:Routledge .\nWilks, Yorick yMark Stevenson (1998). ( (Word sense di-\nsambiguation using optimised combinations of knowledge sour-\nces) ), enCOLING-ACL , p\u00b4 ags. 1398\u20131402.\nBIBLIOGRAF \u00b4IA 269\nWitten, Ian H. yEibe Frank (1999). Data Mining: Practical\nMachine Learning Tools and Techniques with Java Implementa-\ntions, Morgan Kaufmann.\nYarowsky, David (1992). ( (Word sense disambiguation using\nstatistical models of Roget\u00b4s categories trained on large cor-\npora) ), en Proceedings of the 14th International Conference on\nComputational Linguistic, COLING\u00b492 , p\u00b4 ags. 454\u2013460, Nantes,\nFrance.\nYarowsky, David (1993). ( (One sense per collocation ) ), enPro-\nceedings of the DARPA Workshop on Human Language Techno-\nlogy, p\u00b4 ags. 266\u2013271, Princenton, NJ.\nYarowsky, David (1994a). ( (A comparison of corpus-based te-\nchniques for restoring accents in Spanish and French text ) ), en\nProceedings of the 2th Annual Workshop on Very Large Text Cor-\npora, p\u00b4 ags. 19\u201332.\nYarowsky, David (1994b). ( (Decision lists for lexical ambi-\nguity resolution: Application to accent restoration in Spanish\nand French ) ), enProceedings of the 32th Annual Meeting of the\nAssociation for Computational Linguistic , p\u00b4 ags. 88\u201395.\nYarowsky, David (1995). ( (Unsupervised word sense disambi-\nguation rivaling supervised methods ) ), enProceedings of the 33th\nAnnual Meeting of the Association for Computational Linguistic ,\np\u00b4 ags. 189\u2013196.\nYarowsky, David (1996). ( (Homograph disambiguation in\ntext-to-speech synthesis ) ), .\nYarowsky, David (2000a). ( (Hierarchical decision lists for word\nsense disambiguation ) ),Computers and the Humanities ,34, 1\u20132.\nYarowsky, David (2000b). ( (Hierarchical decision lists for word\nsense disambiguation ) ), enComputers and the Humanities , p\u00b4 ags.\n179\u2013186.\nYu, Clara ,John Cuadrado ,Maciej Ceglowski y\nJ. Scott Payne (2004). ( (Patterns in unstructured data, dis-\ncovery, aggregation and visualization ) ), en Presentation to the\nAndrew W. Mellon Foundation .\n270 BIBLIOGRAF \u00b4IA\nReunido el Tribunal que suscribe en el d\u00b4 \u0131a de la fecha acord\u00b4 o otor-\ngar, por\na la Tesis Doctoral de Don =Do\u02dc na. Sonia\nV\u00b4 azquez P\u00b4 erez la cali\ufb01caci\u00b4 on de\n.\nAlicante\nde\nde\nEl Secretario,\nEl Presidente,\nUNIVERSIDAD DE ALICANTE\nComisi\u00b4 on de Doctorado\nLa presente Tesis de D. Sonia V\u00b4 azquez P\u00b4 erez ha sido registra-\nda con el no\ndel registro de entrada correspondiente.\nAlicante\nde\nde\nEl Encargado del Registro,\nLa defensa de la tesis doctoral realizada por D =DaSonia\nV\u00b4 azquez P\u00b4 erez se ha realizado en las siguientes lenguas:\ny\n, lo que unido al cumplimiento del resto de requi-\nsitos establecidos en la Normativa propia de la UA le otorga la\nmenci\u00b4 on de \u201cDoctor Europeo\u201d.\nAlicante,\nde\nde\nEL SECRETARIO EL PRESIDENTE\n", "language": "PDF", "image": "PDF", "pagetype": "PDF", "links": "PDF"}